2021-08-08 03:34:23,642 | train | INFO | ===== Review Model Architecture =====
2021-08-08 03:34:23,665 | train | INFO | PoseHighResolutionNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (transition1): ModuleList(
    (0): Sequential(
      (0): Conv2d(256, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Sequential(
        (0): Conv2d(256, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (stage2): Sequential(
    (0): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (transition2): ModuleList(
    (0): None
    (1): None
    (2): Sequential(
      (0): Sequential(
        (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (stage3): Sequential(
    (0): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
        )
      )
      (relu): ReLU(inplace=True)
    )
    (1): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
        )
      )
      (relu): ReLU(inplace=True)
    )
    (3): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (transition3): ModuleList(
    (0): None
    (1): None
    (2): None
    (3): Sequential(
      (0): Sequential(
        (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (stage4): Sequential(
    (0): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
          (3): Sequential(
            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=8.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (3): Sequential(
            (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
          (3): Sequential(
            (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (3): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): Sequential(
              (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): None
        )
      )
      (relu): ReLU(inplace=True)
    )
    (1): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
          (3): Sequential(
            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=8.0, mode=nearest)
          )
        )
        (1): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): None
          (2): Sequential(
            (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (3): Sequential(
            (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
        )
        (2): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): None
          (3): Sequential(
            (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
        )
        (3): ModuleList(
          (0): Sequential(
            (0): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (2): Sequential(
              (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): Sequential(
              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
            (1): Sequential(
              (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): Sequential(
              (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): None
        )
      )
      (relu): ReLU(inplace=True)
    )
    (2): HighResolutionModule(
      (branches): ModuleList(
        (0): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((6, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(6, 48, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((12, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((24, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(24, 192, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): Sequential(
          (0): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): BasicBlock(
            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (PSA): PSA_s(
              (conv_q_right): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_v_right): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (conv_up): Sequential(
                (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
                (1): LayerNorm((48, 1, 1), eps=1e-05, elementwise_affine=True)
                (2): ReLU(inplace=True)
                (3): Conv2d(48, 384, kernel_size=(1, 1), stride=(1, 1))
              )
              (softmax_right): Softmax(dim=2)
              (sigmoid): Sigmoid()
              (conv_q_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (avg_pool): AdaptiveAvgPool2d(output_size=1)
              (conv_v_left): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (softmax_left): Softmax(dim=2)
            )
            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (fuse_layers): ModuleList(
        (0): ModuleList(
          (0): None
          (1): Sequential(
            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=2.0, mode=nearest)
          )
          (2): Sequential(
            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=4.0, mode=nearest)
          )
          (3): Sequential(
            (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): Upsample(scale_factor=8.0, mode=nearest)
          )
        )
      )
      (relu): ReLU(inplace=True)
    )
  )
  (final_layer): Conv2d(48, 17, kernel_size=(1, 1), stride=(1, 1))
) 

2021-08-08 03:34:28,470 | train | INFO | Epoch 0 train batch 0/450: 0/7200 mean loss: 0.0020138495601713657 score: 0.9921568627450981
2021-08-08 03:34:34,180 | train | INFO | Epoch 0 train batch 1/450: 16/7200 mean loss: 0.002006014110520482 score: 0.9963235294117647
2021-08-08 03:34:35,008 | train | INFO | Epoch 0 train batch 2/450: 32/7200 mean loss: 0.0020182786975055933 score: 0.7772058823529412
2021-08-08 03:34:35,813 | train | INFO | Epoch 0 train batch 3/450: 48/7200 mean loss: 0.0020224822219461203 score: 1.0
2021-08-08 03:34:36,609 | train | INFO | Epoch 0 train batch 4/450: 64/7200 mean loss: 0.0020013535395264626 score: 0.9349789915966387
2021-08-08 03:34:37,460 | train | INFO | Epoch 0 train batch 5/450: 80/7200 mean loss: 0.002003156114369631 score: 0.9742647058823529
2021-08-08 03:34:38,265 | train | INFO | Epoch 0 train batch 6/450: 96/7200 mean loss: 0.002010531723499298 score: 1.0
2021-08-08 03:34:39,111 | train | INFO | Epoch 0 train batch 7/450: 112/7200 mean loss: 0.002000883687287569 score: 0.9330532212885154
2021-08-08 03:34:39,990 | train | INFO | Epoch 0 train batch 8/450: 128/7200 mean loss: 0.0020055589266121387 score: 0.9573529411764705
2021-08-08 03:34:40,793 | train | INFO | Epoch 0 train batch 9/450: 144/7200 mean loss: 0.0019981006626039743 score: 0.9850490196078432
2021-08-08 03:34:41,616 | train | INFO | Epoch 0 train batch 10/450: 160/7200 mean loss: 0.002003295347094536 score: 0.996078431372549
2021-08-08 03:34:42,443 | train | INFO | Epoch 0 train batch 11/450: 176/7200 mean loss: 0.002023353474214673 score: 0.9411764705882353
2021-08-08 03:34:43,275 | train | INFO | Epoch 0 train batch 12/450: 192/7200 mean loss: 0.0020082092378288507 score: 0.9262254901960785
2021-08-08 03:34:44,069 | train | INFO | Epoch 0 train batch 13/450: 208/7200 mean loss: 0.0020188523922115564 score: 1.0
2021-08-08 03:34:44,859 | train | INFO | Epoch 0 train batch 14/450: 224/7200 mean loss: 0.002015722217038274 score: 0.9963235294117647
2021-08-08 03:34:45,688 | train | INFO | Epoch 0 train batch 15/450: 240/7200 mean loss: 0.0020038816146552563 score: 0.9779411764705882
2021-08-08 03:34:46,485 | train | INFO | Epoch 0 train batch 16/450: 256/7200 mean loss: 0.0019954389426857233 score: 0.9553921568627451
2021-08-08 03:34:47,284 | train | INFO | Epoch 0 train batch 17/450: 272/7200 mean loss: 0.002011603210121393 score: 1.0
2021-08-08 03:34:48,171 | train | INFO | Epoch 0 train batch 18/450: 288/7200 mean loss: 0.002007613657042384 score: 0.9924019607843138
2021-08-08 03:34:49,000 | train | INFO | Epoch 0 train batch 19/450: 304/7200 mean loss: 0.0020018815994262695 score: 1.0
2021-08-08 03:34:49,813 | train | INFO | Epoch 0 train batch 20/450: 320/7200 mean loss: 0.001999275991693139 score: 0.9850490196078432
2021-08-08 03:34:50,681 | train | INFO | Epoch 0 train batch 21/450: 336/7200 mean loss: 0.002007451606914401 score: 1.0
2021-08-08 03:34:51,495 | train | INFO | Epoch 0 train batch 22/450: 352/7200 mean loss: 0.002003864385187626 score: 0.9044117647058824
2021-08-08 03:34:52,339 | train | INFO | Epoch 0 train batch 23/450: 368/7200 mean loss: 0.0019978040363639593 score: 0.9096638655462185
2021-08-08 03:34:53,194 | train | INFO | Epoch 0 train batch 24/450: 384/7200 mean loss: 0.001988435862585902 score: 1.0
2021-08-08 03:34:53,996 | train | INFO | Epoch 0 train batch 25/450: 400/7200 mean loss: 0.0020053707994520664 score: 1.0
2021-08-08 03:34:54,820 | train | INFO | Epoch 0 train batch 26/450: 416/7200 mean loss: 0.0020046185236424208 score: 0.9926470588235294
2021-08-08 03:34:55,628 | train | INFO | Epoch 0 train batch 27/450: 432/7200 mean loss: 0.002005272312089801 score: 1.0
2021-08-08 03:34:56,432 | train | INFO | Epoch 0 train batch 28/450: 448/7200 mean loss: 0.002007736125960946 score: 0.9632352941176471
2021-08-08 03:34:57,228 | train | INFO | Epoch 0 train batch 29/450: 464/7200 mean loss: 0.0019960312638431787 score: 1.0
2021-08-08 03:34:58,043 | train | INFO | Epoch 0 train batch 30/450: 480/7200 mean loss: 0.0019908256363123655 score: 1.0
2021-08-08 03:34:58,839 | train | INFO | Epoch 0 train batch 31/450: 496/7200 mean loss: 0.001997588435187936 score: 1.0
2021-08-08 03:34:59,662 | train | INFO | Epoch 0 train batch 32/450: 512/7200 mean loss: 0.0019734154921025038 score: 1.0
2021-08-08 03:35:00,491 | train | INFO | Epoch 0 train batch 33/450: 528/7200 mean loss: 0.0020042129326611757 score: 0.9522058823529411
2021-08-08 03:35:01,311 | train | INFO | Epoch 0 train batch 34/450: 544/7200 mean loss: 0.002002342138439417 score: 0.6617647058823529
2021-08-08 03:35:02,161 | train | INFO | Epoch 0 train batch 35/450: 560/7200 mean loss: 0.0019875490106642246 score: 1.0
2021-08-08 03:35:02,958 | train | INFO | Epoch 0 train batch 36/450: 576/7200 mean loss: 0.001988285919651389 score: 0.9963235294117647
2021-08-08 03:35:03,760 | train | INFO | Epoch 0 train batch 37/450: 592/7200 mean loss: 0.0019801948219537735 score: 1.0
2021-08-08 03:35:04,601 | train | INFO | Epoch 0 train batch 38/450: 608/7200 mean loss: 0.0019850991666316986 score: 1.0
2021-08-08 03:35:05,424 | train | INFO | Epoch 0 train batch 39/450: 624/7200 mean loss: 0.0020035216584801674 score: 0.3247549019607843
2021-08-08 03:35:06,288 | train | INFO | Epoch 0 train batch 40/450: 640/7200 mean loss: 0.0019878544844686985 score: 0.9887254901960785
2021-08-08 03:35:07,138 | train | INFO | Epoch 0 train batch 41/450: 656/7200 mean loss: 0.0019697563257068396 score: 0.22034313725490196
2021-08-08 03:35:07,969 | train | INFO | Epoch 0 train batch 42/450: 672/7200 mean loss: 0.0019861937034875154 score: 0.7781512605042017
2021-08-08 03:35:08,805 | train | INFO | Epoch 0 train batch 43/450: 688/7200 mean loss: 0.0019815966952592134 score: 0.9924019607843138
2021-08-08 03:35:09,601 | train | INFO | Epoch 0 train batch 44/450: 704/7200 mean loss: 0.002001299522817135 score: 0.9889705882352942
2021-08-08 03:35:10,439 | train | INFO | Epoch 0 train batch 45/450: 720/7200 mean loss: 0.00197622855193913 score: 1.0
2021-08-08 03:35:11,293 | train | INFO | Epoch 0 train batch 46/450: 736/7200 mean loss: 0.0019852553959935904 score: 1.0
2021-08-08 03:35:12,088 | train | INFO | Epoch 0 train batch 47/450: 752/7200 mean loss: 0.0019733814988285303 score: 1.0
2021-08-08 03:35:12,926 | train | INFO | Epoch 0 train batch 48/450: 768/7200 mean loss: 0.0020001051016151905 score: 0.9669117647058824
2021-08-08 03:35:13,853 | train | INFO | Epoch 0 train batch 49/450: 784/7200 mean loss: 0.0019782190211117268 score: 1.0
2021-08-08 03:35:14,682 | train | INFO | Epoch 0 train batch 50/450: 800/7200 mean loss: 0.001977478852495551 score: 1.0
2021-08-08 03:35:15,507 | train | INFO | Epoch 0 train batch 51/450: 816/7200 mean loss: 0.0019979169592261314 score: 0.9593137254901961
2021-08-08 03:35:16,328 | train | INFO | Epoch 0 train batch 52/450: 832/7200 mean loss: 0.001966838724911213 score: 1.0
2021-08-08 03:35:17,149 | train | INFO | Epoch 0 train batch 53/450: 848/7200 mean loss: 0.0019851268734782934 score: 0.9889705882352942
2021-08-08 03:35:17,951 | train | INFO | Epoch 0 train batch 54/450: 864/7200 mean loss: 0.0019886696245521307 score: 1.0
2021-08-08 03:35:18,771 | train | INFO | Epoch 0 train batch 55/450: 880/7200 mean loss: 0.0019850251264870167 score: 1.0
2021-08-08 03:35:19,659 | train | INFO | Epoch 0 train batch 56/450: 896/7200 mean loss: 0.0019957360345870256 score: 1.0
2021-08-08 03:35:20,523 | train | INFO | Epoch 0 train batch 57/450: 912/7200 mean loss: 0.001986589515581727 score: 1.0
2021-08-08 03:35:21,314 | train | INFO | Epoch 0 train batch 58/450: 928/7200 mean loss: 0.001987280324101448 score: 0.9666666666666667
2021-08-08 03:35:22,172 | train | INFO | Epoch 0 train batch 59/450: 944/7200 mean loss: 0.0019792711827903986 score: 1.0
2021-08-08 03:35:22,986 | train | INFO | Epoch 0 train batch 60/450: 960/7200 mean loss: 0.001980670727789402 score: 1.0
2021-08-08 03:35:23,818 | train | INFO | Epoch 0 train batch 61/450: 976/7200 mean loss: 0.0019857457373291254 score: 0.9926470588235294
2021-08-08 03:35:24,611 | train | INFO | Epoch 0 train batch 62/450: 992/7200 mean loss: 0.001984108705073595 score: 1.0
2021-08-08 03:35:25,453 | train | INFO | Epoch 0 train batch 63/450: 1008/7200 mean loss: 0.0019954887684434652 score: 0.9776960784313725
2021-08-08 03:35:26,313 | train | INFO | Epoch 0 train batch 64/450: 1024/7200 mean loss: 0.0019765752367675304 score: 1.0
2021-08-08 03:35:27,165 | train | INFO | Epoch 0 train batch 65/450: 1040/7200 mean loss: 0.0019833554979413748 score: 1.0
2021-08-08 03:35:28,006 | train | INFO | Epoch 0 train batch 66/450: 1056/7200 mean loss: 0.001994678983464837 score: 0.9884803921568628
2021-08-08 03:35:28,821 | train | INFO | Epoch 0 train batch 67/450: 1072/7200 mean loss: 0.001975965453311801 score: 0.9926470588235294
2021-08-08 03:35:29,699 | train | INFO | Epoch 0 train batch 68/450: 1088/7200 mean loss: 0.0019785526674240828 score: 0.9963235294117647
2021-08-08 03:35:30,536 | train | INFO | Epoch 0 train batch 69/450: 1104/7200 mean loss: 0.0019891744013875723 score: 0.8272058823529411
2021-08-08 03:35:31,380 | train | INFO | Epoch 0 train batch 70/450: 1120/7200 mean loss: 0.001986691728234291 score: 1.0
2021-08-08 03:35:32,198 | train | INFO | Epoch 0 train batch 71/450: 1136/7200 mean loss: 0.001959716435521841 score: 0.9154411764705882
2021-08-08 03:35:32,999 | train | INFO | Epoch 0 train batch 72/450: 1152/7200 mean loss: 0.001976640662178397 score: 1.0
2021-08-08 03:35:33,799 | train | INFO | Epoch 0 train batch 73/450: 1168/7200 mean loss: 0.0019764250610023737 score: 1.0
2021-08-08 03:35:34,595 | train | INFO | Epoch 0 train batch 74/450: 1184/7200 mean loss: 0.0019854423590004444 score: 0.9889705882352942
2021-08-08 03:35:35,444 | train | INFO | Epoch 0 train batch 75/450: 1200/7200 mean loss: 0.0019702063873410225 score: 1.0
2021-08-08 03:35:36,238 | train | INFO | Epoch 0 train batch 76/450: 1216/7200 mean loss: 0.0019718941766768694 score: 1.0
2021-08-08 03:35:37,052 | train | INFO | Epoch 0 train batch 77/450: 1232/7200 mean loss: 0.001976905856281519 score: 1.0
2021-08-08 03:35:37,877 | train | INFO | Epoch 0 train batch 78/450: 1248/7200 mean loss: 0.0019789538346230984 score: 0.9921218487394957
2021-08-08 03:35:38,682 | train | INFO | Epoch 0 train batch 79/450: 1264/7200 mean loss: 0.001986155519261956 score: 1.0
2021-08-08 03:35:39,495 | train | INFO | Epoch 0 train batch 80/450: 1280/7200 mean loss: 0.0019860239699482918 score: 1.0
2021-08-08 03:35:40,303 | train | INFO | Epoch 0 train batch 81/450: 1296/7200 mean loss: 0.0019809810910373926 score: 1.0
2021-08-08 03:35:41,120 | train | INFO | Epoch 0 train batch 82/450: 1312/7200 mean loss: 0.001991081750020385 score: 0.9816176470588235
2021-08-08 03:35:41,924 | train | INFO | Epoch 0 train batch 83/450: 1328/7200 mean loss: 0.0019839792512357235 score: 1.0
2021-08-08 03:35:42,724 | train | INFO | Epoch 0 train batch 84/450: 1344/7200 mean loss: 0.0019783375319093466 score: 1.0
2021-08-08 03:35:43,632 | train | INFO | Epoch 0 train batch 85/450: 1360/7200 mean loss: 0.0019851981196552515 score: 1.0
2021-08-08 03:35:44,503 | train | INFO | Epoch 0 train batch 86/450: 1376/7200 mean loss: 0.001973060192540288 score: 1.0
2021-08-08 03:35:45,365 | train | INFO | Epoch 0 train batch 87/450: 1392/7200 mean loss: 0.001972635043784976 score: 0.9924019607843138
2021-08-08 03:35:46,158 | train | INFO | Epoch 0 train batch 88/450: 1408/7200 mean loss: 0.0019794392865151167 score: 0.6098739495798319
2021-08-08 03:35:46,982 | train | INFO | Epoch 0 train batch 89/450: 1424/7200 mean loss: 0.0019810337107628584 score: 0.8860294117647058
2021-08-08 03:35:47,815 | train | INFO | Epoch 0 train batch 90/450: 1440/7200 mean loss: 0.0019730732310563326 score: 0.9963235294117647
2021-08-08 03:35:48,624 | train | INFO | Epoch 0 train batch 91/450: 1456/7200 mean loss: 0.00197928911074996 score: 1.0
2021-08-08 03:35:49,441 | train | INFO | Epoch 0 train batch 92/450: 1472/7200 mean loss: 0.001978834392502904 score: 0.9776960784313725
2021-08-08 03:35:50,257 | train | INFO | Epoch 0 train batch 93/450: 1488/7200 mean loss: 0.0019680727273225784 score: 0.9963235294117647
2021-08-08 03:35:51,038 | train | INFO | Epoch 0 train batch 94/450: 1504/7200 mean loss: 0.0019776690751314163 score: 0.9924019607843138
2021-08-08 03:35:51,847 | train | INFO | Epoch 0 train batch 95/450: 1520/7200 mean loss: 0.0019692732021212578 score: 0.9394257703081232
2021-08-08 03:35:52,646 | train | INFO | Epoch 0 train batch 96/450: 1536/7200 mean loss: 0.0019816167186945677 score: 1.0
2021-08-08 03:35:53,466 | train | INFO | Epoch 0 train batch 97/450: 1552/7200 mean loss: 0.001966979121789336 score: 1.0
2021-08-08 03:35:54,278 | train | INFO | Epoch 0 train batch 98/450: 1568/7200 mean loss: 0.0019621571991592646 score: 1.0
2021-08-08 03:35:55,151 | train | INFO | Epoch 0 train batch 99/450: 1584/7200 mean loss: 0.001973293721675873 score: 0.9658182503770739
2021-08-08 03:35:55,950 | train | INFO | Epoch 0 train batch 100/450: 1600/7200 mean loss: 0.001957954140380025 score: 1.0
2021-08-08 03:35:56,815 | train | INFO | Epoch 0 train batch 101/450: 1616/7200 mean loss: 0.001978716580197215 score: 1.0
2021-08-08 03:35:57,612 | train | INFO | Epoch 0 train batch 102/450: 1632/7200 mean loss: 0.001979211112484336 score: 0.996078431372549
2021-08-08 03:35:58,409 | train | INFO | Epoch 0 train batch 103/450: 1648/7200 mean loss: 0.0019576256163418293 score: 0.9512254901960785
2021-08-08 03:35:59,250 | train | INFO | Epoch 0 train batch 104/450: 1664/7200 mean loss: 0.0019636142533272505 score: 1.0
2021-08-08 03:36:00,060 | train | INFO | Epoch 0 train batch 105/450: 1680/7200 mean loss: 0.00196560169570148 score: 1.0
2021-08-08 03:36:00,888 | train | INFO | Epoch 0 train batch 106/450: 1696/7200 mean loss: 0.001975889317691326 score: 1.0
2021-08-08 03:36:01,687 | train | INFO | Epoch 0 train batch 107/450: 1712/7200 mean loss: 0.0019849571399390697 score: 1.0
2021-08-08 03:36:02,511 | train | INFO | Epoch 0 train batch 108/450: 1728/7200 mean loss: 0.001962523441761732 score: 1.0
2021-08-08 03:36:03,345 | train | INFO | Epoch 0 train batch 109/450: 1744/7200 mean loss: 0.0019590763840824366 score: 0.9887254901960785
2021-08-08 03:36:04,214 | train | INFO | Epoch 0 train batch 110/450: 1760/7200 mean loss: 0.001962426118552685 score: 1.0
2021-08-08 03:36:05,011 | train | INFO | Epoch 0 train batch 111/450: 1776/7200 mean loss: 0.0019752024672925472 score: 1.0
2021-08-08 03:36:05,847 | train | INFO | Epoch 0 train batch 112/450: 1792/7200 mean loss: 0.0019652440678328276 score: 0.9889705882352942
2021-08-08 03:36:06,633 | train | INFO | Epoch 0 train batch 113/450: 1808/7200 mean loss: 0.001969357021152973 score: 1.0
2021-08-08 03:36:07,428 | train | INFO | Epoch 0 train batch 114/450: 1824/7200 mean loss: 0.001963468501344323 score: 0.9963235294117647
2021-08-08 03:36:08,228 | train | INFO | Epoch 0 train batch 115/450: 1840/7200 mean loss: 0.001979759894311428 score: 1.0
2021-08-08 03:36:09,014 | train | INFO | Epoch 0 train batch 116/450: 1856/7200 mean loss: 0.0019761936273425817 score: 1.0
2021-08-08 03:36:09,932 | train | INFO | Epoch 0 train batch 117/450: 1872/7200 mean loss: 0.001959798391908407 score: 1.0
2021-08-08 03:36:10,775 | train | INFO | Epoch 0 train batch 118/450: 1888/7200 mean loss: 0.00195879815146327 score: 1.0
2021-08-08 03:36:11,577 | train | INFO | Epoch 0 train batch 119/450: 1904/7200 mean loss: 0.0019635609351098537 score: 0.9963235294117647
2021-08-08 03:36:12,358 | train | INFO | Epoch 0 train batch 120/450: 1920/7200 mean loss: 0.001970292069017887 score: 0.9740196078431372
2021-08-08 03:36:13,173 | train | INFO | Epoch 0 train batch 121/450: 1936/7200 mean loss: 0.00196678820066154 score: 0.9921568627450981
2021-08-08 03:36:14,023 | train | INFO | Epoch 0 train batch 122/450: 1952/7200 mean loss: 0.0019647865556180477 score: 0.9556372549019608
2021-08-08 03:36:14,809 | train | INFO | Epoch 0 train batch 123/450: 1968/7200 mean loss: 0.0019758546259254217 score: 0.996078431372549
2021-08-08 03:36:15,595 | train | INFO | Epoch 0 train batch 124/450: 1984/7200 mean loss: 0.0019565641414374113 score: 0.9740196078431372
2021-08-08 03:36:16,391 | train | INFO | Epoch 0 train batch 125/450: 2000/7200 mean loss: 0.0019669407047331333 score: 0.6107843137254901
2021-08-08 03:36:17,169 | train | INFO | Epoch 0 train batch 126/450: 2016/7200 mean loss: 0.0019691509660333395 score: 0.9926470588235294
2021-08-08 03:36:17,969 | train | INFO | Epoch 0 train batch 127/450: 2032/7200 mean loss: 0.0019728331826627254 score: 0.9742647058823529
2021-08-08 03:36:18,758 | train | INFO | Epoch 0 train batch 128/450: 2048/7200 mean loss: 0.00194819294847548 score: 1.0
2021-08-08 03:36:19,587 | train | INFO | Epoch 0 train batch 129/450: 2064/7200 mean loss: 0.0019554891623556614 score: 1.0
2021-08-08 03:36:20,407 | train | INFO | Epoch 0 train batch 130/450: 2080/7200 mean loss: 0.001966445241123438 score: 1.0
2021-08-08 03:36:21,229 | train | INFO | Epoch 0 train batch 131/450: 2096/7200 mean loss: 0.0019751659128814936 score: 0.40808823529411764
2021-08-08 03:36:22,020 | train | INFO | Epoch 0 train batch 132/450: 2112/7200 mean loss: 0.0019491888815537095 score: 1.0
2021-08-08 03:36:22,822 | train | INFO | Epoch 0 train batch 133/450: 2128/7200 mean loss: 0.001970896730199456 score: 1.0
2021-08-08 03:36:23,658 | train | INFO | Epoch 0 train batch 134/450: 2144/7200 mean loss: 0.001962602138519287 score: 1.0
2021-08-08 03:36:24,491 | train | INFO | Epoch 0 train batch 135/450: 2160/7200 mean loss: 0.001965216128155589 score: 1.0
2021-08-08 03:36:25,319 | train | INFO | Epoch 0 train batch 136/450: 2176/7200 mean loss: 0.001969108358025551 score: 1.0
2021-08-08 03:36:26,117 | train | INFO | Epoch 0 train batch 137/450: 2192/7200 mean loss: 0.001951211248524487 score: 0.9850490196078432
2021-08-08 03:36:26,941 | train | INFO | Epoch 0 train batch 138/450: 2208/7200 mean loss: 0.0019731714855879545 score: 0.996078431372549
2021-08-08 03:36:27,778 | train | INFO | Epoch 0 train batch 139/450: 2224/7200 mean loss: 0.001966214505955577 score: 1.0
2021-08-08 03:36:28,609 | train | INFO | Epoch 0 train batch 140/450: 2240/7200 mean loss: 0.001959871966391802 score: 0.8700980392156863
2021-08-08 03:36:29,402 | train | INFO | Epoch 0 train batch 141/450: 2256/7200 mean loss: 0.0019042270723730326 score: 1.0
2021-08-08 03:36:30,216 | train | INFO | Epoch 0 train batch 142/450: 2272/7200 mean loss: 0.0019466124940663576 score: 1.0
2021-08-08 03:36:31,014 | train | INFO | Epoch 0 train batch 143/450: 2288/7200 mean loss: 0.0019697099924087524 score: 1.0
2021-08-08 03:36:31,805 | train | INFO | Epoch 0 train batch 144/450: 2304/7200 mean loss: 0.0019613082986325026 score: 1.0
2021-08-08 03:36:32,605 | train | INFO | Epoch 0 train batch 145/450: 2320/7200 mean loss: 0.0019542390946298838 score: 1.0
2021-08-08 03:36:33,398 | train | INFO | Epoch 0 train batch 146/450: 2336/7200 mean loss: 0.0019629672169685364 score: 1.0
2021-08-08 03:36:34,281 | train | INFO | Epoch 0 train batch 147/450: 2352/7200 mean loss: 0.0019566293340176344 score: 1.0
2021-08-08 03:36:35,068 | train | INFO | Epoch 0 train batch 148/450: 2368/7200 mean loss: 0.0019581804517656565 score: 1.0
2021-08-08 03:36:35,911 | train | INFO | Epoch 0 train batch 149/450: 2384/7200 mean loss: 0.001955462619662285 score: 0.9926470588235294
2021-08-08 03:36:36,718 | train | INFO | Epoch 0 train batch 150/450: 2400/7200 mean loss: 0.0019633283372968435 score: 0.9779411764705882
2021-08-08 03:36:37,556 | train | INFO | Epoch 0 train batch 151/450: 2416/7200 mean loss: 0.0019484750228002667 score: 1.0
2021-08-08 03:36:38,360 | train | INFO | Epoch 0 train batch 152/450: 2432/7200 mean loss: 0.0019553890451788902 score: 1.0
2021-08-08 03:36:39,191 | train | INFO | Epoch 0 train batch 153/450: 2448/7200 mean loss: 0.0019500995986163616 score: 1.0
2021-08-08 03:36:40,011 | train | INFO | Epoch 0 train batch 154/450: 2464/7200 mean loss: 0.0019299896666780114 score: 1.0
2021-08-08 03:36:40,900 | train | INFO | Epoch 0 train batch 155/450: 2480/7200 mean loss: 0.0019450424006208777 score: 1.0
2021-08-08 03:36:41,742 | train | INFO | Epoch 0 train batch 156/450: 2496/7200 mean loss: 0.0019263682188466191 score: 1.0
2021-08-08 03:36:42,550 | train | INFO | Epoch 0 train batch 157/450: 2512/7200 mean loss: 0.0019652070477604866 score: 1.0
2021-08-08 03:36:43,334 | train | INFO | Epoch 0 train batch 158/450: 2528/7200 mean loss: 0.001971988473087549 score: 0.9887254901960785
2021-08-08 03:36:44,186 | train | INFO | Epoch 0 train batch 159/450: 2544/7200 mean loss: 0.001936292857863009 score: 0.9779411764705882
2021-08-08 03:36:45,012 | train | INFO | Epoch 0 train batch 160/450: 2560/7200 mean loss: 0.0019504271913319826 score: 1.0
2021-08-08 03:36:45,838 | train | INFO | Epoch 0 train batch 161/450: 2576/7200 mean loss: 0.0019307333277538419 score: 0.9926470588235294
2021-08-08 03:36:46,652 | train | INFO | Epoch 0 train batch 162/450: 2592/7200 mean loss: 0.001964119030162692 score: 1.0
2021-08-08 03:36:47,481 | train | INFO | Epoch 0 train batch 163/450: 2608/7200 mean loss: 0.001966167241334915 score: 1.0
2021-08-08 03:36:48,274 | train | INFO | Epoch 0 train batch 164/450: 2624/7200 mean loss: 0.001944556599482894 score: 1.0
2021-08-08 03:36:49,066 | train | INFO | Epoch 0 train batch 165/450: 2640/7200 mean loss: 0.001962590729817748 score: 1.0
2021-08-08 03:36:49,890 | train | INFO | Epoch 0 train batch 166/450: 2656/7200 mean loss: 0.0019582314416766167 score: 1.0
2021-08-08 03:36:50,702 | train | INFO | Epoch 0 train batch 167/450: 2672/7200 mean loss: 0.0019403343321755528 score: 0.9926470588235294
2021-08-08 03:36:51,643 | train | INFO | Epoch 0 train batch 168/450: 2688/7200 mean loss: 0.001965215662494302 score: 0.9889705882352942
2021-08-08 03:36:52,445 | train | INFO | Epoch 0 train batch 169/450: 2704/7200 mean loss: 0.0019517146283760667 score: 0.9519607843137255
2021-08-08 03:36:53,262 | train | INFO | Epoch 0 train batch 170/450: 2720/7200 mean loss: 0.001964231953024864 score: 0.9742647058823529
2021-08-08 03:36:54,070 | train | INFO | Epoch 0 train batch 171/450: 2736/7200 mean loss: 0.001932673156261444 score: 0.9957983193277312
2021-08-08 03:36:54,912 | train | INFO | Epoch 0 train batch 172/450: 2752/7200 mean loss: 0.001933328341692686 score: 1.0
2021-08-08 03:36:55,706 | train | INFO | Epoch 0 train batch 173/450: 2768/7200 mean loss: 0.0019523431546986103 score: 1.0
2021-08-08 03:36:56,526 | train | INFO | Epoch 0 train batch 174/450: 2784/7200 mean loss: 0.0019490736303851008 score: 1.0
2021-08-08 03:36:57,336 | train | INFO | Epoch 0 train batch 175/450: 2800/7200 mean loss: 0.001968148397281766 score: 1.0
2021-08-08 03:36:58,154 | train | INFO | Epoch 0 train batch 176/450: 2816/7200 mean loss: 0.0019520418718457222 score: 0.9926470588235294
2021-08-08 03:36:58,961 | train | INFO | Epoch 0 train batch 177/450: 2832/7200 mean loss: 0.0019464672077447176 score: 1.0
2021-08-08 03:36:59,785 | train | INFO | Epoch 0 train batch 178/450: 2848/7200 mean loss: 0.0019520334899425507 score: 1.0
2021-08-08 03:37:00,635 | train | INFO | Epoch 0 train batch 179/450: 2864/7200 mean loss: 0.0019588617142289877 score: 1.0
2021-08-08 03:37:01,519 | train | INFO | Epoch 0 train batch 180/450: 2880/7200 mean loss: 0.0019553673919290304 score: 1.0
2021-08-08 03:37:02,367 | train | INFO | Epoch 0 train batch 181/450: 2896/7200 mean loss: 0.0019504802767187357 score: 1.0
2021-08-08 03:37:03,153 | train | INFO | Epoch 0 train batch 182/450: 2912/7200 mean loss: 0.0019416651921346784 score: 1.0
2021-08-08 03:37:03,973 | train | INFO | Epoch 0 train batch 183/450: 2928/7200 mean loss: 0.001937582273967564 score: 0.9887254901960785
2021-08-08 03:37:04,761 | train | INFO | Epoch 0 train batch 184/450: 2944/7200 mean loss: 0.0019333752570673823 score: 1.0
2021-08-08 03:37:05,591 | train | INFO | Epoch 0 train batch 185/450: 2960/7200 mean loss: 0.0019494816660881042 score: 1.0
2021-08-08 03:37:06,409 | train | INFO | Epoch 0 train batch 186/450: 2976/7200 mean loss: 0.0019443968776613474 score: 0.9889705882352942
2021-08-08 03:37:07,205 | train | INFO | Epoch 0 train batch 187/450: 2992/7200 mean loss: 0.001951279235072434 score: 1.0
2021-08-08 03:37:08,003 | train | INFO | Epoch 0 train batch 188/450: 3008/7200 mean loss: 0.001936160959303379 score: 1.0
2021-08-08 03:37:08,820 | train | INFO | Epoch 0 train batch 189/450: 3024/7200 mean loss: 0.0019426281796768308 score: 0.9669117647058824
2021-08-08 03:37:09,635 | train | INFO | Epoch 0 train batch 190/450: 3040/7200 mean loss: 0.0019522872753441334 score: 0.9889705882352942
2021-08-08 03:37:10,427 | train | INFO | Epoch 0 train batch 191/450: 3056/7200 mean loss: 0.0019484800286591053 score: 0.9963235294117647
2021-08-08 03:37:11,241 | train | INFO | Epoch 0 train batch 192/450: 3072/7200 mean loss: 0.0019634293857961893 score: 1.0
2021-08-08 03:37:12,065 | train | INFO | Epoch 0 train batch 193/450: 3088/7200 mean loss: 0.0019572614692151546 score: 1.0
2021-08-08 03:37:12,891 | train | INFO | Epoch 0 train batch 194/450: 3104/7200 mean loss: 0.0019430344691500068 score: 0.9963235294117647
2021-08-08 03:37:13,737 | train | INFO | Epoch 0 train batch 195/450: 3120/7200 mean loss: 0.001967685529962182 score: 1.0
2021-08-08 03:37:14,536 | train | INFO | Epoch 0 train batch 196/450: 3136/7200 mean loss: 0.0019526411779224873 score: 1.0
2021-08-08 03:37:15,352 | train | INFO | Epoch 0 train batch 197/450: 3152/7200 mean loss: 0.001956478925421834 score: 1.0
2021-08-08 03:37:16,176 | train | INFO | Epoch 0 train batch 198/450: 3168/7200 mean loss: 0.0019444053759798408 score: 1.0
2021-08-08 03:37:16,957 | train | INFO | Epoch 0 train batch 199/450: 3184/7200 mean loss: 0.0019536176696419716 score: 1.0
2021-08-08 03:37:17,758 | train | INFO | Epoch 0 train batch 200/450: 3200/7200 mean loss: 0.0019452976994216442 score: 0.8217787114845938
2021-08-08 03:37:18,552 | train | INFO | Epoch 0 train batch 201/450: 3216/7200 mean loss: 0.001938901375979185 score: 1.0
2021-08-08 03:37:19,366 | train | INFO | Epoch 0 train batch 202/450: 3232/7200 mean loss: 0.001962294802069664 score: 1.0
2021-08-08 03:37:20,163 | train | INFO | Epoch 0 train batch 203/450: 3248/7200 mean loss: 0.0019398813601583242 score: 1.0
2021-08-08 03:37:20,951 | train | INFO | Epoch 0 train batch 204/450: 3264/7200 mean loss: 0.0019389447988942266 score: 1.0
2021-08-08 03:37:21,780 | train | INFO | Epoch 0 train batch 205/450: 3280/7200 mean loss: 0.0019245572621002793 score: 1.0
2021-08-08 03:37:22,593 | train | INFO | Epoch 0 train batch 206/450: 3296/7200 mean loss: 0.0019341438310220838 score: 1.0
2021-08-08 03:37:23,401 | train | INFO | Epoch 0 train batch 207/450: 3312/7200 mean loss: 0.0019470254192128778 score: 1.0
2021-08-08 03:37:24,220 | train | INFO | Epoch 0 train batch 208/450: 3328/7200 mean loss: 0.0019292905926704407 score: 0.9963235294117647
2021-08-08 03:37:25,043 | train | INFO | Epoch 0 train batch 209/450: 3344/7200 mean loss: 0.001926719443872571 score: 1.0
2021-08-08 03:37:25,826 | train | INFO | Epoch 0 train batch 210/450: 3360/7200 mean loss: 0.0019409834640100598 score: 0.9889705882352942
2021-08-08 03:37:26,660 | train | INFO | Epoch 0 train batch 211/450: 3376/7200 mean loss: 0.0019454745342954993 score: 1.0
2021-08-08 03:37:27,499 | train | INFO | Epoch 0 train batch 212/450: 3392/7200 mean loss: 0.001939737587235868 score: 1.0
2021-08-08 03:37:28,326 | train | INFO | Epoch 0 train batch 213/450: 3408/7200 mean loss: 0.0019501233473420143 score: 1.0
2021-08-08 03:37:29,134 | train | INFO | Epoch 0 train batch 214/450: 3424/7200 mean loss: 0.0019234436331316829 score: 1.0
2021-08-08 03:37:29,926 | train | INFO | Epoch 0 train batch 215/450: 3440/7200 mean loss: 0.0019470937550067902 score: 1.0
2021-08-08 03:37:30,718 | train | INFO | Epoch 0 train batch 216/450: 3456/7200 mean loss: 0.0019433038542047143 score: 1.0
2021-08-08 03:37:31,530 | train | INFO | Epoch 0 train batch 217/450: 3472/7200 mean loss: 0.0019501904025673866 score: 1.0
2021-08-08 03:37:32,320 | train | INFO | Epoch 0 train batch 218/450: 3488/7200 mean loss: 0.0019329634960740805 score: 1.0
2021-08-08 03:37:33,119 | train | INFO | Epoch 0 train batch 219/450: 3504/7200 mean loss: 0.0019393942784518003 score: 1.0
2021-08-08 03:37:33,976 | train | INFO | Epoch 0 train batch 220/450: 3520/7200 mean loss: 0.0019270124612376094 score: 1.0
2021-08-08 03:37:34,799 | train | INFO | Epoch 0 train batch 221/450: 3536/7200 mean loss: 0.0019445721991360188 score: 0.9852941176470589
2021-08-08 03:37:35,622 | train | INFO | Epoch 0 train batch 222/450: 3552/7200 mean loss: 0.0019348725909367204 score: 1.0
2021-08-08 03:37:36,416 | train | INFO | Epoch 0 train batch 223/450: 3568/7200 mean loss: 0.001962509239092469 score: 0.9926470588235294
2021-08-08 03:37:37,247 | train | INFO | Epoch 0 train batch 224/450: 3584/7200 mean loss: 0.0019468535901978612 score: 1.0
2021-08-08 03:37:38,056 | train | INFO | Epoch 0 train batch 225/450: 3600/7200 mean loss: 0.001930301426909864 score: 0.9852941176470589
2021-08-08 03:37:38,842 | train | INFO | Epoch 0 train batch 226/450: 3616/7200 mean loss: 0.0019170447485521436 score: 1.0
2021-08-08 03:37:39,694 | train | INFO | Epoch 0 train batch 227/450: 3632/7200 mean loss: 0.001935847569257021 score: 1.0
2021-08-08 03:37:40,511 | train | INFO | Epoch 0 train batch 228/450: 3648/7200 mean loss: 0.001942442380823195 score: 0.9963235294117647
2021-08-08 03:37:41,306 | train | INFO | Epoch 0 train batch 229/450: 3664/7200 mean loss: 0.0019415406277403235 score: 1.0
2021-08-08 03:37:42,138 | train | INFO | Epoch 0 train batch 230/450: 3680/7200 mean loss: 0.0019251209450885653 score: 0.9963235294117647
2021-08-08 03:37:42,953 | train | INFO | Epoch 0 train batch 231/450: 3696/7200 mean loss: 0.0019402955658733845 score: 1.0
2021-08-08 03:37:43,742 | train | INFO | Epoch 0 train batch 232/450: 3712/7200 mean loss: 0.001935628242790699 score: 0.9963235294117647
2021-08-08 03:37:44,571 | train | INFO | Epoch 0 train batch 233/450: 3728/7200 mean loss: 0.0018973280675709248 score: 1.0
2021-08-08 03:37:45,360 | train | INFO | Epoch 0 train batch 234/450: 3744/7200 mean loss: 0.0019243421265855432 score: 1.0
2021-08-08 03:37:46,191 | train | INFO | Epoch 0 train batch 235/450: 3760/7200 mean loss: 0.0019422927871346474 score: 1.0
2021-08-08 03:37:47,049 | train | INFO | Epoch 0 train batch 236/450: 3776/7200 mean loss: 0.001934478641487658 score: 1.0
2021-08-08 03:37:47,863 | train | INFO | Epoch 0 train batch 237/450: 3792/7200 mean loss: 0.0019741153810173273 score: 1.0
2021-08-08 03:37:48,642 | train | INFO | Epoch 0 train batch 238/450: 3808/7200 mean loss: 0.0019531354773789644 score: 1.0
2021-08-08 03:37:49,464 | train | INFO | Epoch 0 train batch 239/450: 3824/7200 mean loss: 0.001923399860970676 score: 1.0
2021-08-08 03:37:50,293 | train | INFO | Epoch 0 train batch 240/450: 3840/7200 mean loss: 0.001938146073371172 score: 1.0
2021-08-08 03:37:51,113 | train | INFO | Epoch 0 train batch 241/450: 3856/7200 mean loss: 0.0019114324823021889 score: 0.9926470588235294
2021-08-08 03:37:51,898 | train | INFO | Epoch 0 train batch 242/450: 3872/7200 mean loss: 0.0019352390663698316 score: 0.9926470588235294
2021-08-08 03:37:52,722 | train | INFO | Epoch 0 train batch 243/450: 3888/7200 mean loss: 0.0019231820479035378 score: 1.0
2021-08-08 03:37:53,504 | train | INFO | Epoch 0 train batch 244/450: 3904/7200 mean loss: 0.0019476542947813869 score: 1.0
2021-08-08 03:37:54,306 | train | INFO | Epoch 0 train batch 245/450: 3920/7200 mean loss: 0.00195381254889071 score: 1.0
2021-08-08 03:37:55,159 | train | INFO | Epoch 0 train batch 246/450: 3936/7200 mean loss: 0.0019286691676825285 score: 1.0
2021-08-08 03:37:55,943 | train | INFO | Epoch 0 train batch 247/450: 3952/7200 mean loss: 0.001910348772071302 score: 1.0
2021-08-08 03:37:56,738 | train | INFO | Epoch 0 train batch 248/450: 3968/7200 mean loss: 0.0019297157414257526 score: 1.0
2021-08-08 03:37:57,534 | train | INFO | Epoch 0 train batch 249/450: 3984/7200 mean loss: 0.0019364050822332501 score: 1.0
2021-08-08 03:37:58,328 | train | INFO | Epoch 0 train batch 250/450: 4000/7200 mean loss: 0.0019390478264540434 score: 1.0
2021-08-08 03:37:59,163 | train | INFO | Epoch 0 train batch 251/450: 4016/7200 mean loss: 0.0019604472909122705 score: 0.9963235294117647
2021-08-08 03:37:59,993 | train | INFO | Epoch 0 train batch 252/450: 4032/7200 mean loss: 0.001967980293557048 score: 1.0
2021-08-08 03:38:00,845 | train | INFO | Epoch 0 train batch 253/450: 4048/7200 mean loss: 0.001923341304063797 score: 1.0
2021-08-08 03:38:01,652 | train | INFO | Epoch 0 train batch 254/450: 4064/7200 mean loss: 0.0019192069303244352 score: 1.0
2021-08-08 03:38:02,449 | train | INFO | Epoch 0 train batch 255/450: 4080/7200 mean loss: 0.001934882951900363 score: 1.0
2021-08-08 03:38:03,251 | train | INFO | Epoch 0 train batch 256/450: 4096/7200 mean loss: 0.0019473396241664886 score: 0.6823529411764706
2021-08-08 03:38:04,090 | train | INFO | Epoch 0 train batch 257/450: 4112/7200 mean loss: 0.0019215362844988704 score: 1.0
2021-08-08 03:38:04,894 | train | INFO | Epoch 0 train batch 258/450: 4128/7200 mean loss: 0.0019259646069258451 score: 1.0
2021-08-08 03:38:05,689 | train | INFO | Epoch 0 train batch 259/450: 4144/7200 mean loss: 0.0019304427551105618 score: 1.0
2021-08-08 03:38:06,509 | train | INFO | Epoch 0 train batch 260/450: 4160/7200 mean loss: 0.0019377557327970862 score: 0.996078431372549
2021-08-08 03:38:07,356 | train | INFO | Epoch 0 train batch 261/450: 4176/7200 mean loss: 0.0019267529714852571 score: 1.0
2021-08-08 03:38:08,155 | train | INFO | Epoch 0 train batch 262/450: 4192/7200 mean loss: 0.0019369329093024135 score: 1.0
2021-08-08 03:38:09,010 | train | INFO | Epoch 0 train batch 263/450: 4208/7200 mean loss: 0.0019156788475811481 score: 0.9852941176470589
2021-08-08 03:38:09,810 | train | INFO | Epoch 0 train batch 264/450: 4224/7200 mean loss: 0.001923556555993855 score: 0.873529411764706
2021-08-08 03:38:10,649 | train | INFO | Epoch 0 train batch 265/450: 4240/7200 mean loss: 0.0019502515206113458 score: 1.0
2021-08-08 03:38:11,446 | train | INFO | Epoch 0 train batch 266/450: 4256/7200 mean loss: 0.001905950135551393 score: 1.0
2021-08-08 03:38:12,241 | train | INFO | Epoch 0 train batch 267/450: 4272/7200 mean loss: 0.0019048978574573994 score: 1.0
2021-08-08 03:38:13,045 | train | INFO | Epoch 0 train batch 268/450: 4288/7200 mean loss: 0.0019205769058316946 score: 1.0
2021-08-08 03:38:13,853 | train | INFO | Epoch 0 train batch 269/450: 4304/7200 mean loss: 0.0019236303633078933 score: 0.9963235294117647
2021-08-08 03:38:14,666 | train | INFO | Epoch 0 train batch 270/450: 4320/7200 mean loss: 0.0019189397571608424 score: 1.0
2021-08-08 03:38:15,461 | train | INFO | Epoch 0 train batch 271/450: 4336/7200 mean loss: 0.0019147135317325592 score: 0.996078431372549
2021-08-08 03:38:16,271 | train | INFO | Epoch 0 train batch 272/450: 4352/7200 mean loss: 0.0019257579697296023 score: 0.9963235294117647
2021-08-08 03:38:17,144 | train | INFO | Epoch 0 train batch 273/450: 4368/7200 mean loss: 0.0019197155488654971 score: 1.0
2021-08-08 03:38:17,984 | train | INFO | Epoch 0 train batch 274/450: 4384/7200 mean loss: 0.0019228877499699593 score: 1.0
2021-08-08 03:38:18,787 | train | INFO | Epoch 0 train batch 275/450: 4400/7200 mean loss: 0.0019355746917426586 score: 0.9509803921568628
2021-08-08 03:38:19,595 | train | INFO | Epoch 0 train batch 276/450: 4416/7200 mean loss: 0.001912943203933537 score: 1.0
2021-08-08 03:38:20,388 | train | INFO | Epoch 0 train batch 277/450: 4432/7200 mean loss: 0.0019149986328557134 score: 1.0
2021-08-08 03:38:21,217 | train | INFO | Epoch 0 train batch 278/450: 4448/7200 mean loss: 0.001889664912596345 score: 1.0
2021-08-08 03:38:22,016 | train | INFO | Epoch 0 train batch 279/450: 4464/7200 mean loss: 0.0019253643695265055 score: 1.0
2021-08-08 03:38:22,867 | train | INFO | Epoch 0 train batch 280/450: 4480/7200 mean loss: 0.0019059135811403394 score: 0.9889705882352942
2021-08-08 03:38:23,670 | train | INFO | Epoch 0 train batch 281/450: 4496/7200 mean loss: 0.0019268614705651999 score: 1.0
2021-08-08 03:38:24,459 | train | INFO | Epoch 0 train batch 282/450: 4512/7200 mean loss: 0.0019234756473451853 score: 1.0
2021-08-08 03:38:25,247 | train | INFO | Epoch 0 train batch 283/450: 4528/7200 mean loss: 0.0019082792568951845 score: 1.0
2021-08-08 03:38:26,047 | train | INFO | Epoch 0 train batch 284/450: 4544/7200 mean loss: 0.0019321340369060636 score: 1.0
2021-08-08 03:38:26,840 | train | INFO | Epoch 0 train batch 285/450: 4560/7200 mean loss: 0.0019268010510131717 score: 1.0
2021-08-08 03:38:27,658 | train | INFO | Epoch 0 train batch 286/450: 4576/7200 mean loss: 0.0019081761129200459 score: 1.0
2021-08-08 03:38:28,477 | train | INFO | Epoch 0 train batch 287/450: 4592/7200 mean loss: 0.0019493867876008153 score: 1.0
2021-08-08 03:38:29,291 | train | INFO | Epoch 0 train batch 288/450: 4608/7200 mean loss: 0.0019267608877271414 score: 1.0
2021-08-08 03:38:30,136 | train | INFO | Epoch 0 train batch 289/450: 4624/7200 mean loss: 0.0019231969490647316 score: 0.9737745098039216
2021-08-08 03:38:30,960 | train | INFO | Epoch 0 train batch 290/450: 4640/7200 mean loss: 0.0019134387839585543 score: 1.0
2021-08-08 03:38:31,753 | train | INFO | Epoch 0 train batch 291/450: 4656/7200 mean loss: 0.0019213489722460508 score: 1.0
2021-08-08 03:38:32,565 | train | INFO | Epoch 0 train batch 292/450: 4672/7200 mean loss: 0.001916677807457745 score: 1.0
2021-08-08 03:38:33,379 | train | INFO | Epoch 0 train batch 293/450: 4688/7200 mean loss: 0.0019383643520995975 score: 1.0
2021-08-08 03:38:34,227 | train | INFO | Epoch 0 train batch 294/450: 4704/7200 mean loss: 0.0019262494752183557 score: 0.9884803921568628
2021-08-08 03:38:35,023 | train | INFO | Epoch 0 train batch 295/450: 4720/7200 mean loss: 0.001917839515954256 score: 1.0
2021-08-08 03:38:35,863 | train | INFO | Epoch 0 train batch 296/450: 4736/7200 mean loss: 0.0019229385070502758 score: 0.9816176470588235
2021-08-08 03:38:36,666 | train | INFO | Epoch 0 train batch 297/450: 4752/7200 mean loss: 0.0019279089756309986 score: 1.0
2021-08-08 03:38:37,478 | train | INFO | Epoch 0 train batch 298/450: 4768/7200 mean loss: 0.0019172471947968006 score: 1.0
2021-08-08 03:38:38,288 | train | INFO | Epoch 0 train batch 299/450: 4784/7200 mean loss: 0.0019063991494476795 score: 0.995798319327731
2021-08-08 03:38:39,080 | train | INFO | Epoch 0 train batch 300/450: 4800/7200 mean loss: 0.0019144025864079595 score: 1.0
2021-08-08 03:38:39,900 | train | INFO | Epoch 0 train batch 301/450: 4816/7200 mean loss: 0.001912831561639905 score: 1.0
2021-08-08 03:38:40,678 | train | INFO | Epoch 0 train batch 302/450: 4832/7200 mean loss: 0.0019000048050656915 score: 1.0
2021-08-08 03:38:41,462 | train | INFO | Epoch 0 train batch 303/450: 4848/7200 mean loss: 0.0019362663151696324 score: 1.0
2021-08-08 03:38:42,306 | train | INFO | Epoch 0 train batch 304/450: 4864/7200 mean loss: 0.0019192693289369345 score: 0.9921218487394957
2021-08-08 03:38:43,135 | train | INFO | Epoch 0 train batch 305/450: 4880/7200 mean loss: 0.0019199199741706252 score: 0.9779411764705882
2021-08-08 03:38:43,934 | train | INFO | Epoch 0 train batch 306/450: 4896/7200 mean loss: 0.0019258668180555105 score: 1.0
2021-08-08 03:38:44,732 | train | INFO | Epoch 0 train batch 307/450: 4912/7200 mean loss: 0.0019288460025563836 score: 1.0
2021-08-08 03:38:45,562 | train | INFO | Epoch 0 train batch 308/450: 4928/7200 mean loss: 0.001924476702697575 score: 1.0
2021-08-08 03:38:46,359 | train | INFO | Epoch 0 train batch 309/450: 4944/7200 mean loss: 0.0018966305069625378 score: 1.0
2021-08-08 03:38:47,173 | train | INFO | Epoch 0 train batch 310/450: 4960/7200 mean loss: 0.0019121108343824744 score: 1.0
2021-08-08 03:38:47,989 | train | INFO | Epoch 0 train batch 311/450: 4976/7200 mean loss: 0.0019134215544909239 score: 0.9852941176470589
2021-08-08 03:38:48,842 | train | INFO | Epoch 0 train batch 312/450: 4992/7200 mean loss: 0.001926270080730319 score: 1.0
2021-08-08 03:38:49,629 | train | INFO | Epoch 0 train batch 313/450: 5008/7200 mean loss: 0.0019145982805639505 score: 1.0
2021-08-08 03:38:50,424 | train | INFO | Epoch 0 train batch 314/450: 5024/7200 mean loss: 0.0018979278393089771 score: 1.0
2021-08-08 03:38:51,244 | train | INFO | Epoch 0 train batch 315/450: 5040/7200 mean loss: 0.001892147003673017 score: 1.0
2021-08-08 03:38:52,070 | train | INFO | Epoch 0 train batch 316/450: 5056/7200 mean loss: 0.0019346711924299598 score: 0.9852941176470589
2021-08-08 03:38:52,875 | train | INFO | Epoch 0 train batch 317/450: 5072/7200 mean loss: 0.0019047512905672193 score: 1.0
2021-08-08 03:38:53,676 | train | INFO | Epoch 0 train batch 318/450: 5088/7200 mean loss: 0.0019320391584187746 score: 0.9740196078431372
2021-08-08 03:38:54,466 | train | INFO | Epoch 0 train batch 319/450: 5104/7200 mean loss: 0.0019266967428848147 score: 1.0
2021-08-08 03:38:55,269 | train | INFO | Epoch 0 train batch 320/450: 5120/7200 mean loss: 0.001909365295432508 score: 0.9957983193277312
2021-08-08 03:38:56,053 | train | INFO | Epoch 0 train batch 321/450: 5136/7200 mean loss: 0.0019401356112211943 score: 1.0
2021-08-08 03:38:56,863 | train | INFO | Epoch 0 train batch 322/450: 5152/7200 mean loss: 0.0019034852739423513 score: 1.0
2021-08-08 03:38:57,664 | train | INFO | Epoch 0 train batch 323/450: 5168/7200 mean loss: 0.001911376602947712 score: 1.0
2021-08-08 03:38:58,461 | train | INFO | Epoch 0 train batch 324/450: 5184/7200 mean loss: 0.0019038538448512554 score: 0.9669117647058824
2021-08-08 03:38:59,265 | train | INFO | Epoch 0 train batch 325/450: 5200/7200 mean loss: 0.0019219015957787633 score: 1.0
2021-08-08 03:39:00,058 | train | INFO | Epoch 0 train batch 326/450: 5216/7200 mean loss: 0.0019024935318157077 score: 1.0
2021-08-08 03:39:00,880 | train | INFO | Epoch 0 train batch 327/450: 5232/7200 mean loss: 0.0019072997383773327 score: 0.9443627450980392
2021-08-08 03:39:01,686 | train | INFO | Epoch 0 train batch 328/450: 5248/7200 mean loss: 0.001899649971164763 score: 1.0
2021-08-08 03:39:02,534 | train | INFO | Epoch 0 train batch 329/450: 5264/7200 mean loss: 0.0019045408116653562 score: 1.0
2021-08-08 03:39:03,328 | train | INFO | Epoch 0 train batch 330/450: 5280/7200 mean loss: 0.0019389033550396562 score: 1.0
2021-08-08 03:39:04,142 | train | INFO | Epoch 0 train batch 331/450: 5296/7200 mean loss: 0.0019060892518609762 score: 1.0
2021-08-08 03:39:04,945 | train | INFO | Epoch 0 train batch 332/450: 5312/7200 mean loss: 0.0019055885495617986 score: 0.9926470588235294
2021-08-08 03:39:05,804 | train | INFO | Epoch 0 train batch 333/450: 5328/7200 mean loss: 0.00190673116594553 score: 0.9811274509803922
2021-08-08 03:39:06,659 | train | INFO | Epoch 0 train batch 334/450: 5344/7200 mean loss: 0.0019140471704304218 score: 1.0
2021-08-08 03:39:07,470 | train | INFO | Epoch 0 train batch 335/450: 5360/7200 mean loss: 0.0019023166969418526 score: 1.0
2021-08-08 03:39:08,263 | train | INFO | Epoch 0 train batch 336/450: 5376/7200 mean loss: 0.0018954748520627618 score: 0.9963235294117647
2021-08-08 03:39:09,065 | train | INFO | Epoch 0 train batch 337/450: 5392/7200 mean loss: 0.001909118378534913 score: 1.0
2021-08-08 03:39:09,867 | train | INFO | Epoch 0 train batch 338/450: 5408/7200 mean loss: 0.0019583075772970915 score: 1.0
2021-08-08 03:39:10,673 | train | INFO | Epoch 0 train batch 339/450: 5424/7200 mean loss: 0.0019333590753376484 score: 1.0
2021-08-08 03:39:11,471 | train | INFO | Epoch 0 train batch 340/450: 5440/7200 mean loss: 0.0018945159390568733 score: 1.0
2021-08-08 03:39:12,269 | train | INFO | Epoch 0 train batch 341/450: 5456/7200 mean loss: 0.0018948051147162914 score: 1.0
2021-08-08 03:39:13,074 | train | INFO | Epoch 0 train batch 342/450: 5472/7200 mean loss: 0.0019107277039438486 score: 0.9779411764705882
2021-08-08 03:39:13,868 | train | INFO | Epoch 0 train batch 343/450: 5488/7200 mean loss: 0.0019128469284623861 score: 0.9926470588235294
2021-08-08 03:39:14,663 | train | INFO | Epoch 0 train batch 344/450: 5504/7200 mean loss: 0.0019172305474057794 score: 1.0
2021-08-08 03:39:15,478 | train | INFO | Epoch 0 train batch 345/450: 5520/7200 mean loss: 0.001898686052300036 score: 1.0
2021-08-08 03:39:16,269 | train | INFO | Epoch 0 train batch 346/450: 5536/7200 mean loss: 0.0019134690519422293 score: 1.0
2021-08-08 03:39:17,062 | train | INFO | Epoch 0 train batch 347/450: 5552/7200 mean loss: 0.0019108076812699437 score: 1.0
2021-08-08 03:39:17,890 | train | INFO | Epoch 0 train batch 348/450: 5568/7200 mean loss: 0.0019036364974454045 score: 1.0
2021-08-08 03:39:18,763 | train | INFO | Epoch 0 train batch 349/450: 5584/7200 mean loss: 0.0018806050065904856 score: 1.0
2021-08-08 03:39:19,614 | train | INFO | Epoch 0 train batch 350/450: 5600/7200 mean loss: 0.0019324610475450754 score: 1.0
2021-08-08 03:39:20,451 | train | INFO | Epoch 0 train batch 351/450: 5616/7200 mean loss: 0.0018939723959192634 score: 1.0
2021-08-08 03:39:21,329 | train | INFO | Epoch 0 train batch 352/450: 5632/7200 mean loss: 0.0018898919224739075 score: 0.9963235294117647
2021-08-08 03:39:22,136 | train | INFO | Epoch 0 train batch 353/450: 5648/7200 mean loss: 0.0019136025803163648 score: 0.9887254901960785
2021-08-08 03:39:22,952 | train | INFO | Epoch 0 train batch 354/450: 5664/7200 mean loss: 0.0019055214943364263 score: 1.0
2021-08-08 03:39:23,767 | train | INFO | Epoch 0 train batch 355/450: 5680/7200 mean loss: 0.0019277709070593119 score: 0.9850490196078432
2021-08-08 03:39:24,557 | train | INFO | Epoch 0 train batch 356/450: 5696/7200 mean loss: 0.0018889266066253185 score: 0.9779411764705882
2021-08-08 03:39:25,376 | train | INFO | Epoch 0 train batch 357/450: 5712/7200 mean loss: 0.0018910340731963515 score: 1.0
2021-08-08 03:39:26,186 | train | INFO | Epoch 0 train batch 358/450: 5728/7200 mean loss: 0.0018972423858940601 score: 1.0
2021-08-08 03:39:26,968 | train | INFO | Epoch 0 train batch 359/450: 5744/7200 mean loss: 0.001901904703117907 score: 0.9852941176470589
2021-08-08 03:39:27,764 | train | INFO | Epoch 0 train batch 360/450: 5760/7200 mean loss: 0.0018840909469872713 score: 1.0
2021-08-08 03:39:28,574 | train | INFO | Epoch 0 train batch 361/450: 5776/7200 mean loss: 0.0018914041575044394 score: 1.0
2021-08-08 03:39:29,369 | train | INFO | Epoch 0 train batch 362/450: 5792/7200 mean loss: 0.0018819975666701794 score: 0.9963235294117647
2021-08-08 03:39:30,165 | train | INFO | Epoch 0 train batch 363/450: 5808/7200 mean loss: 0.001932272338308394 score: 1.0
2021-08-08 03:39:30,987 | train | INFO | Epoch 0 train batch 364/450: 5824/7200 mean loss: 0.0018731715390458703 score: 1.0
2021-08-08 03:39:31,799 | train | INFO | Epoch 0 train batch 365/450: 5840/7200 mean loss: 0.0018684744136407971 score: 1.0
2021-08-08 03:39:32,633 | train | INFO | Epoch 0 train batch 366/450: 5856/7200 mean loss: 0.0019277160754427314 score: 1.0
2021-08-08 03:39:33,432 | train | INFO | Epoch 0 train batch 367/450: 5872/7200 mean loss: 0.00192922109272331 score: 1.0
2021-08-08 03:39:34,224 | train | INFO | Epoch 0 train batch 368/450: 5888/7200 mean loss: 0.0019155238987877965 score: 1.0
2021-08-08 03:39:35,037 | train | INFO | Epoch 0 train batch 369/450: 5904/7200 mean loss: 0.0019133809255436063 score: 1.0
2021-08-08 03:39:35,871 | train | INFO | Epoch 0 train batch 370/450: 5920/7200 mean loss: 0.00190380634739995 score: 1.0
2021-08-08 03:39:36,661 | train | INFO | Epoch 0 train batch 371/450: 5936/7200 mean loss: 0.0019139897776767612 score: 0.9963235294117647
2021-08-08 03:39:37,483 | train | INFO | Epoch 0 train batch 372/450: 5952/7200 mean loss: 0.001881611649878323 score: 1.0
2021-08-08 03:39:38,312 | train | INFO | Epoch 0 train batch 373/450: 5968/7200 mean loss: 0.0018895042594522238 score: 0.9737745098039216
2021-08-08 03:39:39,115 | train | INFO | Epoch 0 train batch 374/450: 5984/7200 mean loss: 0.0019279142143204808 score: 1.0
2021-08-08 03:39:39,914 | train | INFO | Epoch 0 train batch 375/450: 6000/7200 mean loss: 0.0018786926520988345 score: 1.0
2021-08-08 03:39:40,752 | train | INFO | Epoch 0 train batch 376/450: 6016/7200 mean loss: 0.0018520841840654612 score: 1.0
2021-08-08 03:39:41,540 | train | INFO | Epoch 0 train batch 377/450: 6032/7200 mean loss: 0.0018814611248672009 score: 1.0
2021-08-08 03:39:42,389 | train | INFO | Epoch 0 train batch 378/450: 6048/7200 mean loss: 0.0019307630136609077 score: 0.9659313725490196
2021-08-08 03:39:43,185 | train | INFO | Epoch 0 train batch 379/450: 6064/7200 mean loss: 0.0018981914035975933 score: 1.0
2021-08-08 03:39:44,013 | train | INFO | Epoch 0 train batch 380/450: 6080/7200 mean loss: 0.0019059354672208428 score: 0.9963235294117647
2021-08-08 03:39:44,801 | train | INFO | Epoch 0 train batch 381/450: 6096/7200 mean loss: 0.0019294205121695995 score: 1.0
2021-08-08 03:39:45,597 | train | INFO | Epoch 0 train batch 382/450: 6112/7200 mean loss: 0.001886973506771028 score: 1.0
2021-08-08 03:39:46,391 | train | INFO | Epoch 0 train batch 383/450: 6128/7200 mean loss: 0.0018701838562265038 score: 1.0
2021-08-08 03:39:47,215 | train | INFO | Epoch 0 train batch 384/450: 6144/7200 mean loss: 0.0019241479458287358 score: 1.0
2021-08-08 03:39:48,039 | train | INFO | Epoch 0 train batch 385/450: 6160/7200 mean loss: 0.001930693513713777 score: 0.5078431372549019
2021-08-08 03:39:48,833 | train | INFO | Epoch 0 train batch 386/450: 6176/7200 mean loss: 0.0019060618942603469 score: 1.0
2021-08-08 03:39:49,650 | train | INFO | Epoch 0 train batch 387/450: 6192/7200 mean loss: 0.001904916949570179 score: 1.0
2021-08-08 03:39:50,484 | train | INFO | Epoch 0 train batch 388/450: 6208/7200 mean loss: 0.0018965681083500385 score: 1.0
2021-08-08 03:39:51,387 | train | INFO | Epoch 0 train batch 389/450: 6224/7200 mean loss: 0.0018694080645218492 score: 1.0
2021-08-08 03:39:52,202 | train | INFO | Epoch 0 train batch 390/450: 6240/7200 mean loss: 0.0018746403511613607 score: 1.0
2021-08-08 03:39:52,996 | train | INFO | Epoch 0 train batch 391/450: 6256/7200 mean loss: 0.0018703944515436888 score: 1.0
2021-08-08 03:39:53,792 | train | INFO | Epoch 0 train batch 392/450: 6272/7200 mean loss: 0.0018787587760016322 score: 1.0
2021-08-08 03:39:54,617 | train | INFO | Epoch 0 train batch 393/450: 6288/7200 mean loss: 0.001893483567982912 score: 1.0
2021-08-08 03:39:55,415 | train | INFO | Epoch 0 train batch 394/450: 6304/7200 mean loss: 0.001898086746223271 score: 1.0
2021-08-08 03:39:56,238 | train | INFO | Epoch 0 train batch 395/450: 6320/7200 mean loss: 0.0019035284640267491 score: 1.0
2021-08-08 03:39:57,038 | train | INFO | Epoch 0 train batch 396/450: 6336/7200 mean loss: 0.0018934364197775722 score: 1.0
2021-08-08 03:39:57,843 | train | INFO | Epoch 0 train batch 397/450: 6352/7200 mean loss: 0.0018822033889591694 score: 0.9926470588235294
2021-08-08 03:39:58,710 | train | INFO | Epoch 0 train batch 398/450: 6368/7200 mean loss: 0.0018974088598042727 score: 1.0
2021-08-08 03:39:59,512 | train | INFO | Epoch 0 train batch 399/450: 6384/7200 mean loss: 0.0018747654976323247 score: 1.0
2021-08-08 03:40:00,330 | train | INFO | Epoch 0 train batch 400/450: 6400/7200 mean loss: 0.0018900008872151375 score: 1.0
2021-08-08 03:40:01,138 | train | INFO | Epoch 0 train batch 401/450: 6416/7200 mean loss: 0.0019033205462619662 score: 1.0
2021-08-08 03:40:01,992 | train | INFO | Epoch 0 train batch 402/450: 6432/7200 mean loss: 0.0019098309567198157 score: 1.0
2021-08-08 03:40:02,787 | train | INFO | Epoch 0 train batch 403/450: 6448/7200 mean loss: 0.0018732972675934434 score: 0.996078431372549
2021-08-08 03:40:03,585 | train | INFO | Epoch 0 train batch 404/450: 6464/7200 mean loss: 0.0018951460951939225 score: 1.0
2021-08-08 03:40:04,407 | train | INFO | Epoch 0 train batch 405/450: 6480/7200 mean loss: 0.001898153335787356 score: 0.9963235294117647
2021-08-08 03:40:05,247 | train | INFO | Epoch 0 train batch 406/450: 6496/7200 mean loss: 0.0018481658771634102 score: 1.0
2021-08-08 03:40:06,051 | train | INFO | Epoch 0 train batch 407/450: 6512/7200 mean loss: 0.001908430946059525 score: 0.9963235294117647
2021-08-08 03:40:06,889 | train | INFO | Epoch 0 train batch 408/450: 6528/7200 mean loss: 0.0018991321558132768 score: 0.9889705882352942
2021-08-08 03:40:07,728 | train | INFO | Epoch 0 train batch 409/450: 6544/7200 mean loss: 0.001850282191298902 score: 1.0
2021-08-08 03:40:08,540 | train | INFO | Epoch 0 train batch 410/450: 6560/7200 mean loss: 0.0019048198591917753 score: 0.9301470588235294
2021-08-08 03:40:09,350 | train | INFO | Epoch 0 train batch 411/450: 6576/7200 mean loss: 0.0018995038699358702 score: 0.9737745098039216
2021-08-08 03:40:10,199 | train | INFO | Epoch 0 train batch 412/450: 6592/7200 mean loss: 0.001915216213092208 score: 0.9926470588235294
2021-08-08 03:40:10,990 | train | INFO | Epoch 0 train batch 413/450: 6608/7200 mean loss: 0.0018856225069612265 score: 0.9926470588235294
2021-08-08 03:40:11,825 | train | INFO | Epoch 0 train batch 414/450: 6624/7200 mean loss: 0.0019040795741602778 score: 1.0
2021-08-08 03:40:12,704 | train | INFO | Epoch 0 train batch 415/450: 6640/7200 mean loss: 0.0018926983466371894 score: 0.9963235294117647
2021-08-08 03:40:13,494 | train | INFO | Epoch 0 train batch 416/450: 6656/7200 mean loss: 0.0018663115333765745 score: 1.0
2021-08-08 03:40:14,300 | train | INFO | Epoch 0 train batch 417/450: 6672/7200 mean loss: 0.0018884293967857957 score: 1.0
2021-08-08 03:40:15,144 | train | INFO | Epoch 0 train batch 418/450: 6688/7200 mean loss: 0.001901611452922225 score: 1.0
2021-08-08 03:40:15,979 | train | INFO | Epoch 0 train batch 419/450: 6704/7200 mean loss: 0.001877468079328537 score: 1.0
2021-08-08 03:40:16,814 | train | INFO | Epoch 0 train batch 420/450: 6720/7200 mean loss: 0.0018890745704993606 score: 0.9963235294117647
2021-08-08 03:40:17,626 | train | INFO | Epoch 0 train batch 421/450: 6736/7200 mean loss: 0.001885159290395677 score: 1.0
2021-08-08 03:40:18,462 | train | INFO | Epoch 0 train batch 422/450: 6752/7200 mean loss: 0.0019081960199400783 score: 0.996078431372549
2021-08-08 03:40:19,300 | train | INFO | Epoch 0 train batch 423/450: 6768/7200 mean loss: 0.0018800246762111783 score: 0.996078431372549
2021-08-08 03:40:20,112 | train | INFO | Epoch 0 train batch 424/450: 6784/7200 mean loss: 0.0019178661750629544 score: 0.5115196078431373
2021-08-08 03:40:20,903 | train | INFO | Epoch 0 train batch 425/450: 6800/7200 mean loss: 0.001877893810160458 score: 0.9558823529411765
2021-08-08 03:40:21,700 | train | INFO | Epoch 0 train batch 426/450: 6816/7200 mean loss: 0.0019214424537494779 score: 1.0
2021-08-08 03:40:22,566 | train | INFO | Epoch 0 train batch 427/450: 6832/7200 mean loss: 0.0018928061472252011 score: 0.9884803921568628
2021-08-08 03:40:23,391 | train | INFO | Epoch 0 train batch 428/450: 6848/7200 mean loss: 0.0018662295769900084 score: 0.9963235294117647
2021-08-08 03:40:24,215 | train | INFO | Epoch 0 train batch 429/450: 6864/7200 mean loss: 0.001857471652328968 score: 0.9924019607843138
2021-08-08 03:40:25,057 | train | INFO | Epoch 0 train batch 430/450: 6880/7200 mean loss: 0.0019043206702917814 score: 1.0
2021-08-08 03:40:25,853 | train | INFO | Epoch 0 train batch 431/450: 6896/7200 mean loss: 0.001851542736403644 score: 1.0
2021-08-08 03:40:26,658 | train | INFO | Epoch 0 train batch 432/450: 6912/7200 mean loss: 0.001894283341243863 score: 1.0
2021-08-08 03:40:27,450 | train | INFO | Epoch 0 train batch 433/450: 6928/7200 mean loss: 0.001894146902486682 score: 1.0
2021-08-08 03:40:28,265 | train | INFO | Epoch 0 train batch 434/450: 6944/7200 mean loss: 0.001902596210129559 score: 1.0
2021-08-08 03:40:29,053 | train | INFO | Epoch 0 train batch 435/450: 6960/7200 mean loss: 0.0018844440346583724 score: 1.0
2021-08-08 03:40:29,854 | train | INFO | Epoch 0 train batch 436/450: 6976/7200 mean loss: 0.001843184232711792 score: 0.9963235294117647
2021-08-08 03:40:30,704 | train | INFO | Epoch 0 train batch 437/450: 6992/7200 mean loss: 0.0019161028321832418 score: 1.0
2021-08-08 03:40:31,489 | train | INFO | Epoch 0 train batch 438/450: 7008/7200 mean loss: 0.0018895292887464166 score: 1.0
2021-08-08 03:40:32,305 | train | INFO | Epoch 0 train batch 439/450: 7024/7200 mean loss: 0.0018992831464856863 score: 0.9848039215686275
2021-08-08 03:40:33,090 | train | INFO | Epoch 0 train batch 440/450: 7040/7200 mean loss: 0.001877005328424275 score: 1.0
2021-08-08 03:40:33,905 | train | INFO | Epoch 0 train batch 441/450: 7056/7200 mean loss: 0.0018960200250148773 score: 1.0
2021-08-08 03:40:34,715 | train | INFO | Epoch 0 train batch 442/450: 7072/7200 mean loss: 0.0018798934761434793 score: 1.0
2021-08-08 03:40:35,522 | train | INFO | Epoch 0 train batch 443/450: 7088/7200 mean loss: 0.0018767272122204304 score: 1.0
2021-08-08 03:40:36,309 | train | INFO | Epoch 0 train batch 444/450: 7104/7200 mean loss: 0.0018247736152261496 score: 1.0
2021-08-08 03:40:37,091 | train | INFO | Epoch 0 train batch 445/450: 7120/7200 mean loss: 0.0018475910183042288 score: 0.9627450980392157
2021-08-08 03:40:37,873 | train | INFO | Epoch 0 train batch 446/450: 7136/7200 mean loss: 0.001857276540249586 score: 0.9926470588235294
2021-08-08 03:40:38,655 | train | INFO | Epoch 0 train batch 447/450: 7152/7200 mean loss: 0.001904827542603016 score: 1.0
2021-08-08 03:40:39,438 | train | INFO | Epoch 0 train batch 448/450: 7168/7200 mean loss: 0.0018398507963865995 score: 1.0
2021-08-08 03:40:40,260 | train | INFO | Epoch 0 train batch 449/450: 7184/7200 mean loss: 0.0018868038896471262 score: 1.0
2021-08-08 03:40:40,359 | train | INFO | Epoch 0, Train, Mean loss: 0.031024367242223686, Score: 0.9817536390624626
2021-08-08 03:40:41,967 | train | INFO | Epoch 0 validation batch 0/113: 0/1800 mean loss: 0.0018238493939861655 score: 0.9730392156862746
2021-08-08 03:40:42,222 | train | INFO | Epoch 0 validation batch 1/113: 16/1800 mean loss: 0.0017808029660955071 score: 0.9924019607843138
2021-08-08 03:40:42,529 | train | INFO | Epoch 0 validation batch 2/113: 32/1800 mean loss: 0.0018437978578731418 score: 1.0
2021-08-08 03:40:42,770 | train | INFO | Epoch 0 validation batch 3/113: 48/1800 mean loss: 0.0018190069822594523 score: 1.0
2021-08-08 03:40:43,021 | train | INFO | Epoch 0 validation batch 4/113: 64/1800 mean loss: 0.0018048122292384505 score: 1.0
2021-08-08 03:40:43,256 | train | INFO | Epoch 0 validation batch 5/113: 80/1800 mean loss: 0.0018322047544643283 score: 0.9921218487394957
2021-08-08 03:40:43,495 | train | INFO | Epoch 0 validation batch 6/113: 96/1800 mean loss: 0.0017970307962968946 score: 1.0
2021-08-08 03:40:43,738 | train | INFO | Epoch 0 validation batch 7/113: 112/1800 mean loss: 0.00183277134783566 score: 0.9963235294117647
2021-08-08 03:40:43,976 | train | INFO | Epoch 0 validation batch 8/113: 128/1800 mean loss: 0.0018345710122957826 score: 1.0
2021-08-08 03:40:44,216 | train | INFO | Epoch 0 validation batch 9/113: 144/1800 mean loss: 0.0017509976169094443 score: 1.0
2021-08-08 03:40:44,472 | train | INFO | Epoch 0 validation batch 10/113: 160/1800 mean loss: 0.001784650725312531 score: 0.9480392156862746
2021-08-08 03:40:44,705 | train | INFO | Epoch 0 validation batch 11/113: 176/1800 mean loss: 0.001830511842854321 score: 0.9852941176470589
2021-08-08 03:40:45,033 | train | INFO | Epoch 0 validation batch 12/113: 192/1800 mean loss: 0.0017993145156651735 score: 0.9926470588235294
2021-08-08 03:40:45,284 | train | INFO | Epoch 0 validation batch 13/113: 208/1800 mean loss: 0.001817467506043613 score: 0.9887254901960785
2021-08-08 03:40:45,535 | train | INFO | Epoch 0 validation batch 14/113: 224/1800 mean loss: 0.0017929082969203591 score: 1.0
2021-08-08 03:40:45,788 | train | INFO | Epoch 0 validation batch 15/113: 240/1800 mean loss: 0.0017832351149991155 score: 1.0
2021-08-08 03:40:46,022 | train | INFO | Epoch 0 validation batch 16/113: 256/1800 mean loss: 0.0018064893083646894 score: 1.0
2021-08-08 03:40:46,260 | train | INFO | Epoch 0 validation batch 17/113: 272/1800 mean loss: 0.0018377177184447646 score: 1.0
2021-08-08 03:40:46,499 | train | INFO | Epoch 0 validation batch 18/113: 288/1800 mean loss: 0.0017217540880665183 score: 1.0
2021-08-08 03:40:46,732 | train | INFO | Epoch 0 validation batch 19/113: 304/1800 mean loss: 0.0017794381128624082 score: 1.0
2021-08-08 03:40:46,979 | train | INFO | Epoch 0 validation batch 20/113: 320/1800 mean loss: 0.001818862627260387 score: 0.9149509803921569
2021-08-08 03:40:47,231 | train | INFO | Epoch 0 validation batch 21/113: 336/1800 mean loss: 0.001792456372641027 score: 0.9963235294117647
2021-08-08 03:40:47,497 | train | INFO | Epoch 0 validation batch 22/113: 352/1800 mean loss: 0.0017230226658284664 score: 1.0
2021-08-08 03:40:47,757 | train | INFO | Epoch 0 validation batch 23/113: 368/1800 mean loss: 0.0017818559426814318 score: 0.9963235294117647
2021-08-08 03:40:48,025 | train | INFO | Epoch 0 validation batch 24/113: 384/1800 mean loss: 0.0017929206369444728 score: 1.0
2021-08-08 03:40:48,282 | train | INFO | Epoch 0 validation batch 25/113: 400/1800 mean loss: 0.0018341966206207871 score: 0.996078431372549
2021-08-08 03:40:48,566 | train | INFO | Epoch 0 validation batch 26/113: 416/1800 mean loss: 0.0017864349065348506 score: 1.0
2021-08-08 03:40:48,802 | train | INFO | Epoch 0 validation batch 27/113: 432/1800 mean loss: 0.0018485236214473844 score: 1.0
2021-08-08 03:40:49,073 | train | INFO | Epoch 0 validation batch 28/113: 448/1800 mean loss: 0.0017702607437968254 score: 1.0
2021-08-08 03:40:49,327 | train | INFO | Epoch 0 validation batch 29/113: 464/1800 mean loss: 0.0018214186420664191 score: 1.0
2021-08-08 03:40:49,569 | train | INFO | Epoch 0 validation batch 30/113: 480/1800 mean loss: 0.0018347608856856823 score: 0.9522058823529411
2021-08-08 03:40:49,810 | train | INFO | Epoch 0 validation batch 31/113: 496/1800 mean loss: 0.0017731161788105965 score: 1.0
2021-08-08 03:40:50,065 | train | INFO | Epoch 0 validation batch 32/113: 512/1800 mean loss: 0.0018141890177503228 score: 0.9705882352941176
2021-08-08 03:40:50,299 | train | INFO | Epoch 0 validation batch 33/113: 528/1800 mean loss: 0.0017899576341733336 score: 1.0
2021-08-08 03:40:50,567 | train | INFO | Epoch 0 validation batch 34/113: 544/1800 mean loss: 0.001741644344292581 score: 1.0
2021-08-08 03:40:50,809 | train | INFO | Epoch 0 validation batch 35/113: 560/1800 mean loss: 0.0018303485121577978 score: 1.0
2021-08-08 03:40:51,063 | train | INFO | Epoch 0 validation batch 36/113: 576/1800 mean loss: 0.0018428300973027945 score: 0.5490196078431373
2021-08-08 03:40:51,322 | train | INFO | Epoch 0 validation batch 37/113: 592/1800 mean loss: 0.0017697225557640195 score: 1.0
2021-08-08 03:40:51,565 | train | INFO | Epoch 0 validation batch 38/113: 608/1800 mean loss: 0.0018357147928327322 score: 1.0
2021-08-08 03:40:51,800 | train | INFO | Epoch 0 validation batch 39/113: 624/1800 mean loss: 0.0018016467802226543 score: 0.9963235294117647
2021-08-08 03:40:52,059 | train | INFO | Epoch 0 validation batch 40/113: 640/1800 mean loss: 0.0018042739247903228 score: 0.9850490196078432
2021-08-08 03:40:52,341 | train | INFO | Epoch 0 validation batch 41/113: 656/1800 mean loss: 0.0017822255613282323 score: 1.0
2021-08-08 03:40:52,577 | train | INFO | Epoch 0 validation batch 42/113: 672/1800 mean loss: 0.0018021243158727884 score: 0.8010154061624649
2021-08-08 03:40:52,811 | train | INFO | Epoch 0 validation batch 43/113: 688/1800 mean loss: 0.0018036188557744026 score: 1.0
2021-08-08 03:40:53,056 | train | INFO | Epoch 0 validation batch 44/113: 704/1800 mean loss: 0.0018506004707887769 score: 0.9264705882352942
2021-08-08 03:40:53,297 | train | INFO | Epoch 0 validation batch 45/113: 720/1800 mean loss: 0.001800172496587038 score: 1.0
2021-08-08 03:40:53,545 | train | INFO | Epoch 0 validation batch 46/113: 736/1800 mean loss: 0.0018135473364964128 score: 0.9926470588235294
2021-08-08 03:40:53,819 | train | INFO | Epoch 0 validation batch 47/113: 752/1800 mean loss: 0.0017856567865237594 score: 1.0
2021-08-08 03:40:54,079 | train | INFO | Epoch 0 validation batch 48/113: 768/1800 mean loss: 0.0018427707254886627 score: 1.0
2021-08-08 03:40:54,339 | train | INFO | Epoch 0 validation batch 49/113: 784/1800 mean loss: 0.00181886600330472 score: 1.0
2021-08-08 03:40:54,607 | train | INFO | Epoch 0 validation batch 50/113: 800/1800 mean loss: 0.001813626615330577 score: 0.9889705882352942
2021-08-08 03:40:54,841 | train | INFO | Epoch 0 validation batch 51/113: 816/1800 mean loss: 0.0018105496419593692 score: 0.9553921568627451
2021-08-08 03:40:55,107 | train | INFO | Epoch 0 validation batch 52/113: 832/1800 mean loss: 0.001832124893553555 score: 0.9887254901960785
2021-08-08 03:40:55,348 | train | INFO | Epoch 0 validation batch 53/113: 848/1800 mean loss: 0.0018183342181146145 score: 1.0
2021-08-08 03:40:55,662 | train | INFO | Epoch 0 validation batch 54/113: 864/1800 mean loss: 0.0018219478661194444 score: 1.0
2021-08-08 03:40:55,935 | train | INFO | Epoch 0 validation batch 55/113: 880/1800 mean loss: 0.0018328122096136212 score: 1.0
2021-08-08 03:40:56,177 | train | INFO | Epoch 0 validation batch 56/113: 896/1800 mean loss: 0.0018194011645391583 score: 1.0
2021-08-08 03:40:56,439 | train | INFO | Epoch 0 validation batch 57/113: 912/1800 mean loss: 0.0018545957282185555 score: 0.995798319327731
2021-08-08 03:40:56,678 | train | INFO | Epoch 0 validation batch 58/113: 928/1800 mean loss: 0.0018433433724567294 score: 0.9813725490196079
2021-08-08 03:40:56,935 | train | INFO | Epoch 0 validation batch 59/113: 944/1800 mean loss: 0.0017904434353113174 score: 1.0
2021-08-08 03:40:57,206 | train | INFO | Epoch 0 validation batch 60/113: 960/1800 mean loss: 0.0017567621544003487 score: 1.0
2021-08-08 03:40:57,473 | train | INFO | Epoch 0 validation batch 61/113: 976/1800 mean loss: 0.0017581965075805783 score: 1.0
2021-08-08 03:40:57,715 | train | INFO | Epoch 0 validation batch 62/113: 992/1800 mean loss: 0.0018003853037953377 score: 0.996078431372549
2021-08-08 03:40:57,957 | train | INFO | Epoch 0 validation batch 63/113: 1008/1800 mean loss: 0.0017894409829750657 score: 1.0
2021-08-08 03:40:58,193 | train | INFO | Epoch 0 validation batch 64/113: 1024/1800 mean loss: 0.0018267306732013822 score: 1.0
2021-08-08 03:40:58,437 | train | INFO | Epoch 0 validation batch 65/113: 1040/1800 mean loss: 0.0018065611366182566 score: 0.9887254901960785
2021-08-08 03:40:58,675 | train | INFO | Epoch 0 validation batch 66/113: 1056/1800 mean loss: 0.0018535698764026165 score: 0.9963235294117647
2021-08-08 03:40:58,949 | train | INFO | Epoch 0 validation batch 67/113: 1072/1800 mean loss: 0.0017893763724714518 score: 1.0
2021-08-08 03:40:59,204 | train | INFO | Epoch 0 validation batch 68/113: 1088/1800 mean loss: 0.0017380277859047055 score: 1.0
2021-08-08 03:40:59,470 | train | INFO | Epoch 0 validation batch 69/113: 1104/1800 mean loss: 0.00182913220487535 score: 1.0
2021-08-08 03:40:59,726 | train | INFO | Epoch 0 validation batch 70/113: 1120/1800 mean loss: 0.0018273408059030771 score: 0.9850490196078432
2021-08-08 03:40:59,963 | train | INFO | Epoch 0 validation batch 71/113: 1136/1800 mean loss: 0.0017889660084620118 score: 1.0
2021-08-08 03:41:00,235 | train | INFO | Epoch 0 validation batch 72/113: 1152/1800 mean loss: 0.0017840703949332237 score: 1.0
2021-08-08 03:41:00,505 | train | INFO | Epoch 0 validation batch 73/113: 1168/1800 mean loss: 0.0018629225669428706 score: 1.0
2021-08-08 03:41:00,774 | train | INFO | Epoch 0 validation batch 74/113: 1184/1800 mean loss: 0.0018123959889635444 score: 1.0
2021-08-08 03:41:01,039 | train | INFO | Epoch 0 validation batch 75/113: 1200/1800 mean loss: 0.0018153255805373192 score: 1.0
2021-08-08 03:41:01,294 | train | INFO | Epoch 0 validation batch 76/113: 1216/1800 mean loss: 0.0017955399816855788 score: 1.0
2021-08-08 03:41:01,526 | train | INFO | Epoch 0 validation batch 77/113: 1232/1800 mean loss: 0.001783623592928052 score: 1.0
2021-08-08 03:41:01,778 | train | INFO | Epoch 0 validation batch 78/113: 1248/1800 mean loss: 0.0017922131810337305 score: 0.7951330532212886
2021-08-08 03:41:02,029 | train | INFO | Epoch 0 validation batch 79/113: 1264/1800 mean loss: 0.0018338726367801428 score: 0.9850490196078432
2021-08-08 03:41:02,262 | train | INFO | Epoch 0 validation batch 80/113: 1280/1800 mean loss: 0.0018853562651202083 score: 1.0
2021-08-08 03:41:02,502 | train | INFO | Epoch 0 validation batch 81/113: 1296/1800 mean loss: 0.0018270291620865464 score: 0.9963235294117647
2021-08-08 03:41:02,776 | train | INFO | Epoch 0 validation batch 82/113: 1312/1800 mean loss: 0.0017529457109048963 score: 1.0
2021-08-08 03:41:03,039 | train | INFO | Epoch 0 validation batch 83/113: 1328/1800 mean loss: 0.0018409788608551025 score: 1.0
2021-08-08 03:41:03,292 | train | INFO | Epoch 0 validation batch 84/113: 1344/1800 mean loss: 0.001825063955038786 score: 0.8848039215686274
2021-08-08 03:41:03,563 | train | INFO | Epoch 0 validation batch 85/113: 1360/1800 mean loss: 0.0018156657461076975 score: 0.996078431372549
2021-08-08 03:41:03,820 | train | INFO | Epoch 0 validation batch 86/113: 1376/1800 mean loss: 0.0018693925812840462 score: 1.0
2021-08-08 03:41:04,081 | train | INFO | Epoch 0 validation batch 87/113: 1392/1800 mean loss: 0.0018085150513797998 score: 0.9963235294117647
2021-08-08 03:41:04,314 | train | INFO | Epoch 0 validation batch 88/113: 1408/1800 mean loss: 0.0017888109432533383 score: 1.0
2021-08-08 03:41:04,562 | train | INFO | Epoch 0 validation batch 89/113: 1424/1800 mean loss: 0.0017159951385110617 score: 1.0
2021-08-08 03:41:04,813 | train | INFO | Epoch 0 validation batch 90/113: 1440/1800 mean loss: 0.0018099099397659302 score: 1.0
2021-08-08 03:41:05,073 | train | INFO | Epoch 0 validation batch 91/113: 1456/1800 mean loss: 0.0018417922547087073 score: 0.9889705882352942
2021-08-08 03:41:05,333 | train | INFO | Epoch 0 validation batch 92/113: 1472/1800 mean loss: 0.0018136939033865929 score: 1.0
2021-08-08 03:41:05,613 | train | INFO | Epoch 0 validation batch 93/113: 1488/1800 mean loss: 0.0017907153815031052 score: 1.0
2021-08-08 03:41:05,857 | train | INFO | Epoch 0 validation batch 94/113: 1504/1800 mean loss: 0.001807364751584828 score: 1.0
2021-08-08 03:41:06,105 | train | INFO | Epoch 0 validation batch 95/113: 1520/1800 mean loss: 0.0017998452531173825 score: 1.0
2021-08-08 03:41:06,363 | train | INFO | Epoch 0 validation batch 96/113: 1536/1800 mean loss: 0.0017866701819002628 score: 0.9705882352941176
2021-08-08 03:41:06,598 | train | INFO | Epoch 0 validation batch 97/113: 1552/1800 mean loss: 0.0017989416373893619 score: 1.0
2021-08-08 03:41:06,836 | train | INFO | Epoch 0 validation batch 98/113: 1568/1800 mean loss: 0.0018034736858680844 score: 1.0
2021-08-08 03:41:07,078 | train | INFO | Epoch 0 validation batch 99/113: 1584/1800 mean loss: 0.001815148745663464 score: 1.0
2021-08-08 03:41:07,328 | train | INFO | Epoch 0 validation batch 100/113: 1600/1800 mean loss: 0.0018417658284306526 score: 1.0
2021-08-08 03:41:07,565 | train | INFO | Epoch 0 validation batch 101/113: 1616/1800 mean loss: 0.0018086546333506703 score: 1.0
2021-08-08 03:41:07,799 | train | INFO | Epoch 0 validation batch 102/113: 1632/1800 mean loss: 0.0017940786201506853 score: 1.0
2021-08-08 03:41:08,033 | train | INFO | Epoch 0 validation batch 103/113: 1648/1800 mean loss: 0.0018045679898932576 score: 1.0
2021-08-08 03:41:08,266 | train | INFO | Epoch 0 validation batch 104/113: 1664/1800 mean loss: 0.0018133856356143951 score: 1.0
2021-08-08 03:41:08,500 | train | INFO | Epoch 0 validation batch 105/113: 1680/1800 mean loss: 0.0018111723475158215 score: 1.0
2021-08-08 03:41:08,735 | train | INFO | Epoch 0 validation batch 106/113: 1696/1800 mean loss: 0.0018465692410245538 score: 1.0
2021-08-08 03:41:08,973 | train | INFO | Epoch 0 validation batch 107/113: 1712/1800 mean loss: 0.001816800213418901 score: 1.0
2021-08-08 03:41:09,206 | train | INFO | Epoch 0 validation batch 108/113: 1728/1800 mean loss: 0.0018310770392417908 score: 0.9924019607843138
2021-08-08 03:41:09,440 | train | INFO | Epoch 0 validation batch 109/113: 1744/1800 mean loss: 0.0018511732341721654 score: 1.0
2021-08-08 03:41:09,674 | train | INFO | Epoch 0 validation batch 110/113: 1760/1800 mean loss: 0.001816235133446753 score: 1.0
2021-08-08 03:41:09,913 | train | INFO | Epoch 0 validation batch 111/113: 1776/1800 mean loss: 0.0018319179071113467 score: 0.996078431372549
2021-08-08 03:41:10,381 | train | INFO | Epoch 0 validation batch 112/113: 1792/1800 mean loss: 0.0017529184697195888 score: 1.0
2021-08-08 03:41:10,541 | train | INFO | Epoch 0, Validation, Mean loss: 0.028924648575814425, Score: 0.9860511018566719
2021-08-08 03:41:10,541 | train | INFO | Write row 0
2021-08-08 03:41:11,581 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 03:41:11,584 | train | INFO | Update best record row 1, checkpoints inf -> 0.028924648575814425
2021-08-08 03:41:13,945 | train | INFO | Epoch 1 train batch 0/450: 0/7200 mean loss: 0.0018599180039018393 score: 0.996078431372549
2021-08-08 03:41:14,771 | train | INFO | Epoch 1 train batch 1/450: 16/7200 mean loss: 0.0018751071766018867 score: 1.0
2021-08-08 03:41:15,571 | train | INFO | Epoch 1 train batch 2/450: 32/7200 mean loss: 0.001865830970928073 score: 1.0
2021-08-08 03:41:16,399 | train | INFO | Epoch 1 train batch 3/450: 48/7200 mean loss: 0.001845738966949284 score: 1.0
2021-08-08 03:41:17,206 | train | INFO | Epoch 1 train batch 4/450: 64/7200 mean loss: 0.001886554528027773 score: 1.0
2021-08-08 03:41:18,030 | train | INFO | Epoch 1 train batch 5/450: 80/7200 mean loss: 0.001847864710725844 score: 1.0
2021-08-08 03:41:18,865 | train | INFO | Epoch 1 train batch 6/450: 96/7200 mean loss: 0.0018491764785721898 score: 1.0
2021-08-08 03:41:19,681 | train | INFO | Epoch 1 train batch 7/450: 112/7200 mean loss: 0.0018633450381457806 score: 1.0
2021-08-08 03:41:20,480 | train | INFO | Epoch 1 train batch 8/450: 128/7200 mean loss: 0.001884628552943468 score: 0.7696078431372548
2021-08-08 03:41:21,296 | train | INFO | Epoch 1 train batch 9/450: 144/7200 mean loss: 0.0018941146554425359 score: 1.0
2021-08-08 03:41:22,104 | train | INFO | Epoch 1 train batch 10/450: 160/7200 mean loss: 0.0019006083020940423 score: 0.9924019607843138
2021-08-08 03:41:22,941 | train | INFO | Epoch 1 train batch 11/450: 176/7200 mean loss: 0.0018720132065936923 score: 1.0
2021-08-08 03:41:23,769 | train | INFO | Epoch 1 train batch 12/450: 192/7200 mean loss: 0.0018848796607926488 score: 0.9963235294117647
2021-08-08 03:41:24,580 | train | INFO | Epoch 1 train batch 13/450: 208/7200 mean loss: 0.0018924921751022339 score: 1.0
2021-08-08 03:41:25,442 | train | INFO | Epoch 1 train batch 14/450: 224/7200 mean loss: 0.0018867470789700747 score: 0.9705882352941176
2021-08-08 03:41:26,229 | train | INFO | Epoch 1 train batch 15/450: 240/7200 mean loss: 0.0018935372354462743 score: 0.919607843137255
2021-08-08 03:41:27,057 | train | INFO | Epoch 1 train batch 16/450: 256/7200 mean loss: 0.001854637055657804 score: 1.0
2021-08-08 03:41:27,881 | train | INFO | Epoch 1 train batch 17/450: 272/7200 mean loss: 0.0018622517818585038 score: 1.0
2021-08-08 03:41:28,703 | train | INFO | Epoch 1 train batch 18/450: 288/7200 mean loss: 0.001911088591441512 score: 1.0
2021-08-08 03:41:29,533 | train | INFO | Epoch 1 train batch 19/450: 304/7200 mean loss: 0.001937049557454884 score: 1.0
2021-08-08 03:41:30,358 | train | INFO | Epoch 1 train batch 20/450: 320/7200 mean loss: 0.0019109849818050861 score: 0.8161764705882353
2021-08-08 03:41:31,210 | train | INFO | Epoch 1 train batch 21/450: 336/7200 mean loss: 0.0018417845712974668 score: 1.0
2021-08-08 03:41:32,051 | train | INFO | Epoch 1 train batch 22/450: 352/7200 mean loss: 0.00184405199252069 score: 1.0
2021-08-08 03:41:32,890 | train | INFO | Epoch 1 train batch 23/450: 368/7200 mean loss: 0.001878727925941348 score: 1.0
2021-08-08 03:41:33,693 | train | INFO | Epoch 1 train batch 24/450: 384/7200 mean loss: 0.0018847609171643853 score: 0.969607843137255
2021-08-08 03:41:34,492 | train | INFO | Epoch 1 train batch 25/450: 400/7200 mean loss: 0.0018405643058940768 score: 0.9926470588235294
2021-08-08 03:41:35,286 | train | INFO | Epoch 1 train batch 26/450: 416/7200 mean loss: 0.0018727888818830252 score: 1.0
2021-08-08 03:41:36,088 | train | INFO | Epoch 1 train batch 27/450: 432/7200 mean loss: 0.0018812509952113032 score: 0.9963235294117647
2021-08-08 03:41:36,889 | train | INFO | Epoch 1 train batch 28/450: 448/7200 mean loss: 0.0018634495791047812 score: 1.0
2021-08-08 03:41:37,730 | train | INFO | Epoch 1 train batch 29/450: 464/7200 mean loss: 0.001879207557067275 score: 1.0
2021-08-08 03:41:38,576 | train | INFO | Epoch 1 train batch 30/450: 480/7200 mean loss: 0.001881138770841062 score: 1.0
2021-08-08 03:41:39,392 | train | INFO | Epoch 1 train batch 31/450: 496/7200 mean loss: 0.0018522274913266301 score: 0.9963235294117647
2021-08-08 03:41:40,245 | train | INFO | Epoch 1 train batch 32/450: 512/7200 mean loss: 0.0018953507533296943 score: 1.0
2021-08-08 03:41:41,082 | train | INFO | Epoch 1 train batch 33/450: 528/7200 mean loss: 0.0018728901632130146 score: 1.0
2021-08-08 03:41:41,918 | train | INFO | Epoch 1 train batch 34/450: 544/7200 mean loss: 0.0018715880578383803 score: 1.0
2021-08-08 03:41:42,785 | train | INFO | Epoch 1 train batch 35/450: 560/7200 mean loss: 0.0018555623246356845 score: 0.9726890756302521
2021-08-08 03:41:43,634 | train | INFO | Epoch 1 train batch 36/450: 576/7200 mean loss: 0.0018878800328820944 score: 0.9926470588235294
2021-08-08 03:41:44,468 | train | INFO | Epoch 1 train batch 37/450: 592/7200 mean loss: 0.0019316462567076087 score: 1.0
2021-08-08 03:41:45,280 | train | INFO | Epoch 1 train batch 38/450: 608/7200 mean loss: 0.001836244249716401 score: 0.9848039215686275
2021-08-08 03:41:46,081 | train | INFO | Epoch 1 train batch 39/450: 624/7200 mean loss: 0.0018913145177066326 score: 1.0
2021-08-08 03:41:46,917 | train | INFO | Epoch 1 train batch 40/450: 640/7200 mean loss: 0.001904807984828949 score: 0.9963235294117647
2021-08-08 03:41:47,762 | train | INFO | Epoch 1 train batch 41/450: 656/7200 mean loss: 0.001887764548882842 score: 1.0
2021-08-08 03:41:48,609 | train | INFO | Epoch 1 train batch 42/450: 672/7200 mean loss: 0.0018293901812285185 score: 1.0
2021-08-08 03:41:49,423 | train | INFO | Epoch 1 train batch 43/450: 688/7200 mean loss: 0.0018642829963937402 score: 1.0
2021-08-08 03:41:50,248 | train | INFO | Epoch 1 train batch 44/450: 704/7200 mean loss: 0.001872844179160893 score: 0.9924019607843138
2021-08-08 03:41:51,070 | train | INFO | Epoch 1 train batch 45/450: 720/7200 mean loss: 0.0018429388292133808 score: 1.0
2021-08-08 03:41:51,855 | train | INFO | Epoch 1 train batch 46/450: 736/7200 mean loss: 0.0018638637848198414 score: 0.9924019607843138
2021-08-08 03:41:52,677 | train | INFO | Epoch 1 train batch 47/450: 752/7200 mean loss: 0.0019405402708798647 score: 1.0
2021-08-08 03:41:53,488 | train | INFO | Epoch 1 train batch 48/450: 768/7200 mean loss: 0.001880811876617372 score: 0.9165966386554623
2021-08-08 03:41:54,304 | train | INFO | Epoch 1 train batch 49/450: 784/7200 mean loss: 0.0018899309216067195 score: 0.9884803921568628
2021-08-08 03:41:55,130 | train | INFO | Epoch 1 train batch 50/450: 800/7200 mean loss: 0.00183391897007823 score: 0.9924019607843138
2021-08-08 03:41:55,929 | train | INFO | Epoch 1 train batch 51/450: 816/7200 mean loss: 0.0019123179372400045 score: 0.9963235294117647
2021-08-08 03:41:56,743 | train | INFO | Epoch 1 train batch 52/450: 832/7200 mean loss: 0.0018512860406190157 score: 1.0
2021-08-08 03:41:57,530 | train | INFO | Epoch 1 train batch 53/450: 848/7200 mean loss: 0.001860094373114407 score: 1.0
2021-08-08 03:41:58,393 | train | INFO | Epoch 1 train batch 54/450: 864/7200 mean loss: 0.0018101362511515617 score: 1.0
2021-08-08 03:41:59,195 | train | INFO | Epoch 1 train batch 55/450: 880/7200 mean loss: 0.0018648619297891855 score: 0.9666666666666667
2021-08-08 03:42:00,009 | train | INFO | Epoch 1 train batch 56/450: 896/7200 mean loss: 0.0019310949137434363 score: 1.0
2021-08-08 03:42:00,797 | train | INFO | Epoch 1 train batch 57/450: 912/7200 mean loss: 0.0018637287430465221 score: 0.9963235294117647
2021-08-08 03:42:01,635 | train | INFO | Epoch 1 train batch 58/450: 928/7200 mean loss: 0.001857854425907135 score: 1.0
2021-08-08 03:42:02,467 | train | INFO | Epoch 1 train batch 59/450: 944/7200 mean loss: 0.001847610343247652 score: 0.9924019607843138
2021-08-08 03:42:03,264 | train | INFO | Epoch 1 train batch 60/450: 960/7200 mean loss: 0.001845568185672164 score: 1.0
2021-08-08 03:42:04,099 | train | INFO | Epoch 1 train batch 61/450: 976/7200 mean loss: 0.0018514386611059308 score: 1.0
2021-08-08 03:42:04,909 | train | INFO | Epoch 1 train batch 62/450: 992/7200 mean loss: 0.0018556768773123622 score: 1.0
2021-08-08 03:42:05,741 | train | INFO | Epoch 1 train batch 63/450: 1008/7200 mean loss: 0.0018768931040540338 score: 1.0
2021-08-08 03:42:06,541 | train | INFO | Epoch 1 train batch 64/450: 1024/7200 mean loss: 0.001849210006184876 score: 1.0
2021-08-08 03:42:07,363 | train | INFO | Epoch 1 train batch 65/450: 1040/7200 mean loss: 0.001889913808554411 score: 1.0
2021-08-08 03:42:08,156 | train | INFO | Epoch 1 train batch 66/450: 1056/7200 mean loss: 0.0018537176074460149 score: 0.9847689075630254
2021-08-08 03:42:08,993 | train | INFO | Epoch 1 train batch 67/450: 1072/7200 mean loss: 0.001873973524197936 score: 1.0
2021-08-08 03:42:09,833 | train | INFO | Epoch 1 train batch 68/450: 1088/7200 mean loss: 0.001863865996710956 score: 0.9850490196078432
2021-08-08 03:42:10,631 | train | INFO | Epoch 1 train batch 69/450: 1104/7200 mean loss: 0.0018381780246272683 score: 1.0
2021-08-08 03:42:11,486 | train | INFO | Epoch 1 train batch 70/450: 1120/7200 mean loss: 0.0017845205729827285 score: 0.9963235294117647
2021-08-08 03:42:12,307 | train | INFO | Epoch 1 train batch 71/450: 1136/7200 mean loss: 0.0018217737087979913 score: 0.9654411764705884
2021-08-08 03:42:13,103 | train | INFO | Epoch 1 train batch 72/450: 1152/7200 mean loss: 0.001835330156609416 score: 1.0
2021-08-08 03:42:13,958 | train | INFO | Epoch 1 train batch 73/450: 1168/7200 mean loss: 0.0018036176916211843 score: 0.9779411764705882
2021-08-08 03:42:14,799 | train | INFO | Epoch 1 train batch 74/450: 1184/7200 mean loss: 0.0018584005301818252 score: 0.9889705882352942
2021-08-08 03:42:15,605 | train | INFO | Epoch 1 train batch 75/450: 1200/7200 mean loss: 0.0018331195460632443 score: 1.0
2021-08-08 03:42:16,425 | train | INFO | Epoch 1 train batch 76/450: 1216/7200 mean loss: 0.001848323387093842 score: 0.9926470588235294
2021-08-08 03:42:17,253 | train | INFO | Epoch 1 train batch 77/450: 1232/7200 mean loss: 0.001848136424086988 score: 1.0
2021-08-08 03:42:18,053 | train | INFO | Epoch 1 train batch 78/450: 1248/7200 mean loss: 0.0018248248379677534 score: 1.0
2021-08-08 03:42:18,882 | train | INFO | Epoch 1 train batch 79/450: 1264/7200 mean loss: 0.0017816025065258145 score: 1.0
2021-08-08 03:42:19,757 | train | INFO | Epoch 1 train batch 80/450: 1280/7200 mean loss: 0.0017911521717905998 score: 1.0
2021-08-08 03:42:20,575 | train | INFO | Epoch 1 train batch 81/450: 1296/7200 mean loss: 0.0018796853255480528 score: 0.9811274509803922
2021-08-08 03:42:21,420 | train | INFO | Epoch 1 train batch 82/450: 1312/7200 mean loss: 0.0017949803732335567 score: 1.0
2021-08-08 03:42:22,245 | train | INFO | Epoch 1 train batch 83/450: 1328/7200 mean loss: 0.0018223917577415705 score: 1.0
2021-08-08 03:42:23,084 | train | INFO | Epoch 1 train batch 84/450: 1344/7200 mean loss: 0.0018107012147083879 score: 1.0
2021-08-08 03:42:23,973 | train | INFO | Epoch 1 train batch 85/450: 1360/7200 mean loss: 0.0017688756342977285 score: 1.0
2021-08-08 03:42:24,776 | train | INFO | Epoch 1 train batch 86/450: 1376/7200 mean loss: 0.001851972658187151 score: 1.0
2021-08-08 03:42:25,563 | train | INFO | Epoch 1 train batch 87/450: 1392/7200 mean loss: 0.0017445051344111562 score: 0.9926470588235294
2021-08-08 03:42:26,348 | train | INFO | Epoch 1 train batch 88/450: 1408/7200 mean loss: 0.0017921735998243093 score: 1.0
2021-08-08 03:42:27,154 | train | INFO | Epoch 1 train batch 89/450: 1424/7200 mean loss: 0.0018660976784303784 score: 0.9629901960784314
2021-08-08 03:42:27,939 | train | INFO | Epoch 1 train batch 90/450: 1440/7200 mean loss: 0.0018026346806436777 score: 1.0
2021-08-08 03:42:28,787 | train | INFO | Epoch 1 train batch 91/450: 1456/7200 mean loss: 0.0017760826740413904 score: 1.0
2021-08-08 03:42:29,585 | train | INFO | Epoch 1 train batch 92/450: 1472/7200 mean loss: 0.0018880943534895778 score: 1.0
2021-08-08 03:42:30,388 | train | INFO | Epoch 1 train batch 93/450: 1488/7200 mean loss: 0.0018183726351708174 score: 0.9963235294117647
2021-08-08 03:42:31,178 | train | INFO | Epoch 1 train batch 94/450: 1504/7200 mean loss: 0.001864839345216751 score: 1.0
2021-08-08 03:42:31,974 | train | INFO | Epoch 1 train batch 95/450: 1520/7200 mean loss: 0.001798512996174395 score: 1.0
2021-08-08 03:42:32,766 | train | INFO | Epoch 1 train batch 96/450: 1536/7200 mean loss: 0.0018488705391064286 score: 1.0
2021-08-08 03:42:33,556 | train | INFO | Epoch 1 train batch 97/450: 1552/7200 mean loss: 0.001888923579826951 score: 1.0
2021-08-08 03:42:34,370 | train | INFO | Epoch 1 train batch 98/450: 1568/7200 mean loss: 0.0018420142587274313 score: 1.0
2021-08-08 03:42:35,186 | train | INFO | Epoch 1 train batch 99/450: 1584/7200 mean loss: 0.0018577126320451498 score: 1.0
2021-08-08 03:42:35,987 | train | INFO | Epoch 1 train batch 100/450: 1600/7200 mean loss: 0.0017837394261732697 score: 1.0
2021-08-08 03:42:36,847 | train | INFO | Epoch 1 train batch 101/450: 1616/7200 mean loss: 0.0018291855230927467 score: 1.0
2021-08-08 03:42:37,648 | train | INFO | Epoch 1 train batch 102/450: 1632/7200 mean loss: 0.0018808479653671384 score: 1.0
2021-08-08 03:42:38,437 | train | INFO | Epoch 1 train batch 103/450: 1648/7200 mean loss: 0.0018345414428040385 score: 1.0
2021-08-08 03:42:39,252 | train | INFO | Epoch 1 train batch 104/450: 1664/7200 mean loss: 0.0017960944678634405 score: 1.0
2021-08-08 03:42:40,067 | train | INFO | Epoch 1 train batch 105/450: 1680/7200 mean loss: 0.0018206745153293014 score: 1.0
2021-08-08 03:42:40,862 | train | INFO | Epoch 1 train batch 106/450: 1696/7200 mean loss: 0.0018220767378807068 score: 1.0
2021-08-08 03:42:41,711 | train | INFO | Epoch 1 train batch 107/450: 1712/7200 mean loss: 0.001844428712502122 score: 1.0
2021-08-08 03:42:42,624 | train | INFO | Epoch 1 train batch 108/450: 1728/7200 mean loss: 0.0018957696156576276 score: 1.0
2021-08-08 03:42:43,443 | train | INFO | Epoch 1 train batch 109/450: 1744/7200 mean loss: 0.0018894677050411701 score: 1.0
2021-08-08 03:42:44,229 | train | INFO | Epoch 1 train batch 110/450: 1760/7200 mean loss: 0.0018551925895735621 score: 1.0
2021-08-08 03:42:45,020 | train | INFO | Epoch 1 train batch 111/450: 1776/7200 mean loss: 0.0019630168098956347 score: 1.0
2021-08-08 03:42:45,825 | train | INFO | Epoch 1 train batch 112/450: 1792/7200 mean loss: 0.0018478301353752613 score: 1.0
2021-08-08 03:42:46,612 | train | INFO | Epoch 1 train batch 113/450: 1808/7200 mean loss: 0.001884149736724794 score: 0.9963235294117647
2021-08-08 03:42:47,462 | train | INFO | Epoch 1 train batch 114/450: 1824/7200 mean loss: 0.0017686737701296806 score: 1.0
2021-08-08 03:42:48,304 | train | INFO | Epoch 1 train batch 115/450: 1840/7200 mean loss: 0.0018367707962170243 score: 1.0
2021-08-08 03:42:49,133 | train | INFO | Epoch 1 train batch 116/450: 1856/7200 mean loss: 0.0018052123486995697 score: 1.0
2021-08-08 03:42:49,934 | train | INFO | Epoch 1 train batch 117/450: 1872/7200 mean loss: 0.0017927995650097728 score: 1.0
2021-08-08 03:42:50,745 | train | INFO | Epoch 1 train batch 118/450: 1888/7200 mean loss: 0.0018245021346956491 score: 0.9779411764705882
2021-08-08 03:42:51,578 | train | INFO | Epoch 1 train batch 119/450: 1904/7200 mean loss: 0.0018374331993982196 score: 0.9963235294117647
2021-08-08 03:42:52,380 | train | INFO | Epoch 1 train batch 120/450: 1920/7200 mean loss: 0.0018283482640981674 score: 1.0
2021-08-08 03:42:53,222 | train | INFO | Epoch 1 train batch 121/450: 1936/7200 mean loss: 0.0018811554182320833 score: 0.9963235294117647
2021-08-08 03:42:54,041 | train | INFO | Epoch 1 train batch 122/450: 1952/7200 mean loss: 0.0018793443450704217 score: 1.0
2021-08-08 03:42:54,893 | train | INFO | Epoch 1 train batch 123/450: 1968/7200 mean loss: 0.001746607362292707 score: 1.0
2021-08-08 03:42:55,729 | train | INFO | Epoch 1 train batch 124/450: 1984/7200 mean loss: 0.0017937436932697892 score: 0.9926470588235294
2021-08-08 03:42:56,519 | train | INFO | Epoch 1 train batch 125/450: 2000/7200 mean loss: 0.0018934408435598016 score: 1.0
2021-08-08 03:42:57,360 | train | INFO | Epoch 1 train batch 126/450: 2016/7200 mean loss: 0.0018392573110759258 score: 1.0
2021-08-08 03:42:58,183 | train | INFO | Epoch 1 train batch 127/450: 2032/7200 mean loss: 0.001802437356673181 score: 0.9963235294117647
2021-08-08 03:42:58,967 | train | INFO | Epoch 1 train batch 128/450: 2048/7200 mean loss: 0.0019036215962842107 score: 1.0
2021-08-08 03:42:59,796 | train | INFO | Epoch 1 train batch 129/450: 2064/7200 mean loss: 0.0017562702996656299 score: 1.0
2021-08-08 03:43:00,639 | train | INFO | Epoch 1 train batch 130/450: 2080/7200 mean loss: 0.0018327488796785474 score: 1.0
2021-08-08 03:43:01,539 | train | INFO | Epoch 1 train batch 131/450: 2096/7200 mean loss: 0.0018388638272881508 score: 1.0
2021-08-08 03:43:02,378 | train | INFO | Epoch 1 train batch 132/450: 2112/7200 mean loss: 0.001776188495568931 score: 1.0
2021-08-08 03:43:03,173 | train | INFO | Epoch 1 train batch 133/450: 2128/7200 mean loss: 0.001750754308886826 score: 1.0
2021-08-08 03:43:03,958 | train | INFO | Epoch 1 train batch 134/450: 2144/7200 mean loss: 0.0018105118069797754 score: 1.0
2021-08-08 03:43:04,737 | train | INFO | Epoch 1 train batch 135/450: 2160/7200 mean loss: 0.0018539989832788706 score: 0.9742647058823529
2021-08-08 03:43:05,520 | train | INFO | Epoch 1 train batch 136/450: 2176/7200 mean loss: 0.001809250796213746 score: 1.0
2021-08-08 03:43:06,330 | train | INFO | Epoch 1 train batch 137/450: 2192/7200 mean loss: 0.001892358297482133 score: 0.9924019607843138
2021-08-08 03:43:07,109 | train | INFO | Epoch 1 train batch 138/450: 2208/7200 mean loss: 0.0018303768010810018 score: 1.0
2021-08-08 03:43:07,921 | train | INFO | Epoch 1 train batch 139/450: 2224/7200 mean loss: 0.0018195022130385041 score: 0.996078431372549
2021-08-08 03:43:08,709 | train | INFO | Epoch 1 train batch 140/450: 2240/7200 mean loss: 0.001813231618143618 score: 1.0
2021-08-08 03:43:09,559 | train | INFO | Epoch 1 train batch 141/450: 2256/7200 mean loss: 0.0018231520662084222 score: 0.9921568627450981
2021-08-08 03:43:10,393 | train | INFO | Epoch 1 train batch 142/450: 2272/7200 mean loss: 0.0018415863160043955 score: 1.0
2021-08-08 03:43:11,212 | train | INFO | Epoch 1 train batch 143/450: 2288/7200 mean loss: 0.0017332612769678235 score: 0.9889705882352942
2021-08-08 03:43:12,028 | train | INFO | Epoch 1 train batch 144/450: 2304/7200 mean loss: 0.001824681763537228 score: 1.0
2021-08-08 03:43:12,911 | train | INFO | Epoch 1 train batch 145/450: 2320/7200 mean loss: 0.001849076827056706 score: 1.0
2021-08-08 03:43:13,745 | train | INFO | Epoch 1 train batch 146/450: 2336/7200 mean loss: 0.001794614945538342 score: 1.0
2021-08-08 03:43:14,535 | train | INFO | Epoch 1 train batch 147/450: 2352/7200 mean loss: 0.0018960724119096994 score: 1.0
2021-08-08 03:43:15,344 | train | INFO | Epoch 1 train batch 148/450: 2368/7200 mean loss: 0.0017531909979879856 score: 1.0
2021-08-08 03:43:16,163 | train | INFO | Epoch 1 train batch 149/450: 2384/7200 mean loss: 0.0018072579987347126 score: 1.0
2021-08-08 03:43:16,948 | train | INFO | Epoch 1 train batch 150/450: 2400/7200 mean loss: 0.001865897560492158 score: 0.995798319327731
2021-08-08 03:43:17,716 | train | INFO | Epoch 1 train batch 151/450: 2416/7200 mean loss: 0.0018811223562806845 score: 1.0
2021-08-08 03:43:18,514 | train | INFO | Epoch 1 train batch 152/450: 2432/7200 mean loss: 0.0018199089681729674 score: 0.9921568627450981
2021-08-08 03:43:19,299 | train | INFO | Epoch 1 train batch 153/450: 2448/7200 mean loss: 0.001844477141276002 score: 1.0
2021-08-08 03:43:20,070 | train | INFO | Epoch 1 train batch 154/450: 2464/7200 mean loss: 0.00185407476965338 score: 1.0
2021-08-08 03:43:20,860 | train | INFO | Epoch 1 train batch 155/450: 2480/7200 mean loss: 0.0018536957213655114 score: 1.0
2021-08-08 03:43:21,665 | train | INFO | Epoch 1 train batch 156/450: 2496/7200 mean loss: 0.0018401873530820012 score: 0.9816176470588235
2021-08-08 03:43:22,466 | train | INFO | Epoch 1 train batch 157/450: 2512/7200 mean loss: 0.001847251201979816 score: 1.0
2021-08-08 03:43:23,248 | train | INFO | Epoch 1 train batch 158/450: 2528/7200 mean loss: 0.0017489116871729493 score: 1.0
2021-08-08 03:43:24,027 | train | INFO | Epoch 1 train batch 159/450: 2544/7200 mean loss: 0.0018179402686655521 score: 1.0
2021-08-08 03:43:24,815 | train | INFO | Epoch 1 train batch 160/450: 2560/7200 mean loss: 0.0017928938614204526 score: 1.0
2021-08-08 03:43:25,588 | train | INFO | Epoch 1 train batch 161/450: 2576/7200 mean loss: 0.001809478853829205 score: 0.9963235294117647
2021-08-08 03:43:26,379 | train | INFO | Epoch 1 train batch 162/450: 2592/7200 mean loss: 0.001872445922344923 score: 1.0
2021-08-08 03:43:27,181 | train | INFO | Epoch 1 train batch 163/450: 2608/7200 mean loss: 0.001843219273723662 score: 1.0
2021-08-08 03:43:28,014 | train | INFO | Epoch 1 train batch 164/450: 2624/7200 mean loss: 0.0018024344462901354 score: 1.0
2021-08-08 03:43:28,809 | train | INFO | Epoch 1 train batch 165/450: 2640/7200 mean loss: 0.0019069693516939878 score: 1.0
2021-08-08 03:43:29,611 | train | INFO | Epoch 1 train batch 166/450: 2656/7200 mean loss: 0.001822063117288053 score: 1.0
2021-08-08 03:43:30,384 | train | INFO | Epoch 1 train batch 167/450: 2672/7200 mean loss: 0.0018295805202797055 score: 1.0
2021-08-08 03:43:31,175 | train | INFO | Epoch 1 train batch 168/450: 2688/7200 mean loss: 0.001798751880414784 score: 1.0
2021-08-08 03:43:32,009 | train | INFO | Epoch 1 train batch 169/450: 2704/7200 mean loss: 0.001778588630259037 score: 0.9740196078431372
2021-08-08 03:43:32,788 | train | INFO | Epoch 1 train batch 170/450: 2720/7200 mean loss: 0.001790724927559495 score: 0.9627450980392157
2021-08-08 03:43:33,607 | train | INFO | Epoch 1 train batch 171/450: 2736/7200 mean loss: 0.0017514480277895927 score: 1.0
2021-08-08 03:43:34,382 | train | INFO | Epoch 1 train batch 172/450: 2752/7200 mean loss: 0.0017936037620529532 score: 0.9850490196078432
2021-08-08 03:43:35,186 | train | INFO | Epoch 1 train batch 173/450: 2768/7200 mean loss: 0.0017288028029724956 score: 1.0
2021-08-08 03:43:35,988 | train | INFO | Epoch 1 train batch 174/450: 2784/7200 mean loss: 0.001784615684300661 score: 1.0
2021-08-08 03:43:36,770 | train | INFO | Epoch 1 train batch 175/450: 2800/7200 mean loss: 0.0018319613300263882 score: 0.9847689075630254
2021-08-08 03:43:37,594 | train | INFO | Epoch 1 train batch 176/450: 2816/7200 mean loss: 0.0018316134810447693 score: 0.9889705882352942
2021-08-08 03:43:38,408 | train | INFO | Epoch 1 train batch 177/450: 2832/7200 mean loss: 0.0018992566037923098 score: 1.0
2021-08-08 03:43:39,184 | train | INFO | Epoch 1 train batch 178/450: 2848/7200 mean loss: 0.0018139966996386647 score: 0.9926470588235294
2021-08-08 03:43:39,958 | train | INFO | Epoch 1 train batch 179/450: 2864/7200 mean loss: 0.0019598088692873716 score: 0.9926470588235294
2021-08-08 03:43:40,739 | train | INFO | Epoch 1 train batch 180/450: 2880/7200 mean loss: 0.0017669395310804248 score: 1.0
2021-08-08 03:43:41,526 | train | INFO | Epoch 1 train batch 181/450: 2896/7200 mean loss: 0.0017850776202976704 score: 1.0
2021-08-08 03:43:42,315 | train | INFO | Epoch 1 train batch 182/450: 2912/7200 mean loss: 0.001786557724699378 score: 0.9443627450980392
2021-08-08 03:43:43,095 | train | INFO | Epoch 1 train batch 183/450: 2928/7200 mean loss: 0.0018487150082364678 score: 0.9963235294117647
2021-08-08 03:43:43,873 | train | INFO | Epoch 1 train batch 184/450: 2944/7200 mean loss: 0.0018222291255369782 score: 0.9850490196078432
2021-08-08 03:43:44,658 | train | INFO | Epoch 1 train batch 185/450: 2960/7200 mean loss: 0.001820464851334691 score: 0.9881221719457014
2021-08-08 03:43:45,440 | train | INFO | Epoch 1 train batch 186/450: 2976/7200 mean loss: 0.0018614019500091672 score: 1.0
2021-08-08 03:43:46,263 | train | INFO | Epoch 1 train batch 187/450: 2992/7200 mean loss: 0.0018665569368749857 score: 1.0
2021-08-08 03:43:47,073 | train | INFO | Epoch 1 train batch 188/450: 3008/7200 mean loss: 0.0017976411618292332 score: 1.0
2021-08-08 03:43:47,872 | train | INFO | Epoch 1 train batch 189/450: 3024/7200 mean loss: 0.0017816596664488316 score: 0.9296568627450981
2021-08-08 03:43:48,658 | train | INFO | Epoch 1 train batch 190/450: 3040/7200 mean loss: 0.001816667732782662 score: 0.9705882352941176
2021-08-08 03:43:49,465 | train | INFO | Epoch 1 train batch 191/450: 3056/7200 mean loss: 0.0018715308979153633 score: 1.0
2021-08-08 03:43:50,244 | train | INFO | Epoch 1 train batch 192/450: 3072/7200 mean loss: 0.001781452214345336 score: 1.0
2021-08-08 03:43:51,051 | train | INFO | Epoch 1 train batch 193/450: 3088/7200 mean loss: 0.0018100092420354486 score: 0.9774509803921569
2021-08-08 03:43:51,865 | train | INFO | Epoch 1 train batch 194/450: 3104/7200 mean loss: 0.0017875187331810594 score: 1.0
2021-08-08 03:43:52,679 | train | INFO | Epoch 1 train batch 195/450: 3120/7200 mean loss: 0.001783784944564104 score: 1.0
2021-08-08 03:43:53,498 | train | INFO | Epoch 1 train batch 196/450: 3136/7200 mean loss: 0.0017385759856551886 score: 1.0
2021-08-08 03:43:54,394 | train | INFO | Epoch 1 train batch 197/450: 3152/7200 mean loss: 0.0018309404840692878 score: 1.0
2021-08-08 03:43:55,190 | train | INFO | Epoch 1 train batch 198/450: 3168/7200 mean loss: 0.0017369462875649333 score: 1.0
2021-08-08 03:43:55,999 | train | INFO | Epoch 1 train batch 199/450: 3184/7200 mean loss: 0.0017033722251653671 score: 0.9963235294117647
2021-08-08 03:43:56,821 | train | INFO | Epoch 1 train batch 200/450: 3200/7200 mean loss: 0.0017295541474595666 score: 1.0
2021-08-08 03:43:57,599 | train | INFO | Epoch 1 train batch 201/450: 3216/7200 mean loss: 0.0018590522231534123 score: 1.0
2021-08-08 03:43:58,416 | train | INFO | Epoch 1 train batch 202/450: 3232/7200 mean loss: 0.0017798453336581588 score: 1.0
2021-08-08 03:43:59,240 | train | INFO | Epoch 1 train batch 203/450: 3248/7200 mean loss: 0.0018333131447434425 score: 1.0
2021-08-08 03:44:00,050 | train | INFO | Epoch 1 train batch 204/450: 3264/7200 mean loss: 0.001780645688995719 score: 1.0
2021-08-08 03:44:00,864 | train | INFO | Epoch 1 train batch 205/450: 3280/7200 mean loss: 0.0017996183596551418 score: 1.0
2021-08-08 03:44:01,675 | train | INFO | Epoch 1 train batch 206/450: 3296/7200 mean loss: 0.0017310522962361574 score: 1.0
2021-08-08 03:44:02,450 | train | INFO | Epoch 1 train batch 207/450: 3312/7200 mean loss: 0.0017992279026657343 score: 1.0
2021-08-08 03:44:03,239 | train | INFO | Epoch 1 train batch 208/450: 3328/7200 mean loss: 0.0017932169139385223 score: 1.0
2021-08-08 03:44:04,041 | train | INFO | Epoch 1 train batch 209/450: 3344/7200 mean loss: 0.0017844107933342457 score: 1.0
2021-08-08 03:44:04,831 | train | INFO | Epoch 1 train batch 210/450: 3360/7200 mean loss: 0.0018419414991512895 score: 1.0
2021-08-08 03:44:05,621 | train | INFO | Epoch 1 train batch 211/450: 3376/7200 mean loss: 0.0018300694646313787 score: 0.9154411764705882
2021-08-08 03:44:06,425 | train | INFO | Epoch 1 train batch 212/450: 3392/7200 mean loss: 0.0018050926737487316 score: 1.0
2021-08-08 03:44:07,245 | train | INFO | Epoch 1 train batch 213/450: 3408/7200 mean loss: 0.0018398307729512453 score: 0.966421568627451
2021-08-08 03:44:08,115 | train | INFO | Epoch 1 train batch 214/450: 3424/7200 mean loss: 0.0018398573156446218 score: 1.0
2021-08-08 03:44:08,922 | train | INFO | Epoch 1 train batch 215/450: 3440/7200 mean loss: 0.001710677519440651 score: 0.9926470588235294
2021-08-08 03:44:09,709 | train | INFO | Epoch 1 train batch 216/450: 3456/7200 mean loss: 0.00184961361810565 score: 1.0
2021-08-08 03:44:10,483 | train | INFO | Epoch 1 train batch 217/450: 3472/7200 mean loss: 0.001819203607738018 score: 1.0
2021-08-08 03:44:11,263 | train | INFO | Epoch 1 train batch 218/450: 3488/7200 mean loss: 0.0017779907211661339 score: 1.0
2021-08-08 03:44:12,189 | train | INFO | Epoch 1 train batch 219/450: 3504/7200 mean loss: 0.001764250104315579 score: 1.0
2021-08-08 03:44:13,015 | train | INFO | Epoch 1 train batch 220/450: 3520/7200 mean loss: 0.0018404178554192185 score: 1.0
2021-08-08 03:44:13,797 | train | INFO | Epoch 1 train batch 221/450: 3536/7200 mean loss: 0.0018333431798964739 score: 1.0
2021-08-08 03:44:14,709 | train | INFO | Epoch 1 train batch 222/450: 3552/7200 mean loss: 0.0018410864286124706 score: 1.0
2021-08-08 03:44:15,516 | train | INFO | Epoch 1 train batch 223/450: 3568/7200 mean loss: 0.0017924676649272442 score: 0.9889705882352942
2021-08-08 03:44:16,309 | train | INFO | Epoch 1 train batch 224/450: 3584/7200 mean loss: 0.0017526248702779412 score: 1.0
2021-08-08 03:44:17,095 | train | INFO | Epoch 1 train batch 225/450: 3600/7200 mean loss: 0.0017660781741142273 score: 1.0
2021-08-08 03:44:17,882 | train | INFO | Epoch 1 train batch 226/450: 3616/7200 mean loss: 0.001733678742311895 score: 0.9926470588235294
2021-08-08 03:44:18,665 | train | INFO | Epoch 1 train batch 227/450: 3632/7200 mean loss: 0.0016877598827704787 score: 0.9779411764705882
2021-08-08 03:44:19,443 | train | INFO | Epoch 1 train batch 228/450: 3648/7200 mean loss: 0.0018018533010035753 score: 1.0
2021-08-08 03:44:20,251 | train | INFO | Epoch 1 train batch 229/450: 3664/7200 mean loss: 0.0017630817601457238 score: 1.0
2021-08-08 03:44:21,052 | train | INFO | Epoch 1 train batch 230/450: 3680/7200 mean loss: 0.0017771130660548806 score: 0.9776960784313725
2021-08-08 03:44:21,855 | train | INFO | Epoch 1 train batch 231/450: 3696/7200 mean loss: 0.001735445111989975 score: 0.996078431372549
2021-08-08 03:44:22,632 | train | INFO | Epoch 1 train batch 232/450: 3712/7200 mean loss: 0.0017647494096308947 score: 1.0
2021-08-08 03:44:23,432 | train | INFO | Epoch 1 train batch 233/450: 3728/7200 mean loss: 0.0017321298364549875 score: 1.0
2021-08-08 03:44:24,215 | train | INFO | Epoch 1 train batch 234/450: 3744/7200 mean loss: 0.0016582816606387496 score: 1.0
2021-08-08 03:44:24,995 | train | INFO | Epoch 1 train batch 235/450: 3760/7200 mean loss: 0.0018033540109172463 score: 1.0
2021-08-08 03:44:25,774 | train | INFO | Epoch 1 train batch 236/450: 3776/7200 mean loss: 0.0017879210645332932 score: 1.0
2021-08-08 03:44:26,564 | train | INFO | Epoch 1 train batch 237/450: 3792/7200 mean loss: 0.0016929071862250566 score: 1.0
2021-08-08 03:44:27,348 | train | INFO | Epoch 1 train batch 238/450: 3808/7200 mean loss: 0.001762586529366672 score: 0.9926470588235294
2021-08-08 03:44:28,155 | train | INFO | Epoch 1 train batch 239/450: 3824/7200 mean loss: 0.0017676466377452016 score: 0.9926470588235294
2021-08-08 03:44:28,945 | train | INFO | Epoch 1 train batch 240/450: 3840/7200 mean loss: 0.001822563004679978 score: 1.0
2021-08-08 03:44:29,732 | train | INFO | Epoch 1 train batch 241/450: 3856/7200 mean loss: 0.001766602392308414 score: 1.0
2021-08-08 03:44:30,545 | train | INFO | Epoch 1 train batch 242/450: 3872/7200 mean loss: 0.0018661478534340858 score: 1.0
2021-08-08 03:44:31,412 | train | INFO | Epoch 1 train batch 243/450: 3888/7200 mean loss: 0.001783229410648346 score: 1.0
2021-08-08 03:44:32,254 | train | INFO | Epoch 1 train batch 244/450: 3904/7200 mean loss: 0.001863836427219212 score: 1.0
2021-08-08 03:44:33,096 | train | INFO | Epoch 1 train batch 245/450: 3920/7200 mean loss: 0.001847105915658176 score: 1.0
2021-08-08 03:44:34,047 | train | INFO | Epoch 1 train batch 246/450: 3936/7200 mean loss: 0.001863505458459258 score: 1.0
2021-08-08 03:44:34,913 | train | INFO | Epoch 1 train batch 247/450: 3952/7200 mean loss: 0.0018682489171624184 score: 0.996078431372549
2021-08-08 03:44:35,768 | train | INFO | Epoch 1 train batch 248/450: 3968/7200 mean loss: 0.0017964658327400684 score: 1.0
2021-08-08 03:44:36,620 | train | INFO | Epoch 1 train batch 249/450: 3984/7200 mean loss: 0.0017321495106443763 score: 1.0
2021-08-08 03:44:37,490 | train | INFO | Epoch 1 train batch 250/450: 4000/7200 mean loss: 0.0017993624787777662 score: 1.0
2021-08-08 03:44:38,271 | train | INFO | Epoch 1 train batch 251/450: 4016/7200 mean loss: 0.0018540441524237394 score: 1.0
2021-08-08 03:44:39,143 | train | INFO | Epoch 1 train batch 252/450: 4032/7200 mean loss: 0.0018735352205112576 score: 1.0
2021-08-08 03:44:39,953 | train | INFO | Epoch 1 train batch 253/450: 4048/7200 mean loss: 0.001781667466275394 score: 0.9889705882352942
2021-08-08 03:44:40,840 | train | INFO | Epoch 1 train batch 254/450: 4064/7200 mean loss: 0.0018250220455229282 score: 1.0
2021-08-08 03:44:41,749 | train | INFO | Epoch 1 train batch 255/450: 4080/7200 mean loss: 0.0018583076307550073 score: 1.0
2021-08-08 03:44:42,705 | train | INFO | Epoch 1 train batch 256/450: 4096/7200 mean loss: 0.0018437303369864821 score: 1.0
2021-08-08 03:44:43,903 | train | INFO | Epoch 1 train batch 257/450: 4112/7200 mean loss: 0.001817165408283472 score: 1.0
2021-08-08 03:44:44,781 | train | INFO | Epoch 1 train batch 258/450: 4128/7200 mean loss: 0.0017152412328869104 score: 1.0
2021-08-08 03:44:45,601 | train | INFO | Epoch 1 train batch 259/450: 4144/7200 mean loss: 0.0017691351240500808 score: 1.0
2021-08-08 03:44:46,385 | train | INFO | Epoch 1 train batch 260/450: 4160/7200 mean loss: 0.0016543632373213768 score: 1.0
2021-08-08 03:44:47,197 | train | INFO | Epoch 1 train batch 261/450: 4176/7200 mean loss: 0.0018304969416931272 score: 1.0
2021-08-08 03:44:47,979 | train | INFO | Epoch 1 train batch 262/450: 4192/7200 mean loss: 0.0017189527861773968 score: 1.0
2021-08-08 03:44:48,834 | train | INFO | Epoch 1 train batch 263/450: 4208/7200 mean loss: 0.0017542076529935002 score: 1.0
2021-08-08 03:44:49,615 | train | INFO | Epoch 1 train batch 264/450: 4224/7200 mean loss: 0.0018034515669569373 score: 0.9852941176470589
2021-08-08 03:44:50,405 | train | INFO | Epoch 1 train batch 265/450: 4240/7200 mean loss: 0.0018050079233944416 score: 1.0
2021-08-08 03:44:51,212 | train | INFO | Epoch 1 train batch 266/450: 4256/7200 mean loss: 0.0017353568691760302 score: 0.9884453781512604
2021-08-08 03:44:52,062 | train | INFO | Epoch 1 train batch 267/450: 4272/7200 mean loss: 0.001747025060467422 score: 0.9926470588235294
2021-08-08 03:44:52,930 | train | INFO | Epoch 1 train batch 268/450: 4288/7200 mean loss: 0.001750192721374333 score: 1.0
2021-08-08 03:44:53,739 | train | INFO | Epoch 1 train batch 269/450: 4304/7200 mean loss: 0.0017687168437987566 score: 1.0
2021-08-08 03:44:54,541 | train | INFO | Epoch 1 train batch 270/450: 4320/7200 mean loss: 0.0017820949433371425 score: 1.0
2021-08-08 03:44:55,322 | train | INFO | Epoch 1 train batch 271/450: 4336/7200 mean loss: 0.0018425469752401114 score: 1.0
2021-08-08 03:44:56,129 | train | INFO | Epoch 1 train batch 272/450: 4352/7200 mean loss: 0.0017817472107708454 score: 0.9924019607843138
2021-08-08 03:44:56,949 | train | INFO | Epoch 1 train batch 273/450: 4368/7200 mean loss: 0.0018427016912028193 score: 1.0
2021-08-08 03:44:57,760 | train | INFO | Epoch 1 train batch 274/450: 4384/7200 mean loss: 0.001825620885938406 score: 1.0
2021-08-08 03:44:58,570 | train | INFO | Epoch 1 train batch 275/450: 4400/7200 mean loss: 0.001864666468463838 score: 0.9816176470588235
2021-08-08 03:44:59,373 | train | INFO | Epoch 1 train batch 276/450: 4416/7200 mean loss: 0.0017734445864334702 score: 1.0
2021-08-08 03:45:00,155 | train | INFO | Epoch 1 train batch 277/450: 4432/7200 mean loss: 0.0017881699604913592 score: 1.0
2021-08-08 03:45:00,959 | train | INFO | Epoch 1 train batch 278/450: 4448/7200 mean loss: 0.0017293132841587067 score: 0.9700980392156863
2021-08-08 03:45:01,731 | train | INFO | Epoch 1 train batch 279/450: 4464/7200 mean loss: 0.00178877345751971 score: 1.0
2021-08-08 03:45:02,518 | train | INFO | Epoch 1 train batch 280/450: 4480/7200 mean loss: 0.0017854210454970598 score: 1.0
2021-08-08 03:45:03,301 | train | INFO | Epoch 1 train batch 281/450: 4496/7200 mean loss: 0.0017479677917435765 score: 1.0
2021-08-08 03:45:04,090 | train | INFO | Epoch 1 train batch 282/450: 4512/7200 mean loss: 0.0017562502762302756 score: 1.0
2021-08-08 03:45:04,915 | train | INFO | Epoch 1 train batch 283/450: 4528/7200 mean loss: 0.0018659025663509965 score: 0.9648459383753502
2021-08-08 03:45:05,731 | train | INFO | Epoch 1 train batch 284/450: 4544/7200 mean loss: 0.0017973227659240365 score: 0.9963235294117647
2021-08-08 03:45:06,550 | train | INFO | Epoch 1 train batch 285/450: 4560/7200 mean loss: 0.0017621921142563224 score: 0.9963235294117647
2021-08-08 03:45:07,366 | train | INFO | Epoch 1 train batch 286/450: 4576/7200 mean loss: 0.0018635543528944254 score: 1.0
2021-08-08 03:45:08,178 | train | INFO | Epoch 1 train batch 287/450: 4592/7200 mean loss: 0.0017704133642837405 score: 1.0
2021-08-08 03:45:08,979 | train | INFO | Epoch 1 train batch 288/450: 4608/7200 mean loss: 0.0017943198326975107 score: 0.9772058823529413
2021-08-08 03:45:09,812 | train | INFO | Epoch 1 train batch 289/450: 4624/7200 mean loss: 0.0018554809503257275 score: 0.9816176470588235
2021-08-08 03:45:10,601 | train | INFO | Epoch 1 train batch 290/450: 4640/7200 mean loss: 0.0018503626342862844 score: 1.0
2021-08-08 03:45:11,383 | train | INFO | Epoch 1 train batch 291/450: 4656/7200 mean loss: 0.0018130335956811905 score: 1.0
2021-08-08 03:45:12,182 | train | INFO | Epoch 1 train batch 292/450: 4672/7200 mean loss: 0.0018964605405926704 score: 1.0
2021-08-08 03:45:12,970 | train | INFO | Epoch 1 train batch 293/450: 4688/7200 mean loss: 0.0017903238767758012 score: 1.0
2021-08-08 03:45:13,789 | train | INFO | Epoch 1 train batch 294/450: 4704/7200 mean loss: 0.0017408446874469519 score: 1.0
2021-08-08 03:45:14,605 | train | INFO | Epoch 1 train batch 295/450: 4720/7200 mean loss: 0.0017774474108591676 score: 0.996078431372549
2021-08-08 03:45:15,411 | train | INFO | Epoch 1 train batch 296/450: 4736/7200 mean loss: 0.0017728768289089203 score: 1.0
2021-08-08 03:45:16,192 | train | INFO | Epoch 1 train batch 297/450: 4752/7200 mean loss: 0.0017407585401088 score: 0.9543067226890756
2021-08-08 03:45:17,014 | train | INFO | Epoch 1 train batch 298/450: 4768/7200 mean loss: 0.001745457062497735 score: 1.0
2021-08-08 03:45:17,840 | train | INFO | Epoch 1 train batch 299/450: 4784/7200 mean loss: 0.0018191339913755655 score: 1.0
2021-08-08 03:45:18,654 | train | INFO | Epoch 1 train batch 300/450: 4800/7200 mean loss: 0.0018031597137451172 score: 1.0
2021-08-08 03:45:19,454 | train | INFO | Epoch 1 train batch 301/450: 4816/7200 mean loss: 0.0017991072963923216 score: 0.9926470588235294
2021-08-08 03:45:20,269 | train | INFO | Epoch 1 train batch 302/450: 4832/7200 mean loss: 0.0017031215829774737 score: 1.0
2021-08-08 03:45:21,041 | train | INFO | Epoch 1 train batch 303/450: 4848/7200 mean loss: 0.001749133225530386 score: 0.9514705882352942
2021-08-08 03:45:21,826 | train | INFO | Epoch 1 train batch 304/450: 4864/7200 mean loss: 0.0017761493800207973 score: 0.9830882352941176
2021-08-08 03:45:22,655 | train | INFO | Epoch 1 train batch 305/450: 4880/7200 mean loss: 0.0018422971479594707 score: 1.0
2021-08-08 03:45:23,442 | train | INFO | Epoch 1 train batch 306/450: 4896/7200 mean loss: 0.00164337910246104 score: 1.0
2021-08-08 03:45:24,226 | train | INFO | Epoch 1 train batch 307/450: 4912/7200 mean loss: 0.001833598013035953 score: 0.9774509803921569
2021-08-08 03:45:25,039 | train | INFO | Epoch 1 train batch 308/450: 4928/7200 mean loss: 0.0017442748649045825 score: 1.0
2021-08-08 03:45:25,814 | train | INFO | Epoch 1 train batch 309/450: 4944/7200 mean loss: 0.0018236212199553847 score: 1.0
2021-08-08 03:45:26,597 | train | INFO | Epoch 1 train batch 310/450: 4960/7200 mean loss: 0.0017909527523443103 score: 1.0
2021-08-08 03:45:27,381 | train | INFO | Epoch 1 train batch 311/450: 4976/7200 mean loss: 0.00176525698043406 score: 1.0
2021-08-08 03:45:28,160 | train | INFO | Epoch 1 train batch 312/450: 4992/7200 mean loss: 0.0016834358684718609 score: 1.0
2021-08-08 03:45:28,967 | train | INFO | Epoch 1 train batch 313/450: 5008/7200 mean loss: 0.0018376928055658937 score: 0.9889705882352942
2021-08-08 03:45:29,765 | train | INFO | Epoch 1 train batch 314/450: 5024/7200 mean loss: 0.0017246530624106526 score: 1.0
2021-08-08 03:45:30,547 | train | INFO | Epoch 1 train batch 315/450: 5040/7200 mean loss: 0.0018775268690660596 score: 0.9848039215686275
2021-08-08 03:45:31,339 | train | INFO | Epoch 1 train batch 316/450: 5056/7200 mean loss: 0.001815450144931674 score: 0.9848039215686275
2021-08-08 03:45:32,154 | train | INFO | Epoch 1 train batch 317/450: 5072/7200 mean loss: 0.0017762628849595785 score: 1.0
2021-08-08 03:45:32,933 | train | INFO | Epoch 1 train batch 318/450: 5088/7200 mean loss: 0.0017780726775527 score: 1.0
2021-08-08 03:45:33,733 | train | INFO | Epoch 1 train batch 319/450: 5104/7200 mean loss: 0.0018871222855523229 score: 1.0
2021-08-08 03:45:34,522 | train | INFO | Epoch 1 train batch 320/450: 5120/7200 mean loss: 0.0018296787748113275 score: 1.0
2021-08-08 03:45:35,347 | train | INFO | Epoch 1 train batch 321/450: 5136/7200 mean loss: 0.0018059455323964357 score: 0.9470588235294118
2021-08-08 03:45:36,156 | train | INFO | Epoch 1 train batch 322/450: 5152/7200 mean loss: 0.001896306057460606 score: 1.0
2021-08-08 03:45:36,931 | train | INFO | Epoch 1 train batch 323/450: 5168/7200 mean loss: 0.0018361343536525965 score: 0.9776960784313725
2021-08-08 03:45:37,739 | train | INFO | Epoch 1 train batch 324/450: 5184/7200 mean loss: 0.0018308699363842607 score: 1.0
2021-08-08 03:45:38,556 | train | INFO | Epoch 1 train batch 325/450: 5200/7200 mean loss: 0.0016312615480273962 score: 0.9963235294117647
2021-08-08 03:45:39,356 | train | INFO | Epoch 1 train batch 326/450: 5216/7200 mean loss: 0.0017054268391802907 score: 0.9926470588235294
2021-08-08 03:45:40,128 | train | INFO | Epoch 1 train batch 327/450: 5232/7200 mean loss: 0.0017053867923095822 score: 1.0
2021-08-08 03:45:40,942 | train | INFO | Epoch 1 train batch 328/450: 5248/7200 mean loss: 0.001751395990140736 score: 1.0
2021-08-08 03:45:41,783 | train | INFO | Epoch 1 train batch 329/450: 5264/7200 mean loss: 0.0017863847315311432 score: 0.9889705882352942
2021-08-08 03:45:42,603 | train | INFO | Epoch 1 train batch 330/450: 5280/7200 mean loss: 0.0018009396735578775 score: 1.0
2021-08-08 03:45:43,377 | train | INFO | Epoch 1 train batch 331/450: 5296/7200 mean loss: 0.0017997418763116002 score: 0.9805672268907564
2021-08-08 03:45:44,154 | train | INFO | Epoch 1 train batch 332/450: 5312/7200 mean loss: 0.0018944770563393831 score: 0.8491946778711486
2021-08-08 03:45:44,940 | train | INFO | Epoch 1 train batch 333/450: 5328/7200 mean loss: 0.0018494173418730497 score: 0.9772058823529413
2021-08-08 03:45:45,718 | train | INFO | Epoch 1 train batch 334/450: 5344/7200 mean loss: 0.0017239777371287346 score: 1.0
2021-08-08 03:45:46,498 | train | INFO | Epoch 1 train batch 335/450: 5360/7200 mean loss: 0.0016409718664363027 score: 0.996078431372549
2021-08-08 03:45:47,316 | train | INFO | Epoch 1 train batch 336/450: 5376/7200 mean loss: 0.0017277667066082358 score: 1.0
2021-08-08 03:45:48,134 | train | INFO | Epoch 1 train batch 337/450: 5392/7200 mean loss: 0.0018197317840531468 score: 0.9887254901960785
2021-08-08 03:45:48,930 | train | INFO | Epoch 1 train batch 338/450: 5408/7200 mean loss: 0.001730991411022842 score: 0.9963235294117647
2021-08-08 03:45:49,714 | train | INFO | Epoch 1 train batch 339/450: 5424/7200 mean loss: 0.0017846020637080073 score: 1.0
2021-08-08 03:45:50,544 | train | INFO | Epoch 1 train batch 340/450: 5440/7200 mean loss: 0.0018325807759538293 score: 1.0
2021-08-08 03:45:51,323 | train | INFO | Epoch 1 train batch 341/450: 5456/7200 mean loss: 0.0016998406499624252 score: 1.0
2021-08-08 03:45:52,102 | train | INFO | Epoch 1 train batch 342/450: 5472/7200 mean loss: 0.001798645593225956 score: 1.0
2021-08-08 03:45:52,878 | train | INFO | Epoch 1 train batch 343/450: 5488/7200 mean loss: 0.0017687203362584114 score: 1.0
2021-08-08 03:45:53,718 | train | INFO | Epoch 1 train batch 344/450: 5504/7200 mean loss: 0.0017364945961162448 score: 1.0
2021-08-08 03:45:54,517 | train | INFO | Epoch 1 train batch 345/450: 5520/7200 mean loss: 0.0018774816999211907 score: 0.9963235294117647
2021-08-08 03:45:55,326 | train | INFO | Epoch 1 train batch 346/450: 5536/7200 mean loss: 0.0018150340765714645 score: 0.9963235294117647
2021-08-08 03:45:56,100 | train | INFO | Epoch 1 train batch 347/450: 5552/7200 mean loss: 0.001761851366609335 score: 1.0
2021-08-08 03:45:56,926 | train | INFO | Epoch 1 train batch 348/450: 5568/7200 mean loss: 0.0018524036277085543 score: 1.0
2021-08-08 03:45:57,729 | train | INFO | Epoch 1 train batch 349/450: 5584/7200 mean loss: 0.0017188501078635454 score: 1.0
2021-08-08 03:45:58,497 | train | INFO | Epoch 1 train batch 350/450: 5600/7200 mean loss: 0.0018635789165273309 score: 0.9926470588235294
2021-08-08 03:45:59,264 | train | INFO | Epoch 1 train batch 351/450: 5616/7200 mean loss: 0.001659519737586379 score: 1.0
2021-08-08 03:46:00,059 | train | INFO | Epoch 1 train batch 352/450: 5632/7200 mean loss: 0.001620795577764511 score: 0.9963235294117647
2021-08-08 03:46:00,959 | train | INFO | Epoch 1 train batch 353/450: 5648/7200 mean loss: 0.0018569576786831021 score: 0.99187675070028
2021-08-08 03:46:01,767 | train | INFO | Epoch 1 train batch 354/450: 5664/7200 mean loss: 0.001814455958083272 score: 0.7044117647058823
2021-08-08 03:46:02,578 | train | INFO | Epoch 1 train batch 355/450: 5680/7200 mean loss: 0.0018228553235530853 score: 1.0
2021-08-08 03:46:03,355 | train | INFO | Epoch 1 train batch 356/450: 5696/7200 mean loss: 0.0017165109748020768 score: 1.0
2021-08-08 03:46:04,167 | train | INFO | Epoch 1 train batch 357/450: 5712/7200 mean loss: 0.001795911812223494 score: 1.0
2021-08-08 03:46:04,971 | train | INFO | Epoch 1 train batch 358/450: 5728/7200 mean loss: 0.0017455684719607234 score: 1.0
2021-08-08 03:46:05,739 | train | INFO | Epoch 1 train batch 359/450: 5744/7200 mean loss: 0.0016890611732378602 score: 1.0
2021-08-08 03:46:06,549 | train | INFO | Epoch 1 train batch 360/450: 5760/7200 mean loss: 0.0017770410049706697 score: 1.0
2021-08-08 03:46:07,339 | train | INFO | Epoch 1 train batch 361/450: 5776/7200 mean loss: 0.0017813785234466195 score: 0.9963235294117647
2021-08-08 03:46:08,126 | train | INFO | Epoch 1 train batch 362/450: 5792/7200 mean loss: 0.0017683731857687235 score: 1.0
2021-08-08 03:46:08,906 | train | INFO | Epoch 1 train batch 363/450: 5808/7200 mean loss: 0.0018067335477098823 score: 1.0
2021-08-08 03:46:09,779 | train | INFO | Epoch 1 train batch 364/450: 5824/7200 mean loss: 0.0017245943890884519 score: 1.0
2021-08-08 03:46:10,612 | train | INFO | Epoch 1 train batch 365/450: 5840/7200 mean loss: 0.0017490562750026584 score: 1.0
2021-08-08 03:46:11,414 | train | INFO | Epoch 1 train batch 366/450: 5856/7200 mean loss: 0.0018104101764038205 score: 1.0
2021-08-08 03:46:12,185 | train | INFO | Epoch 1 train batch 367/450: 5872/7200 mean loss: 0.0018277607159689069 score: 1.0
2021-08-08 03:46:12,958 | train | INFO | Epoch 1 train batch 368/450: 5888/7200 mean loss: 0.0017445802222937346 score: 0.9921218487394957
2021-08-08 03:46:13,755 | train | INFO | Epoch 1 train batch 369/450: 5904/7200 mean loss: 0.0018519496079534292 score: 1.0
2021-08-08 03:46:14,545 | train | INFO | Epoch 1 train batch 370/450: 5920/7200 mean loss: 0.0018217915203422308 score: 1.0
2021-08-08 03:46:15,332 | train | INFO | Epoch 1 train batch 371/450: 5936/7200 mean loss: 0.0018425522139295936 score: 1.0
2021-08-08 03:46:16,104 | train | INFO | Epoch 1 train batch 372/450: 5952/7200 mean loss: 0.0017613681266084313 score: 1.0
2021-08-08 03:46:16,881 | train | INFO | Epoch 1 train batch 373/450: 5968/7200 mean loss: 0.0017198867863044143 score: 0.9813725490196079
2021-08-08 03:46:17,688 | train | INFO | Epoch 1 train batch 374/450: 5984/7200 mean loss: 0.0017759108450263739 score: 1.0
2021-08-08 03:46:18,461 | train | INFO | Epoch 1 train batch 375/450: 6000/7200 mean loss: 0.0016906711971387267 score: 1.0
2021-08-08 03:46:19,270 | train | INFO | Epoch 1 train batch 376/450: 6016/7200 mean loss: 0.0017116471426561475 score: 1.0
2021-08-08 03:46:20,043 | train | INFO | Epoch 1 train batch 377/450: 6032/7200 mean loss: 0.0017636201810091734 score: 1.0
2021-08-08 03:46:20,815 | train | INFO | Epoch 1 train batch 378/450: 6048/7200 mean loss: 0.0017278086161240935 score: 1.0
2021-08-08 03:46:21,617 | train | INFO | Epoch 1 train batch 379/450: 6064/7200 mean loss: 0.0017356774769723415 score: 1.0
2021-08-08 03:46:22,393 | train | INFO | Epoch 1 train batch 380/450: 6080/7200 mean loss: 0.0016686971066519618 score: 1.0
2021-08-08 03:46:23,215 | train | INFO | Epoch 1 train batch 381/450: 6096/7200 mean loss: 0.0018042484298348427 score: 1.0
2021-08-08 03:46:24,008 | train | INFO | Epoch 1 train batch 382/450: 6112/7200 mean loss: 0.0017731830012053251 score: 1.0
2021-08-08 03:46:24,806 | train | INFO | Epoch 1 train batch 383/450: 6128/7200 mean loss: 0.0017814146121963859 score: 1.0
2021-08-08 03:46:25,579 | train | INFO | Epoch 1 train batch 384/450: 6144/7200 mean loss: 0.0018104898044839501 score: 1.0
2021-08-08 03:46:26,344 | train | INFO | Epoch 1 train batch 385/450: 6160/7200 mean loss: 0.0017229393124580383 score: 0.9889705882352942
2021-08-08 03:46:27,149 | train | INFO | Epoch 1 train batch 386/450: 6176/7200 mean loss: 0.0018650188576430082 score: 1.0
2021-08-08 03:46:27,973 | train | INFO | Epoch 1 train batch 387/450: 6192/7200 mean loss: 0.0018583687487989664 score: 1.0
2021-08-08 03:46:28,773 | train | INFO | Epoch 1 train batch 388/450: 6208/7200 mean loss: 0.0017756320303305984 score: 1.0
2021-08-08 03:46:29,567 | train | INFO | Epoch 1 train batch 389/450: 6224/7200 mean loss: 0.0018023181473836303 score: 0.9926470588235294
2021-08-08 03:46:30,340 | train | INFO | Epoch 1 train batch 390/450: 6240/7200 mean loss: 0.0016484478255733848 score: 1.0
2021-08-08 03:46:31,114 | train | INFO | Epoch 1 train batch 391/450: 6256/7200 mean loss: 0.0017538033425807953 score: 1.0
2021-08-08 03:46:31,896 | train | INFO | Epoch 1 train batch 392/450: 6272/7200 mean loss: 0.0017456613713875413 score: 1.0
2021-08-08 03:46:32,673 | train | INFO | Epoch 1 train batch 393/450: 6288/7200 mean loss: 0.0016469219699501991 score: 0.9740196078431372
2021-08-08 03:46:33,447 | train | INFO | Epoch 1 train batch 394/450: 6304/7200 mean loss: 0.00172806263435632 score: 1.0
2021-08-08 03:46:34,221 | train | INFO | Epoch 1 train batch 395/450: 6320/7200 mean loss: 0.0016127856215462089 score: 1.0
2021-08-08 03:46:34,993 | train | INFO | Epoch 1 train batch 396/450: 6336/7200 mean loss: 0.0017285243375226855 score: 1.0
2021-08-08 03:46:35,785 | train | INFO | Epoch 1 train batch 397/450: 6352/7200 mean loss: 0.0017075801733881235 score: 1.0
2021-08-08 03:46:36,589 | train | INFO | Epoch 1 train batch 398/450: 6368/7200 mean loss: 0.0018074242398142815 score: 1.0
2021-08-08 03:46:37,428 | train | INFO | Epoch 1 train batch 399/450: 6384/7200 mean loss: 0.001778697012923658 score: 1.0
2021-08-08 03:46:38,213 | train | INFO | Epoch 1 train batch 400/450: 6400/7200 mean loss: 0.001802811399102211 score: 0.9705882352941176
2021-08-08 03:46:38,991 | train | INFO | Epoch 1 train batch 401/450: 6416/7200 mean loss: 0.001794281997717917 score: 1.0
2021-08-08 03:46:39,768 | train | INFO | Epoch 1 train batch 402/450: 6432/7200 mean loss: 0.0017785310046747327 score: 0.9816176470588235
2021-08-08 03:46:40,642 | train | INFO | Epoch 1 train batch 403/450: 6448/7200 mean loss: 0.0016675051301717758 score: 0.9889705882352942
2021-08-08 03:46:41,461 | train | INFO | Epoch 1 train batch 404/450: 6464/7200 mean loss: 0.00178334501106292 score: 1.0
2021-08-08 03:46:42,248 | train | INFO | Epoch 1 train batch 405/450: 6480/7200 mean loss: 0.0017586629837751389 score: 1.0
2021-08-08 03:46:43,033 | train | INFO | Epoch 1 train batch 406/450: 6496/7200 mean loss: 0.001668367418460548 score: 1.0
2021-08-08 03:46:43,803 | train | INFO | Epoch 1 train batch 407/450: 6512/7200 mean loss: 0.001826938008889556 score: 1.0
2021-08-08 03:46:44,600 | train | INFO | Epoch 1 train batch 408/450: 6528/7200 mean loss: 0.001700634486041963 score: 0.9811274509803922
2021-08-08 03:46:45,393 | train | INFO | Epoch 1 train batch 409/450: 6544/7200 mean loss: 0.0017975382506847382 score: 0.9776960784313725
2021-08-08 03:46:46,237 | train | INFO | Epoch 1 train batch 410/450: 6560/7200 mean loss: 0.0017650485970079899 score: 1.0
2021-08-08 03:46:47,015 | train | INFO | Epoch 1 train batch 411/450: 6576/7200 mean loss: 0.001619243063032627 score: 1.0
2021-08-08 03:46:47,827 | train | INFO | Epoch 1 train batch 412/450: 6592/7200 mean loss: 0.0017543305875733495 score: 0.9926470588235294
2021-08-08 03:46:48,608 | train | INFO | Epoch 1 train batch 413/450: 6608/7200 mean loss: 0.0016744737513363361 score: 1.0
2021-08-08 03:46:49,387 | train | INFO | Epoch 1 train batch 414/450: 6624/7200 mean loss: 0.0016336862463504076 score: 1.0
2021-08-08 03:46:50,163 | train | INFO | Epoch 1 train batch 415/450: 6640/7200 mean loss: 0.0016925575910136104 score: 1.0
2021-08-08 03:46:50,991 | train | INFO | Epoch 1 train batch 416/450: 6656/7200 mean loss: 0.0017361538484692574 score: 0.9514705882352942
2021-08-08 03:46:51,763 | train | INFO | Epoch 1 train batch 417/450: 6672/7200 mean loss: 0.001663060043938458 score: 1.0
2021-08-08 03:46:52,535 | train | INFO | Epoch 1 train batch 418/450: 6688/7200 mean loss: 0.0017356259049847722 score: 1.0
2021-08-08 03:46:53,349 | train | INFO | Epoch 1 train batch 419/450: 6704/7200 mean loss: 0.001737019163556397 score: 0.9926470588235294
2021-08-08 03:46:54,155 | train | INFO | Epoch 1 train batch 420/450: 6720/7200 mean loss: 0.0017541530542075634 score: 1.0
2021-08-08 03:46:54,972 | train | INFO | Epoch 1 train batch 421/450: 6736/7200 mean loss: 0.0018342576222494245 score: 1.0
2021-08-08 03:46:55,763 | train | INFO | Epoch 1 train batch 422/450: 6752/7200 mean loss: 0.0015960034215822816 score: 0.9963235294117647
2021-08-08 03:46:56,540 | train | INFO | Epoch 1 train batch 423/450: 6768/7200 mean loss: 0.0017458113143220544 score: 1.0
2021-08-08 03:46:57,313 | train | INFO | Epoch 1 train batch 424/450: 6784/7200 mean loss: 0.001716571394354105 score: 0.9963235294117647
2021-08-08 03:46:58,091 | train | INFO | Epoch 1 train batch 425/450: 6800/7200 mean loss: 0.0017553948564454913 score: 1.0
2021-08-08 03:46:58,884 | train | INFO | Epoch 1 train batch 426/450: 6816/7200 mean loss: 0.0018641751958057284 score: 0.9921568627450981
2021-08-08 03:46:59,653 | train | INFO | Epoch 1 train batch 427/450: 6832/7200 mean loss: 0.0016616072971373796 score: 1.0
2021-08-08 03:47:00,448 | train | INFO | Epoch 1 train batch 428/450: 6848/7200 mean loss: 0.0017493267077952623 score: 1.0
2021-08-08 03:47:01,235 | train | INFO | Epoch 1 train batch 429/450: 6864/7200 mean loss: 0.0018419163534417748 score: 1.0
2021-08-08 03:47:02,037 | train | INFO | Epoch 1 train batch 430/450: 6880/7200 mean loss: 0.0017418150091543794 score: 0.9889705882352942
2021-08-08 03:47:02,823 | train | INFO | Epoch 1 train batch 431/450: 6896/7200 mean loss: 0.0017929942114278674 score: 0.9963235294117647
2021-08-08 03:47:03,597 | train | INFO | Epoch 1 train batch 432/450: 6912/7200 mean loss: 0.0016937648179009557 score: 0.9926470588235294
2021-08-08 03:47:04,367 | train | INFO | Epoch 1 train batch 433/450: 6928/7200 mean loss: 0.0018041386501863599 score: 1.0
2021-08-08 03:47:05,155 | train | INFO | Epoch 1 train batch 434/450: 6944/7200 mean loss: 0.001691498444415629 score: 1.0
2021-08-08 03:47:05,934 | train | INFO | Epoch 1 train batch 435/450: 6960/7200 mean loss: 0.0016176209319382906 score: 0.9813725490196079
2021-08-08 03:47:06,738 | train | INFO | Epoch 1 train batch 436/450: 6976/7200 mean loss: 0.0017528425669297576 score: 0.9884453781512604
2021-08-08 03:47:07,522 | train | INFO | Epoch 1 train batch 437/450: 6992/7200 mean loss: 0.00173280481249094 score: 1.0
2021-08-08 03:47:08,292 | train | INFO | Epoch 1 train batch 438/450: 7008/7200 mean loss: 0.0018218361074104905 score: 0.9926470588235294
2021-08-08 03:47:09,062 | train | INFO | Epoch 1 train batch 439/450: 7024/7200 mean loss: 0.0017009737202897668 score: 0.9924019607843138
2021-08-08 03:47:09,835 | train | INFO | Epoch 1 train batch 440/450: 7040/7200 mean loss: 0.0018190860282629728 score: 1.0
2021-08-08 03:47:10,609 | train | INFO | Epoch 1 train batch 441/450: 7056/7200 mean loss: 0.0016380049055442214 score: 1.0
2021-08-08 03:47:11,377 | train | INFO | Epoch 1 train batch 442/450: 7072/7200 mean loss: 0.0017144731245934963 score: 1.0
2021-08-08 03:47:12,144 | train | INFO | Epoch 1 train batch 443/450: 7088/7200 mean loss: 0.0017350200796499848 score: 1.0
2021-08-08 03:47:12,912 | train | INFO | Epoch 1 train batch 444/450: 7104/7200 mean loss: 0.0017648778157308698 score: 1.0
2021-08-08 03:47:13,680 | train | INFO | Epoch 1 train batch 445/450: 7120/7200 mean loss: 0.0017201716545969248 score: 0.8826680672268907
2021-08-08 03:47:14,454 | train | INFO | Epoch 1 train batch 446/450: 7136/7200 mean loss: 0.001728752045892179 score: 1.0
2021-08-08 03:47:15,234 | train | INFO | Epoch 1 train batch 447/450: 7152/7200 mean loss: 0.0016809748485684395 score: 0.9963235294117647
2021-08-08 03:47:16,011 | train | INFO | Epoch 1 train batch 448/450: 7168/7200 mean loss: 0.0017740215407684445 score: 0.9926470588235294
2021-08-08 03:47:16,790 | train | INFO | Epoch 1 train batch 449/450: 7184/7200 mean loss: 0.0017333484720438719 score: 1.0
2021-08-08 03:47:16,970 | train | INFO | Epoch 1, Train, Mean loss: 0.028838227395382193, Score: 0.9930967763173645
2021-08-08 03:47:18,487 | train | INFO | Epoch 1 validation batch 0/113: 0/1800 mean loss: 0.001518809818662703 score: 1.0
2021-08-08 03:47:18,746 | train | INFO | Epoch 1 validation batch 1/113: 16/1800 mean loss: 0.0014852674212306738 score: 1.0
2021-08-08 03:47:19,005 | train | INFO | Epoch 1 validation batch 2/113: 32/1800 mean loss: 0.001625006552785635 score: 1.0
2021-08-08 03:47:19,270 | train | INFO | Epoch 1 validation batch 3/113: 48/1800 mean loss: 0.001569609623402357 score: 1.0
2021-08-08 03:47:19,513 | train | INFO | Epoch 1 validation batch 4/113: 64/1800 mean loss: 0.001509026624262333 score: 1.0
2021-08-08 03:47:19,755 | train | INFO | Epoch 1 validation batch 5/113: 80/1800 mean loss: 0.0015721169766038656 score: 0.995798319327731
2021-08-08 03:47:19,992 | train | INFO | Epoch 1 validation batch 6/113: 96/1800 mean loss: 0.0014670410891994834 score: 1.0
2021-08-08 03:47:20,226 | train | INFO | Epoch 1 validation batch 7/113: 112/1800 mean loss: 0.0015734046464785933 score: 0.9963235294117647
2021-08-08 03:47:20,468 | train | INFO | Epoch 1 validation batch 8/113: 128/1800 mean loss: 0.0015970796812325716 score: 1.0
2021-08-08 03:47:20,700 | train | INFO | Epoch 1 validation batch 9/113: 144/1800 mean loss: 0.001456070109270513 score: 1.0
2021-08-08 03:47:20,937 | train | INFO | Epoch 1 validation batch 10/113: 160/1800 mean loss: 0.0014367300318554044 score: 0.9669117647058824
2021-08-08 03:47:21,168 | train | INFO | Epoch 1 validation batch 11/113: 176/1800 mean loss: 0.0015695338370278478 score: 0.9926470588235294
2021-08-08 03:47:21,399 | train | INFO | Epoch 1 validation batch 12/113: 192/1800 mean loss: 0.0015185537049546838 score: 0.9963235294117647
2021-08-08 03:47:21,629 | train | INFO | Epoch 1 validation batch 13/113: 208/1800 mean loss: 0.0015131524996832013 score: 0.9924019607843138
2021-08-08 03:47:21,864 | train | INFO | Epoch 1 validation batch 14/113: 224/1800 mean loss: 0.0014919163659214973 score: 1.0
2021-08-08 03:47:22,099 | train | INFO | Epoch 1 validation batch 15/113: 240/1800 mean loss: 0.0014438022626563907 score: 1.0
2021-08-08 03:47:22,392 | train | INFO | Epoch 1 validation batch 16/113: 256/1800 mean loss: 0.0015085026388987899 score: 1.0
2021-08-08 03:47:22,628 | train | INFO | Epoch 1 validation batch 17/113: 272/1800 mean loss: 0.0015538245206698775 score: 1.0
2021-08-08 03:47:22,859 | train | INFO | Epoch 1 validation batch 18/113: 288/1800 mean loss: 0.0013772174715995789 score: 1.0
2021-08-08 03:47:23,101 | train | INFO | Epoch 1 validation batch 19/113: 304/1800 mean loss: 0.0014459200901910663 score: 1.0
2021-08-08 03:47:23,340 | train | INFO | Epoch 1 validation batch 20/113: 320/1800 mean loss: 0.0015673646703362465 score: 0.9811274509803922
2021-08-08 03:47:23,576 | train | INFO | Epoch 1 validation batch 21/113: 336/1800 mean loss: 0.0014752114657312632 score: 1.0
2021-08-08 03:47:23,822 | train | INFO | Epoch 1 validation batch 22/113: 352/1800 mean loss: 0.0013923345832154155 score: 1.0
2021-08-08 03:47:24,055 | train | INFO | Epoch 1 validation batch 23/113: 368/1800 mean loss: 0.001448897528462112 score: 0.9963235294117647
2021-08-08 03:47:24,302 | train | INFO | Epoch 1 validation batch 24/113: 384/1800 mean loss: 0.0014867509016767144 score: 1.0
2021-08-08 03:47:24,543 | train | INFO | Epoch 1 validation batch 25/113: 400/1800 mean loss: 0.0015772072365507483 score: 1.0
2021-08-08 03:47:24,786 | train | INFO | Epoch 1 validation batch 26/113: 416/1800 mean loss: 0.0014692047843709588 score: 1.0
2021-08-08 03:47:25,041 | train | INFO | Epoch 1 validation batch 27/113: 432/1800 mean loss: 0.0016032896237447858 score: 1.0
2021-08-08 03:47:25,281 | train | INFO | Epoch 1 validation batch 28/113: 448/1800 mean loss: 0.001432696240954101 score: 1.0
2021-08-08 03:47:25,513 | train | INFO | Epoch 1 validation batch 29/113: 464/1800 mean loss: 0.0015770578756928444 score: 1.0
2021-08-08 03:47:25,746 | train | INFO | Epoch 1 validation batch 30/113: 480/1800 mean loss: 0.001575128291733563 score: 0.9705882352941176
2021-08-08 03:47:25,977 | train | INFO | Epoch 1 validation batch 31/113: 496/1800 mean loss: 0.0014372016303241253 score: 1.0
2021-08-08 03:47:26,209 | train | INFO | Epoch 1 validation batch 32/113: 512/1800 mean loss: 0.0015018496196717024 score: 0.9963235294117647
2021-08-08 03:47:26,447 | train | INFO | Epoch 1 validation batch 33/113: 528/1800 mean loss: 0.0014751466223970056 score: 1.0
2021-08-08 03:47:26,697 | train | INFO | Epoch 1 validation batch 34/113: 544/1800 mean loss: 0.001338249072432518 score: 1.0
2021-08-08 03:47:26,949 | train | INFO | Epoch 1 validation batch 35/113: 560/1800 mean loss: 0.001562918652780354 score: 1.0
2021-08-08 03:47:27,180 | train | INFO | Epoch 1 validation batch 36/113: 576/1800 mean loss: 0.0016558897914364934 score: 0.7514705882352941
2021-08-08 03:47:27,450 | train | INFO | Epoch 1 validation batch 37/113: 592/1800 mean loss: 0.001362206065095961 score: 1.0
2021-08-08 03:47:27,690 | train | INFO | Epoch 1 validation batch 38/113: 608/1800 mean loss: 0.0015628295950591564 score: 1.0
2021-08-08 03:47:27,947 | train | INFO | Epoch 1 validation batch 39/113: 624/1800 mean loss: 0.0014878197107464075 score: 1.0
2021-08-08 03:47:28,179 | train | INFO | Epoch 1 validation batch 40/113: 640/1800 mean loss: 0.0015456016408279538 score: 0.9889705882352942
2021-08-08 03:47:28,415 | train | INFO | Epoch 1 validation batch 41/113: 656/1800 mean loss: 0.0014631079975515604 score: 1.0
2021-08-08 03:47:28,675 | train | INFO | Epoch 1 validation batch 42/113: 672/1800 mean loss: 0.0014796785544604063 score: 0.9587885154061624
2021-08-08 03:47:28,923 | train | INFO | Epoch 1 validation batch 43/113: 688/1800 mean loss: 0.0014994163066148758 score: 1.0
2021-08-08 03:47:29,165 | train | INFO | Epoch 1 validation batch 44/113: 704/1800 mean loss: 0.0015957418363541365 score: 0.9558823529411765
2021-08-08 03:47:29,397 | train | INFO | Epoch 1 validation batch 45/113: 720/1800 mean loss: 0.0014882571995258331 score: 1.0
2021-08-08 03:47:29,634 | train | INFO | Epoch 1 validation batch 46/113: 736/1800 mean loss: 0.0015358607051894069 score: 0.9926470588235294
2021-08-08 03:47:29,885 | train | INFO | Epoch 1 validation batch 47/113: 752/1800 mean loss: 0.0014643741305917501 score: 1.0
2021-08-08 03:47:30,138 | train | INFO | Epoch 1 validation batch 48/113: 768/1800 mean loss: 0.001572626642882824 score: 1.0
2021-08-08 03:47:30,368 | train | INFO | Epoch 1 validation batch 49/113: 784/1800 mean loss: 0.0015238829655572772 score: 1.0
2021-08-08 03:47:30,621 | train | INFO | Epoch 1 validation batch 50/113: 800/1800 mean loss: 0.0014662443427368999 score: 0.9963235294117647
2021-08-08 03:47:30,869 | train | INFO | Epoch 1 validation batch 51/113: 816/1800 mean loss: 0.0015456494875252247 score: 0.9669117647058824
2021-08-08 03:47:31,110 | train | INFO | Epoch 1 validation batch 52/113: 832/1800 mean loss: 0.0015771881444379687 score: 1.0
2021-08-08 03:47:31,370 | train | INFO | Epoch 1 validation batch 53/113: 848/1800 mean loss: 0.0015377062372863293 score: 1.0
2021-08-08 03:47:31,605 | train | INFO | Epoch 1 validation batch 54/113: 864/1800 mean loss: 0.0014596822438761592 score: 1.0
2021-08-08 03:47:31,854 | train | INFO | Epoch 1 validation batch 55/113: 880/1800 mean loss: 0.0015761523973196745 score: 1.0
2021-08-08 03:47:32,098 | train | INFO | Epoch 1 validation batch 56/113: 896/1800 mean loss: 0.00154218846000731 score: 1.0
2021-08-08 03:47:32,331 | train | INFO | Epoch 1 validation batch 57/113: 912/1800 mean loss: 0.0015679922653362155 score: 0.9921218487394957
2021-08-08 03:47:32,562 | train | INFO | Epoch 1 validation batch 58/113: 928/1800 mean loss: 0.0015637552132830024 score: 0.9813725490196079
2021-08-08 03:47:32,807 | train | INFO | Epoch 1 validation batch 59/113: 944/1800 mean loss: 0.0014805910177528858 score: 1.0
2021-08-08 03:47:33,066 | train | INFO | Epoch 1 validation batch 60/113: 960/1800 mean loss: 0.0013249526964500546 score: 1.0
2021-08-08 03:47:33,301 | train | INFO | Epoch 1 validation batch 61/113: 976/1800 mean loss: 0.0014498525997623801 score: 0.9963235294117647
2021-08-08 03:47:33,534 | train | INFO | Epoch 1 validation batch 62/113: 992/1800 mean loss: 0.0014994115335866809 score: 1.0
2021-08-08 03:47:33,785 | train | INFO | Epoch 1 validation batch 63/113: 1008/1800 mean loss: 0.001499137026257813 score: 1.0
2021-08-08 03:47:34,057 | train | INFO | Epoch 1 validation batch 64/113: 1024/1800 mean loss: 0.001546995248645544 score: 1.0
2021-08-08 03:47:34,290 | train | INFO | Epoch 1 validation batch 65/113: 1040/1800 mean loss: 0.0014907839940860868 score: 0.9889705882352942
2021-08-08 03:47:34,535 | train | INFO | Epoch 1 validation batch 66/113: 1056/1800 mean loss: 0.0016068757977336645 score: 0.996078431372549
2021-08-08 03:47:34,817 | train | INFO | Epoch 1 validation batch 67/113: 1072/1800 mean loss: 0.0014910208992660046 score: 1.0
2021-08-08 03:47:35,058 | train | INFO | Epoch 1 validation batch 68/113: 1088/1800 mean loss: 0.0013737973058596253 score: 1.0
2021-08-08 03:47:35,307 | train | INFO | Epoch 1 validation batch 69/113: 1104/1800 mean loss: 0.001558927004225552 score: 1.0
2021-08-08 03:47:35,551 | train | INFO | Epoch 1 validation batch 70/113: 1120/1800 mean loss: 0.0016013596905395389 score: 0.9887254901960785
2021-08-08 03:47:35,825 | train | INFO | Epoch 1 validation batch 71/113: 1136/1800 mean loss: 0.0014897823566570878 score: 1.0
2021-08-08 03:47:36,073 | train | INFO | Epoch 1 validation batch 72/113: 1152/1800 mean loss: 0.001489359186962247 score: 1.0
2021-08-08 03:47:36,319 | train | INFO | Epoch 1 validation batch 73/113: 1168/1800 mean loss: 0.0015994032146409154 score: 1.0
2021-08-08 03:47:36,557 | train | INFO | Epoch 1 validation batch 74/113: 1184/1800 mean loss: 0.0015067066997289658 score: 1.0
2021-08-08 03:47:36,788 | train | INFO | Epoch 1 validation batch 75/113: 1200/1800 mean loss: 0.0015370935434475541 score: 1.0
2021-08-08 03:47:37,023 | train | INFO | Epoch 1 validation batch 76/113: 1216/1800 mean loss: 0.0015019435668364167 score: 1.0
2021-08-08 03:47:37,256 | train | INFO | Epoch 1 validation batch 77/113: 1232/1800 mean loss: 0.0014298099558800459 score: 1.0
2021-08-08 03:47:37,502 | train | INFO | Epoch 1 validation batch 78/113: 1248/1800 mean loss: 0.001525691943243146 score: 0.9473039215686273
2021-08-08 03:47:37,755 | train | INFO | Epoch 1 validation batch 79/113: 1264/1800 mean loss: 0.0015755268977954984 score: 0.9884803921568628
2021-08-08 03:47:37,987 | train | INFO | Epoch 1 validation batch 80/113: 1280/1800 mean loss: 0.0016631706384941936 score: 1.0
2021-08-08 03:47:38,252 | train | INFO | Epoch 1 validation batch 81/113: 1296/1800 mean loss: 0.001600033836439252 score: 1.0
2021-08-08 03:47:38,492 | train | INFO | Epoch 1 validation batch 82/113: 1312/1800 mean loss: 0.0013784050242975354 score: 1.0
2021-08-08 03:47:38,724 | train | INFO | Epoch 1 validation batch 83/113: 1328/1800 mean loss: 0.0015823249705135822 score: 1.0
2021-08-08 03:47:38,981 | train | INFO | Epoch 1 validation batch 84/113: 1344/1800 mean loss: 0.0015635930467396975 score: 0.9852941176470589
2021-08-08 03:47:39,255 | train | INFO | Epoch 1 validation batch 85/113: 1360/1800 mean loss: 0.0014919202076271176 score: 1.0
2021-08-08 03:47:39,509 | train | INFO | Epoch 1 validation batch 86/113: 1376/1800 mean loss: 0.0016905273078009486 score: 1.0
2021-08-08 03:47:39,744 | train | INFO | Epoch 1 validation batch 87/113: 1392/1800 mean loss: 0.0015175736043602228 score: 0.9963235294117647
2021-08-08 03:47:40,054 | train | INFO | Epoch 1 validation batch 88/113: 1408/1800 mean loss: 0.0014118906110525131 score: 1.0
2021-08-08 03:47:40,295 | train | INFO | Epoch 1 validation batch 89/113: 1424/1800 mean loss: 0.001331822364591062 score: 1.0
2021-08-08 03:47:40,527 | train | INFO | Epoch 1 validation batch 90/113: 1440/1800 mean loss: 0.0015211247373372316 score: 1.0
2021-08-08 03:47:40,783 | train | INFO | Epoch 1 validation batch 91/113: 1456/1800 mean loss: 0.0015816474333405495 score: 0.9926470588235294
2021-08-08 03:47:41,019 | train | INFO | Epoch 1 validation batch 92/113: 1472/1800 mean loss: 0.0015925001353025436 score: 1.0
2021-08-08 03:47:41,264 | train | INFO | Epoch 1 validation batch 93/113: 1488/1800 mean loss: 0.001510367845185101 score: 1.0
2021-08-08 03:47:41,510 | train | INFO | Epoch 1 validation batch 94/113: 1504/1800 mean loss: 0.001562456483952701 score: 1.0
2021-08-08 03:47:41,743 | train | INFO | Epoch 1 validation batch 95/113: 1520/1800 mean loss: 0.0015762854600325227 score: 1.0
2021-08-08 03:47:41,991 | train | INFO | Epoch 1 validation batch 96/113: 1536/1800 mean loss: 0.0014765376690775156 score: 0.9816176470588235
2021-08-08 03:47:42,225 | train | INFO | Epoch 1 validation batch 97/113: 1552/1800 mean loss: 0.0015386850573122501 score: 1.0
2021-08-08 03:47:42,456 | train | INFO | Epoch 1 validation batch 98/113: 1568/1800 mean loss: 0.0015154267894104123 score: 1.0
2021-08-08 03:47:42,688 | train | INFO | Epoch 1 validation batch 99/113: 1584/1800 mean loss: 0.0014860025839880109 score: 1.0
2021-08-08 03:47:42,925 | train | INFO | Epoch 1 validation batch 100/113: 1600/1800 mean loss: 0.001574483816511929 score: 1.0
2021-08-08 03:47:43,155 | train | INFO | Epoch 1 validation batch 101/113: 1616/1800 mean loss: 0.0014933693455532193 score: 1.0
2021-08-08 03:47:43,385 | train | INFO | Epoch 1 validation batch 102/113: 1632/1800 mean loss: 0.0014950978802517056 score: 1.0
2021-08-08 03:47:43,614 | train | INFO | Epoch 1 validation batch 103/113: 1648/1800 mean loss: 0.0014574180822819471 score: 1.0
2021-08-08 03:47:43,844 | train | INFO | Epoch 1 validation batch 104/113: 1664/1800 mean loss: 0.0015235324390232563 score: 1.0
2021-08-08 03:47:44,074 | train | INFO | Epoch 1 validation batch 105/113: 1680/1800 mean loss: 0.0015347227454185486 score: 1.0
2021-08-08 03:47:44,304 | train | INFO | Epoch 1 validation batch 106/113: 1696/1800 mean loss: 0.001584207289852202 score: 1.0
2021-08-08 03:47:44,533 | train | INFO | Epoch 1 validation batch 107/113: 1712/1800 mean loss: 0.0015838958788663149 score: 1.0
2021-08-08 03:47:44,764 | train | INFO | Epoch 1 validation batch 108/113: 1728/1800 mean loss: 0.0015691848238930106 score: 1.0
2021-08-08 03:47:44,994 | train | INFO | Epoch 1 validation batch 109/113: 1744/1800 mean loss: 0.0016000446630641818 score: 0.9963235294117647
2021-08-08 03:47:45,224 | train | INFO | Epoch 1 validation batch 110/113: 1760/1800 mean loss: 0.0015416183741763234 score: 1.0
2021-08-08 03:47:45,455 | train | INFO | Epoch 1 validation batch 111/113: 1776/1800 mean loss: 0.0015430537750944495 score: 1.0
2021-08-08 03:47:45,619 | train | INFO | Epoch 1 validation batch 112/113: 1792/1800 mean loss: 0.0013836425496265292 score: 1.0
2021-08-08 03:47:45,769 | train | INFO | Epoch 1, Validation, Mean loss: 0.02425239452746062, Score: 0.9940473091891624
2021-08-08 03:47:45,770 | train | INFO | Write row 1
2021-08-08 03:47:48,448 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 03:47:48,451 | train | INFO | Update best record row 2, checkpoints 0.028924648575814425 -> 0.02425239452746062
2021-08-08 03:47:50,441 | train | INFO | Epoch 2 train batch 0/450: 0/7200 mean loss: 0.001692035235464573 score: 1.0
2021-08-08 03:47:51,213 | train | INFO | Epoch 2 train batch 1/450: 16/7200 mean loss: 0.0017074226634576917 score: 1.0
2021-08-08 03:47:51,997 | train | INFO | Epoch 2 train batch 2/450: 32/7200 mean loss: 0.001682434929534793 score: 1.0
2021-08-08 03:47:52,803 | train | INFO | Epoch 2 train batch 3/450: 48/7200 mean loss: 0.0017787233227863908 score: 0.9887254901960785
2021-08-08 03:47:53,593 | train | INFO | Epoch 2 train batch 4/450: 64/7200 mean loss: 0.0017176531255245209 score: 1.0
2021-08-08 03:47:54,430 | train | INFO | Epoch 2 train batch 5/450: 80/7200 mean loss: 0.001719677704386413 score: 1.0
2021-08-08 03:47:55,220 | train | INFO | Epoch 2 train batch 6/450: 96/7200 mean loss: 0.0017714272253215313 score: 0.9963235294117647
2021-08-08 03:47:56,000 | train | INFO | Epoch 2 train batch 7/450: 112/7200 mean loss: 0.0018564725760370493 score: 1.0
2021-08-08 03:47:56,778 | train | INFO | Epoch 2 train batch 8/450: 128/7200 mean loss: 0.001739113125950098 score: 1.0
2021-08-08 03:47:57,548 | train | INFO | Epoch 2 train batch 9/450: 144/7200 mean loss: 0.0016257328679785132 score: 1.0
2021-08-08 03:47:58,339 | train | INFO | Epoch 2 train batch 10/450: 160/7200 mean loss: 0.0017461880343034863 score: 0.9551470588235295
2021-08-08 03:47:59,236 | train | INFO | Epoch 2 train batch 11/450: 176/7200 mean loss: 0.0018005457241088152 score: 1.0
2021-08-08 03:48:00,019 | train | INFO | Epoch 2 train batch 12/450: 192/7200 mean loss: 0.0018137393053621054 score: 0.9963235294117647
2021-08-08 03:48:00,835 | train | INFO | Epoch 2 train batch 13/450: 208/7200 mean loss: 0.0016954090679064393 score: 1.0
2021-08-08 03:48:01,645 | train | INFO | Epoch 2 train batch 14/450: 224/7200 mean loss: 0.001728563685901463 score: 1.0
2021-08-08 03:48:02,470 | train | INFO | Epoch 2 train batch 15/450: 240/7200 mean loss: 0.0018462341977283359 score: 1.0
2021-08-08 03:48:03,272 | train | INFO | Epoch 2 train batch 16/450: 256/7200 mean loss: 0.0018746443092823029 score: 1.0
2021-08-08 03:48:04,051 | train | INFO | Epoch 2 train batch 17/450: 272/7200 mean loss: 0.0017010564915835857 score: 0.9926470588235294
2021-08-08 03:48:04,822 | train | INFO | Epoch 2 train batch 18/450: 288/7200 mean loss: 0.001687697134912014 score: 1.0
2021-08-08 03:48:05,588 | train | INFO | Epoch 2 train batch 19/450: 304/7200 mean loss: 0.0019079913618043065 score: 1.0
2021-08-08 03:48:06,392 | train | INFO | Epoch 2 train batch 20/450: 320/7200 mean loss: 0.00183159951120615 score: 0.9887254901960785
2021-08-08 03:48:07,167 | train | INFO | Epoch 2 train batch 21/450: 336/7200 mean loss: 0.0017714594723656774 score: 1.0
2021-08-08 03:48:07,939 | train | INFO | Epoch 2 train batch 22/450: 352/7200 mean loss: 0.001777489436790347 score: 1.0
2021-08-08 03:48:08,719 | train | INFO | Epoch 2 train batch 23/450: 368/7200 mean loss: 0.0017071068286895752 score: 1.0
2021-08-08 03:48:09,534 | train | INFO | Epoch 2 train batch 24/450: 384/7200 mean loss: 0.0016050724079832435 score: 1.0
2021-08-08 03:48:10,321 | train | INFO | Epoch 2 train batch 25/450: 400/7200 mean loss: 0.0017407600535079837 score: 1.0
2021-08-08 03:48:11,096 | train | INFO | Epoch 2 train batch 26/450: 416/7200 mean loss: 0.0017406977713108063 score: 0.9852941176470589
2021-08-08 03:48:11,936 | train | INFO | Epoch 2 train batch 27/450: 432/7200 mean loss: 0.0018030187347903848 score: 1.0
2021-08-08 03:48:12,830 | train | INFO | Epoch 2 train batch 28/450: 448/7200 mean loss: 0.0017519075190648437 score: 1.0
2021-08-08 03:48:13,654 | train | INFO | Epoch 2 train batch 29/450: 464/7200 mean loss: 0.001819595810957253 score: 1.0
2021-08-08 03:48:14,429 | train | INFO | Epoch 2 train batch 30/450: 480/7200 mean loss: 0.001698301057331264 score: 0.9921218487394957
2021-08-08 03:48:15,258 | train | INFO | Epoch 2 train batch 31/450: 496/7200 mean loss: 0.0018606983358040452 score: 1.0
2021-08-08 03:48:16,079 | train | INFO | Epoch 2 train batch 32/450: 512/7200 mean loss: 0.0017929599853232503 score: 1.0
2021-08-08 03:48:16,885 | train | INFO | Epoch 2 train batch 33/450: 528/7200 mean loss: 0.0018164218636229634 score: 1.0
2021-08-08 03:48:17,713 | train | INFO | Epoch 2 train batch 34/450: 544/7200 mean loss: 0.0017412363085895777 score: 1.0
2021-08-08 03:48:18,488 | train | INFO | Epoch 2 train batch 35/450: 560/7200 mean loss: 0.0017660749144852161 score: 1.0
2021-08-08 03:48:19,279 | train | INFO | Epoch 2 train batch 36/450: 576/7200 mean loss: 0.001723668770864606 score: 0.9963235294117647
2021-08-08 03:48:20,081 | train | INFO | Epoch 2 train batch 37/450: 592/7200 mean loss: 0.001595682348124683 score: 0.9926470588235294
2021-08-08 03:48:20,861 | train | INFO | Epoch 2 train batch 38/450: 608/7200 mean loss: 0.001929654972627759 score: 0.9595588235294118
2021-08-08 03:48:21,703 | train | INFO | Epoch 2 train batch 39/450: 624/7200 mean loss: 0.0016772937960922718 score: 1.0
2021-08-08 03:48:22,500 | train | INFO | Epoch 2 train batch 40/450: 640/7200 mean loss: 0.00176480901427567 score: 0.9475140056022411
2021-08-08 03:48:23,311 | train | INFO | Epoch 2 train batch 41/450: 656/7200 mean loss: 0.0016378976870328188 score: 1.0
2021-08-08 03:48:24,092 | train | INFO | Epoch 2 train batch 42/450: 672/7200 mean loss: 0.0017462552059441805 score: 0.9338235294117647
2021-08-08 03:48:24,865 | train | INFO | Epoch 2 train batch 43/450: 688/7200 mean loss: 0.001620144466869533 score: 0.9926470588235294
2021-08-08 03:48:25,695 | train | INFO | Epoch 2 train batch 44/450: 704/7200 mean loss: 0.001639456837438047 score: 1.0
2021-08-08 03:48:26,474 | train | INFO | Epoch 2 train batch 45/450: 720/7200 mean loss: 0.0017297720769420266 score: 1.0
2021-08-08 03:48:27,277 | train | INFO | Epoch 2 train batch 46/450: 736/7200 mean loss: 0.0016813435358926654 score: 0.9816176470588235
2021-08-08 03:48:28,057 | train | INFO | Epoch 2 train batch 47/450: 752/7200 mean loss: 0.0017358020413666964 score: 0.9963235294117647
2021-08-08 03:48:28,828 | train | INFO | Epoch 2 train batch 48/450: 768/7200 mean loss: 0.001697842264547944 score: 1.0
2021-08-08 03:48:29,627 | train | INFO | Epoch 2 train batch 49/450: 784/7200 mean loss: 0.0015268606366589665 score: 1.0
2021-08-08 03:48:30,428 | train | INFO | Epoch 2 train batch 50/450: 800/7200 mean loss: 0.0017048972658813 score: 0.9887254901960785
2021-08-08 03:48:31,249 | train | INFO | Epoch 2 train batch 51/450: 816/7200 mean loss: 0.0016710098134353757 score: 1.0
2021-08-08 03:48:32,060 | train | INFO | Epoch 2 train batch 52/450: 832/7200 mean loss: 0.0017765369266271591 score: 0.9926470588235294
2021-08-08 03:48:32,882 | train | INFO | Epoch 2 train batch 53/450: 848/7200 mean loss: 0.001668503857217729 score: 1.0
2021-08-08 03:48:33,663 | train | INFO | Epoch 2 train batch 54/450: 864/7200 mean loss: 0.001644321484491229 score: 1.0
2021-08-08 03:48:34,470 | train | INFO | Epoch 2 train batch 55/450: 880/7200 mean loss: 0.0017739922041073442 score: 0.9926470588235294
2021-08-08 03:48:35,261 | train | INFO | Epoch 2 train batch 56/450: 896/7200 mean loss: 0.001750989118590951 score: 1.0
2021-08-08 03:48:36,064 | train | INFO | Epoch 2 train batch 57/450: 912/7200 mean loss: 0.0014699863968417048 score: 1.0
2021-08-08 03:48:36,862 | train | INFO | Epoch 2 train batch 58/450: 928/7200 mean loss: 0.0017809343989938498 score: 1.0
2021-08-08 03:48:37,671 | train | INFO | Epoch 2 train batch 59/450: 944/7200 mean loss: 0.001685164519585669 score: 1.0
2021-08-08 03:48:38,480 | train | INFO | Epoch 2 train batch 60/450: 960/7200 mean loss: 0.001818740158341825 score: 0.9357843137254902
2021-08-08 03:48:39,277 | train | INFO | Epoch 2 train batch 61/450: 976/7200 mean loss: 0.0017811415018513799 score: 1.0
2021-08-08 03:48:40,095 | train | INFO | Epoch 2 train batch 62/450: 992/7200 mean loss: 0.0017714017303660512 score: 0.9024509803921569
2021-08-08 03:48:40,896 | train | INFO | Epoch 2 train batch 63/450: 1008/7200 mean loss: 0.001746970578096807 score: 1.0
2021-08-08 03:48:41,663 | train | INFO | Epoch 2 train batch 64/450: 1024/7200 mean loss: 0.001783283893018961 score: 1.0
2021-08-08 03:48:42,455 | train | INFO | Epoch 2 train batch 65/450: 1040/7200 mean loss: 0.0016961297951638699 score: 1.0
2021-08-08 03:48:43,237 | train | INFO | Epoch 2 train batch 66/450: 1056/7200 mean loss: 0.0018705482361838222 score: 0.9963235294117647
2021-08-08 03:48:44,049 | train | INFO | Epoch 2 train batch 67/450: 1072/7200 mean loss: 0.001663516741245985 score: 1.0
2021-08-08 03:48:44,843 | train | INFO | Epoch 2 train batch 68/450: 1088/7200 mean loss: 0.0016354479594156146 score: 0.9808823529411765
2021-08-08 03:48:45,626 | train | INFO | Epoch 2 train batch 69/450: 1104/7200 mean loss: 0.0017400785582140088 score: 1.0
2021-08-08 03:48:46,404 | train | INFO | Epoch 2 train batch 70/450: 1120/7200 mean loss: 0.0016425229841843247 score: 0.9779411764705882
2021-08-08 03:48:47,222 | train | INFO | Epoch 2 train batch 71/450: 1136/7200 mean loss: 0.0017218246357515454 score: 1.0
2021-08-08 03:48:48,010 | train | INFO | Epoch 2 train batch 72/450: 1152/7200 mean loss: 0.0016655304934829473 score: 1.0
2021-08-08 03:48:48,781 | train | INFO | Epoch 2 train batch 73/450: 1168/7200 mean loss: 0.0016804098850116134 score: 1.0
2021-08-08 03:48:49,580 | train | INFO | Epoch 2 train batch 74/450: 1184/7200 mean loss: 0.0016449159011244774 score: 1.0
2021-08-08 03:48:50,350 | train | INFO | Epoch 2 train batch 75/450: 1200/7200 mean loss: 0.0016719454433768988 score: 1.0
2021-08-08 03:48:51,172 | train | INFO | Epoch 2 train batch 76/450: 1216/7200 mean loss: 0.0017569403862580657 score: 0.9166666666666667
2021-08-08 03:48:51,940 | train | INFO | Epoch 2 train batch 77/450: 1232/7200 mean loss: 0.001695274724625051 score: 0.996078431372549
2021-08-08 03:48:52,703 | train | INFO | Epoch 2 train batch 78/450: 1248/7200 mean loss: 0.0017135234083980322 score: 1.0
2021-08-08 03:48:53,470 | train | INFO | Epoch 2 train batch 79/450: 1264/7200 mean loss: 0.0016620244132354856 score: 1.0
2021-08-08 03:48:54,246 | train | INFO | Epoch 2 train batch 80/450: 1280/7200 mean loss: 0.0018069338984787464 score: 1.0
2021-08-08 03:48:55,059 | train | INFO | Epoch 2 train batch 81/450: 1296/7200 mean loss: 0.0016509081469848752 score: 1.0
2021-08-08 03:48:55,857 | train | INFO | Epoch 2 train batch 82/450: 1312/7200 mean loss: 0.0015869762282818556 score: 1.0
2021-08-08 03:48:56,661 | train | INFO | Epoch 2 train batch 83/450: 1328/7200 mean loss: 0.0016664537834003568 score: 1.0
2021-08-08 03:48:57,442 | train | INFO | Epoch 2 train batch 84/450: 1344/7200 mean loss: 0.0017372058937326074 score: 0.9963235294117647
2021-08-08 03:48:58,260 | train | INFO | Epoch 2 train batch 85/450: 1360/7200 mean loss: 0.001758854603394866 score: 0.9921218487394957
2021-08-08 03:48:59,080 | train | INFO | Epoch 2 train batch 86/450: 1376/7200 mean loss: 0.0015712451422587037 score: 1.0
2021-08-08 03:48:59,892 | train | INFO | Epoch 2 train batch 87/450: 1392/7200 mean loss: 0.0016191995237022638 score: 1.0
2021-08-08 03:49:00,730 | train | INFO | Epoch 2 train batch 88/450: 1408/7200 mean loss: 0.0016304446617141366 score: 1.0
2021-08-08 03:49:01,521 | train | INFO | Epoch 2 train batch 89/450: 1424/7200 mean loss: 0.0018545821076259017 score: 0.9406862745098039
2021-08-08 03:49:02,296 | train | INFO | Epoch 2 train batch 90/450: 1440/7200 mean loss: 0.0018135199788957834 score: 1.0
2021-08-08 03:49:03,082 | train | INFO | Epoch 2 train batch 91/450: 1456/7200 mean loss: 0.0017404945101588964 score: 0.996078431372549
2021-08-08 03:49:03,891 | train | INFO | Epoch 2 train batch 92/450: 1472/7200 mean loss: 0.00171889946796 score: 1.0
2021-08-08 03:49:04,687 | train | INFO | Epoch 2 train batch 93/450: 1488/7200 mean loss: 0.001615624874830246 score: 1.0
2021-08-08 03:49:05,477 | train | INFO | Epoch 2 train batch 94/450: 1504/7200 mean loss: 0.0017928365850821137 score: 0.9926470588235294
2021-08-08 03:49:06,279 | train | INFO | Epoch 2 train batch 95/450: 1520/7200 mean loss: 0.001702014822512865 score: 1.0
2021-08-08 03:49:07,055 | train | INFO | Epoch 2 train batch 96/450: 1536/7200 mean loss: 0.0017157781403511763 score: 1.0
2021-08-08 03:49:07,853 | train | INFO | Epoch 2 train batch 97/450: 1552/7200 mean loss: 0.0016155566554516554 score: 1.0
2021-08-08 03:49:08,688 | train | INFO | Epoch 2 train batch 98/450: 1568/7200 mean loss: 0.001688655698671937 score: 1.0
2021-08-08 03:49:09,480 | train | INFO | Epoch 2 train batch 99/450: 1584/7200 mean loss: 0.0015523675829172134 score: 1.0
2021-08-08 03:49:10,278 | train | INFO | Epoch 2 train batch 100/450: 1600/7200 mean loss: 0.0017131548374891281 score: 0.9808823529411765
2021-08-08 03:49:11,057 | train | INFO | Epoch 2 train batch 101/450: 1616/7200 mean loss: 0.001832717563956976 score: 1.0
2021-08-08 03:49:11,870 | train | INFO | Epoch 2 train batch 102/450: 1632/7200 mean loss: 0.0016677065286785364 score: 1.0
2021-08-08 03:49:12,653 | train | INFO | Epoch 2 train batch 103/450: 1648/7200 mean loss: 0.0016775131225585938 score: 1.0
2021-08-08 03:49:13,435 | train | INFO | Epoch 2 train batch 104/450: 1664/7200 mean loss: 0.0016933092847466469 score: 0.9852941176470589
2021-08-08 03:49:14,207 | train | INFO | Epoch 2 train batch 105/450: 1680/7200 mean loss: 0.0017586136236786842 score: 1.0
2021-08-08 03:49:14,982 | train | INFO | Epoch 2 train batch 106/450: 1696/7200 mean loss: 0.0016622646944597363 score: 1.0
2021-08-08 03:49:15,870 | train | INFO | Epoch 2 train batch 107/450: 1712/7200 mean loss: 0.001629673526622355 score: 0.9884803921568628
2021-08-08 03:49:16,649 | train | INFO | Epoch 2 train batch 108/450: 1728/7200 mean loss: 0.0017112171044573188 score: 0.9926470588235294
2021-08-08 03:49:17,449 | train | INFO | Epoch 2 train batch 109/450: 1744/7200 mean loss: 0.0017575909150764346 score: 1.0
2021-08-08 03:49:18,260 | train | INFO | Epoch 2 train batch 110/450: 1760/7200 mean loss: 0.0018082794267684221 score: 1.0
2021-08-08 03:49:19,066 | train | INFO | Epoch 2 train batch 111/450: 1776/7200 mean loss: 0.0017462808173149824 score: 1.0
2021-08-08 03:49:19,854 | train | INFO | Epoch 2 train batch 112/450: 1792/7200 mean loss: 0.0018127391813322902 score: 1.0
2021-08-08 03:49:20,702 | train | INFO | Epoch 2 train batch 113/450: 1808/7200 mean loss: 0.0016936365282163024 score: 0.9963235294117647
2021-08-08 03:49:21,484 | train | INFO | Epoch 2 train batch 114/450: 1824/7200 mean loss: 0.0017513791099190712 score: 0.9889705882352942
2021-08-08 03:49:22,275 | train | INFO | Epoch 2 train batch 115/450: 1840/7200 mean loss: 0.0017556343227624893 score: 0.966421568627451
2021-08-08 03:49:23,087 | train | INFO | Epoch 2 train batch 116/450: 1856/7200 mean loss: 0.0015836607199162245 score: 1.0
2021-08-08 03:49:23,871 | train | INFO | Epoch 2 train batch 117/450: 1872/7200 mean loss: 0.0017260537715628743 score: 1.0
2021-08-08 03:49:24,665 | train | INFO | Epoch 2 train batch 118/450: 1888/7200 mean loss: 0.001697274623438716 score: 1.0
2021-08-08 03:49:25,432 | train | INFO | Epoch 2 train batch 119/450: 1904/7200 mean loss: 0.0017118494724854827 score: 1.0
2021-08-08 03:49:26,203 | train | INFO | Epoch 2 train batch 120/450: 1920/7200 mean loss: 0.0017505339346826077 score: 1.0
2021-08-08 03:49:27,007 | train | INFO | Epoch 2 train batch 121/450: 1936/7200 mean loss: 0.0018210146808996797 score: 1.0
2021-08-08 03:49:27,774 | train | INFO | Epoch 2 train batch 122/450: 1952/7200 mean loss: 0.0017101633129641414 score: 1.0
2021-08-08 03:49:28,538 | train | INFO | Epoch 2 train batch 123/450: 1968/7200 mean loss: 0.0015877019613981247 score: 0.39093137254901966
2021-08-08 03:49:29,358 | train | INFO | Epoch 2 train batch 124/450: 1984/7200 mean loss: 0.0017306574154645205 score: 0.996078431372549
2021-08-08 03:49:30,140 | train | INFO | Epoch 2 train batch 125/450: 2000/7200 mean loss: 0.0017356284661218524 score: 1.0
2021-08-08 03:49:30,916 | train | INFO | Epoch 2 train batch 126/450: 2016/7200 mean loss: 0.001790671143680811 score: 1.0
2021-08-08 03:49:31,770 | train | INFO | Epoch 2 train batch 127/450: 2032/7200 mean loss: 0.0014871153980493546 score: 1.0
2021-08-08 03:49:32,664 | train | INFO | Epoch 2 train batch 128/450: 2048/7200 mean loss: 0.0015990841202437878 score: 1.0
2021-08-08 03:49:33,451 | train | INFO | Epoch 2 train batch 129/450: 2064/7200 mean loss: 0.0016350049991160631 score: 1.0
2021-08-08 03:49:34,260 | train | INFO | Epoch 2 train batch 130/450: 2080/7200 mean loss: 0.0016814819537103176 score: 1.0
2021-08-08 03:49:35,080 | train | INFO | Epoch 2 train batch 131/450: 2096/7200 mean loss: 0.0018064695177599788 score: 1.0
2021-08-08 03:49:35,937 | train | INFO | Epoch 2 train batch 132/450: 2112/7200 mean loss: 0.001778515288606286 score: 1.0
2021-08-08 03:49:36,723 | train | INFO | Epoch 2 train batch 133/450: 2128/7200 mean loss: 0.0015911160735413432 score: 1.0
2021-08-08 03:49:37,535 | train | INFO | Epoch 2 train batch 134/450: 2144/7200 mean loss: 0.0016262418357655406 score: 1.0
2021-08-08 03:49:38,365 | train | INFO | Epoch 2 train batch 135/450: 2160/7200 mean loss: 0.0018086141208186746 score: 0.9963235294117647
2021-08-08 03:49:39,146 | train | INFO | Epoch 2 train batch 136/450: 2176/7200 mean loss: 0.001593752414919436 score: 0.9963235294117647
2021-08-08 03:49:39,917 | train | INFO | Epoch 2 train batch 137/450: 2192/7200 mean loss: 0.0017585570458322763 score: 1.0
2021-08-08 03:49:40,687 | train | INFO | Epoch 2 train batch 138/450: 2208/7200 mean loss: 0.0016014816937968135 score: 0.9909502262443439
2021-08-08 03:49:41,496 | train | INFO | Epoch 2 train batch 139/450: 2224/7200 mean loss: 0.0017069021705538034 score: 1.0
2021-08-08 03:49:42,291 | train | INFO | Epoch 2 train batch 140/450: 2240/7200 mean loss: 0.0016465351218357682 score: 0.9963235294117647
2021-08-08 03:49:43,062 | train | INFO | Epoch 2 train batch 141/450: 2256/7200 mean loss: 0.0017196787521243095 score: 0.9924019607843138
2021-08-08 03:49:43,834 | train | INFO | Epoch 2 train batch 142/450: 2272/7200 mean loss: 0.001727789407595992 score: 1.0
2021-08-08 03:49:44,606 | train | INFO | Epoch 2 train batch 143/450: 2288/7200 mean loss: 0.0015606341185048223 score: 1.0
2021-08-08 03:49:45,381 | train | INFO | Epoch 2 train batch 144/450: 2304/7200 mean loss: 0.0018281396478414536 score: 1.0
2021-08-08 03:49:46,197 | train | INFO | Epoch 2 train batch 145/450: 2320/7200 mean loss: 0.0016963923117145896 score: 1.0
2021-08-08 03:49:47,002 | train | INFO | Epoch 2 train batch 146/450: 2336/7200 mean loss: 0.0017117143142968416 score: 0.9963235294117647
2021-08-08 03:49:47,859 | train | INFO | Epoch 2 train batch 147/450: 2352/7200 mean loss: 0.0016496849711984396 score: 1.0
2021-08-08 03:49:48,737 | train | INFO | Epoch 2 train batch 148/450: 2368/7200 mean loss: 0.0017320998013019562 score: 1.0
2021-08-08 03:49:49,555 | train | INFO | Epoch 2 train batch 149/450: 2384/7200 mean loss: 0.0016361020971089602 score: 1.0
2021-08-08 03:49:50,338 | train | INFO | Epoch 2 train batch 150/450: 2400/7200 mean loss: 0.001743319327943027 score: 0.8990196078431373
2021-08-08 03:49:51,133 | train | INFO | Epoch 2 train batch 151/450: 2416/7200 mean loss: 0.0016068541444838047 score: 1.0
2021-08-08 03:49:51,944 | train | INFO | Epoch 2 train batch 152/450: 2432/7200 mean loss: 0.0017886589048430324 score: 1.0
2021-08-08 03:49:52,757 | train | INFO | Epoch 2 train batch 153/450: 2448/7200 mean loss: 0.0016919353511184454 score: 0.9774509803921569
2021-08-08 03:49:53,532 | train | INFO | Epoch 2 train batch 154/450: 2464/7200 mean loss: 0.0018117476720362902 score: 1.0
2021-08-08 03:49:54,333 | train | INFO | Epoch 2 train batch 155/450: 2480/7200 mean loss: 0.00173427804838866 score: 0.9926470588235294
2021-08-08 03:49:55,109 | train | INFO | Epoch 2 train batch 156/450: 2496/7200 mean loss: 0.0019122111843898892 score: 1.0
2021-08-08 03:49:55,877 | train | INFO | Epoch 2 train batch 157/450: 2512/7200 mean loss: 0.0017255389830097556 score: 1.0
2021-08-08 03:49:56,654 | train | INFO | Epoch 2 train batch 158/450: 2528/7200 mean loss: 0.0017568632028996944 score: 0.9776960784313725
2021-08-08 03:49:57,429 | train | INFO | Epoch 2 train batch 159/450: 2544/7200 mean loss: 0.0015422767028212547 score: 1.0
2021-08-08 03:49:58,301 | train | INFO | Epoch 2 train batch 160/450: 2560/7200 mean loss: 0.0017182102892547846 score: 1.0
2021-08-08 03:49:59,094 | train | INFO | Epoch 2 train batch 161/450: 2576/7200 mean loss: 0.0015729628503322601 score: 1.0
2021-08-08 03:49:59,863 | train | INFO | Epoch 2 train batch 162/450: 2592/7200 mean loss: 0.0018183918436989188 score: 1.0
2021-08-08 03:50:00,709 | train | INFO | Epoch 2 train batch 163/450: 2608/7200 mean loss: 0.00184400356374681 score: 1.0
2021-08-08 03:50:01,496 | train | INFO | Epoch 2 train batch 164/450: 2624/7200 mean loss: 0.0016880190232768655 score: 1.0
2021-08-08 03:50:02,282 | train | INFO | Epoch 2 train batch 165/450: 2640/7200 mean loss: 0.001675685285590589 score: 0.9926470588235294
2021-08-08 03:50:03,078 | train | INFO | Epoch 2 train batch 166/450: 2656/7200 mean loss: 0.0017310279654338956 score: 1.0
2021-08-08 03:50:03,947 | train | INFO | Epoch 2 train batch 167/450: 2672/7200 mean loss: 0.0017592136282473803 score: 1.0
2021-08-08 03:50:04,797 | train | INFO | Epoch 2 train batch 168/450: 2688/7200 mean loss: 0.0017562361899763346 score: 1.0
2021-08-08 03:50:05,572 | train | INFO | Epoch 2 train batch 169/450: 2704/7200 mean loss: 0.0017608612542971969 score: 1.0
2021-08-08 03:50:06,353 | train | INFO | Epoch 2 train batch 170/450: 2720/7200 mean loss: 0.0016497495817020535 score: 0.995798319327731
2021-08-08 03:50:07,125 | train | INFO | Epoch 2 train batch 171/450: 2736/7200 mean loss: 0.0017860970692709088 score: 0.9889705882352942
2021-08-08 03:50:07,898 | train | INFO | Epoch 2 train batch 172/450: 2752/7200 mean loss: 0.0017736483132466674 score: 1.0
2021-08-08 03:50:08,693 | train | INFO | Epoch 2 train batch 173/450: 2768/7200 mean loss: 0.0016566376434639096 score: 0.9963235294117647
2021-08-08 03:50:09,468 | train | INFO | Epoch 2 train batch 174/450: 2784/7200 mean loss: 0.0017710397951304913 score: 0.8855392156862746
2021-08-08 03:50:10,244 | train | INFO | Epoch 2 train batch 175/450: 2800/7200 mean loss: 0.001780993421562016 score: 0.9924019607843138
2021-08-08 03:50:11,060 | train | INFO | Epoch 2 train batch 176/450: 2816/7200 mean loss: 0.001670250901952386 score: 1.0
2021-08-08 03:50:11,847 | train | INFO | Epoch 2 train batch 177/450: 2832/7200 mean loss: 0.0017160928109660745 score: 1.0
2021-08-08 03:50:12,655 | train | INFO | Epoch 2 train batch 178/450: 2848/7200 mean loss: 0.0017856295453384519 score: 0.9963235294117647
2021-08-08 03:50:13,463 | train | INFO | Epoch 2 train batch 179/450: 2864/7200 mean loss: 0.0017044473206624389 score: 1.0
2021-08-08 03:50:14,364 | train | INFO | Epoch 2 train batch 180/450: 2880/7200 mean loss: 0.0015609529800713062 score: 1.0
2021-08-08 03:50:15,173 | train | INFO | Epoch 2 train batch 181/450: 2896/7200 mean loss: 0.001525862724520266 score: 1.0
2021-08-08 03:50:15,942 | train | INFO | Epoch 2 train batch 182/450: 2912/7200 mean loss: 0.001768764341250062 score: 1.0
2021-08-08 03:50:16,828 | train | INFO | Epoch 2 train batch 183/450: 2928/7200 mean loss: 0.0016451954143121839 score: 1.0
2021-08-08 03:50:17,622 | train | INFO | Epoch 2 train batch 184/450: 2944/7200 mean loss: 0.0017141341231763363 score: 1.0
2021-08-08 03:50:18,393 | train | INFO | Epoch 2 train batch 185/450: 2960/7200 mean loss: 0.0017145281890407205 score: 1.0
2021-08-08 03:50:19,169 | train | INFO | Epoch 2 train batch 186/450: 2976/7200 mean loss: 0.0016122300876304507 score: 1.0
2021-08-08 03:50:19,995 | train | INFO | Epoch 2 train batch 187/450: 2992/7200 mean loss: 0.0017703196499496698 score: 1.0
2021-08-08 03:50:20,801 | train | INFO | Epoch 2 train batch 188/450: 3008/7200 mean loss: 0.0016756342956796288 score: 0.9957983193277312
2021-08-08 03:50:21,579 | train | INFO | Epoch 2 train batch 189/450: 3024/7200 mean loss: 0.0016224596183747053 score: 1.0
2021-08-08 03:50:22,386 | train | INFO | Epoch 2 train batch 190/450: 3040/7200 mean loss: 0.0017412478337064385 score: 0.8933823529411766
2021-08-08 03:50:23,177 | train | INFO | Epoch 2 train batch 191/450: 3056/7200 mean loss: 0.0017763993237167597 score: 1.0
2021-08-08 03:50:24,010 | train | INFO | Epoch 2 train batch 192/450: 3072/7200 mean loss: 0.0016538273775950074 score: 1.0
2021-08-08 03:50:24,825 | train | INFO | Epoch 2 train batch 193/450: 3088/7200 mean loss: 0.0018162417691200972 score: 0.996078431372549
2021-08-08 03:50:25,649 | train | INFO | Epoch 2 train batch 194/450: 3104/7200 mean loss: 0.001707766787149012 score: 1.0
2021-08-08 03:50:26,420 | train | INFO | Epoch 2 train batch 195/450: 3120/7200 mean loss: 0.0016107010887935758 score: 0.9963235294117647
2021-08-08 03:50:27,244 | train | INFO | Epoch 2 train batch 196/450: 3136/7200 mean loss: 0.001624482567422092 score: 1.0
2021-08-08 03:50:28,028 | train | INFO | Epoch 2 train batch 197/450: 3152/7200 mean loss: 0.0017460823291912675 score: 1.0
2021-08-08 03:50:28,853 | train | INFO | Epoch 2 train batch 198/450: 3168/7200 mean loss: 0.001641752547584474 score: 1.0
2021-08-08 03:50:29,624 | train | INFO | Epoch 2 train batch 199/450: 3184/7200 mean loss: 0.0017048502340912819 score: 0.996078431372549
2021-08-08 03:50:30,415 | train | INFO | Epoch 2 train batch 200/450: 3200/7200 mean loss: 0.0018016669200733304 score: 1.0
2021-08-08 03:50:31,199 | train | INFO | Epoch 2 train batch 201/450: 3216/7200 mean loss: 0.0016614842461422086 score: 1.0
2021-08-08 03:50:32,041 | train | INFO | Epoch 2 train batch 202/450: 3232/7200 mean loss: 0.0017568523762747645 score: 1.0
2021-08-08 03:50:32,845 | train | INFO | Epoch 2 train batch 203/450: 3248/7200 mean loss: 0.0016489776317030191 score: 0.9181372549019607
2021-08-08 03:50:33,663 | train | INFO | Epoch 2 train batch 204/450: 3264/7200 mean loss: 0.001651523751206696 score: 1.0
2021-08-08 03:50:34,439 | train | INFO | Epoch 2 train batch 205/450: 3280/7200 mean loss: 0.0016675418009981513 score: 1.0
2021-08-08 03:50:35,234 | train | INFO | Epoch 2 train batch 206/450: 3296/7200 mean loss: 0.0016907183453440666 score: 0.9852941176470589
2021-08-08 03:50:36,028 | train | INFO | Epoch 2 train batch 207/450: 3312/7200 mean loss: 0.0017552187200635672 score: 1.0
2021-08-08 03:50:36,818 | train | INFO | Epoch 2 train batch 208/450: 3328/7200 mean loss: 0.001691032201051712 score: 1.0
2021-08-08 03:50:37,597 | train | INFO | Epoch 2 train batch 209/450: 3344/7200 mean loss: 0.0017408833373337984 score: 1.0
2021-08-08 03:50:38,370 | train | INFO | Epoch 2 train batch 210/450: 3360/7200 mean loss: 0.0016958940541371703 score: 1.0
2021-08-08 03:50:39,147 | train | INFO | Epoch 2 train batch 211/450: 3376/7200 mean loss: 0.0017148444894701242 score: 1.0
2021-08-08 03:50:39,921 | train | INFO | Epoch 2 train batch 212/450: 3392/7200 mean loss: 0.0018235789611935616 score: 0.970343137254902
2021-08-08 03:50:40,703 | train | INFO | Epoch 2 train batch 213/450: 3408/7200 mean loss: 0.0017430714797228575 score: 1.0
2021-08-08 03:50:41,537 | train | INFO | Epoch 2 train batch 214/450: 3424/7200 mean loss: 0.0016726000467315316 score: 0.9850490196078432
2021-08-08 03:50:42,360 | train | INFO | Epoch 2 train batch 215/450: 3440/7200 mean loss: 0.0017829284770414233 score: 0.9732142857142857
2021-08-08 03:50:43,142 | train | INFO | Epoch 2 train batch 216/450: 3456/7200 mean loss: 0.0017526133451610804 score: 1.0
2021-08-08 03:50:43,923 | train | INFO | Epoch 2 train batch 217/450: 3472/7200 mean loss: 0.0017348193796351552 score: 1.0
2021-08-08 03:50:44,698 | train | INFO | Epoch 2 train batch 218/450: 3488/7200 mean loss: 0.0018140316242352128 score: 1.0
2021-08-08 03:50:45,466 | train | INFO | Epoch 2 train batch 219/450: 3504/7200 mean loss: 0.0017213447717949748 score: 1.0
2021-08-08 03:50:46,272 | train | INFO | Epoch 2 train batch 220/450: 3520/7200 mean loss: 0.0018368854653090239 score: 1.0
2021-08-08 03:50:47,060 | train | INFO | Epoch 2 train batch 221/450: 3536/7200 mean loss: 0.0018154524732381105 score: 1.0
2021-08-08 03:50:47,866 | train | INFO | Epoch 2 train batch 222/450: 3552/7200 mean loss: 0.001722759916447103 score: 1.0
2021-08-08 03:50:48,642 | train | INFO | Epoch 2 train batch 223/450: 3568/7200 mean loss: 0.0018288524588569999 score: 0.9582633053221289
2021-08-08 03:50:49,408 | train | INFO | Epoch 2 train batch 224/450: 3584/7200 mean loss: 0.0017126178136095405 score: 1.0
2021-08-08 03:50:50,173 | train | INFO | Epoch 2 train batch 225/450: 3600/7200 mean loss: 0.0016028109239414334 score: 1.0
2021-08-08 03:50:50,940 | train | INFO | Epoch 2 train batch 226/450: 3616/7200 mean loss: 0.001671583391726017 score: 0.9725678733031674
2021-08-08 03:50:51,718 | train | INFO | Epoch 2 train batch 227/450: 3632/7200 mean loss: 0.0016551361186429858 score: 1.0
2021-08-08 03:50:52,519 | train | INFO | Epoch 2 train batch 228/450: 3648/7200 mean loss: 0.0017426066333428025 score: 0.9963235294117647
2021-08-08 03:50:53,293 | train | INFO | Epoch 2 train batch 229/450: 3664/7200 mean loss: 0.001822756603360176 score: 1.0
2021-08-08 03:50:54,073 | train | INFO | Epoch 2 train batch 230/450: 3680/7200 mean loss: 0.0016451424453407526 score: 0.9963235294117647
2021-08-08 03:50:54,849 | train | INFO | Epoch 2 train batch 231/450: 3696/7200 mean loss: 0.001719514257274568 score: 0.9811274509803922
2021-08-08 03:50:55,726 | train | INFO | Epoch 2 train batch 232/450: 3712/7200 mean loss: 0.0016279323026537895 score: 1.0
2021-08-08 03:50:56,619 | train | INFO | Epoch 2 train batch 233/450: 3728/7200 mean loss: 0.0016767843626439571 score: 0.9963235294117647
2021-08-08 03:50:57,436 | train | INFO | Epoch 2 train batch 234/450: 3744/7200 mean loss: 0.0017215509433299303 score: 1.0
2021-08-08 03:50:58,244 | train | INFO | Epoch 2 train batch 235/450: 3760/7200 mean loss: 0.0015251814620569348 score: 1.0
2021-08-08 03:50:59,060 | train | INFO | Epoch 2 train batch 236/450: 3776/7200 mean loss: 0.0016629399033263326 score: 1.0
2021-08-08 03:50:59,853 | train | INFO | Epoch 2 train batch 237/450: 3792/7200 mean loss: 0.001677243271842599 score: 1.0
2021-08-08 03:51:00,643 | train | INFO | Epoch 2 train batch 238/450: 3808/7200 mean loss: 0.0017122516874223948 score: 1.0
2021-08-08 03:51:01,425 | train | INFO | Epoch 2 train batch 239/450: 3824/7200 mean loss: 0.0015460076974704862 score: 1.0
2021-08-08 03:51:02,204 | train | INFO | Epoch 2 train batch 240/450: 3840/7200 mean loss: 0.0016046649543568492 score: 0.9963235294117647
2021-08-08 03:51:02,985 | train | INFO | Epoch 2 train batch 241/450: 3856/7200 mean loss: 0.0016697344835847616 score: 0.9884803921568628
2021-08-08 03:51:03,769 | train | INFO | Epoch 2 train batch 242/450: 3872/7200 mean loss: 0.0016867087688297033 score: 1.0
2021-08-08 03:51:04,551 | train | INFO | Epoch 2 train batch 243/450: 3888/7200 mean loss: 0.0017571052303537726 score: 0.996078431372549
2021-08-08 03:51:05,326 | train | INFO | Epoch 2 train batch 244/450: 3904/7200 mean loss: 0.0017812036676332355 score: 0.9963235294117647
2021-08-08 03:51:06,090 | train | INFO | Epoch 2 train batch 245/450: 3920/7200 mean loss: 0.0016572467284277081 score: 1.0
2021-08-08 03:51:06,927 | train | INFO | Epoch 2 train batch 246/450: 3936/7200 mean loss: 0.0016101833898574114 score: 0.9889705882352942
2021-08-08 03:51:07,737 | train | INFO | Epoch 2 train batch 247/450: 3952/7200 mean loss: 0.0015712934546172619 score: 1.0
2021-08-08 03:51:08,511 | train | INFO | Epoch 2 train batch 248/450: 3968/7200 mean loss: 0.0016959068598225713 score: 1.0
2021-08-08 03:51:09,289 | train | INFO | Epoch 2 train batch 249/450: 3984/7200 mean loss: 0.0018079897854477167 score: 1.0
2021-08-08 03:51:10,060 | train | INFO | Epoch 2 train batch 250/450: 4000/7200 mean loss: 0.0016184120904654264 score: 0.9889705882352942
2021-08-08 03:51:10,849 | train | INFO | Epoch 2 train batch 251/450: 4016/7200 mean loss: 0.0016833862755447626 score: 1.0
2021-08-08 03:51:11,752 | train | INFO | Epoch 2 train batch 252/450: 4032/7200 mean loss: 0.001699376618489623 score: 1.0
2021-08-08 03:51:12,576 | train | INFO | Epoch 2 train batch 253/450: 4048/7200 mean loss: 0.0017646582564339042 score: 1.0
2021-08-08 03:51:13,379 | train | INFO | Epoch 2 train batch 254/450: 4064/7200 mean loss: 0.0017017185455188155 score: 1.0
2021-08-08 03:51:14,167 | train | INFO | Epoch 2 train batch 255/450: 4080/7200 mean loss: 0.0017759427428245544 score: 0.9889705882352942
2021-08-08 03:51:14,970 | train | INFO | Epoch 2 train batch 256/450: 4096/7200 mean loss: 0.0016239855904132128 score: 1.0
2021-08-08 03:51:15,779 | train | INFO | Epoch 2 train batch 257/450: 4112/7200 mean loss: 0.0016057898756116629 score: 1.0
2021-08-08 03:51:16,601 | train | INFO | Epoch 2 train batch 258/450: 4128/7200 mean loss: 0.0016761677106842399 score: 0.9816176470588235
2021-08-08 03:51:17,375 | train | INFO | Epoch 2 train batch 259/450: 4144/7200 mean loss: 0.0017110352637246251 score: 1.0
2021-08-08 03:51:18,167 | train | INFO | Epoch 2 train batch 260/450: 4160/7200 mean loss: 0.001707113697193563 score: 0.996078431372549
2021-08-08 03:51:18,947 | train | INFO | Epoch 2 train batch 261/450: 4176/7200 mean loss: 0.001661192625761032 score: 1.0
2021-08-08 03:51:19,773 | train | INFO | Epoch 2 train batch 262/450: 4192/7200 mean loss: 0.0018625130178406835 score: 1.0
2021-08-08 03:51:20,548 | train | INFO | Epoch 2 train batch 263/450: 4208/7200 mean loss: 0.0017315571894869208 score: 1.0
2021-08-08 03:51:21,315 | train | INFO | Epoch 2 train batch 264/450: 4224/7200 mean loss: 0.0017315007280558348 score: 1.0
2021-08-08 03:51:22,090 | train | INFO | Epoch 2 train batch 265/450: 4240/7200 mean loss: 0.0018009190680459142 score: 1.0
2021-08-08 03:51:22,856 | train | INFO | Epoch 2 train batch 266/450: 4256/7200 mean loss: 0.0018201725324615836 score: 1.0
2021-08-08 03:51:23,635 | train | INFO | Epoch 2 train batch 267/450: 4272/7200 mean loss: 0.0016309027560055256 score: 1.0
2021-08-08 03:51:24,417 | train | INFO | Epoch 2 train batch 268/450: 4288/7200 mean loss: 0.0018007504986599088 score: 1.0
2021-08-08 03:51:25,214 | train | INFO | Epoch 2 train batch 269/450: 4304/7200 mean loss: 0.0016928352415561676 score: 1.0
2021-08-08 03:51:25,984 | train | INFO | Epoch 2 train batch 270/450: 4320/7200 mean loss: 0.00178488006349653 score: 1.0
2021-08-08 03:51:26,781 | train | INFO | Epoch 2 train batch 271/450: 4336/7200 mean loss: 0.0017509614117443562 score: 1.0
2021-08-08 03:51:27,553 | train | INFO | Epoch 2 train batch 272/450: 4352/7200 mean loss: 0.00175772188231349 score: 0.995798319327731
2021-08-08 03:51:28,358 | train | INFO | Epoch 2 train batch 273/450: 4368/7200 mean loss: 0.0016710265772417188 score: 0.9889705882352942
2021-08-08 03:51:29,139 | train | INFO | Epoch 2 train batch 274/450: 4384/7200 mean loss: 0.0017072652699425817 score: 1.0
2021-08-08 03:51:29,936 | train | INFO | Epoch 2 train batch 275/450: 4400/7200 mean loss: 0.0018576227594166994 score: 0.9889705882352942
2021-08-08 03:51:30,744 | train | INFO | Epoch 2 train batch 276/450: 4416/7200 mean loss: 0.001683368464000523 score: 1.0
2021-08-08 03:51:31,520 | train | INFO | Epoch 2 train batch 277/450: 4432/7200 mean loss: 0.0016094568418338895 score: 1.0
2021-08-08 03:51:32,347 | train | INFO | Epoch 2 train batch 278/450: 4448/7200 mean loss: 0.0017152278451249003 score: 0.9963235294117647
2021-08-08 03:51:33,132 | train | INFO | Epoch 2 train batch 279/450: 4464/7200 mean loss: 0.001704960479401052 score: 1.0
2021-08-08 03:51:33,964 | train | INFO | Epoch 2 train batch 280/450: 4480/7200 mean loss: 0.0015833729412406683 score: 1.0
2021-08-08 03:51:34,858 | train | INFO | Epoch 2 train batch 281/450: 4496/7200 mean loss: 0.0017557741375640035 score: 0.9742647058823529
2021-08-08 03:51:35,747 | train | INFO | Epoch 2 train batch 282/450: 4512/7200 mean loss: 0.001673368620686233 score: 1.0
2021-08-08 03:51:36,678 | train | INFO | Epoch 2 train batch 283/450: 4528/7200 mean loss: 0.0017814177554100752 score: 1.0
2021-08-08 03:51:37,584 | train | INFO | Epoch 2 train batch 284/450: 4544/7200 mean loss: 0.0017079812241718173 score: 1.0
2021-08-08 03:51:38,393 | train | INFO | Epoch 2 train batch 285/450: 4560/7200 mean loss: 0.001692228834144771 score: 1.0
2021-08-08 03:51:39,175 | train | INFO | Epoch 2 train batch 286/450: 4576/7200 mean loss: 0.0017041813116520643 score: 1.0
2021-08-08 03:51:39,966 | train | INFO | Epoch 2 train batch 287/450: 4592/7200 mean loss: 0.0017291445983573794 score: 1.0
2021-08-08 03:51:40,739 | train | INFO | Epoch 2 train batch 288/450: 4608/7200 mean loss: 0.0017684142803773284 score: 1.0
2021-08-08 03:51:41,540 | train | INFO | Epoch 2 train batch 289/450: 4624/7200 mean loss: 0.0017607762711122632 score: 0.9406862745098039
2021-08-08 03:51:42,393 | train | INFO | Epoch 2 train batch 290/450: 4640/7200 mean loss: 0.0018656703177839518 score: 1.0
2021-08-08 03:51:43,196 | train | INFO | Epoch 2 train batch 291/450: 4656/7200 mean loss: 0.0017159224953502417 score: 1.0
2021-08-08 03:51:44,096 | train | INFO | Epoch 2 train batch 292/450: 4672/7200 mean loss: 0.0019375073025003076 score: 0.996078431372549
2021-08-08 03:51:44,873 | train | INFO | Epoch 2 train batch 293/450: 4688/7200 mean loss: 0.0018018987029790878 score: 0.9742647058823529
2021-08-08 03:51:45,650 | train | INFO | Epoch 2 train batch 294/450: 4704/7200 mean loss: 0.001642404473386705 score: 1.0
2021-08-08 03:51:46,463 | train | INFO | Epoch 2 train batch 295/450: 4720/7200 mean loss: 0.0016169017180800438 score: 1.0
2021-08-08 03:51:47,237 | train | INFO | Epoch 2 train batch 296/450: 4736/7200 mean loss: 0.0016650125617161393 score: 1.0
2021-08-08 03:51:48,056 | train | INFO | Epoch 2 train batch 297/450: 4752/7200 mean loss: 0.0015852309297770262 score: 1.0
2021-08-08 03:51:48,860 | train | INFO | Epoch 2 train batch 298/450: 4768/7200 mean loss: 0.0016705711605027318 score: 1.0
2021-08-08 03:51:49,687 | train | INFO | Epoch 2 train batch 299/450: 4784/7200 mean loss: 0.0017253590049222112 score: 1.0
2021-08-08 03:51:50,477 | train | INFO | Epoch 2 train batch 300/450: 4800/7200 mean loss: 0.0016542100347578526 score: 1.0
2021-08-08 03:51:51,275 | train | INFO | Epoch 2 train batch 301/450: 4816/7200 mean loss: 0.0017186451004818082 score: 1.0
2021-08-08 03:51:52,059 | train | INFO | Epoch 2 train batch 302/450: 4832/7200 mean loss: 0.0016814443515613675 score: 1.0
2021-08-08 03:51:52,839 | train | INFO | Epoch 2 train batch 303/450: 4848/7200 mean loss: 0.001619373564608395 score: 1.0
2021-08-08 03:51:53,614 | train | INFO | Epoch 2 train batch 304/450: 4864/7200 mean loss: 0.001705455593764782 score: 0.9963235294117647
2021-08-08 03:51:54,393 | train | INFO | Epoch 2 train batch 305/450: 4880/7200 mean loss: 0.0018560667522251606 score: 1.0
2021-08-08 03:51:55,195 | train | INFO | Epoch 2 train batch 306/450: 4896/7200 mean loss: 0.001730612013489008 score: 1.0
2021-08-08 03:51:55,989 | train | INFO | Epoch 2 train batch 307/450: 4912/7200 mean loss: 0.0017093939241021872 score: 0.996078431372549
2021-08-08 03:51:56,892 | train | INFO | Epoch 2 train batch 308/450: 4928/7200 mean loss: 0.0017630209913477302 score: 1.0
2021-08-08 03:51:57,670 | train | INFO | Epoch 2 train batch 309/450: 4944/7200 mean loss: 0.00170845293905586 score: 1.0
2021-08-08 03:51:58,457 | train | INFO | Epoch 2 train batch 310/450: 4960/7200 mean loss: 0.0016987352864816785 score: 1.0
2021-08-08 03:51:59,245 | train | INFO | Epoch 2 train batch 311/450: 4976/7200 mean loss: 0.001772622810676694 score: 1.0
2021-08-08 03:52:00,022 | train | INFO | Epoch 2 train batch 312/450: 4992/7200 mean loss: 0.0016131954034790397 score: 0.996078431372549
2021-08-08 03:52:00,825 | train | INFO | Epoch 2 train batch 313/450: 5008/7200 mean loss: 0.0017057411605492234 score: 1.0
2021-08-08 03:52:01,615 | train | INFO | Epoch 2 train batch 314/450: 5024/7200 mean loss: 0.0015984858619049191 score: 1.0
2021-08-08 03:52:02,389 | train | INFO | Epoch 2 train batch 315/450: 5040/7200 mean loss: 0.001610824023373425 score: 1.0
2021-08-08 03:52:03,179 | train | INFO | Epoch 2 train batch 316/450: 5056/7200 mean loss: 0.0014894392807036638 score: 0.9963235294117647
2021-08-08 03:52:03,969 | train | INFO | Epoch 2 train batch 317/450: 5072/7200 mean loss: 0.0018375173676759005 score: 1.0
2021-08-08 03:52:04,773 | train | INFO | Epoch 2 train batch 318/450: 5088/7200 mean loss: 0.0017331002745777369 score: 1.0
2021-08-08 03:52:05,566 | train | INFO | Epoch 2 train batch 319/450: 5104/7200 mean loss: 0.0017848103307187557 score: 1.0
2021-08-08 03:52:06,352 | train | INFO | Epoch 2 train batch 320/450: 5120/7200 mean loss: 0.0016868531238287687 score: 1.0
2021-08-08 03:52:07,142 | train | INFO | Epoch 2 train batch 321/450: 5136/7200 mean loss: 0.0017108391039073467 score: 1.0
2021-08-08 03:52:07,950 | train | INFO | Epoch 2 train batch 322/450: 5152/7200 mean loss: 0.001743422937579453 score: 0.9963235294117647
2021-08-08 03:52:08,765 | train | INFO | Epoch 2 train batch 323/450: 5168/7200 mean loss: 0.0017251140670850873 score: 1.0
2021-08-08 03:52:09,528 | train | INFO | Epoch 2 train batch 324/450: 5184/7200 mean loss: 0.0015375023940578103 score: 0.9963235294117647
2021-08-08 03:52:10,331 | train | INFO | Epoch 2 train batch 325/450: 5200/7200 mean loss: 0.0015818006359040737 score: 1.0
2021-08-08 03:52:11,116 | train | INFO | Epoch 2 train batch 326/450: 5216/7200 mean loss: 0.0015892346855252981 score: 1.0
2021-08-08 03:52:11,982 | train | INFO | Epoch 2 train batch 327/450: 5232/7200 mean loss: 0.0015955603448674083 score: 0.9926470588235294
2021-08-08 03:52:12,750 | train | INFO | Epoch 2 train batch 328/450: 5248/7200 mean loss: 0.0016259158728644252 score: 0.9884803921568628
2021-08-08 03:52:13,534 | train | INFO | Epoch 2 train batch 329/450: 5264/7200 mean loss: 0.0016220267862081528 score: 1.0
2021-08-08 03:52:14,347 | train | INFO | Epoch 2 train batch 330/450: 5280/7200 mean loss: 0.00174768699798733 score: 0.9924019607843138
2021-08-08 03:52:15,140 | train | INFO | Epoch 2 train batch 331/450: 5296/7200 mean loss: 0.0015914022224023938 score: 1.0
2021-08-08 03:52:15,925 | train | INFO | Epoch 2 train batch 332/450: 5312/7200 mean loss: 0.0015998268499970436 score: 1.0
2021-08-08 03:52:16,709 | train | INFO | Epoch 2 train batch 333/450: 5328/7200 mean loss: 0.00161642802413553 score: 1.0
2021-08-08 03:52:17,489 | train | INFO | Epoch 2 train batch 334/450: 5344/7200 mean loss: 0.00156897131819278 score: 1.0
2021-08-08 03:52:18,303 | train | INFO | Epoch 2 train batch 335/450: 5360/7200 mean loss: 0.0016797074349597096 score: 1.0
2021-08-08 03:52:19,083 | train | INFO | Epoch 2 train batch 336/450: 5376/7200 mean loss: 0.0016881299670785666 score: 1.0
2021-08-08 03:52:19,899 | train | INFO | Epoch 2 train batch 337/450: 5392/7200 mean loss: 0.0017765656812116504 score: 1.0
2021-08-08 03:52:20,677 | train | INFO | Epoch 2 train batch 338/450: 5408/7200 mean loss: 0.0015696513000875711 score: 1.0
2021-08-08 03:52:21,506 | train | INFO | Epoch 2 train batch 339/450: 5424/7200 mean loss: 0.0016458979807794094 score: 0.9921218487394959
2021-08-08 03:52:22,334 | train | INFO | Epoch 2 train batch 340/450: 5440/7200 mean loss: 0.0017642119200900197 score: 1.0
2021-08-08 03:52:23,115 | train | INFO | Epoch 2 train batch 341/450: 5456/7200 mean loss: 0.0015016847755759954 score: 1.0
2021-08-08 03:52:24,032 | train | INFO | Epoch 2 train batch 342/450: 5472/7200 mean loss: 0.001608090358786285 score: 1.0
2021-08-08 03:52:24,935 | train | INFO | Epoch 2 train batch 343/450: 5488/7200 mean loss: 0.0016141593223437667 score: 1.0
2021-08-08 03:52:25,723 | train | INFO | Epoch 2 train batch 344/450: 5504/7200 mean loss: 0.0018447142792865634 score: 1.0
2021-08-08 03:52:26,551 | train | INFO | Epoch 2 train batch 345/450: 5520/7200 mean loss: 0.0017558139516040683 score: 1.0
2021-08-08 03:52:27,346 | train | INFO | Epoch 2 train batch 346/450: 5536/7200 mean loss: 0.001766030676662922 score: 1.0
2021-08-08 03:52:28,243 | train | INFO | Epoch 2 train batch 347/450: 5552/7200 mean loss: 0.0017494653584435582 score: 1.0
2021-08-08 03:52:29,010 | train | INFO | Epoch 2 train batch 348/450: 5568/7200 mean loss: 0.0017854712205007672 score: 1.0
2021-08-08 03:52:29,924 | train | INFO | Epoch 2 train batch 349/450: 5584/7200 mean loss: 0.0017568713519722223 score: 1.0
2021-08-08 03:52:30,705 | train | INFO | Epoch 2 train batch 350/450: 5600/7200 mean loss: 0.0017772401915863156 score: 1.0
2021-08-08 03:52:31,475 | train | INFO | Epoch 2 train batch 351/450: 5616/7200 mean loss: 0.0017621186561882496 score: 0.9737745098039216
2021-08-08 03:52:32,247 | train | INFO | Epoch 2 train batch 352/450: 5632/7200 mean loss: 0.0016654131468385458 score: 1.0
2021-08-08 03:52:33,028 | train | INFO | Epoch 2 train batch 353/450: 5648/7200 mean loss: 0.0016743496526032686 score: 0.9889705882352942
2021-08-08 03:52:33,837 | train | INFO | Epoch 2 train batch 354/450: 5664/7200 mean loss: 0.0016393327387049794 score: 0.9852941176470589
2021-08-08 03:52:34,693 | train | INFO | Epoch 2 train batch 355/450: 5680/7200 mean loss: 0.001596454530954361 score: 1.0
2021-08-08 03:52:35,490 | train | INFO | Epoch 2 train batch 356/450: 5696/7200 mean loss: 0.001670156721957028 score: 1.0
2021-08-08 03:52:36,256 | train | INFO | Epoch 2 train batch 357/450: 5712/7200 mean loss: 0.0016728434711694717 score: 1.0
2021-08-08 03:52:37,027 | train | INFO | Epoch 2 train batch 358/450: 5728/7200 mean loss: 0.0015860979910939932 score: 1.0
2021-08-08 03:52:37,812 | train | INFO | Epoch 2 train batch 359/450: 5744/7200 mean loss: 0.001697792555205524 score: 1.0
2021-08-08 03:52:38,620 | train | INFO | Epoch 2 train batch 360/450: 5760/7200 mean loss: 0.0016189133748412132 score: 1.0
2021-08-08 03:52:39,401 | train | INFO | Epoch 2 train batch 361/450: 5776/7200 mean loss: 0.0017139423871412873 score: 1.0
2021-08-08 03:52:40,178 | train | INFO | Epoch 2 train batch 362/450: 5792/7200 mean loss: 0.0015910235233604908 score: 1.0
2021-08-08 03:52:41,069 | train | INFO | Epoch 2 train batch 363/450: 5808/7200 mean loss: 0.0016537160845473409 score: 1.0
2021-08-08 03:52:41,859 | train | INFO | Epoch 2 train batch 364/450: 5824/7200 mean loss: 0.0016316213877871633 score: 0.9963235294117647
2021-08-08 03:52:42,662 | train | INFO | Epoch 2 train batch 365/450: 5840/7200 mean loss: 0.0017568491166457534 score: 1.0
2021-08-08 03:52:43,461 | train | INFO | Epoch 2 train batch 366/450: 5856/7200 mean loss: 0.0017031575553119183 score: 1.0
2021-08-08 03:52:44,244 | train | INFO | Epoch 2 train batch 367/450: 5872/7200 mean loss: 0.001679178443737328 score: 0.9963235294117647
2021-08-08 03:52:45,035 | train | INFO | Epoch 2 train batch 368/450: 5888/7200 mean loss: 0.0017001754604279995 score: 0.9963235294117647
2021-08-08 03:52:45,850 | train | INFO | Epoch 2 train batch 369/450: 5904/7200 mean loss: 0.001758541795425117 score: 1.0
2021-08-08 03:52:46,643 | train | INFO | Epoch 2 train batch 370/450: 5920/7200 mean loss: 0.0017368237022310495 score: 1.0
2021-08-08 03:52:47,437 | train | INFO | Epoch 2 train batch 371/450: 5936/7200 mean loss: 0.0017824477981776 score: 1.0
2021-08-08 03:52:48,218 | train | INFO | Epoch 2 train batch 372/450: 5952/7200 mean loss: 0.0016447781817987561 score: 1.0
2021-08-08 03:52:49,038 | train | INFO | Epoch 2 train batch 373/450: 5968/7200 mean loss: 0.0016319190617650747 score: 1.0
2021-08-08 03:52:49,840 | train | INFO | Epoch 2 train batch 374/450: 5984/7200 mean loss: 0.001749358489178121 score: 0.9963235294117647
2021-08-08 03:52:50,607 | train | INFO | Epoch 2 train batch 375/450: 6000/7200 mean loss: 0.0015928703360259533 score: 1.0
2021-08-08 03:52:51,390 | train | INFO | Epoch 2 train batch 376/450: 6016/7200 mean loss: 0.0016852646367624402 score: 1.0
2021-08-08 03:52:52,159 | train | INFO | Epoch 2 train batch 377/450: 6032/7200 mean loss: 0.0016359068686142564 score: 1.0
2021-08-08 03:52:52,976 | train | INFO | Epoch 2 train batch 378/450: 6048/7200 mean loss: 0.0016021698247641325 score: 1.0
2021-08-08 03:52:53,803 | train | INFO | Epoch 2 train batch 379/450: 6064/7200 mean loss: 0.0017370108980685472 score: 1.0
2021-08-08 03:52:54,617 | train | INFO | Epoch 2 train batch 380/450: 6080/7200 mean loss: 0.001620474737137556 score: 0.9963235294117647
2021-08-08 03:52:55,381 | train | INFO | Epoch 2 train batch 381/450: 6096/7200 mean loss: 0.0017208534991368651 score: 1.0
2021-08-08 03:52:56,147 | train | INFO | Epoch 2 train batch 382/450: 6112/7200 mean loss: 0.0016501706559211016 score: 1.0
2021-08-08 03:52:56,927 | train | INFO | Epoch 2 train batch 383/450: 6128/7200 mean loss: 0.0017715736757963896 score: 1.0
2021-08-08 03:52:57,734 | train | INFO | Epoch 2 train batch 384/450: 6144/7200 mean loss: 0.0016902381321415305 score: 1.0
2021-08-08 03:52:58,516 | train | INFO | Epoch 2 train batch 385/450: 6160/7200 mean loss: 0.0016637046355754137 score: 1.0
2021-08-08 03:52:59,298 | train | INFO | Epoch 2 train batch 386/450: 6176/7200 mean loss: 0.0017657337011769414 score: 0.9963235294117647
2021-08-08 03:53:00,125 | train | INFO | Epoch 2 train batch 387/450: 6192/7200 mean loss: 0.0018656913889572024 score: 1.0
2021-08-08 03:53:00,929 | train | INFO | Epoch 2 train batch 388/450: 6208/7200 mean loss: 0.0016596451168879867 score: 0.9963235294117647
2021-08-08 03:53:01,793 | train | INFO | Epoch 2 train batch 389/450: 6224/7200 mean loss: 0.0018012236105278134 score: 0.836764705882353
2021-08-08 03:53:02,602 | train | INFO | Epoch 2 train batch 390/450: 6240/7200 mean loss: 0.0014750753762200475 score: 0.9889705882352942
2021-08-08 03:53:03,409 | train | INFO | Epoch 2 train batch 391/450: 6256/7200 mean loss: 0.0015727448044344783 score: 1.0
2021-08-08 03:53:04,185 | train | INFO | Epoch 2 train batch 392/450: 6272/7200 mean loss: 0.0014927360462024808 score: 1.0
2021-08-08 03:53:04,969 | train | INFO | Epoch 2 train batch 393/450: 6288/7200 mean loss: 0.0015434875385835767 score: 1.0
2021-08-08 03:53:05,777 | train | INFO | Epoch 2 train batch 394/450: 6304/7200 mean loss: 0.0015606641536578536 score: 1.0
2021-08-08 03:53:06,568 | train | INFO | Epoch 2 train batch 395/450: 6320/7200 mean loss: 0.0015171783743426204 score: 1.0
2021-08-08 03:53:07,344 | train | INFO | Epoch 2 train batch 396/450: 6336/7200 mean loss: 0.0016409135423600674 score: 1.0
2021-08-08 03:53:08,118 | train | INFO | Epoch 2 train batch 397/450: 6352/7200 mean loss: 0.0017977718962356448 score: 1.0
2021-08-08 03:53:08,935 | train | INFO | Epoch 2 train batch 398/450: 6368/7200 mean loss: 0.0016169294249266386 score: 1.0
2021-08-08 03:53:09,722 | train | INFO | Epoch 2 train batch 399/450: 6384/7200 mean loss: 0.0017601862782612443 score: 0.9926470588235294
2021-08-08 03:53:10,549 | train | INFO | Epoch 2 train batch 400/450: 6400/7200 mean loss: 0.0017517107771709561 score: 1.0
2021-08-08 03:53:11,320 | train | INFO | Epoch 2 train batch 401/450: 6416/7200 mean loss: 0.0015678436029702425 score: 1.0
2021-08-08 03:53:12,118 | train | INFO | Epoch 2 train batch 402/450: 6432/7200 mean loss: 0.001671004923991859 score: 1.0
2021-08-08 03:53:12,930 | train | INFO | Epoch 2 train batch 403/450: 6448/7200 mean loss: 0.0016602884279564023 score: 1.0
2021-08-08 03:53:13,733 | train | INFO | Epoch 2 train batch 404/450: 6464/7200 mean loss: 0.001610561739653349 score: 1.0
2021-08-08 03:53:14,505 | train | INFO | Epoch 2 train batch 405/450: 6480/7200 mean loss: 0.0016178296646103263 score: 0.9926470588235294
2021-08-08 03:53:15,307 | train | INFO | Epoch 2 train batch 406/450: 6496/7200 mean loss: 0.0016746718902140856 score: 0.9963235294117647
2021-08-08 03:53:16,119 | train | INFO | Epoch 2 train batch 407/450: 6512/7200 mean loss: 0.001563687459565699 score: 0.9666666666666667
2021-08-08 03:53:16,954 | train | INFO | Epoch 2 train batch 408/450: 6528/7200 mean loss: 0.0016649544704705477 score: 1.0
2021-08-08 03:53:17,758 | train | INFO | Epoch 2 train batch 409/450: 6544/7200 mean loss: 0.0015909104840829968 score: 1.0
2021-08-08 03:53:18,601 | train | INFO | Epoch 2 train batch 410/450: 6560/7200 mean loss: 0.0016555936308577657 score: 1.0
2021-08-08 03:53:19,373 | train | INFO | Epoch 2 train batch 411/450: 6576/7200 mean loss: 0.001704179449006915 score: 0.9921568627450981
2021-08-08 03:53:20,206 | train | INFO | Epoch 2 train batch 412/450: 6592/7200 mean loss: 0.0016924651572480798 score: 1.0
2021-08-08 03:53:20,989 | train | INFO | Epoch 2 train batch 413/450: 6608/7200 mean loss: 0.0016433444106951356 score: 0.995475113122172
2021-08-08 03:53:21,773 | train | INFO | Epoch 2 train batch 414/450: 6624/7200 mean loss: 0.001709692762233317 score: 1.0
2021-08-08 03:53:22,587 | train | INFO | Epoch 2 train batch 415/450: 6640/7200 mean loss: 0.0016486302483826876 score: 1.0
2021-08-08 03:53:23,376 | train | INFO | Epoch 2 train batch 416/450: 6656/7200 mean loss: 0.0015909246867522597 score: 1.0
2021-08-08 03:53:24,164 | train | INFO | Epoch 2 train batch 417/450: 6672/7200 mean loss: 0.001655713771469891 score: 1.0
2021-08-08 03:53:24,951 | train | INFO | Epoch 2 train batch 418/450: 6688/7200 mean loss: 0.0016738916747272015 score: 1.0
2021-08-08 03:53:25,724 | train | INFO | Epoch 2 train batch 419/450: 6704/7200 mean loss: 0.0017621619626879692 score: 1.0
2021-08-08 03:53:26,538 | train | INFO | Epoch 2 train batch 420/450: 6720/7200 mean loss: 0.001830122317187488 score: 1.0
2021-08-08 03:53:27,343 | train | INFO | Epoch 2 train batch 421/450: 6736/7200 mean loss: 0.0018213049042969942 score: 0.9889705882352942
2021-08-08 03:53:28,148 | train | INFO | Epoch 2 train batch 422/450: 6752/7200 mean loss: 0.0016487182583659887 score: 0.995798319327731
2021-08-08 03:53:28,941 | train | INFO | Epoch 2 train batch 423/450: 6768/7200 mean loss: 0.0018227327382192016 score: 1.0
2021-08-08 03:53:29,826 | train | INFO | Epoch 2 train batch 424/450: 6784/7200 mean loss: 0.0016653150087222457 score: 1.0
2021-08-08 03:53:30,658 | train | INFO | Epoch 2 train batch 425/450: 6800/7200 mean loss: 0.0016753275413066149 score: 1.0
2021-08-08 03:53:31,429 | train | INFO | Epoch 2 train batch 426/450: 6816/7200 mean loss: 0.0017089176690205932 score: 0.996078431372549
2021-08-08 03:53:32,210 | train | INFO | Epoch 2 train batch 427/450: 6832/7200 mean loss: 0.001769605209119618 score: 1.0
2021-08-08 03:53:33,014 | train | INFO | Epoch 2 train batch 428/450: 6848/7200 mean loss: 0.0018497173441573977 score: 0.9768907563025211
2021-08-08 03:53:33,790 | train | INFO | Epoch 2 train batch 429/450: 6864/7200 mean loss: 0.0017713489942252636 score: 1.0
2021-08-08 03:53:34,570 | train | INFO | Epoch 2 train batch 430/450: 6880/7200 mean loss: 0.0016609241720288992 score: 1.0
2021-08-08 03:53:35,418 | train | INFO | Epoch 2 train batch 431/450: 6896/7200 mean loss: 0.0018098029540851712 score: 1.0
2021-08-08 03:53:36,204 | train | INFO | Epoch 2 train batch 432/450: 6912/7200 mean loss: 0.0015185073716565967 score: 1.0
2021-08-08 03:53:37,040 | train | INFO | Epoch 2 train batch 433/450: 6928/7200 mean loss: 0.0016136323101818562 score: 0.9963235294117647
2021-08-08 03:53:37,818 | train | INFO | Epoch 2 train batch 434/450: 6944/7200 mean loss: 0.0017567673930898309 score: 1.0
2021-08-08 03:53:38,593 | train | INFO | Epoch 2 train batch 435/450: 6960/7200 mean loss: 0.0016841049073264003 score: 0.9884803921568628
2021-08-08 03:53:39,396 | train | INFO | Epoch 2 train batch 436/450: 6976/7200 mean loss: 0.0016525909304618835 score: 1.0
2021-08-08 03:53:40,204 | train | INFO | Epoch 2 train batch 437/450: 6992/7200 mean loss: 0.001609155093319714 score: 1.0
2021-08-08 03:53:40,972 | train | INFO | Epoch 2 train batch 438/450: 7008/7200 mean loss: 0.0017725639045238495 score: 1.0
2021-08-08 03:53:41,753 | train | INFO | Epoch 2 train batch 439/450: 7024/7200 mean loss: 0.001813350128941238 score: 1.0
2021-08-08 03:53:42,536 | train | INFO | Epoch 2 train batch 440/450: 7040/7200 mean loss: 0.0015871311770752072 score: 0.9926470588235294
2021-08-08 03:53:43,310 | train | INFO | Epoch 2 train batch 441/450: 7056/7200 mean loss: 0.0017369523411616683 score: 0.9963235294117647
2021-08-08 03:53:44,080 | train | INFO | Epoch 2 train batch 442/450: 7072/7200 mean loss: 0.0016166067216545343 score: 1.0
2021-08-08 03:53:44,850 | train | INFO | Epoch 2 train batch 443/450: 7088/7200 mean loss: 0.001713522127829492 score: 1.0
2021-08-08 03:53:45,628 | train | INFO | Epoch 2 train batch 444/450: 7104/7200 mean loss: 0.0017961497651413083 score: 1.0
2021-08-08 03:53:46,398 | train | INFO | Epoch 2 train batch 445/450: 7120/7200 mean loss: 0.0015409012557938695 score: 0.9963235294117647
2021-08-08 03:53:47,186 | train | INFO | Epoch 2 train batch 446/450: 7136/7200 mean loss: 0.00160601653624326 score: 1.0
2021-08-08 03:53:47,971 | train | INFO | Epoch 2 train batch 447/450: 7152/7200 mean loss: 0.0016647811280563474 score: 1.0
2021-08-08 03:53:48,752 | train | INFO | Epoch 2 train batch 448/450: 7168/7200 mean loss: 0.0014463888946920633 score: 1.0
2021-08-08 03:53:49,519 | train | INFO | Epoch 2 train batch 449/450: 7184/7200 mean loss: 0.0016508606495335698 score: 1.0
2021-08-08 03:53:49,684 | train | INFO | Epoch 2, Train, Mean loss: 0.027218873811264834, Score: 0.9937465644377408
2021-08-08 03:53:51,165 | train | INFO | Epoch 2 validation batch 0/113: 0/1800 mean loss: 0.0013968232087790966 score: 1.0
2021-08-08 03:53:51,399 | train | INFO | Epoch 2 validation batch 1/113: 16/1800 mean loss: 0.0013454327126964927 score: 1.0
2021-08-08 03:53:51,648 | train | INFO | Epoch 2 validation batch 2/113: 32/1800 mean loss: 0.001512016518972814 score: 1.0
2021-08-08 03:53:51,896 | train | INFO | Epoch 2 validation batch 3/113: 48/1800 mean loss: 0.0014470245223492384 score: 1.0
2021-08-08 03:53:52,135 | train | INFO | Epoch 2 validation batch 4/113: 64/1800 mean loss: 0.0013654254144057631 score: 1.0
2021-08-08 03:53:52,369 | train | INFO | Epoch 2 validation batch 5/113: 80/1800 mean loss: 0.001439131097868085 score: 1.0
2021-08-08 03:53:52,603 | train | INFO | Epoch 2 validation batch 6/113: 96/1800 mean loss: 0.0013260451378300786 score: 1.0
2021-08-08 03:53:52,837 | train | INFO | Epoch 2 validation batch 7/113: 112/1800 mean loss: 0.0014507791493088007 score: 1.0
2021-08-08 03:53:53,089 | train | INFO | Epoch 2 validation batch 8/113: 128/1800 mean loss: 0.0014217927819117904 score: 1.0
2021-08-08 03:53:53,325 | train | INFO | Epoch 2 validation batch 9/113: 144/1800 mean loss: 0.0013199293753132224 score: 1.0
2021-08-08 03:53:53,559 | train | INFO | Epoch 2 validation batch 10/113: 160/1800 mean loss: 0.0013283452717587352 score: 0.9742647058823529
2021-08-08 03:53:53,790 | train | INFO | Epoch 2 validation batch 11/113: 176/1800 mean loss: 0.0014371228171512485 score: 0.9926470588235294
2021-08-08 03:53:54,022 | train | INFO | Epoch 2 validation batch 12/113: 192/1800 mean loss: 0.001379679306410253 score: 1.0
2021-08-08 03:53:54,254 | train | INFO | Epoch 2 validation batch 13/113: 208/1800 mean loss: 0.0013826723443344235 score: 1.0
2021-08-08 03:53:54,487 | train | INFO | Epoch 2 validation batch 14/113: 224/1800 mean loss: 0.0013289246708154678 score: 1.0
2021-08-08 03:53:54,735 | train | INFO | Epoch 2 validation batch 15/113: 240/1800 mean loss: 0.001307313097640872 score: 1.0
2021-08-08 03:53:54,982 | train | INFO | Epoch 2 validation batch 16/113: 256/1800 mean loss: 0.001345430500805378 score: 1.0
2021-08-08 03:53:55,223 | train | INFO | Epoch 2 validation batch 17/113: 272/1800 mean loss: 0.001431540702469647 score: 1.0
2021-08-08 03:53:55,456 | train | INFO | Epoch 2 validation batch 18/113: 288/1800 mean loss: 0.0012259590439498425 score: 1.0
2021-08-08 03:53:55,687 | train | INFO | Epoch 2 validation batch 19/113: 304/1800 mean loss: 0.0013182043330743909 score: 1.0
2021-08-08 03:53:55,938 | train | INFO | Epoch 2 validation batch 20/113: 320/1800 mean loss: 0.001401355373673141 score: 0.9813725490196079
2021-08-08 03:53:56,176 | train | INFO | Epoch 2 validation batch 21/113: 336/1800 mean loss: 0.0013260270934551954 score: 1.0
2021-08-08 03:53:56,447 | train | INFO | Epoch 2 validation batch 22/113: 352/1800 mean loss: 0.0012634200975298882 score: 1.0
2021-08-08 03:53:56,678 | train | INFO | Epoch 2 validation batch 23/113: 368/1800 mean loss: 0.0012922962196171284 score: 1.0
2021-08-08 03:53:56,914 | train | INFO | Epoch 2 validation batch 24/113: 384/1800 mean loss: 0.0013579665683209896 score: 1.0
2021-08-08 03:53:57,192 | train | INFO | Epoch 2 validation batch 25/113: 400/1800 mean loss: 0.0014462951803579926 score: 1.0
2021-08-08 03:53:57,431 | train | INFO | Epoch 2 validation batch 26/113: 416/1800 mean loss: 0.001323655596934259 score: 1.0
2021-08-08 03:53:57,676 | train | INFO | Epoch 2 validation batch 27/113: 432/1800 mean loss: 0.0014755940064787865 score: 1.0
2021-08-08 03:53:57,913 | train | INFO | Epoch 2 validation batch 28/113: 448/1800 mean loss: 0.001331297098658979 score: 1.0
2021-08-08 03:53:58,163 | train | INFO | Epoch 2 validation batch 29/113: 464/1800 mean loss: 0.0014268989907577634 score: 1.0
2021-08-08 03:53:58,420 | train | INFO | Epoch 2 validation batch 30/113: 480/1800 mean loss: 0.0014490054454654455 score: 1.0
2021-08-08 03:53:58,670 | train | INFO | Epoch 2 validation batch 31/113: 496/1800 mean loss: 0.0013059350894764066 score: 1.0
2021-08-08 03:53:58,900 | train | INFO | Epoch 2 validation batch 32/113: 512/1800 mean loss: 0.0013737003318965435 score: 0.9963235294117647
2021-08-08 03:53:59,147 | train | INFO | Epoch 2 validation batch 33/113: 528/1800 mean loss: 0.0013411843683570623 score: 1.0
2021-08-08 03:53:59,377 | train | INFO | Epoch 2 validation batch 34/113: 544/1800 mean loss: 0.001196629018522799 score: 1.0
2021-08-08 03:53:59,608 | train | INFO | Epoch 2 validation batch 35/113: 560/1800 mean loss: 0.0014352108119055629 score: 1.0
2021-08-08 03:53:59,869 | train | INFO | Epoch 2 validation batch 36/113: 576/1800 mean loss: 0.0015211711870506406 score: 0.8213235294117647
2021-08-08 03:54:00,103 | train | INFO | Epoch 2 validation batch 37/113: 592/1800 mean loss: 0.0012138468446210027 score: 1.0
2021-08-08 03:54:00,334 | train | INFO | Epoch 2 validation batch 38/113: 608/1800 mean loss: 0.0014341825153678656 score: 1.0
2021-08-08 03:54:00,565 | train | INFO | Epoch 2 validation batch 39/113: 624/1800 mean loss: 0.0013563999673351645 score: 0.9963235294117647
2021-08-08 03:54:00,797 | train | INFO | Epoch 2 validation batch 40/113: 640/1800 mean loss: 0.001424372778274119 score: 0.9963235294117647
2021-08-08 03:54:01,032 | train | INFO | Epoch 2 validation batch 41/113: 656/1800 mean loss: 0.0013489958364516497 score: 1.0
2021-08-08 03:54:01,311 | train | INFO | Epoch 2 validation batch 42/113: 672/1800 mean loss: 0.001340477610938251 score: 0.9776960784313725
2021-08-08 03:54:01,565 | train | INFO | Epoch 2 validation batch 43/113: 688/1800 mean loss: 0.0013679718831554055 score: 1.0
2021-08-08 03:54:01,797 | train | INFO | Epoch 2 validation batch 44/113: 704/1800 mean loss: 0.0014821417862549424 score: 0.9632352941176471
2021-08-08 03:54:02,046 | train | INFO | Epoch 2 validation batch 45/113: 720/1800 mean loss: 0.001359813497401774 score: 1.0
2021-08-08 03:54:02,301 | train | INFO | Epoch 2 validation batch 46/113: 736/1800 mean loss: 0.001369409030303359 score: 0.9926470588235294
2021-08-08 03:54:02,575 | train | INFO | Epoch 2 validation batch 47/113: 752/1800 mean loss: 0.0013272659853100777 score: 1.0
2021-08-08 03:54:02,807 | train | INFO | Epoch 2 validation batch 48/113: 768/1800 mean loss: 0.0014265633653849363 score: 1.0
2021-08-08 03:54:03,039 | train | INFO | Epoch 2 validation batch 49/113: 784/1800 mean loss: 0.001380527624860406 score: 1.0
2021-08-08 03:54:03,289 | train | INFO | Epoch 2 validation batch 50/113: 800/1800 mean loss: 0.0013148186262696981 score: 0.9963235294117647
2021-08-08 03:54:03,523 | train | INFO | Epoch 2 validation batch 51/113: 816/1800 mean loss: 0.001428863382898271 score: 0.9558823529411765
2021-08-08 03:54:03,754 | train | INFO | Epoch 2 validation batch 52/113: 832/1800 mean loss: 0.0014650817029178143 score: 1.0
2021-08-08 03:54:03,985 | train | INFO | Epoch 2 validation batch 53/113: 848/1800 mean loss: 0.0014140359126031399 score: 1.0
2021-08-08 03:54:04,228 | train | INFO | Epoch 2 validation batch 54/113: 864/1800 mean loss: 0.0013269075425341725 score: 1.0
2021-08-08 03:54:04,459 | train | INFO | Epoch 2 validation batch 55/113: 880/1800 mean loss: 0.0014592225197702646 score: 0.995798319327731
2021-08-08 03:54:04,689 | train | INFO | Epoch 2 validation batch 56/113: 896/1800 mean loss: 0.001400292618200183 score: 1.0
2021-08-08 03:54:04,920 | train | INFO | Epoch 2 validation batch 57/113: 912/1800 mean loss: 0.0014345119707286358 score: 1.0
2021-08-08 03:54:05,161 | train | INFO | Epoch 2 validation batch 58/113: 928/1800 mean loss: 0.0014471217291429639 score: 0.9816176470588235
2021-08-08 03:54:05,394 | train | INFO | Epoch 2 validation batch 59/113: 944/1800 mean loss: 0.0013481219066306949 score: 1.0
2021-08-08 03:54:05,626 | train | INFO | Epoch 2 validation batch 60/113: 960/1800 mean loss: 0.0011863416293635964 score: 1.0
2021-08-08 03:54:05,868 | train | INFO | Epoch 2 validation batch 61/113: 976/1800 mean loss: 0.001304327859543264 score: 1.0
2021-08-08 03:54:06,115 | train | INFO | Epoch 2 validation batch 62/113: 992/1800 mean loss: 0.0013729643542319536 score: 1.0
2021-08-08 03:54:06,371 | train | INFO | Epoch 2 validation batch 63/113: 1008/1800 mean loss: 0.0013665866572409868 score: 1.0
2021-08-08 03:54:06,624 | train | INFO | Epoch 2 validation batch 64/113: 1024/1800 mean loss: 0.0014232421526685357 score: 1.0
2021-08-08 03:54:06,879 | train | INFO | Epoch 2 validation batch 65/113: 1040/1800 mean loss: 0.0013728473568335176 score: 0.9926470588235294
2021-08-08 03:54:07,128 | train | INFO | Epoch 2 validation batch 66/113: 1056/1800 mean loss: 0.0014650969533249736 score: 1.0
2021-08-08 03:54:07,363 | train | INFO | Epoch 2 validation batch 67/113: 1072/1800 mean loss: 0.0013914303854107857 score: 1.0
2021-08-08 03:54:07,594 | train | INFO | Epoch 2 validation batch 68/113: 1088/1800 mean loss: 0.0012371536577120423 score: 1.0
2021-08-08 03:54:07,824 | train | INFO | Epoch 2 validation batch 69/113: 1104/1800 mean loss: 0.0014343371149152517 score: 1.0
2021-08-08 03:54:08,066 | train | INFO | Epoch 2 validation batch 70/113: 1120/1800 mean loss: 0.0014666756615042686 score: 0.9926470588235294
2021-08-08 03:54:08,315 | train | INFO | Epoch 2 validation batch 71/113: 1136/1800 mean loss: 0.0013516860781237483 score: 1.0
2021-08-08 03:54:08,566 | train | INFO | Epoch 2 validation batch 72/113: 1152/1800 mean loss: 0.001364861847832799 score: 1.0
2021-08-08 03:54:08,801 | train | INFO | Epoch 2 validation batch 73/113: 1168/1800 mean loss: 0.0014751573326066136 score: 1.0
2021-08-08 03:54:09,033 | train | INFO | Epoch 2 validation batch 74/113: 1184/1800 mean loss: 0.00140642118640244 score: 1.0
2021-08-08 03:54:09,282 | train | INFO | Epoch 2 validation batch 75/113: 1200/1800 mean loss: 0.0013982796808704734 score: 1.0
2021-08-08 03:54:09,531 | train | INFO | Epoch 2 validation batch 76/113: 1216/1800 mean loss: 0.0013279124395921826 score: 1.0
2021-08-08 03:54:09,784 | train | INFO | Epoch 2 validation batch 77/113: 1232/1800 mean loss: 0.0012780552497133613 score: 1.0
2021-08-08 03:54:10,056 | train | INFO | Epoch 2 validation batch 78/113: 1248/1800 mean loss: 0.0013900677440688014 score: 0.9512254901960785
2021-08-08 03:54:10,311 | train | INFO | Epoch 2 validation batch 79/113: 1264/1800 mean loss: 0.0014212079113349319 score: 0.9921568627450981
2021-08-08 03:54:10,541 | train | INFO | Epoch 2 validation batch 80/113: 1280/1800 mean loss: 0.0015407099854201078 score: 1.0
2021-08-08 03:54:10,792 | train | INFO | Epoch 2 validation batch 81/113: 1296/1800 mean loss: 0.0014321947237476707 score: 1.0
2021-08-08 03:54:11,042 | train | INFO | Epoch 2 validation batch 82/113: 1312/1800 mean loss: 0.0012592729181051254 score: 1.0
2021-08-08 03:54:11,297 | train | INFO | Epoch 2 validation batch 83/113: 1328/1800 mean loss: 0.0014702886110171676 score: 1.0
2021-08-08 03:54:11,530 | train | INFO | Epoch 2 validation batch 84/113: 1344/1800 mean loss: 0.0014464647974818945 score: 0.9595588235294118
2021-08-08 03:54:11,763 | train | INFO | Epoch 2 validation batch 85/113: 1360/1800 mean loss: 0.0013589985901489854 score: 0.9926470588235294
2021-08-08 03:54:12,027 | train | INFO | Epoch 2 validation batch 86/113: 1376/1800 mean loss: 0.0015532015822827816 score: 1.0
2021-08-08 03:54:12,276 | train | INFO | Epoch 2 validation batch 87/113: 1392/1800 mean loss: 0.00139899761416018 score: 0.9963235294117647
2021-08-08 03:54:12,515 | train | INFO | Epoch 2 validation batch 88/113: 1408/1800 mean loss: 0.0012659610947594047 score: 1.0
2021-08-08 03:54:12,770 | train | INFO | Epoch 2 validation batch 89/113: 1424/1800 mean loss: 0.0012004546588286757 score: 1.0
2021-08-08 03:54:13,025 | train | INFO | Epoch 2 validation batch 90/113: 1440/1800 mean loss: 0.0013894281582906842 score: 1.0
2021-08-08 03:54:13,285 | train | INFO | Epoch 2 validation batch 91/113: 1456/1800 mean loss: 0.0014731272822245955 score: 0.9963235294117647
2021-08-08 03:54:13,523 | train | INFO | Epoch 2 validation batch 92/113: 1472/1800 mean loss: 0.00143379473593086 score: 1.0
2021-08-08 03:54:13,765 | train | INFO | Epoch 2 validation batch 93/113: 1488/1800 mean loss: 0.001394520397298038 score: 1.0
2021-08-08 03:54:14,019 | train | INFO | Epoch 2 validation batch 94/113: 1504/1800 mean loss: 0.0014287487138062716 score: 1.0
2021-08-08 03:54:14,261 | train | INFO | Epoch 2 validation batch 95/113: 1520/1800 mean loss: 0.001438043313100934 score: 1.0
2021-08-08 03:54:14,515 | train | INFO | Epoch 2 validation batch 96/113: 1536/1800 mean loss: 0.001343515352346003 score: 0.9889705882352942
2021-08-08 03:54:14,748 | train | INFO | Epoch 2 validation batch 97/113: 1552/1800 mean loss: 0.0014210017397999763 score: 1.0
2021-08-08 03:54:15,009 | train | INFO | Epoch 2 validation batch 98/113: 1568/1800 mean loss: 0.0013861984480172396 score: 1.0
2021-08-08 03:54:15,277 | train | INFO | Epoch 2 validation batch 99/113: 1584/1800 mean loss: 0.001350544160231948 score: 1.0
2021-08-08 03:54:15,527 | train | INFO | Epoch 2 validation batch 100/113: 1600/1800 mean loss: 0.0014790873974561691 score: 1.0
2021-08-08 03:54:15,760 | train | INFO | Epoch 2 validation batch 101/113: 1616/1800 mean loss: 0.001362037961371243 score: 1.0
2021-08-08 03:54:15,991 | train | INFO | Epoch 2 validation batch 102/113: 1632/1800 mean loss: 0.0013537929626181722 score: 1.0
2021-08-08 03:54:16,222 | train | INFO | Epoch 2 validation batch 103/113: 1648/1800 mean loss: 0.001331860781647265 score: 1.0
2021-08-08 03:54:16,454 | train | INFO | Epoch 2 validation batch 104/113: 1664/1800 mean loss: 0.0013962420634925365 score: 1.0
2021-08-08 03:54:16,685 | train | INFO | Epoch 2 validation batch 105/113: 1680/1800 mean loss: 0.0013946190010756254 score: 1.0
2021-08-08 03:54:16,916 | train | INFO | Epoch 2 validation batch 106/113: 1696/1800 mean loss: 0.0014501502737402916 score: 1.0
2021-08-08 03:54:17,146 | train | INFO | Epoch 2 validation batch 107/113: 1712/1800 mean loss: 0.0014545044396072626 score: 1.0
2021-08-08 03:54:17,377 | train | INFO | Epoch 2 validation batch 108/113: 1728/1800 mean loss: 0.0014502471312880516 score: 1.0
2021-08-08 03:54:17,607 | train | INFO | Epoch 2 validation batch 109/113: 1744/1800 mean loss: 0.001518878387287259 score: 1.0
2021-08-08 03:54:17,838 | train | INFO | Epoch 2 validation batch 110/113: 1760/1800 mean loss: 0.0013873650459572673 score: 1.0
2021-08-08 03:54:18,069 | train | INFO | Epoch 2 validation batch 111/113: 1776/1800 mean loss: 0.0014134850353002548 score: 1.0
2021-08-08 03:54:18,232 | train | INFO | Epoch 2 validation batch 112/113: 1792/1800 mean loss: 0.0012349913595244288 score: 1.0
2021-08-08 03:54:18,404 | train | INFO | Epoch 2, Validation, Mean loss: 0.02213034521689457, Score: 0.9954360947918991
2021-08-08 03:54:18,404 | train | INFO | Write row 2
2021-08-08 03:54:21,002 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 03:54:21,007 | train | INFO | Update best record row 3, checkpoints 0.02425239452746062 -> 0.02213034521689457
2021-08-08 03:54:23,140 | train | INFO | Epoch 3 train batch 0/450: 0/7200 mean loss: 0.001561243669129908 score: 1.0
2021-08-08 03:54:23,917 | train | INFO | Epoch 3 train batch 1/450: 16/7200 mean loss: 0.0016542010707780719 score: 0.9816176470588235
2021-08-08 03:54:24,685 | train | INFO | Epoch 3 train batch 2/450: 32/7200 mean loss: 0.0015926131745800376 score: 1.0
2021-08-08 03:54:25,469 | train | INFO | Epoch 3 train batch 3/450: 48/7200 mean loss: 0.0016144384862855077 score: 1.0
2021-08-08 03:54:26,252 | train | INFO | Epoch 3 train batch 4/450: 64/7200 mean loss: 0.0017566037131473422 score: 1.0
2021-08-08 03:54:27,084 | train | INFO | Epoch 3 train batch 5/450: 80/7200 mean loss: 0.00164242391474545 score: 1.0
2021-08-08 03:54:27,849 | train | INFO | Epoch 3 train batch 6/450: 96/7200 mean loss: 0.0016766401240602136 score: 0.995798319327731
2021-08-08 03:54:28,655 | train | INFO | Epoch 3 train batch 7/450: 112/7200 mean loss: 0.001764526474289596 score: 0.9889705882352942
2021-08-08 03:54:29,431 | train | INFO | Epoch 3 train batch 8/450: 128/7200 mean loss: 0.0017409635474905372 score: 1.0
2021-08-08 03:54:30,209 | train | INFO | Epoch 3 train batch 9/450: 144/7200 mean loss: 0.0016945510869845748 score: 1.0
2021-08-08 03:54:30,982 | train | INFO | Epoch 3 train batch 10/450: 160/7200 mean loss: 0.0016667325980961323 score: 1.0
2021-08-08 03:54:31,802 | train | INFO | Epoch 3 train batch 11/450: 176/7200 mean loss: 0.0017165980534628034 score: 1.0
2021-08-08 03:54:32,572 | train | INFO | Epoch 3 train batch 12/450: 192/7200 mean loss: 0.0017267215298488736 score: 1.0
2021-08-08 03:54:33,480 | train | INFO | Epoch 3 train batch 13/450: 208/7200 mean loss: 0.0016329522477462888 score: 1.0
2021-08-08 03:54:34,367 | train | INFO | Epoch 3 train batch 14/450: 224/7200 mean loss: 0.0016551485750824213 score: 1.0
2021-08-08 03:54:35,162 | train | INFO | Epoch 3 train batch 15/450: 240/7200 mean loss: 0.0015426381723955274 score: 1.0
2021-08-08 03:54:35,933 | train | INFO | Epoch 3 train batch 16/450: 256/7200 mean loss: 0.0018619514303281903 score: 0.9963235294117647
2021-08-08 03:54:36,704 | train | INFO | Epoch 3 train batch 17/450: 272/7200 mean loss: 0.0016474304720759392 score: 1.0
2021-08-08 03:54:37,543 | train | INFO | Epoch 3 train batch 18/450: 288/7200 mean loss: 0.0016546989791095257 score: 0.9924019607843138
2021-08-08 03:54:38,346 | train | INFO | Epoch 3 train batch 19/450: 304/7200 mean loss: 0.0015813276404514909 score: 1.0
2021-08-08 03:54:39,175 | train | INFO | Epoch 3 train batch 20/450: 320/7200 mean loss: 0.001731966040097177 score: 0.995798319327731
2021-08-08 03:54:39,953 | train | INFO | Epoch 3 train batch 21/450: 336/7200 mean loss: 0.0017247596988454461 score: 1.0
2021-08-08 03:54:40,724 | train | INFO | Epoch 3 train batch 22/450: 352/7200 mean loss: 0.001746198395267129 score: 0.995798319327731
2021-08-08 03:54:41,533 | train | INFO | Epoch 3 train batch 23/450: 368/7200 mean loss: 0.0017547045135870576 score: 1.0
2021-08-08 03:54:42,371 | train | INFO | Epoch 3 train batch 24/450: 384/7200 mean loss: 0.0017074765637516975 score: 1.0
2021-08-08 03:54:43,143 | train | INFO | Epoch 3 train batch 25/450: 400/7200 mean loss: 0.0017743654316291213 score: 0.9963235294117647
2021-08-08 03:54:43,920 | train | INFO | Epoch 3 train batch 26/450: 416/7200 mean loss: 0.0016131434822455049 score: 0.996078431372549
2021-08-08 03:54:44,683 | train | INFO | Epoch 3 train batch 27/450: 432/7200 mean loss: 0.0017059298697859049 score: 1.0
2021-08-08 03:54:45,460 | train | INFO | Epoch 3 train batch 28/450: 448/7200 mean loss: 0.001715480932034552 score: 1.0
2021-08-08 03:54:46,244 | train | INFO | Epoch 3 train batch 29/450: 464/7200 mean loss: 0.0018134356942027807 score: 1.0
2021-08-08 03:54:47,078 | train | INFO | Epoch 3 train batch 30/450: 480/7200 mean loss: 0.001786717213690281 score: 1.0
2021-08-08 03:54:47,890 | train | INFO | Epoch 3 train batch 31/450: 496/7200 mean loss: 0.0017302397172898054 score: 1.0
2021-08-08 03:54:48,665 | train | INFO | Epoch 3 train batch 32/450: 512/7200 mean loss: 0.0017126536695286632 score: 0.9889705882352942
2021-08-08 03:54:49,434 | train | INFO | Epoch 3 train batch 33/450: 528/7200 mean loss: 0.0016684330767020583 score: 0.9852941176470589
2021-08-08 03:54:50,244 | train | INFO | Epoch 3 train batch 34/450: 544/7200 mean loss: 0.00169151381123811 score: 1.0
2021-08-08 03:54:51,070 | train | INFO | Epoch 3 train batch 35/450: 560/7200 mean loss: 0.0016766067128628492 score: 1.0
2021-08-08 03:54:51,858 | train | INFO | Epoch 3 train batch 36/450: 576/7200 mean loss: 0.0015517778228968382 score: 1.0
2021-08-08 03:54:52,677 | train | INFO | Epoch 3 train batch 37/450: 592/7200 mean loss: 0.0016404828056693077 score: 0.996078431372549
2021-08-08 03:54:53,452 | train | INFO | Epoch 3 train batch 38/450: 608/7200 mean loss: 0.0016976715996861458 score: 0.9705882352941176
2021-08-08 03:54:54,257 | train | INFO | Epoch 3 train batch 39/450: 624/7200 mean loss: 0.0016396268038079143 score: 1.0
2021-08-08 03:54:55,136 | train | INFO | Epoch 3 train batch 40/450: 640/7200 mean loss: 0.0017322730273008347 score: 1.0
2021-08-08 03:54:55,938 | train | INFO | Epoch 3 train batch 41/450: 656/7200 mean loss: 0.001538227777928114 score: 1.0
2021-08-08 03:54:56,726 | train | INFO | Epoch 3 train batch 42/450: 672/7200 mean loss: 0.0016138739883899689 score: 0.995798319327731
2021-08-08 03:54:57,518 | train | INFO | Epoch 3 train batch 43/450: 688/7200 mean loss: 0.0016593978507444263 score: 0.9669117647058824
2021-08-08 03:54:58,289 | train | INFO | Epoch 3 train batch 44/450: 704/7200 mean loss: 0.0017509977333247662 score: 1.0
2021-08-08 03:54:59,187 | train | INFO | Epoch 3 train batch 45/450: 720/7200 mean loss: 0.0016016355948522687 score: 0.9963235294117647
2021-08-08 03:55:00,031 | train | INFO | Epoch 3 train batch 46/450: 736/7200 mean loss: 0.001618482987396419 score: 1.0
2021-08-08 03:55:00,811 | train | INFO | Epoch 3 train batch 47/450: 752/7200 mean loss: 0.0017790724523365498 score: 0.9963235294117647
2021-08-08 03:55:01,592 | train | INFO | Epoch 3 train batch 48/450: 768/7200 mean loss: 0.0014894880587235093 score: 0.9963235294117647
2021-08-08 03:55:02,378 | train | INFO | Epoch 3 train batch 49/450: 784/7200 mean loss: 0.001548666856251657 score: 0.9963235294117647
2021-08-08 03:55:03,196 | train | INFO | Epoch 3 train batch 50/450: 800/7200 mean loss: 0.0016747283516451716 score: 1.0
2021-08-08 03:55:03,996 | train | INFO | Epoch 3 train batch 51/450: 816/7200 mean loss: 0.001680052257142961 score: 0.9963235294117647
2021-08-08 03:55:04,771 | train | INFO | Epoch 3 train batch 52/450: 832/7200 mean loss: 0.0016490300185978413 score: 0.996078431372549
2021-08-08 03:55:05,578 | train | INFO | Epoch 3 train batch 53/450: 848/7200 mean loss: 0.0016041885828599334 score: 0.9963235294117647
2021-08-08 03:55:06,369 | train | INFO | Epoch 3 train batch 54/450: 864/7200 mean loss: 0.0016859202878549695 score: 0.9850490196078432
2021-08-08 03:55:07,170 | train | INFO | Epoch 3 train batch 55/450: 880/7200 mean loss: 0.001621281378902495 score: 1.0
2021-08-08 03:55:07,943 | train | INFO | Epoch 3 train batch 56/450: 896/7200 mean loss: 0.0016829901142045856 score: 1.0
2021-08-08 03:55:08,759 | train | INFO | Epoch 3 train batch 57/450: 912/7200 mean loss: 0.0014905740972608328 score: 0.9926470588235294
2021-08-08 03:55:09,535 | train | INFO | Epoch 3 train batch 58/450: 928/7200 mean loss: 0.0015134633285924792 score: 1.0
2021-08-08 03:55:10,336 | train | INFO | Epoch 3 train batch 59/450: 944/7200 mean loss: 0.0015640872297808528 score: 1.0
2021-08-08 03:55:11,124 | train | INFO | Epoch 3 train batch 60/450: 960/7200 mean loss: 0.001794939860701561 score: 1.0
2021-08-08 03:55:11,903 | train | INFO | Epoch 3 train batch 61/450: 976/7200 mean loss: 0.001684657414443791 score: 1.0
2021-08-08 03:55:12,699 | train | INFO | Epoch 3 train batch 62/450: 992/7200 mean loss: 0.0017264292109757662 score: 1.0
2021-08-08 03:55:13,501 | train | INFO | Epoch 3 train batch 63/450: 1008/7200 mean loss: 0.0015621938509866595 score: 1.0
2021-08-08 03:55:14,287 | train | INFO | Epoch 3 train batch 64/450: 1024/7200 mean loss: 0.0017025376437231898 score: 1.0
2021-08-08 03:55:15,107 | train | INFO | Epoch 3 train batch 65/450: 1040/7200 mean loss: 0.0017640620935708284 score: 1.0
2021-08-08 03:55:15,895 | train | INFO | Epoch 3 train batch 66/450: 1056/7200 mean loss: 0.0017045509302988648 score: 0.9924019607843138
2021-08-08 03:55:16,766 | train | INFO | Epoch 3 train batch 67/450: 1072/7200 mean loss: 0.001494223834015429 score: 1.0
2021-08-08 03:55:17,577 | train | INFO | Epoch 3 train batch 68/450: 1088/7200 mean loss: 0.0016691004857420921 score: 1.0
2021-08-08 03:55:18,385 | train | INFO | Epoch 3 train batch 69/450: 1104/7200 mean loss: 0.0016438569873571396 score: 1.0
2021-08-08 03:55:19,164 | train | INFO | Epoch 3 train batch 70/450: 1120/7200 mean loss: 0.0016429387032985687 score: 1.0
2021-08-08 03:55:19,989 | train | INFO | Epoch 3 train batch 71/450: 1136/7200 mean loss: 0.0015598142053931952 score: 0.9963235294117647
2021-08-08 03:55:20,776 | train | INFO | Epoch 3 train batch 72/450: 1152/7200 mean loss: 0.0017330687260255218 score: 0.9882352941176471
2021-08-08 03:55:21,686 | train | INFO | Epoch 3 train batch 73/450: 1168/7200 mean loss: 0.001746899331919849 score: 0.9889705882352942
2021-08-08 03:55:22,503 | train | INFO | Epoch 3 train batch 74/450: 1184/7200 mean loss: 0.0016443926142528653 score: 1.0
2021-08-08 03:55:23,280 | train | INFO | Epoch 3 train batch 75/450: 1200/7200 mean loss: 0.0015363347483798862 score: 1.0
2021-08-08 03:55:24,069 | train | INFO | Epoch 3 train batch 76/450: 1216/7200 mean loss: 0.0015809516189619899 score: 1.0
2021-08-08 03:55:24,841 | train | INFO | Epoch 3 train batch 77/450: 1232/7200 mean loss: 0.0015852960059419274 score: 1.0
2021-08-08 03:55:25,613 | train | INFO | Epoch 3 train batch 78/450: 1248/7200 mean loss: 0.0015736762434244156 score: 1.0
2021-08-08 03:55:26,416 | train | INFO | Epoch 3 train batch 79/450: 1264/7200 mean loss: 0.0015920143341645598 score: 1.0
2021-08-08 03:55:27,321 | train | INFO | Epoch 3 train batch 80/450: 1280/7200 mean loss: 0.0015681564109399915 score: 0.9887254901960785
2021-08-08 03:55:28,170 | train | INFO | Epoch 3 train batch 81/450: 1296/7200 mean loss: 0.0016997423954308033 score: 0.9692927170868347
2021-08-08 03:55:28,975 | train | INFO | Epoch 3 train batch 82/450: 1312/7200 mean loss: 0.001707908813841641 score: 1.0
2021-08-08 03:55:29,767 | train | INFO | Epoch 3 train batch 83/450: 1328/7200 mean loss: 0.001598198083229363 score: 1.0
2021-08-08 03:55:30,540 | train | INFO | Epoch 3 train batch 84/450: 1344/7200 mean loss: 0.0015464373864233494 score: 0.9963235294117647
2021-08-08 03:55:31,362 | train | INFO | Epoch 3 train batch 85/450: 1360/7200 mean loss: 0.0016189361922442913 score: 0.9963235294117647
2021-08-08 03:55:32,150 | train | INFO | Epoch 3 train batch 86/450: 1376/7200 mean loss: 0.001528855529613793 score: 1.0
2021-08-08 03:55:32,921 | train | INFO | Epoch 3 train batch 87/450: 1392/7200 mean loss: 0.0016856821021065116 score: 1.0
2021-08-08 03:55:33,716 | train | INFO | Epoch 3 train batch 88/450: 1408/7200 mean loss: 0.001506724744103849 score: 1.0
2021-08-08 03:55:34,522 | train | INFO | Epoch 3 train batch 89/450: 1424/7200 mean loss: 0.001655030995607376 score: 1.0
2021-08-08 03:55:35,298 | train | INFO | Epoch 3 train batch 90/450: 1440/7200 mean loss: 0.0016515383031219244 score: 0.9963235294117647
2021-08-08 03:55:36,115 | train | INFO | Epoch 3 train batch 91/450: 1456/7200 mean loss: 0.0016382811591029167 score: 1.0
2021-08-08 03:55:36,950 | train | INFO | Epoch 3 train batch 92/450: 1472/7200 mean loss: 0.0017189047066494823 score: 1.0
2021-08-08 03:55:37,802 | train | INFO | Epoch 3 train batch 93/450: 1488/7200 mean loss: 0.0014849855797365308 score: 1.0
2021-08-08 03:55:38,617 | train | INFO | Epoch 3 train batch 94/450: 1504/7200 mean loss: 0.0014751327689737082 score: 1.0
2021-08-08 03:55:39,402 | train | INFO | Epoch 3 train batch 95/450: 1520/7200 mean loss: 0.0016926320968195796 score: 1.0
2021-08-08 03:55:40,196 | train | INFO | Epoch 3 train batch 96/450: 1536/7200 mean loss: 0.0016136206686496735 score: 0.995798319327731
2021-08-08 03:55:40,981 | train | INFO | Epoch 3 train batch 97/450: 1552/7200 mean loss: 0.0016152829630300403 score: 0.9816176470588235
2021-08-08 03:55:41,787 | train | INFO | Epoch 3 train batch 98/450: 1568/7200 mean loss: 0.0016638508532196283 score: 1.0
2021-08-08 03:55:42,698 | train | INFO | Epoch 3 train batch 99/450: 1584/7200 mean loss: 0.0015961097087711096 score: 1.0
2021-08-08 03:55:43,600 | train | INFO | Epoch 3 train batch 100/450: 1600/7200 mean loss: 0.0016507788095623255 score: 1.0
2021-08-08 03:55:44,400 | train | INFO | Epoch 3 train batch 101/450: 1616/7200 mean loss: 0.0015664254315197468 score: 1.0
2021-08-08 03:55:45,189 | train | INFO | Epoch 3 train batch 102/450: 1632/7200 mean loss: 0.001683883718214929 score: 1.0
2021-08-08 03:55:45,973 | train | INFO | Epoch 3 train batch 103/450: 1648/7200 mean loss: 0.001735178753733635 score: 1.0
2021-08-08 03:55:46,752 | train | INFO | Epoch 3 train batch 104/450: 1664/7200 mean loss: 0.0017152809305116534 score: 0.9772058823529413
2021-08-08 03:55:47,544 | train | INFO | Epoch 3 train batch 105/450: 1680/7200 mean loss: 0.0016413397388532758 score: 1.0
2021-08-08 03:55:48,346 | train | INFO | Epoch 3 train batch 106/450: 1696/7200 mean loss: 0.00172459427267313 score: 1.0
2021-08-08 03:55:49,130 | train | INFO | Epoch 3 train batch 107/450: 1712/7200 mean loss: 0.0015707567799836397 score: 0.9963235294117647
2021-08-08 03:55:49,999 | train | INFO | Epoch 3 train batch 108/450: 1728/7200 mean loss: 0.0015732236206531525 score: 0.9926470588235294
2021-08-08 03:55:50,794 | train | INFO | Epoch 3 train batch 109/450: 1744/7200 mean loss: 0.0017589401686564088 score: 0.9926470588235294
2021-08-08 03:55:51,594 | train | INFO | Epoch 3 train batch 110/450: 1760/7200 mean loss: 0.0016718925908207893 score: 1.0
2021-08-08 03:55:52,381 | train | INFO | Epoch 3 train batch 111/450: 1776/7200 mean loss: 0.0015685911057516932 score: 1.0
2021-08-08 03:55:53,196 | train | INFO | Epoch 3 train batch 112/450: 1792/7200 mean loss: 0.001786864479072392 score: 0.9848039215686275
2021-08-08 03:55:53,979 | train | INFO | Epoch 3 train batch 113/450: 1808/7200 mean loss: 0.0016313460655510426 score: 1.0
2021-08-08 03:55:54,765 | train | INFO | Epoch 3 train batch 114/450: 1824/7200 mean loss: 0.0015523217152804136 score: 0.996078431372549
2021-08-08 03:55:55,545 | train | INFO | Epoch 3 train batch 115/450: 1840/7200 mean loss: 0.0016676137456670403 score: 1.0
2021-08-08 03:55:56,359 | train | INFO | Epoch 3 train batch 116/450: 1856/7200 mean loss: 0.0016705477610230446 score: 1.0
2021-08-08 03:55:57,174 | train | INFO | Epoch 3 train batch 117/450: 1872/7200 mean loss: 0.0016133151948451996 score: 1.0
2021-08-08 03:55:57,950 | train | INFO | Epoch 3 train batch 118/450: 1888/7200 mean loss: 0.0015654955059289932 score: 1.0
2021-08-08 03:55:58,744 | train | INFO | Epoch 3 train batch 119/450: 1904/7200 mean loss: 0.0015525149647146463 score: 0.9917986425339367
2021-08-08 03:55:59,526 | train | INFO | Epoch 3 train batch 120/450: 1920/7200 mean loss: 0.0015902811428532004 score: 0.996078431372549
2021-08-08 03:56:00,305 | train | INFO | Epoch 3 train batch 121/450: 1936/7200 mean loss: 0.0017125499434769154 score: 1.0
2021-08-08 03:56:01,080 | train | INFO | Epoch 3 train batch 122/450: 1952/7200 mean loss: 0.0015648030675947666 score: 1.0
2021-08-08 03:56:01,863 | train | INFO | Epoch 3 train batch 123/450: 1968/7200 mean loss: 0.0017549586482346058 score: 1.0
2021-08-08 03:56:02,687 | train | INFO | Epoch 3 train batch 124/450: 1984/7200 mean loss: 0.0016468600369989872 score: 1.0
2021-08-08 03:56:03,464 | train | INFO | Epoch 3 train batch 125/450: 2000/7200 mean loss: 0.0016439592000097036 score: 1.0
2021-08-08 03:56:04,266 | train | INFO | Epoch 3 train batch 126/450: 2016/7200 mean loss: 0.0016787376953288913 score: 1.0
2021-08-08 03:56:05,045 | train | INFO | Epoch 3 train batch 127/450: 2032/7200 mean loss: 0.00160691374912858 score: 1.0
2021-08-08 03:56:05,848 | train | INFO | Epoch 3 train batch 128/450: 2048/7200 mean loss: 0.0015079264994710684 score: 0.9963235294117647
2021-08-08 03:56:06,628 | train | INFO | Epoch 3 train batch 129/450: 2064/7200 mean loss: 0.0016337002161890268 score: 1.0
2021-08-08 03:56:07,452 | train | INFO | Epoch 3 train batch 130/450: 2080/7200 mean loss: 0.0016966976691037416 score: 1.0
2021-08-08 03:56:08,247 | train | INFO | Epoch 3 train batch 131/450: 2096/7200 mean loss: 0.0017032093601301312 score: 1.0
2021-08-08 03:56:09,024 | train | INFO | Epoch 3 train batch 132/450: 2112/7200 mean loss: 0.001628069207072258 score: 1.0
2021-08-08 03:56:09,813 | train | INFO | Epoch 3 train batch 133/450: 2128/7200 mean loss: 0.0016232144553214312 score: 1.0
2021-08-08 03:56:10,600 | train | INFO | Epoch 3 train batch 134/450: 2144/7200 mean loss: 0.0017255219863727689 score: 0.907107843137255
2021-08-08 03:56:11,409 | train | INFO | Epoch 3 train batch 135/450: 2160/7200 mean loss: 0.0017085978761315346 score: 1.0
2021-08-08 03:56:12,243 | train | INFO | Epoch 3 train batch 136/450: 2176/7200 mean loss: 0.0015963456826284528 score: 1.0
2021-08-08 03:56:13,045 | train | INFO | Epoch 3 train batch 137/450: 2192/7200 mean loss: 0.0016190474852919579 score: 1.0
2021-08-08 03:56:13,853 | train | INFO | Epoch 3 train batch 138/450: 2208/7200 mean loss: 0.0014741991180926561 score: 0.9816176470588235
2021-08-08 03:56:14,632 | train | INFO | Epoch 3 train batch 139/450: 2224/7200 mean loss: 0.0017529668984934688 score: 1.0
2021-08-08 03:56:15,444 | train | INFO | Epoch 3 train batch 140/450: 2240/7200 mean loss: 0.0014740851474925876 score: 1.0
2021-08-08 03:56:16,249 | train | INFO | Epoch 3 train batch 141/450: 2256/7200 mean loss: 0.0018647799734026194 score: 1.0
2021-08-08 03:56:17,049 | train | INFO | Epoch 3 train batch 142/450: 2272/7200 mean loss: 0.001671993057243526 score: 0.9926470588235294
2021-08-08 03:56:17,886 | train | INFO | Epoch 3 train batch 143/450: 2288/7200 mean loss: 0.0016223631100729108 score: 0.9917986425339367
2021-08-08 03:56:18,682 | train | INFO | Epoch 3 train batch 144/450: 2304/7200 mean loss: 0.0016295138048008084 score: 1.0
2021-08-08 03:56:19,490 | train | INFO | Epoch 3 train batch 145/450: 2320/7200 mean loss: 0.0016009991522878408 score: 1.0
2021-08-08 03:56:20,264 | train | INFO | Epoch 3 train batch 146/450: 2336/7200 mean loss: 0.0016750759677961469 score: 0.9816176470588235
2021-08-08 03:56:21,073 | train | INFO | Epoch 3 train batch 147/450: 2352/7200 mean loss: 0.001636071247048676 score: 1.0
2021-08-08 03:56:21,893 | train | INFO | Epoch 3 train batch 148/450: 2368/7200 mean loss: 0.001555170281790197 score: 0.9926470588235294
2021-08-08 03:56:22,679 | train | INFO | Epoch 3 train batch 149/450: 2384/7200 mean loss: 0.0015656286850571632 score: 0.9963235294117647
2021-08-08 03:56:23,466 | train | INFO | Epoch 3 train batch 150/450: 2400/7200 mean loss: 0.0016079708002507687 score: 0.9585084033613446
2021-08-08 03:56:24,289 | train | INFO | Epoch 3 train batch 151/450: 2416/7200 mean loss: 0.0017324822256341577 score: 0.9115196078431372
2021-08-08 03:56:25,069 | train | INFO | Epoch 3 train batch 152/450: 2432/7200 mean loss: 0.0017174923559650779 score: 0.9889705882352942
2021-08-08 03:56:25,890 | train | INFO | Epoch 3 train batch 153/450: 2448/7200 mean loss: 0.0017294142162427306 score: 0.9963235294117647
2021-08-08 03:56:26,664 | train | INFO | Epoch 3 train batch 154/450: 2464/7200 mean loss: 0.0017186031909659505 score: 1.0
2021-08-08 03:56:27,433 | train | INFO | Epoch 3 train batch 155/450: 2480/7200 mean loss: 0.0017006626585498452 score: 1.0
2021-08-08 03:56:28,205 | train | INFO | Epoch 3 train batch 156/450: 2496/7200 mean loss: 0.0017068039160221815 score: 1.0
2021-08-08 03:56:28,997 | train | INFO | Epoch 3 train batch 157/450: 2512/7200 mean loss: 0.0016592624597251415 score: 1.0
2021-08-08 03:56:29,764 | train | INFO | Epoch 3 train batch 158/450: 2528/7200 mean loss: 0.0016505076782777905 score: 1.0
2021-08-08 03:56:30,577 | train | INFO | Epoch 3 train batch 159/450: 2544/7200 mean loss: 0.001763047301210463 score: 0.996078431372549
2021-08-08 03:56:31,352 | train | INFO | Epoch 3 train batch 160/450: 2560/7200 mean loss: 0.0016359805595129728 score: 1.0
2021-08-08 03:56:32,115 | train | INFO | Epoch 3 train batch 161/450: 2576/7200 mean loss: 0.0016384657938033342 score: 1.0
2021-08-08 03:56:32,908 | train | INFO | Epoch 3 train batch 162/450: 2592/7200 mean loss: 0.0017673298716545105 score: 1.0
2021-08-08 03:56:33,710 | train | INFO | Epoch 3 train batch 163/450: 2608/7200 mean loss: 0.00170198455452919 score: 1.0
2021-08-08 03:56:34,481 | train | INFO | Epoch 3 train batch 164/450: 2624/7200 mean loss: 0.0016420959727838635 score: 1.0
2021-08-08 03:56:35,268 | train | INFO | Epoch 3 train batch 165/450: 2640/7200 mean loss: 0.0016869292594492435 score: 1.0
2021-08-08 03:56:36,060 | train | INFO | Epoch 3 train batch 166/450: 2656/7200 mean loss: 0.0016795243136584759 score: 0.9884453781512607
2021-08-08 03:56:36,871 | train | INFO | Epoch 3 train batch 167/450: 2672/7200 mean loss: 0.0016936248866841197 score: 1.0
2021-08-08 03:56:37,699 | train | INFO | Epoch 3 train batch 168/450: 2688/7200 mean loss: 0.0016430012183263898 score: 1.0
2021-08-08 03:56:38,482 | train | INFO | Epoch 3 train batch 169/450: 2704/7200 mean loss: 0.0015712004387751222 score: 1.0
2021-08-08 03:56:39,264 | train | INFO | Epoch 3 train batch 170/450: 2720/7200 mean loss: 0.0016558576608076692 score: 1.0
2021-08-08 03:56:40,038 | train | INFO | Epoch 3 train batch 171/450: 2736/7200 mean loss: 0.001664346898905933 score: 1.0
2021-08-08 03:56:40,826 | train | INFO | Epoch 3 train batch 172/450: 2752/7200 mean loss: 0.0016419339226558805 score: 1.0
2021-08-08 03:56:41,598 | train | INFO | Epoch 3 train batch 173/450: 2768/7200 mean loss: 0.0016075440216809511 score: 0.9033963585434174
2021-08-08 03:56:42,367 | train | INFO | Epoch 3 train batch 174/450: 2784/7200 mean loss: 0.001757727819494903 score: 0.9852941176470589
2021-08-08 03:56:43,146 | train | INFO | Epoch 3 train batch 175/450: 2800/7200 mean loss: 0.001686934963800013 score: 0.9843137254901961
2021-08-08 03:56:43,969 | train | INFO | Epoch 3 train batch 176/450: 2816/7200 mean loss: 0.0016959022032096982 score: 1.0
2021-08-08 03:56:44,748 | train | INFO | Epoch 3 train batch 177/450: 2832/7200 mean loss: 0.0015407532919198275 score: 1.0
2021-08-08 03:56:45,571 | train | INFO | Epoch 3 train batch 178/450: 2848/7200 mean loss: 0.0016142111271619797 score: 1.0
2021-08-08 03:56:46,412 | train | INFO | Epoch 3 train batch 179/450: 2864/7200 mean loss: 0.0017544709844514728 score: 1.0
2021-08-08 03:56:47,228 | train | INFO | Epoch 3 train batch 180/450: 2880/7200 mean loss: 0.0016182145336642861 score: 1.0
2021-08-08 03:56:48,066 | train | INFO | Epoch 3 train batch 181/450: 2896/7200 mean loss: 0.0016266541788354516 score: 1.0
2021-08-08 03:56:48,858 | train | INFO | Epoch 3 train batch 182/450: 2912/7200 mean loss: 0.0015802921261638403 score: 1.0
2021-08-08 03:56:49,634 | train | INFO | Epoch 3 train batch 183/450: 2928/7200 mean loss: 0.001572085777297616 score: 1.0
2021-08-08 03:56:50,446 | train | INFO | Epoch 3 train batch 184/450: 2944/7200 mean loss: 0.001715114456601441 score: 0.9813725490196079
2021-08-08 03:56:51,219 | train | INFO | Epoch 3 train batch 185/450: 2960/7200 mean loss: 0.001697789877653122 score: 1.0
2021-08-08 03:56:52,006 | train | INFO | Epoch 3 train batch 186/450: 2976/7200 mean loss: 0.001721592154353857 score: 1.0
2021-08-08 03:56:52,785 | train | INFO | Epoch 3 train batch 187/450: 2992/7200 mean loss: 0.00171935698017478 score: 1.0
2021-08-08 03:56:53,588 | train | INFO | Epoch 3 train batch 188/450: 3008/7200 mean loss: 0.0016863332130014896 score: 0.9926470588235294
2021-08-08 03:56:54,413 | train | INFO | Epoch 3 train batch 189/450: 3024/7200 mean loss: 0.0017099303659051657 score: 0.9963235294117647
2021-08-08 03:56:55,228 | train | INFO | Epoch 3 train batch 190/450: 3040/7200 mean loss: 0.0016709644114598632 score: 1.0
2021-08-08 03:56:56,057 | train | INFO | Epoch 3 train batch 191/450: 3056/7200 mean loss: 0.0016966761322692037 score: 1.0
2021-08-08 03:56:56,854 | train | INFO | Epoch 3 train batch 192/450: 3072/7200 mean loss: 0.0016971189761534333 score: 1.0
2021-08-08 03:56:57,678 | train | INFO | Epoch 3 train batch 193/450: 3088/7200 mean loss: 0.001611644634976983 score: 1.0
2021-08-08 03:56:58,457 | train | INFO | Epoch 3 train batch 194/450: 3104/7200 mean loss: 0.0016157029895111918 score: 1.0
2021-08-08 03:56:59,238 | train | INFO | Epoch 3 train batch 195/450: 3120/7200 mean loss: 0.0017374606104567647 score: 1.0
2021-08-08 03:57:00,046 | train | INFO | Epoch 3 train batch 196/450: 3136/7200 mean loss: 0.001537185162305832 score: 1.0
2021-08-08 03:57:00,845 | train | INFO | Epoch 3 train batch 197/450: 3152/7200 mean loss: 0.0015839632833376527 score: 1.0
2021-08-08 03:57:01,681 | train | INFO | Epoch 3 train batch 198/450: 3168/7200 mean loss: 0.0016528547275811434 score: 1.0
2021-08-08 03:57:02,464 | train | INFO | Epoch 3 train batch 199/450: 3184/7200 mean loss: 0.0016159065999090672 score: 1.0
2021-08-08 03:57:03,238 | train | INFO | Epoch 3 train batch 200/450: 3200/7200 mean loss: 0.001526464824564755 score: 1.0
2021-08-08 03:57:04,055 | train | INFO | Epoch 3 train batch 201/450: 3216/7200 mean loss: 0.001585755730047822 score: 1.0
2021-08-08 03:57:04,838 | train | INFO | Epoch 3 train batch 202/450: 3232/7200 mean loss: 0.001689835567958653 score: 1.0
2021-08-08 03:57:05,633 | train | INFO | Epoch 3 train batch 203/450: 3248/7200 mean loss: 0.0014967056922614574 score: 1.0
2021-08-08 03:57:06,417 | train | INFO | Epoch 3 train batch 204/450: 3264/7200 mean loss: 0.0016860984032973647 score: 1.0
2021-08-08 03:57:07,204 | train | INFO | Epoch 3 train batch 205/450: 3280/7200 mean loss: 0.0014765904052183032 score: 1.0
2021-08-08 03:57:08,010 | train | INFO | Epoch 3 train batch 206/450: 3296/7200 mean loss: 0.0015458973357453942 score: 0.9926470588235294
2021-08-08 03:57:08,776 | train | INFO | Epoch 3 train batch 207/450: 3312/7200 mean loss: 0.0016549915308132768 score: 1.0
2021-08-08 03:57:09,558 | train | INFO | Epoch 3 train batch 208/450: 3328/7200 mean loss: 0.0017959416145458817 score: 1.0
2021-08-08 03:57:10,348 | train | INFO | Epoch 3 train batch 209/450: 3344/7200 mean loss: 0.0016741349827498198 score: 0.9963235294117647
2021-08-08 03:57:11,168 | train | INFO | Epoch 3 train batch 210/450: 3360/7200 mean loss: 0.0016918168403208256 score: 1.0
2021-08-08 03:57:11,940 | train | INFO | Epoch 3 train batch 211/450: 3376/7200 mean loss: 0.001611405285075307 score: 0.9833521870286577
2021-08-08 03:57:12,741 | train | INFO | Epoch 3 train batch 212/450: 3392/7200 mean loss: 0.0017342828214168549 score: 0.9583333333333334
2021-08-08 03:57:13,525 | train | INFO | Epoch 3 train batch 213/450: 3408/7200 mean loss: 0.0017353552393615246 score: 1.0
2021-08-08 03:57:14,325 | train | INFO | Epoch 3 train batch 214/450: 3424/7200 mean loss: 0.0016368480864912271 score: 1.0
2021-08-08 03:57:15,113 | train | INFO | Epoch 3 train batch 215/450: 3440/7200 mean loss: 0.0018469534115865827 score: 1.0
2021-08-08 03:57:15,924 | train | INFO | Epoch 3 train batch 216/450: 3456/7200 mean loss: 0.0016140120569616556 score: 1.0
2021-08-08 03:57:16,707 | train | INFO | Epoch 3 train batch 217/450: 3472/7200 mean loss: 0.0017117649549618363 score: 1.0
2021-08-08 03:57:17,554 | train | INFO | Epoch 3 train batch 218/450: 3488/7200 mean loss: 0.0016441042535007 score: 1.0
2021-08-08 03:57:18,333 | train | INFO | Epoch 3 train batch 219/450: 3504/7200 mean loss: 0.0017154192319139838 score: 1.0
2021-08-08 03:57:19,144 | train | INFO | Epoch 3 train batch 220/450: 3520/7200 mean loss: 0.0017227284843102098 score: 0.9963235294117647
2021-08-08 03:57:19,928 | train | INFO | Epoch 3 train batch 221/450: 3536/7200 mean loss: 0.001855021226219833 score: 1.0
2021-08-08 03:57:20,736 | train | INFO | Epoch 3 train batch 222/450: 3552/7200 mean loss: 0.0016575478948652744 score: 0.966421568627451
2021-08-08 03:57:21,539 | train | INFO | Epoch 3 train batch 223/450: 3568/7200 mean loss: 0.001613327069208026 score: 0.9926470588235294
2021-08-08 03:57:22,331 | train | INFO | Epoch 3 train batch 224/450: 3584/7200 mean loss: 0.001616636523976922 score: 1.0
2021-08-08 03:57:23,155 | train | INFO | Epoch 3 train batch 225/450: 3600/7200 mean loss: 0.001618285314179957 score: 1.0
2021-08-08 03:57:23,927 | train | INFO | Epoch 3 train batch 226/450: 3616/7200 mean loss: 0.0016763098537921906 score: 0.9842436974789917
2021-08-08 03:57:24,744 | train | INFO | Epoch 3 train batch 227/450: 3632/7200 mean loss: 0.0016386639326810837 score: 0.9963235294117647
2021-08-08 03:57:25,529 | train | INFO | Epoch 3 train batch 228/450: 3648/7200 mean loss: 0.001692524878308177 score: 1.0
2021-08-08 03:57:26,347 | train | INFO | Epoch 3 train batch 229/450: 3664/7200 mean loss: 0.001557356445118785 score: 1.0
2021-08-08 03:57:27,162 | train | INFO | Epoch 3 train batch 230/450: 3680/7200 mean loss: 0.0016728610498830676 score: 0.9963235294117647
2021-08-08 03:57:27,949 | train | INFO | Epoch 3 train batch 231/450: 3696/7200 mean loss: 0.0016558516072109342 score: 1.0
2021-08-08 03:57:28,732 | train | INFO | Epoch 3 train batch 232/450: 3712/7200 mean loss: 0.0017395230242982507 score: 1.0
2021-08-08 03:57:29,597 | train | INFO | Epoch 3 train batch 233/450: 3728/7200 mean loss: 0.0015474858228117228 score: 1.0
2021-08-08 03:57:30,380 | train | INFO | Epoch 3 train batch 234/450: 3744/7200 mean loss: 0.0016099223867058754 score: 1.0
2021-08-08 03:57:31,283 | train | INFO | Epoch 3 train batch 235/450: 3760/7200 mean loss: 0.0016988373827189207 score: 0.9926470588235294
2021-08-08 03:57:32,057 | train | INFO | Epoch 3 train batch 236/450: 3776/7200 mean loss: 0.0015152249252423644 score: 1.0
2021-08-08 03:57:32,869 | train | INFO | Epoch 3 train batch 237/450: 3792/7200 mean loss: 0.0015422113938257098 score: 1.0
2021-08-08 03:57:33,654 | train | INFO | Epoch 3 train batch 238/450: 3808/7200 mean loss: 0.0016329841455444694 score: 1.0
2021-08-08 03:57:34,461 | train | INFO | Epoch 3 train batch 239/450: 3824/7200 mean loss: 0.0015106747159734368 score: 1.0
2021-08-08 03:57:35,233 | train | INFO | Epoch 3 train batch 240/450: 3840/7200 mean loss: 0.0016510464483872056 score: 0.9776960784313725
2021-08-08 03:57:36,012 | train | INFO | Epoch 3 train batch 241/450: 3856/7200 mean loss: 0.0016988212009891868 score: 1.0
2021-08-08 03:57:36,811 | train | INFO | Epoch 3 train batch 242/450: 3872/7200 mean loss: 0.0015306613640859723 score: 1.0
2021-08-08 03:57:37,614 | train | INFO | Epoch 3 train batch 243/450: 3888/7200 mean loss: 0.0017153900116682053 score: 0.9924019607843138
2021-08-08 03:57:38,418 | train | INFO | Epoch 3 train batch 244/450: 3904/7200 mean loss: 0.0016330110374838114 score: 1.0
2021-08-08 03:57:39,199 | train | INFO | Epoch 3 train batch 245/450: 3920/7200 mean loss: 0.0016150487354025245 score: 0.7220588235294118
2021-08-08 03:57:40,087 | train | INFO | Epoch 3 train batch 246/450: 3936/7200 mean loss: 0.0015944194747135043 score: 0.9370098039215686
2021-08-08 03:57:40,899 | train | INFO | Epoch 3 train batch 247/450: 3952/7200 mean loss: 0.0016116952756419778 score: 0.9813725490196079
2021-08-08 03:57:41,712 | train | INFO | Epoch 3 train batch 248/450: 3968/7200 mean loss: 0.0016095495084300637 score: 1.0
2021-08-08 03:57:42,527 | train | INFO | Epoch 3 train batch 249/450: 3984/7200 mean loss: 0.0015264026587828994 score: 1.0
2021-08-08 03:57:43,344 | train | INFO | Epoch 3 train batch 250/450: 4000/7200 mean loss: 0.0016713292570784688 score: 1.0
2021-08-08 03:57:44,260 | train | INFO | Epoch 3 train batch 251/450: 4016/7200 mean loss: 0.0016860569594427943 score: 1.0
2021-08-08 03:57:45,044 | train | INFO | Epoch 3 train batch 252/450: 4032/7200 mean loss: 0.0016497417818754911 score: 0.9102941176470589
2021-08-08 03:57:45,830 | train | INFO | Epoch 3 train batch 253/450: 4048/7200 mean loss: 0.0016601039096713066 score: 1.0
2021-08-08 03:57:46,604 | train | INFO | Epoch 3 train batch 254/450: 4064/7200 mean loss: 0.0016729868948459625 score: 1.0
2021-08-08 03:57:47,405 | train | INFO | Epoch 3 train batch 255/450: 4080/7200 mean loss: 0.0017470758175477386 score: 1.0
2021-08-08 03:57:48,246 | train | INFO | Epoch 3 train batch 256/450: 4096/7200 mean loss: 0.001608553109690547 score: 1.0
2021-08-08 03:57:49,056 | train | INFO | Epoch 3 train batch 257/450: 4112/7200 mean loss: 0.0016301547875627875 score: 1.0
2021-08-08 03:57:49,860 | train | INFO | Epoch 3 train batch 258/450: 4128/7200 mean loss: 0.0016635919455438852 score: 1.0
2021-08-08 03:57:50,632 | train | INFO | Epoch 3 train batch 259/450: 4144/7200 mean loss: 0.0016901999479159713 score: 1.0
2021-08-08 03:57:51,404 | train | INFO | Epoch 3 train batch 260/450: 4160/7200 mean loss: 0.0018288196297362447 score: 1.0
2021-08-08 03:57:52,177 | train | INFO | Epoch 3 train batch 261/450: 4176/7200 mean loss: 0.001486437744461 score: 0.9924019607843138
2021-08-08 03:57:53,070 | train | INFO | Epoch 3 train batch 262/450: 4192/7200 mean loss: 0.0014977125683799386 score: 1.0
2021-08-08 03:57:53,874 | train | INFO | Epoch 3 train batch 263/450: 4208/7200 mean loss: 0.0015485682524740696 score: 1.0
2021-08-08 03:57:54,658 | train | INFO | Epoch 3 train batch 264/450: 4224/7200 mean loss: 0.001436325372196734 score: 1.0
2021-08-08 03:57:55,435 | train | INFO | Epoch 3 train batch 265/450: 4240/7200 mean loss: 0.0016633946215733886 score: 0.9089285714285714
2021-08-08 03:57:56,257 | train | INFO | Epoch 3 train batch 266/450: 4256/7200 mean loss: 0.0016569060971960425 score: 1.0
2021-08-08 03:57:57,057 | train | INFO | Epoch 3 train batch 267/450: 4272/7200 mean loss: 0.001638413523323834 score: 1.0
2021-08-08 03:57:57,861 | train | INFO | Epoch 3 train batch 268/450: 4288/7200 mean loss: 0.0015786417061462998 score: 1.0
2021-08-08 03:57:58,680 | train | INFO | Epoch 3 train batch 269/450: 4304/7200 mean loss: 0.0014299507020041347 score: 1.0
2021-08-08 03:57:59,475 | train | INFO | Epoch 3 train batch 270/450: 4320/7200 mean loss: 0.0017383017111569643 score: 1.0
2021-08-08 03:58:00,252 | train | INFO | Epoch 3 train batch 271/450: 4336/7200 mean loss: 0.0017417120980098844 score: 0.9963235294117647
2021-08-08 03:58:01,038 | train | INFO | Epoch 3 train batch 272/450: 4352/7200 mean loss: 0.0016807863721624017 score: 1.0
2021-08-08 03:58:01,832 | train | INFO | Epoch 3 train batch 273/450: 4368/7200 mean loss: 0.0016524536767974496 score: 0.9924019607843138
2021-08-08 03:58:02,643 | train | INFO | Epoch 3 train batch 274/450: 4384/7200 mean loss: 0.00158900604583323 score: 0.996078431372549
2021-08-08 03:58:03,446 | train | INFO | Epoch 3 train batch 275/450: 4400/7200 mean loss: 0.0017136811511591077 score: 1.0
2021-08-08 03:58:04,221 | train | INFO | Epoch 3 train batch 276/450: 4416/7200 mean loss: 0.0015373986680060625 score: 1.0
2021-08-08 03:58:05,012 | train | INFO | Epoch 3 train batch 277/450: 4432/7200 mean loss: 0.0015822142595425248 score: 1.0
2021-08-08 03:58:05,791 | train | INFO | Epoch 3 train batch 278/450: 4448/7200 mean loss: 0.0015317414654418826 score: 1.0
2021-08-08 03:58:06,627 | train | INFO | Epoch 3 train batch 279/450: 4464/7200 mean loss: 0.001654172665439546 score: 1.0
2021-08-08 03:58:07,433 | train | INFO | Epoch 3 train batch 280/450: 4480/7200 mean loss: 0.001537939882837236 score: 1.0
2021-08-08 03:58:08,262 | train | INFO | Epoch 3 train batch 281/450: 4496/7200 mean loss: 0.0015867537586018443 score: 1.0
2021-08-08 03:58:09,040 | train | INFO | Epoch 3 train batch 282/450: 4512/7200 mean loss: 0.001632494735531509 score: 1.0
2021-08-08 03:58:09,813 | train | INFO | Epoch 3 train batch 283/450: 4528/7200 mean loss: 0.0016538378549739718 score: 0.9632352941176471
2021-08-08 03:58:10,620 | train | INFO | Epoch 3 train batch 284/450: 4544/7200 mean loss: 0.0016520280623808503 score: 1.0
2021-08-08 03:58:11,462 | train | INFO | Epoch 3 train batch 285/450: 4560/7200 mean loss: 0.0016676720697432756 score: 0.9734162895927602
2021-08-08 03:58:12,265 | train | INFO | Epoch 3 train batch 286/450: 4576/7200 mean loss: 0.0015538393054157495 score: 1.0
2021-08-08 03:58:13,073 | train | INFO | Epoch 3 train batch 287/450: 4592/7200 mean loss: 0.0015971821267157793 score: 1.0
2021-08-08 03:58:13,860 | train | INFO | Epoch 3 train batch 288/450: 4608/7200 mean loss: 0.0016460883198305964 score: 1.0
2021-08-08 03:58:14,634 | train | INFO | Epoch 3 train batch 289/450: 4624/7200 mean loss: 0.0016604394186288118 score: 1.0
2021-08-08 03:58:15,424 | train | INFO | Epoch 3 train batch 290/450: 4640/7200 mean loss: 0.0018143588677048683 score: 0.9921568627450981
2021-08-08 03:58:16,223 | train | INFO | Epoch 3 train batch 291/450: 4656/7200 mean loss: 0.0017365922685712576 score: 1.0
2021-08-08 03:58:17,030 | train | INFO | Epoch 3 train batch 292/450: 4672/7200 mean loss: 0.0017920347163453698 score: 1.0
2021-08-08 03:58:17,836 | train | INFO | Epoch 3 train batch 293/450: 4688/7200 mean loss: 0.0016995241167023778 score: 0.9963235294117647
2021-08-08 03:58:18,637 | train | INFO | Epoch 3 train batch 294/450: 4704/7200 mean loss: 0.001690297736786306 score: 1.0
2021-08-08 03:58:19,406 | train | INFO | Epoch 3 train batch 295/450: 4720/7200 mean loss: 0.0016146590933203697 score: 1.0
2021-08-08 03:58:20,200 | train | INFO | Epoch 3 train batch 296/450: 4736/7200 mean loss: 0.0014559377450495958 score: 1.0
2021-08-08 03:58:20,975 | train | INFO | Epoch 3 train batch 297/450: 4752/7200 mean loss: 0.0014885475393384695 score: 1.0
2021-08-08 03:58:21,759 | train | INFO | Epoch 3 train batch 298/450: 4768/7200 mean loss: 0.0016940352506935596 score: 1.0
2021-08-08 03:58:22,552 | train | INFO | Epoch 3 train batch 299/450: 4784/7200 mean loss: 0.0014945726143196225 score: 0.9889705882352942
2021-08-08 03:58:23,393 | train | INFO | Epoch 3 train batch 300/450: 4800/7200 mean loss: 0.0017306777881458402 score: 0.9632352941176471
2021-08-08 03:58:24,164 | train | INFO | Epoch 3 train batch 301/450: 4816/7200 mean loss: 0.0015999486204236746 score: 0.9813725490196079
2021-08-08 03:58:24,933 | train | INFO | Epoch 3 train batch 302/450: 4832/7200 mean loss: 0.0016428102971985936 score: 1.0
2021-08-08 03:58:25,719 | train | INFO | Epoch 3 train batch 303/450: 4848/7200 mean loss: 0.001610088744200766 score: 1.0
2021-08-08 03:58:26,494 | train | INFO | Epoch 3 train batch 304/450: 4864/7200 mean loss: 0.0016491073183715343 score: 0.9963235294117647
2021-08-08 03:58:27,323 | train | INFO | Epoch 3 train batch 305/450: 4880/7200 mean loss: 0.0015870695933699608 score: 1.0
2021-08-08 03:58:28,098 | train | INFO | Epoch 3 train batch 306/450: 4896/7200 mean loss: 0.001666386378929019 score: 1.0
2021-08-08 03:58:28,896 | train | INFO | Epoch 3 train batch 307/450: 4912/7200 mean loss: 0.001829030574299395 score: 1.0
2021-08-08 03:58:29,710 | train | INFO | Epoch 3 train batch 308/450: 4928/7200 mean loss: 0.0016857213340699673 score: 1.0
2021-08-08 03:58:30,488 | train | INFO | Epoch 3 train batch 309/450: 4944/7200 mean loss: 0.0015873515512794256 score: 1.0
2021-08-08 03:58:31,287 | train | INFO | Epoch 3 train batch 310/450: 4960/7200 mean loss: 0.0016928853001445532 score: 1.0
2021-08-08 03:58:32,063 | train | INFO | Epoch 3 train batch 311/450: 4976/7200 mean loss: 0.0017720629693940282 score: 1.0
2021-08-08 03:58:32,881 | train | INFO | Epoch 3 train batch 312/450: 4992/7200 mean loss: 0.0015192002756521106 score: 1.0
2021-08-08 03:58:33,688 | train | INFO | Epoch 3 train batch 313/450: 5008/7200 mean loss: 0.0016843959456309676 score: 1.0
2021-08-08 03:58:34,497 | train | INFO | Epoch 3 train batch 314/450: 5024/7200 mean loss: 0.0016810486558824778 score: 1.0
2021-08-08 03:58:35,381 | train | INFO | Epoch 3 train batch 315/450: 5040/7200 mean loss: 0.0016294349916279316 score: 1.0
2021-08-08 03:58:36,166 | train | INFO | Epoch 3 train batch 316/450: 5056/7200 mean loss: 0.0016994577599689364 score: 1.0
2021-08-08 03:58:36,964 | train | INFO | Epoch 3 train batch 317/450: 5072/7200 mean loss: 0.0015126439975574613 score: 1.0
2021-08-08 03:58:37,785 | train | INFO | Epoch 3 train batch 318/450: 5088/7200 mean loss: 0.0017156880348920822 score: 1.0
2021-08-08 03:58:38,572 | train | INFO | Epoch 3 train batch 319/450: 5104/7200 mean loss: 0.001737484009936452 score: 1.0
2021-08-08 03:58:39,467 | train | INFO | Epoch 3 train batch 320/450: 5120/7200 mean loss: 0.001644992153160274 score: 1.0
2021-08-08 03:58:40,295 | train | INFO | Epoch 3 train batch 321/450: 5136/7200 mean loss: 0.0017422086093574762 score: 0.9776960784313725
2021-08-08 03:58:41,145 | train | INFO | Epoch 3 train batch 322/450: 5152/7200 mean loss: 0.001746519235894084 score: 1.0
2021-08-08 03:58:41,949 | train | INFO | Epoch 3 train batch 323/450: 5168/7200 mean loss: 0.0016877903835847974 score: 1.0
2021-08-08 03:58:42,738 | train | INFO | Epoch 3 train batch 324/450: 5184/7200 mean loss: 0.001529374741949141 score: 1.0
2021-08-08 03:58:43,520 | train | INFO | Epoch 3 train batch 325/450: 5200/7200 mean loss: 0.0015743448166176677 score: 0.995475113122172
2021-08-08 03:58:44,336 | train | INFO | Epoch 3 train batch 326/450: 5216/7200 mean loss: 0.0014369396958500147 score: 1.0
2021-08-08 03:58:45,119 | train | INFO | Epoch 3 train batch 327/450: 5232/7200 mean loss: 0.0014615475665777922 score: 0.9779411764705882
2021-08-08 03:58:45,914 | train | INFO | Epoch 3 train batch 328/450: 5248/7200 mean loss: 0.001602271688170731 score: 0.9963235294117647
2021-08-08 03:58:46,720 | train | INFO | Epoch 3 train batch 329/450: 5264/7200 mean loss: 0.0014988001203164458 score: 1.0
2021-08-08 03:58:47,507 | train | INFO | Epoch 3 train batch 330/450: 5280/7200 mean loss: 0.001668431330472231 score: 0.9963235294117647
2021-08-08 03:58:48,291 | train | INFO | Epoch 3 train batch 331/450: 5296/7200 mean loss: 0.0015632546273991466 score: 0.996078431372549
2021-08-08 03:58:49,077 | train | INFO | Epoch 3 train batch 332/450: 5312/7200 mean loss: 0.0015067356871441007 score: 1.0
2021-08-08 03:58:49,860 | train | INFO | Epoch 3 train batch 333/450: 5328/7200 mean loss: 0.0015567615628242493 score: 1.0
2021-08-08 03:58:50,644 | train | INFO | Epoch 3 train batch 334/450: 5344/7200 mean loss: 0.0015943337930366397 score: 0.9926470588235294
2021-08-08 03:58:51,427 | train | INFO | Epoch 3 train batch 335/450: 5360/7200 mean loss: 0.001498879981227219 score: 1.0
2021-08-08 03:58:52,203 | train | INFO | Epoch 3 train batch 336/450: 5376/7200 mean loss: 0.001461472944356501 score: 1.0
2021-08-08 03:58:53,006 | train | INFO | Epoch 3 train batch 337/450: 5392/7200 mean loss: 0.001685771974734962 score: 0.9884803921568628
2021-08-08 03:58:53,845 | train | INFO | Epoch 3 train batch 338/450: 5408/7200 mean loss: 0.0015843146247789264 score: 1.0
2021-08-08 03:58:54,627 | train | INFO | Epoch 3 train batch 339/450: 5424/7200 mean loss: 0.001610768842510879 score: 1.0
2021-08-08 03:58:55,454 | train | INFO | Epoch 3 train batch 340/450: 5440/7200 mean loss: 0.0017614320386201143 score: 0.995798319327731
2021-08-08 03:58:56,227 | train | INFO | Epoch 3 train batch 341/450: 5456/7200 mean loss: 0.0013865269720554352 score: 1.0
2021-08-08 03:58:56,999 | train | INFO | Epoch 3 train batch 342/450: 5472/7200 mean loss: 0.001552062458358705 score: 0.9852941176470589
2021-08-08 03:58:57,769 | train | INFO | Epoch 3 train batch 343/450: 5488/7200 mean loss: 0.0017131185159087181 score: 1.0
2021-08-08 03:58:58,547 | train | INFO | Epoch 3 train batch 344/450: 5504/7200 mean loss: 0.0016608770238235593 score: 0.9850490196078432
2021-08-08 03:58:59,350 | train | INFO | Epoch 3 train batch 345/450: 5520/7200 mean loss: 0.0017322765197604895 score: 0.995798319327731
2021-08-08 03:59:00,166 | train | INFO | Epoch 3 train batch 346/450: 5536/7200 mean loss: 0.0016922482755035162 score: 0.9926470588235294
2021-08-08 03:59:00,961 | train | INFO | Epoch 3 train batch 347/450: 5552/7200 mean loss: 0.0016866388032212853 score: 0.9816176470588235
2021-08-08 03:59:01,746 | train | INFO | Epoch 3 train batch 348/450: 5568/7200 mean loss: 0.0015384180005639791 score: 1.0
2021-08-08 03:59:02,531 | train | INFO | Epoch 3 train batch 349/450: 5584/7200 mean loss: 0.001654400723055005 score: 1.0
2021-08-08 03:59:03,310 | train | INFO | Epoch 3 train batch 350/450: 5600/7200 mean loss: 0.0015673231100663543 score: 0.995475113122172
2021-08-08 03:59:04,133 | train | INFO | Epoch 3 train batch 351/450: 5616/7200 mean loss: 0.0016630691243335605 score: 1.0
2021-08-08 03:59:04,907 | train | INFO | Epoch 3 train batch 352/450: 5632/7200 mean loss: 0.0016178094083443284 score: 1.0
2021-08-08 03:59:05,694 | train | INFO | Epoch 3 train batch 353/450: 5648/7200 mean loss: 0.0016663094284012914 score: 1.0
2021-08-08 03:59:06,477 | train | INFO | Epoch 3 train batch 354/450: 5664/7200 mean loss: 0.0016443314962089062 score: 0.8117647058823529
2021-08-08 03:59:07,253 | train | INFO | Epoch 3 train batch 355/450: 5680/7200 mean loss: 0.001653072889894247 score: 1.0
2021-08-08 03:59:08,036 | train | INFO | Epoch 3 train batch 356/450: 5696/7200 mean loss: 0.0016764480387791991 score: 1.0
2021-08-08 03:59:08,804 | train | INFO | Epoch 3 train batch 357/450: 5712/7200 mean loss: 0.001527086365967989 score: 1.0
2021-08-08 03:59:09,586 | train | INFO | Epoch 3 train batch 358/450: 5728/7200 mean loss: 0.0015934692928567529 score: 1.0
2021-08-08 03:59:10,406 | train | INFO | Epoch 3 train batch 359/450: 5744/7200 mean loss: 0.0017249105731025338 score: 1.0
2021-08-08 03:59:11,226 | train | INFO | Epoch 3 train batch 360/450: 5760/7200 mean loss: 0.0016512665897607803 score: 1.0
2021-08-08 03:59:12,035 | train | INFO | Epoch 3 train batch 361/450: 5776/7200 mean loss: 0.0016918749315664172 score: 1.0
2021-08-08 03:59:12,821 | train | INFO | Epoch 3 train batch 362/450: 5792/7200 mean loss: 0.0016025386285036802 score: 1.0
2021-08-08 03:59:13,595 | train | INFO | Epoch 3 train batch 363/450: 5808/7200 mean loss: 0.0016950747231021523 score: 1.0
2021-08-08 03:59:14,395 | train | INFO | Epoch 3 train batch 364/450: 5824/7200 mean loss: 0.0015703346580266953 score: 0.9963235294117647
2021-08-08 03:59:15,252 | train | INFO | Epoch 3 train batch 365/450: 5840/7200 mean loss: 0.0016649762401357293 score: 1.0
2021-08-08 03:59:16,074 | train | INFO | Epoch 3 train batch 366/450: 5856/7200 mean loss: 0.0016580333467572927 score: 1.0
2021-08-08 03:59:16,866 | train | INFO | Epoch 3 train batch 367/450: 5872/7200 mean loss: 0.0016489318804815412 score: 0.9926470588235294
2021-08-08 03:59:17,670 | train | INFO | Epoch 3 train batch 368/450: 5888/7200 mean loss: 0.0017211689846590161 score: 1.0
2021-08-08 03:59:18,462 | train | INFO | Epoch 3 train batch 369/450: 5904/7200 mean loss: 0.0017066156724467874 score: 1.0
2021-08-08 03:59:19,250 | train | INFO | Epoch 3 train batch 370/450: 5920/7200 mean loss: 0.0016781461890786886 score: 1.0
2021-08-08 03:59:20,093 | train | INFO | Epoch 3 train batch 371/450: 5936/7200 mean loss: 0.0017139901174232364 score: 1.0
2021-08-08 03:59:20,862 | train | INFO | Epoch 3 train batch 372/450: 5952/7200 mean loss: 0.0016036212909966707 score: 1.0
2021-08-08 03:59:21,637 | train | INFO | Epoch 3 train batch 373/450: 5968/7200 mean loss: 0.0017355728195980191 score: 1.0
2021-08-08 03:59:22,413 | train | INFO | Epoch 3 train batch 374/450: 5984/7200 mean loss: 0.0016069255070760846 score: 0.9917986425339367
2021-08-08 03:59:23,310 | train | INFO | Epoch 3 train batch 375/450: 6000/7200 mean loss: 0.0016635520150884986 score: 1.0
2021-08-08 03:59:24,207 | train | INFO | Epoch 3 train batch 376/450: 6016/7200 mean loss: 0.001499019330367446 score: 1.0
2021-08-08 03:59:25,053 | train | INFO | Epoch 3 train batch 377/450: 6032/7200 mean loss: 0.0016008744714781642 score: 1.0
2021-08-08 03:59:25,882 | train | INFO | Epoch 3 train batch 378/450: 6048/7200 mean loss: 0.001526729785837233 score: 1.0
2021-08-08 03:59:26,672 | train | INFO | Epoch 3 train batch 379/450: 6064/7200 mean loss: 0.0014916344080120325 score: 1.0
2021-08-08 03:59:27,458 | train | INFO | Epoch 3 train batch 380/450: 6080/7200 mean loss: 0.001652567065320909 score: 0.9963235294117647
2021-08-08 03:59:28,248 | train | INFO | Epoch 3 train batch 381/450: 6096/7200 mean loss: 0.0016102357767522335 score: 1.0
2021-08-08 03:59:29,042 | train | INFO | Epoch 3 train batch 382/450: 6112/7200 mean loss: 0.0016385503113269806 score: 1.0
2021-08-08 03:59:29,830 | train | INFO | Epoch 3 train batch 383/450: 6128/7200 mean loss: 0.0016232198104262352 score: 0.9963235294117647
2021-08-08 03:59:30,630 | train | INFO | Epoch 3 train batch 384/450: 6144/7200 mean loss: 0.0015638746554031968 score: 1.0
2021-08-08 03:59:31,440 | train | INFO | Epoch 3 train batch 385/450: 6160/7200 mean loss: 0.0018029033672064543 score: 0.9845588235294118
2021-08-08 03:59:32,239 | train | INFO | Epoch 3 train batch 386/450: 6176/7200 mean loss: 0.0016458212630823255 score: 0.9887254901960785
2021-08-08 03:59:33,027 | train | INFO | Epoch 3 train batch 387/450: 6192/7200 mean loss: 0.0017057108925655484 score: 0.7536764705882353
2021-08-08 03:59:33,804 | train | INFO | Epoch 3 train batch 388/450: 6208/7200 mean loss: 0.0017341439379379153 score: 0.9926470588235294
2021-08-08 03:59:34,579 | train | INFO | Epoch 3 train batch 389/450: 6224/7200 mean loss: 0.0015901552978903055 score: 0.9963235294117647
2021-08-08 03:59:35,382 | train | INFO | Epoch 3 train batch 390/450: 6240/7200 mean loss: 0.0016049019759520888 score: 1.0
2021-08-08 03:59:36,154 | train | INFO | Epoch 3 train batch 391/450: 6256/7200 mean loss: 0.0014692600816488266 score: 0.8147058823529412
2021-08-08 03:59:36,926 | train | INFO | Epoch 3 train batch 392/450: 6272/7200 mean loss: 0.001530297682620585 score: 0.995798319327731
2021-08-08 03:59:37,743 | train | INFO | Epoch 3 train batch 393/450: 6288/7200 mean loss: 0.001676240935921669 score: 1.0
2021-08-08 03:59:38,535 | train | INFO | Epoch 3 train batch 394/450: 6304/7200 mean loss: 0.0015901762526482344 score: 1.0
2021-08-08 03:59:39,305 | train | INFO | Epoch 3 train batch 395/450: 6320/7200 mean loss: 0.0016011456027626991 score: 0.9963235294117647
2021-08-08 03:59:40,098 | train | INFO | Epoch 3 train batch 396/450: 6336/7200 mean loss: 0.0016331459628418088 score: 1.0
2021-08-08 03:59:40,873 | train | INFO | Epoch 3 train batch 397/450: 6352/7200 mean loss: 0.0015684760874137282 score: 1.0
2021-08-08 03:59:41,655 | train | INFO | Epoch 3 train batch 398/450: 6368/7200 mean loss: 0.0017941773403435946 score: 0.9926470588235294
2021-08-08 03:59:42,465 | train | INFO | Epoch 3 train batch 399/450: 6384/7200 mean loss: 0.0015562810003757477 score: 1.0
2021-08-08 03:59:43,242 | train | INFO | Epoch 3 train batch 400/450: 6400/7200 mean loss: 0.0015999265015125275 score: 1.0
2021-08-08 03:59:44,043 | train | INFO | Epoch 3 train batch 401/450: 6416/7200 mean loss: 0.0016098038759082556 score: 1.0
2021-08-08 03:59:44,871 | train | INFO | Epoch 3 train batch 402/450: 6432/7200 mean loss: 0.0016100411303341389 score: 0.9779411764705882
2021-08-08 03:59:45,665 | train | INFO | Epoch 3 train batch 403/450: 6448/7200 mean loss: 0.001563614932820201 score: 1.0
2021-08-08 03:59:46,489 | train | INFO | Epoch 3 train batch 404/450: 6464/7200 mean loss: 0.0017504855059087276 score: 1.0
2021-08-08 03:59:47,275 | train | INFO | Epoch 3 train batch 405/450: 6480/7200 mean loss: 0.0016204358544200659 score: 0.9963235294117647
2021-08-08 03:59:48,054 | train | INFO | Epoch 3 train batch 406/450: 6496/7200 mean loss: 0.001523669227026403 score: 1.0
2021-08-08 03:59:48,848 | train | INFO | Epoch 3 train batch 407/450: 6512/7200 mean loss: 0.0017436208436265588 score: 0.9963235294117647
2021-08-08 03:59:49,627 | train | INFO | Epoch 3 train batch 408/450: 6528/7200 mean loss: 0.0015545727219432592 score: 1.0
2021-08-08 03:59:50,412 | train | INFO | Epoch 3 train batch 409/450: 6544/7200 mean loss: 0.0017801186768338084 score: 1.0
2021-08-08 03:59:51,190 | train | INFO | Epoch 3 train batch 410/450: 6560/7200 mean loss: 0.0014944728463888168 score: 1.0
2021-08-08 03:59:52,007 | train | INFO | Epoch 3 train batch 411/450: 6576/7200 mean loss: 0.0014565602177754045 score: 1.0
2021-08-08 03:59:52,790 | train | INFO | Epoch 3 train batch 412/450: 6592/7200 mean loss: 0.001561757642775774 score: 1.0
2021-08-08 03:59:53,562 | train | INFO | Epoch 3 train batch 413/450: 6608/7200 mean loss: 0.0014085278380662203 score: 1.0
2021-08-08 03:59:54,399 | train | INFO | Epoch 3 train batch 414/450: 6624/7200 mean loss: 0.0015979679301381111 score: 1.0
2021-08-08 03:59:55,182 | train | INFO | Epoch 3 train batch 415/450: 6640/7200 mean loss: 0.0017145053716376424 score: 1.0
2021-08-08 03:59:56,009 | train | INFO | Epoch 3 train batch 416/450: 6656/7200 mean loss: 0.0015745848650112748 score: 1.0
2021-08-08 03:59:56,798 | train | INFO | Epoch 3 train batch 417/450: 6672/7200 mean loss: 0.0016687988536432385 score: 1.0
2021-08-08 03:59:57,578 | train | INFO | Epoch 3 train batch 418/450: 6688/7200 mean loss: 0.0015178724424913526 score: 1.0
2021-08-08 03:59:58,379 | train | INFO | Epoch 3 train batch 419/450: 6704/7200 mean loss: 0.0015541340690106153 score: 1.0
2021-08-08 03:59:59,150 | train | INFO | Epoch 3 train batch 420/450: 6720/7200 mean loss: 0.0017574625089764595 score: 1.0
2021-08-08 03:59:59,955 | train | INFO | Epoch 3 train batch 421/450: 6736/7200 mean loss: 0.0016284935409203172 score: 0.9963235294117647
2021-08-08 04:00:00,759 | train | INFO | Epoch 3 train batch 422/450: 6752/7200 mean loss: 0.0016630144091323018 score: 1.0
2021-08-08 04:00:01,553 | train | INFO | Epoch 3 train batch 423/450: 6768/7200 mean loss: 0.0015363199636340141 score: 0.9926470588235294
2021-08-08 04:00:02,346 | train | INFO | Epoch 3 train batch 424/450: 6784/7200 mean loss: 0.0017023911932483315 score: 0.9963235294117647
2021-08-08 04:00:03,254 | train | INFO | Epoch 3 train batch 425/450: 6800/7200 mean loss: 0.0017144704470410943 score: 0.920343137254902
2021-08-08 04:00:04,034 | train | INFO | Epoch 3 train batch 426/450: 6816/7200 mean loss: 0.0017457365756854415 score: 1.0
2021-08-08 04:00:04,806 | train | INFO | Epoch 3 train batch 427/450: 6832/7200 mean loss: 0.0017049371963366866 score: 0.9852941176470589
2021-08-08 04:00:05,597 | train | INFO | Epoch 3 train batch 428/450: 6848/7200 mean loss: 0.0017587407492101192 score: 1.0
2021-08-08 04:00:06,375 | train | INFO | Epoch 3 train batch 429/450: 6864/7200 mean loss: 0.0015349473105743527 score: 1.0
2021-08-08 04:00:07,151 | train | INFO | Epoch 3 train batch 430/450: 6880/7200 mean loss: 0.0016616210341453552 score: 1.0
2021-08-08 04:00:07,923 | train | INFO | Epoch 3 train batch 431/450: 6896/7200 mean loss: 0.0016961804358288646 score: 1.0
2021-08-08 04:00:08,789 | train | INFO | Epoch 3 train batch 432/450: 6912/7200 mean loss: 0.0017017129575833678 score: 1.0
2021-08-08 04:00:09,624 | train | INFO | Epoch 3 train batch 433/450: 6928/7200 mean loss: 0.001617338741198182 score: 1.0
2021-08-08 04:00:10,409 | train | INFO | Epoch 3 train batch 434/450: 6944/7200 mean loss: 0.0016222965205088258 score: 0.995798319327731
2021-08-08 04:00:11,190 | train | INFO | Epoch 3 train batch 435/450: 6960/7200 mean loss: 0.0016154574695974588 score: 1.0
2021-08-08 04:00:11,975 | train | INFO | Epoch 3 train batch 436/450: 6976/7200 mean loss: 0.001695073558948934 score: 1.0
2021-08-08 04:00:12,780 | train | INFO | Epoch 3 train batch 437/450: 6992/7200 mean loss: 0.0016405569622293115 score: 1.0
2021-08-08 04:00:13,545 | train | INFO | Epoch 3 train batch 438/450: 7008/7200 mean loss: 0.0017060473328456283 score: 1.0
2021-08-08 04:00:14,313 | train | INFO | Epoch 3 train batch 439/450: 7024/7200 mean loss: 0.0015208427794277668 score: 0.9921218487394957
2021-08-08 04:00:15,190 | train | INFO | Epoch 3 train batch 440/450: 7040/7200 mean loss: 0.001706210896372795 score: 1.0
2021-08-08 04:00:15,966 | train | INFO | Epoch 3 train batch 441/450: 7056/7200 mean loss: 0.0015939316945150495 score: 1.0
2021-08-08 04:00:16,741 | train | INFO | Epoch 3 train batch 442/450: 7072/7200 mean loss: 0.0015344992280006409 score: 1.0
2021-08-08 04:00:17,511 | train | INFO | Epoch 3 train batch 443/450: 7088/7200 mean loss: 0.001632904983125627 score: 1.0
2021-08-08 04:00:18,298 | train | INFO | Epoch 3 train batch 444/450: 7104/7200 mean loss: 0.0014596120454370975 score: 1.0
2021-08-08 04:00:19,074 | train | INFO | Epoch 3 train batch 445/450: 7120/7200 mean loss: 0.0015530635137110949 score: 0.995798319327731
2021-08-08 04:00:19,844 | train | INFO | Epoch 3 train batch 446/450: 7136/7200 mean loss: 0.0018490522634238005 score: 0.9963235294117647
2021-08-08 04:00:20,620 | train | INFO | Epoch 3 train batch 447/450: 7152/7200 mean loss: 0.0015058846911415458 score: 1.0
2021-08-08 04:00:21,394 | train | INFO | Epoch 3 train batch 448/450: 7168/7200 mean loss: 0.0016884620999917388 score: 1.0
2021-08-08 04:00:22,162 | train | INFO | Epoch 3 train batch 449/450: 7184/7200 mean loss: 0.0015963626792654395 score: 0.9963235294117647
2021-08-08 04:00:22,301 | train | INFO | Epoch 3, Train, Mean loss: 0.026251121651795176, Score: 0.9938763736263737
2021-08-08 04:00:23,796 | train | INFO | Epoch 3 validation batch 0/113: 0/1800 mean loss: 0.001281801494769752 score: 1.0
2021-08-08 04:00:24,030 | train | INFO | Epoch 3 validation batch 1/113: 16/1800 mean loss: 0.0012586198281496763 score: 0.9963235294117647
2021-08-08 04:00:24,263 | train | INFO | Epoch 3 validation batch 2/113: 32/1800 mean loss: 0.0014568953774869442 score: 1.0
2021-08-08 04:00:24,496 | train | INFO | Epoch 3 validation batch 3/113: 48/1800 mean loss: 0.0013819672167301178 score: 1.0
2021-08-08 04:00:24,738 | train | INFO | Epoch 3 validation batch 4/113: 64/1800 mean loss: 0.0012852615909650922 score: 1.0
2021-08-08 04:00:24,968 | train | INFO | Epoch 3 validation batch 5/113: 80/1800 mean loss: 0.0013197227381169796 score: 1.0
2021-08-08 04:00:25,207 | train | INFO | Epoch 3 validation batch 6/113: 96/1800 mean loss: 0.0012592612765729427 score: 1.0
2021-08-08 04:00:25,453 | train | INFO | Epoch 3 validation batch 7/113: 112/1800 mean loss: 0.0013512775767594576 score: 1.0
2021-08-08 04:00:25,689 | train | INFO | Epoch 3 validation batch 8/113: 128/1800 mean loss: 0.001321669900789857 score: 1.0
2021-08-08 04:00:25,926 | train | INFO | Epoch 3 validation batch 9/113: 144/1800 mean loss: 0.0012207692489027977 score: 1.0
2021-08-08 04:00:26,156 | train | INFO | Epoch 3 validation batch 10/113: 160/1800 mean loss: 0.0012579315807670355 score: 0.9816176470588235
2021-08-08 04:00:26,387 | train | INFO | Epoch 3 validation batch 11/113: 176/1800 mean loss: 0.0013601548271253705 score: 0.9926470588235294
2021-08-08 04:00:26,618 | train | INFO | Epoch 3 validation batch 12/113: 192/1800 mean loss: 0.0012759191449731588 score: 1.0
2021-08-08 04:00:26,873 | train | INFO | Epoch 3 validation batch 13/113: 208/1800 mean loss: 0.0012844818411394954 score: 0.9963235294117647
2021-08-08 04:00:27,123 | train | INFO | Epoch 3 validation batch 14/113: 224/1800 mean loss: 0.0012208473635837436 score: 1.0
2021-08-08 04:00:27,380 | train | INFO | Epoch 3 validation batch 15/113: 240/1800 mean loss: 0.0012283996911719441 score: 1.0
2021-08-08 04:00:27,626 | train | INFO | Epoch 3 validation batch 16/113: 256/1800 mean loss: 0.001258820528164506 score: 1.0
2021-08-08 04:00:27,859 | train | INFO | Epoch 3 validation batch 17/113: 272/1800 mean loss: 0.0013570367591455579 score: 1.0
2021-08-08 04:00:28,111 | train | INFO | Epoch 3 validation batch 18/113: 288/1800 mean loss: 0.001164784887805581 score: 1.0
2021-08-08 04:00:28,355 | train | INFO | Epoch 3 validation batch 19/113: 304/1800 mean loss: 0.001235249568708241 score: 1.0
2021-08-08 04:00:28,597 | train | INFO | Epoch 3 validation batch 20/113: 320/1800 mean loss: 0.001313243294134736 score: 0.9813725490196079
2021-08-08 04:00:28,828 | train | INFO | Epoch 3 validation batch 21/113: 336/1800 mean loss: 0.0012480943696573377 score: 1.0
2021-08-08 04:00:29,084 | train | INFO | Epoch 3 validation batch 22/113: 352/1800 mean loss: 0.0011945768492296338 score: 1.0
2021-08-08 04:00:29,314 | train | INFO | Epoch 3 validation batch 23/113: 368/1800 mean loss: 0.0012039804132655263 score: 1.0
2021-08-08 04:00:29,545 | train | INFO | Epoch 3 validation batch 24/113: 384/1800 mean loss: 0.0012632202124223113 score: 1.0
2021-08-08 04:00:29,777 | train | INFO | Epoch 3 validation batch 25/113: 400/1800 mean loss: 0.0013662533601745963 score: 1.0
2021-08-08 04:00:30,040 | train | INFO | Epoch 3 validation batch 26/113: 416/1800 mean loss: 0.0012329546734690666 score: 1.0
2021-08-08 04:00:30,275 | train | INFO | Epoch 3 validation batch 27/113: 432/1800 mean loss: 0.0013859772589057684 score: 1.0
2021-08-08 04:00:30,524 | train | INFO | Epoch 3 validation batch 28/113: 448/1800 mean loss: 0.0012665847316384315 score: 1.0
2021-08-08 04:00:30,754 | train | INFO | Epoch 3 validation batch 29/113: 464/1800 mean loss: 0.0013091866858303547 score: 1.0
2021-08-08 04:00:30,985 | train | INFO | Epoch 3 validation batch 30/113: 480/1800 mean loss: 0.0013405567733570933 score: 0.9963235294117647
2021-08-08 04:00:31,227 | train | INFO | Epoch 3 validation batch 31/113: 496/1800 mean loss: 0.0012160955229774117 score: 1.0
2021-08-08 04:00:31,458 | train | INFO | Epoch 3 validation batch 32/113: 512/1800 mean loss: 0.0012658777413889766 score: 0.9963235294117647
2021-08-08 04:00:31,688 | train | INFO | Epoch 3 validation batch 33/113: 528/1800 mean loss: 0.0012456632684916258 score: 1.0
2021-08-08 04:00:31,934 | train | INFO | Epoch 3 validation batch 34/113: 544/1800 mean loss: 0.0010702040744945407 score: 1.0
2021-08-08 04:00:32,230 | train | INFO | Epoch 3 validation batch 35/113: 560/1800 mean loss: 0.0013501611538231373 score: 1.0
2021-08-08 04:00:32,481 | train | INFO | Epoch 3 validation batch 36/113: 576/1800 mean loss: 0.0014225599588826299 score: 0.8514705882352941
2021-08-08 04:00:32,733 | train | INFO | Epoch 3 validation batch 37/113: 592/1800 mean loss: 0.001129005802795291 score: 1.0
2021-08-08 04:00:32,968 | train | INFO | Epoch 3 validation batch 38/113: 608/1800 mean loss: 0.0013385089114308357 score: 1.0
2021-08-08 04:00:33,200 | train | INFO | Epoch 3 validation batch 39/113: 624/1800 mean loss: 0.001261259545572102 score: 1.0
2021-08-08 04:00:33,442 | train | INFO | Epoch 3 validation batch 40/113: 640/1800 mean loss: 0.0013368322979658842 score: 1.0
2021-08-08 04:00:33,690 | train | INFO | Epoch 3 validation batch 41/113: 656/1800 mean loss: 0.001247428823262453 score: 1.0
2021-08-08 04:00:33,935 | train | INFO | Epoch 3 validation batch 42/113: 672/1800 mean loss: 0.0012483944883570075 score: 0.9926470588235294
2021-08-08 04:00:34,185 | train | INFO | Epoch 3 validation batch 43/113: 688/1800 mean loss: 0.0012785226572304964 score: 1.0
2021-08-08 04:00:34,416 | train | INFO | Epoch 3 validation batch 44/113: 704/1800 mean loss: 0.0014191278023645282 score: 0.9669117647058824
2021-08-08 04:00:34,678 | train | INFO | Epoch 3 validation batch 45/113: 720/1800 mean loss: 0.0012713739415630698 score: 1.0
2021-08-08 04:00:34,928 | train | INFO | Epoch 3 validation batch 46/113: 736/1800 mean loss: 0.001265711965970695 score: 0.9889705882352942
2021-08-08 04:00:35,171 | train | INFO | Epoch 3 validation batch 47/113: 752/1800 mean loss: 0.0012156569864600897 score: 1.0
2021-08-08 04:00:35,427 | train | INFO | Epoch 3 validation batch 48/113: 768/1800 mean loss: 0.0012831109343096614 score: 1.0
2021-08-08 04:00:35,675 | train | INFO | Epoch 3 validation batch 49/113: 784/1800 mean loss: 0.0012796529335901141 score: 1.0
2021-08-08 04:00:35,907 | train | INFO | Epoch 3 validation batch 50/113: 800/1800 mean loss: 0.0012297523207962513 score: 0.9963235294117647
2021-08-08 04:00:36,154 | train | INFO | Epoch 3 validation batch 51/113: 816/1800 mean loss: 0.0013389093801379204 score: 0.9742647058823529
2021-08-08 04:00:36,396 | train | INFO | Epoch 3 validation batch 52/113: 832/1800 mean loss: 0.0013389192754402757 score: 1.0
2021-08-08 04:00:36,625 | train | INFO | Epoch 3 validation batch 53/113: 848/1800 mean loss: 0.0013109507272019982 score: 1.0
2021-08-08 04:00:36,871 | train | INFO | Epoch 3 validation batch 54/113: 864/1800 mean loss: 0.0012321291724219918 score: 1.0
2021-08-08 04:00:37,126 | train | INFO | Epoch 3 validation batch 55/113: 880/1800 mean loss: 0.0013429771643131971 score: 0.995798319327731
2021-08-08 04:00:37,388 | train | INFO | Epoch 3 validation batch 56/113: 896/1800 mean loss: 0.0012947991490364075 score: 1.0
2021-08-08 04:00:37,626 | train | INFO | Epoch 3 validation batch 57/113: 912/1800 mean loss: 0.0013491056161001325 score: 1.0
2021-08-08 04:00:37,888 | train | INFO | Epoch 3 validation batch 58/113: 928/1800 mean loss: 0.0013804289046674967 score: 0.9742647058823529
2021-08-08 04:00:38,139 | train | INFO | Epoch 3 validation batch 59/113: 944/1800 mean loss: 0.0012535006972029805 score: 1.0
2021-08-08 04:00:38,388 | train | INFO | Epoch 3 validation batch 60/113: 960/1800 mean loss: 0.0010835659923031926 score: 1.0
2021-08-08 04:00:38,622 | train | INFO | Epoch 3 validation batch 61/113: 976/1800 mean loss: 0.001205835840664804 score: 1.0
2021-08-08 04:00:38,876 | train | INFO | Epoch 3 validation batch 62/113: 992/1800 mean loss: 0.001260489341802895 score: 1.0
2021-08-08 04:00:39,124 | train | INFO | Epoch 3 validation batch 63/113: 1008/1800 mean loss: 0.0012684226967394352 score: 1.0
2021-08-08 04:00:39,367 | train | INFO | Epoch 3 validation batch 64/113: 1024/1800 mean loss: 0.001315929926931858 score: 1.0
2021-08-08 04:00:39,599 | train | INFO | Epoch 3 validation batch 65/113: 1040/1800 mean loss: 0.001296425238251686 score: 0.9963235294117647
2021-08-08 04:00:39,828 | train | INFO | Epoch 3 validation batch 66/113: 1056/1800 mean loss: 0.0013490526471287012 score: 1.0
2021-08-08 04:00:40,092 | train | INFO | Epoch 3 validation batch 67/113: 1072/1800 mean loss: 0.0013047319371253252 score: 1.0
2021-08-08 04:00:40,334 | train | INFO | Epoch 3 validation batch 68/113: 1088/1800 mean loss: 0.0011273289564996958 score: 1.0
2021-08-08 04:00:40,592 | train | INFO | Epoch 3 validation batch 69/113: 1104/1800 mean loss: 0.0013203190173953772 score: 1.0
2021-08-08 04:00:40,838 | train | INFO | Epoch 3 validation batch 70/113: 1120/1800 mean loss: 0.0013845231151208282 score: 0.9963235294117647
2021-08-08 04:00:41,070 | train | INFO | Epoch 3 validation batch 71/113: 1136/1800 mean loss: 0.0012489431537687778 score: 1.0
2021-08-08 04:00:41,316 | train | INFO | Epoch 3 validation batch 72/113: 1152/1800 mean loss: 0.0012736687203869224 score: 1.0
2021-08-08 04:00:41,574 | train | INFO | Epoch 3 validation batch 73/113: 1168/1800 mean loss: 0.0013794254045933485 score: 1.0
2021-08-08 04:00:41,835 | train | INFO | Epoch 3 validation batch 74/113: 1184/1800 mean loss: 0.0013218532549217343 score: 1.0
2021-08-08 04:00:42,083 | train | INFO | Epoch 3 validation batch 75/113: 1200/1800 mean loss: 0.0012856359826400876 score: 1.0
2021-08-08 04:00:42,330 | train | INFO | Epoch 3 validation batch 76/113: 1216/1800 mean loss: 0.001212924369610846 score: 1.0
2021-08-08 04:00:42,591 | train | INFO | Epoch 3 validation batch 77/113: 1232/1800 mean loss: 0.0011650967644527555 score: 1.0
2021-08-08 04:00:42,845 | train | INFO | Epoch 3 validation batch 78/113: 1248/1800 mean loss: 0.0013138223439455032 score: 0.9544117647058824
2021-08-08 04:00:43,103 | train | INFO | Epoch 3 validation batch 79/113: 1264/1800 mean loss: 0.0013208306627348065 score: 0.9921568627450981
2021-08-08 04:00:43,342 | train | INFO | Epoch 3 validation batch 80/113: 1280/1800 mean loss: 0.001445204485207796 score: 1.0
2021-08-08 04:00:43,584 | train | INFO | Epoch 3 validation batch 81/113: 1296/1800 mean loss: 0.0012982625048607588 score: 1.0
2021-08-08 04:00:43,839 | train | INFO | Epoch 3 validation batch 82/113: 1312/1800 mean loss: 0.0011755169834941626 score: 1.0
2021-08-08 04:00:44,083 | train | INFO | Epoch 3 validation batch 83/113: 1328/1800 mean loss: 0.0013970488216727972 score: 1.0
2021-08-08 04:00:44,326 | train | INFO | Epoch 3 validation batch 84/113: 1344/1800 mean loss: 0.0013617455260828137 score: 0.9666666666666667
2021-08-08 04:00:44,578 | train | INFO | Epoch 3 validation batch 85/113: 1360/1800 mean loss: 0.0012699496001005173 score: 1.0
2021-08-08 04:00:44,810 | train | INFO | Epoch 3 validation batch 86/113: 1376/1800 mean loss: 0.0014707472873851657 score: 1.0
2021-08-08 04:00:45,061 | train | INFO | Epoch 3 validation batch 87/113: 1392/1800 mean loss: 0.001341417315416038 score: 1.0
2021-08-08 04:00:45,293 | train | INFO | Epoch 3 validation batch 88/113: 1408/1800 mean loss: 0.0011720629408955574 score: 1.0
2021-08-08 04:00:45,524 | train | INFO | Epoch 3 validation batch 89/113: 1424/1800 mean loss: 0.0011225328780710697 score: 1.0
2021-08-08 04:00:45,755 | train | INFO | Epoch 3 validation batch 90/113: 1440/1800 mean loss: 0.0012751864269375801 score: 1.0
2021-08-08 04:00:46,008 | train | INFO | Epoch 3 validation batch 91/113: 1456/1800 mean loss: 0.0014232724206522107 score: 0.9963235294117647
2021-08-08 04:00:46,269 | train | INFO | Epoch 3 validation batch 92/113: 1472/1800 mean loss: 0.001323909847997129 score: 1.0
2021-08-08 04:00:46,499 | train | INFO | Epoch 3 validation batch 93/113: 1488/1800 mean loss: 0.0013106296537443995 score: 1.0
2021-08-08 04:00:46,731 | train | INFO | Epoch 3 validation batch 94/113: 1504/1800 mean loss: 0.0013135124463588 score: 1.0
2021-08-08 04:00:46,975 | train | INFO | Epoch 3 validation batch 95/113: 1520/1800 mean loss: 0.0013647631276398897 score: 1.0
2021-08-08 04:00:47,207 | train | INFO | Epoch 3 validation batch 96/113: 1536/1800 mean loss: 0.00129576469771564 score: 1.0
2021-08-08 04:00:47,478 | train | INFO | Epoch 3 validation batch 97/113: 1552/1800 mean loss: 0.0013240172993391752 score: 1.0
2021-08-08 04:00:47,718 | train | INFO | Epoch 3 validation batch 98/113: 1568/1800 mean loss: 0.0012939991429448128 score: 1.0
2021-08-08 04:00:47,960 | train | INFO | Epoch 3 validation batch 99/113: 1584/1800 mean loss: 0.0012593776918947697 score: 1.0
2021-08-08 04:00:48,195 | train | INFO | Epoch 3 validation batch 100/113: 1600/1800 mean loss: 0.001415091915987432 score: 1.0
2021-08-08 04:00:48,426 | train | INFO | Epoch 3 validation batch 101/113: 1616/1800 mean loss: 0.0012887072516605258 score: 1.0
2021-08-08 04:00:48,657 | train | INFO | Epoch 3 validation batch 102/113: 1632/1800 mean loss: 0.0012354361824691296 score: 1.0
2021-08-08 04:00:48,889 | train | INFO | Epoch 3 validation batch 103/113: 1648/1800 mean loss: 0.0012306314893066883 score: 1.0
2021-08-08 04:00:49,120 | train | INFO | Epoch 3 validation batch 104/113: 1664/1800 mean loss: 0.0013067821273580194 score: 1.0
2021-08-08 04:00:49,352 | train | INFO | Epoch 3 validation batch 105/113: 1680/1800 mean loss: 0.0013013309799134731 score: 1.0
2021-08-08 04:00:49,583 | train | INFO | Epoch 3 validation batch 106/113: 1696/1800 mean loss: 0.001344278221949935 score: 1.0
2021-08-08 04:00:49,814 | train | INFO | Epoch 3 validation batch 107/113: 1712/1800 mean loss: 0.0013873183634132147 score: 1.0
2021-08-08 04:00:50,044 | train | INFO | Epoch 3 validation batch 108/113: 1728/1800 mean loss: 0.0013924399390816689 score: 1.0
2021-08-08 04:00:50,276 | train | INFO | Epoch 3 validation batch 109/113: 1744/1800 mean loss: 0.0014249075902625918 score: 1.0
2021-08-08 04:00:50,511 | train | INFO | Epoch 3 validation batch 110/113: 1760/1800 mean loss: 0.001261593191884458 score: 1.0
2021-08-08 04:00:50,741 | train | INFO | Epoch 3 validation batch 111/113: 1776/1800 mean loss: 0.0013153802137821913 score: 1.0
2021-08-08 04:00:50,906 | train | INFO | Epoch 3 validation batch 112/113: 1792/1800 mean loss: 0.0011339707998558879 score: 1.0
2021-08-08 04:00:51,064 | train | INFO | Epoch 3, Validation, Mean loss: 0.02064959108170155, Score: 0.9963167125257182
2021-08-08 04:00:51,064 | train | INFO | Write row 3
2021-08-08 04:00:53,795 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:00:53,799 | train | INFO | Update best record row 4, checkpoints 0.02213034521689457 -> 0.02064959108170155
2021-08-08 04:00:55,781 | train | INFO | Epoch 4 train batch 0/450: 0/7200 mean loss: 0.0015486881602555513 score: 0.995798319327731
2021-08-08 04:00:56,593 | train | INFO | Epoch 4 train batch 1/450: 16/7200 mean loss: 0.0014982675202190876 score: 1.0
2021-08-08 04:00:57,366 | train | INFO | Epoch 4 train batch 2/450: 32/7200 mean loss: 0.0016433231066912413 score: 0.9926470588235294
2021-08-08 04:00:58,132 | train | INFO | Epoch 4 train batch 3/450: 48/7200 mean loss: 0.001562739722430706 score: 1.0
2021-08-08 04:00:58,913 | train | INFO | Epoch 4 train batch 4/450: 64/7200 mean loss: 0.001509526977315545 score: 1.0
2021-08-08 04:00:59,696 | train | INFO | Epoch 4 train batch 5/450: 80/7200 mean loss: 0.0016230747569352388 score: 1.0
2021-08-08 04:01:00,502 | train | INFO | Epoch 4 train batch 6/450: 96/7200 mean loss: 0.001748683862388134 score: 1.0
2021-08-08 04:01:01,288 | train | INFO | Epoch 4 train batch 7/450: 112/7200 mean loss: 0.0016883938806131482 score: 1.0
2021-08-08 04:01:02,127 | train | INFO | Epoch 4 train batch 8/450: 128/7200 mean loss: 0.0016806608764454722 score: 1.0
2021-08-08 04:01:02,949 | train | INFO | Epoch 4 train batch 9/450: 144/7200 mean loss: 0.0016096734907478094 score: 1.0
2021-08-08 04:01:03,813 | train | INFO | Epoch 4 train batch 10/450: 160/7200 mean loss: 0.0015410046325996518 score: 0.9963235294117647
2021-08-08 04:01:04,599 | train | INFO | Epoch 4 train batch 11/450: 176/7200 mean loss: 0.001786256325431168 score: 1.0
2021-08-08 04:01:05,384 | train | INFO | Epoch 4 train batch 12/450: 192/7200 mean loss: 0.001672790851444006 score: 1.0
2021-08-08 04:01:06,173 | train | INFO | Epoch 4 train batch 13/450: 208/7200 mean loss: 0.0016289978520944715 score: 1.0
2021-08-08 04:01:06,963 | train | INFO | Epoch 4 train batch 14/450: 224/7200 mean loss: 0.0016304205637425184 score: 1.0
2021-08-08 04:01:07,737 | train | INFO | Epoch 4 train batch 15/450: 240/7200 mean loss: 0.0016984264366328716 score: 0.9926470588235294
2021-08-08 04:01:08,536 | train | INFO | Epoch 4 train batch 16/450: 256/7200 mean loss: 0.001650552498176694 score: 0.996078431372549
2021-08-08 04:01:09,345 | train | INFO | Epoch 4 train batch 17/450: 272/7200 mean loss: 0.0016895344015210867 score: 1.0
2021-08-08 04:01:10,134 | train | INFO | Epoch 4 train batch 18/450: 288/7200 mean loss: 0.0016127219423651695 score: 0.9805241327300152
2021-08-08 04:01:10,931 | train | INFO | Epoch 4 train batch 19/450: 304/7200 mean loss: 0.0015479850117117167 score: 1.0
2021-08-08 04:01:11,717 | train | INFO | Epoch 4 train batch 20/450: 320/7200 mean loss: 0.0016898023895919323 score: 1.0
2021-08-08 04:01:12,539 | train | INFO | Epoch 4 train batch 21/450: 336/7200 mean loss: 0.0015931706875562668 score: 0.996078431372549
2021-08-08 04:01:13,320 | train | INFO | Epoch 4 train batch 22/450: 352/7200 mean loss: 0.0015700693475082517 score: 1.0
2021-08-08 04:01:14,107 | train | INFO | Epoch 4 train batch 23/450: 368/7200 mean loss: 0.0016142502427101135 score: 1.0
2021-08-08 04:01:14,930 | train | INFO | Epoch 4 train batch 24/450: 384/7200 mean loss: 0.0016248710453510284 score: 0.9774509803921569
2021-08-08 04:01:15,737 | train | INFO | Epoch 4 train batch 25/450: 400/7200 mean loss: 0.0015074120601639152 score: 1.0
2021-08-08 04:01:16,549 | train | INFO | Epoch 4 train batch 26/450: 416/7200 mean loss: 0.0015420335112139583 score: 1.0
2021-08-08 04:01:17,406 | train | INFO | Epoch 4 train batch 27/450: 432/7200 mean loss: 0.0017054270720109344 score: 0.9963235294117647
2021-08-08 04:01:18,310 | train | INFO | Epoch 4 train batch 28/450: 448/7200 mean loss: 0.0014997991966083646 score: 0.9926470588235294
2021-08-08 04:01:19,122 | train | INFO | Epoch 4 train batch 29/450: 464/7200 mean loss: 0.0016904780641198158 score: 1.0
2021-08-08 04:01:19,926 | train | INFO | Epoch 4 train batch 30/450: 480/7200 mean loss: 0.0016504840459674597 score: 1.0
2021-08-08 04:01:20,714 | train | INFO | Epoch 4 train batch 31/450: 496/7200 mean loss: 0.0016363494796678424 score: 1.0
2021-08-08 04:01:21,491 | train | INFO | Epoch 4 train batch 32/450: 512/7200 mean loss: 0.0017734883585944772 score: 0.9926470588235294
2021-08-08 04:01:22,299 | train | INFO | Epoch 4 train batch 33/450: 528/7200 mean loss: 0.0017403630772605538 score: 1.0
2021-08-08 04:01:23,074 | train | INFO | Epoch 4 train batch 34/450: 544/7200 mean loss: 0.00162982486654073 score: 1.0
2021-08-08 04:01:23,861 | train | INFO | Epoch 4 train batch 35/450: 560/7200 mean loss: 0.0015340382233262062 score: 1.0
2021-08-08 04:01:24,666 | train | INFO | Epoch 4 train batch 36/450: 576/7200 mean loss: 0.001610971405170858 score: 1.0
2021-08-08 04:01:25,488 | train | INFO | Epoch 4 train batch 37/450: 592/7200 mean loss: 0.0016410573152825236 score: 1.0
2021-08-08 04:01:26,303 | train | INFO | Epoch 4 train batch 38/450: 608/7200 mean loss: 0.0017700557364150882 score: 1.0
2021-08-08 04:01:27,105 | train | INFO | Epoch 4 train batch 39/450: 624/7200 mean loss: 0.0015695649199187756 score: 0.9852941176470589
2021-08-08 04:01:27,905 | train | INFO | Epoch 4 train batch 40/450: 640/7200 mean loss: 0.0015943116741254926 score: 1.0
2021-08-08 04:01:28,680 | train | INFO | Epoch 4 train batch 41/450: 656/7200 mean loss: 0.0016028612153604627 score: 1.0
2021-08-08 04:01:29,472 | train | INFO | Epoch 4 train batch 42/450: 672/7200 mean loss: 0.0016995592741295695 score: 1.0
2021-08-08 04:01:30,245 | train | INFO | Epoch 4 train batch 43/450: 688/7200 mean loss: 0.0016180422389879823 score: 1.0
2021-08-08 04:01:31,089 | train | INFO | Epoch 4 train batch 44/450: 704/7200 mean loss: 0.0016797042917460203 score: 0.6328781512605042
2021-08-08 04:01:31,865 | train | INFO | Epoch 4 train batch 45/450: 720/7200 mean loss: 0.0017087939195334911 score: 1.0
2021-08-08 04:01:32,662 | train | INFO | Epoch 4 train batch 46/450: 736/7200 mean loss: 0.0016155296470969915 score: 0.9921568627450981
2021-08-08 04:01:33,439 | train | INFO | Epoch 4 train batch 47/450: 752/7200 mean loss: 0.0015013240044936538 score: 0.9884453781512604
2021-08-08 04:01:34,234 | train | INFO | Epoch 4 train batch 48/450: 768/7200 mean loss: 0.0016449124086648226 score: 1.0
2021-08-08 04:01:35,013 | train | INFO | Epoch 4 train batch 49/450: 784/7200 mean loss: 0.0015918605495244265 score: 1.0
2021-08-08 04:01:35,810 | train | INFO | Epoch 4 train batch 50/450: 800/7200 mean loss: 0.0015226248651742935 score: 1.0
2021-08-08 04:01:36,609 | train | INFO | Epoch 4 train batch 51/450: 816/7200 mean loss: 0.0016075812745839357 score: 1.0
2021-08-08 04:01:37,473 | train | INFO | Epoch 4 train batch 52/450: 832/7200 mean loss: 0.0015652219299227 score: 0.9926470588235294
2021-08-08 04:01:38,282 | train | INFO | Epoch 4 train batch 53/450: 848/7200 mean loss: 0.0015438067493960261 score: 1.0
2021-08-08 04:01:39,088 | train | INFO | Epoch 4 train batch 54/450: 864/7200 mean loss: 0.0015091925160959363 score: 1.0
2021-08-08 04:01:39,950 | train | INFO | Epoch 4 train batch 55/450: 880/7200 mean loss: 0.0016164638800546527 score: 0.9921568627450981
2021-08-08 04:01:40,848 | train | INFO | Epoch 4 train batch 56/450: 896/7200 mean loss: 0.0014536273665726185 score: 1.0
2021-08-08 04:01:41,664 | train | INFO | Epoch 4 train batch 57/450: 912/7200 mean loss: 0.0014904839918017387 score: 1.0
2021-08-08 04:01:42,455 | train | INFO | Epoch 4 train batch 58/450: 928/7200 mean loss: 0.001478237216360867 score: 1.0
2021-08-08 04:01:43,244 | train | INFO | Epoch 4 train batch 59/450: 944/7200 mean loss: 0.0015758622903376818 score: 1.0
2021-08-08 04:01:44,084 | train | INFO | Epoch 4 train batch 60/450: 960/7200 mean loss: 0.0016283815493807197 score: 1.0
2021-08-08 04:01:44,920 | train | INFO | Epoch 4 train batch 61/450: 976/7200 mean loss: 0.001680570188909769 score: 0.9963235294117647
2021-08-08 04:01:45,707 | train | INFO | Epoch 4 train batch 62/450: 992/7200 mean loss: 0.001785675180144608 score: 1.0
2021-08-08 04:01:46,493 | train | INFO | Epoch 4 train batch 63/450: 1008/7200 mean loss: 0.0016479509649798274 score: 1.0
2021-08-08 04:01:47,279 | train | INFO | Epoch 4 train batch 64/450: 1024/7200 mean loss: 0.0016012691194191575 score: 1.0
2021-08-08 04:01:48,063 | train | INFO | Epoch 4 train batch 65/450: 1040/7200 mean loss: 0.0016980855725705624 score: 0.9811274509803922
2021-08-08 04:01:48,849 | train | INFO | Epoch 4 train batch 66/450: 1056/7200 mean loss: 0.001525480067357421 score: 1.0
2021-08-08 04:01:49,641 | train | INFO | Epoch 4 train batch 67/450: 1072/7200 mean loss: 0.0015240367501974106 score: 0.9411764705882353
2021-08-08 04:01:50,419 | train | INFO | Epoch 4 train batch 68/450: 1088/7200 mean loss: 0.001592157525010407 score: 0.9887254901960785
2021-08-08 04:01:51,200 | train | INFO | Epoch 4 train batch 69/450: 1104/7200 mean loss: 0.0014169183559715748 score: 1.0
2021-08-08 04:01:51,998 | train | INFO | Epoch 4 train batch 70/450: 1120/7200 mean loss: 0.001634465646930039 score: 0.9517156862745099
2021-08-08 04:01:52,825 | train | INFO | Epoch 4 train batch 71/450: 1136/7200 mean loss: 0.0015816105296835303 score: 1.0
2021-08-08 04:01:53,639 | train | INFO | Epoch 4 train batch 72/450: 1152/7200 mean loss: 0.001534606097266078 score: 1.0
2021-08-08 04:01:54,465 | train | INFO | Epoch 4 train batch 73/450: 1168/7200 mean loss: 0.0017335204174742103 score: 1.0
2021-08-08 04:01:55,256 | train | INFO | Epoch 4 train batch 74/450: 1184/7200 mean loss: 0.001567043480463326 score: 1.0
2021-08-08 04:01:56,038 | train | INFO | Epoch 4 train batch 75/450: 1200/7200 mean loss: 0.0016223049024119973 score: 0.9882002801120447
2021-08-08 04:01:56,844 | train | INFO | Epoch 4 train batch 76/450: 1216/7200 mean loss: 0.0016092153964564204 score: 1.0
2021-08-08 04:01:57,653 | train | INFO | Epoch 4 train batch 77/450: 1232/7200 mean loss: 0.0013494616141542792 score: 1.0
2021-08-08 04:01:58,427 | train | INFO | Epoch 4 train batch 78/450: 1248/7200 mean loss: 0.0017608392518013716 score: 0.9772058823529413
2021-08-08 04:01:59,195 | train | INFO | Epoch 4 train batch 79/450: 1264/7200 mean loss: 0.0015903741586953402 score: 0.9650910364145657
2021-08-08 04:01:59,988 | train | INFO | Epoch 4 train batch 80/450: 1280/7200 mean loss: 0.0016465161461383104 score: 1.0
2021-08-08 04:02:00,759 | train | INFO | Epoch 4 train batch 81/450: 1296/7200 mean loss: 0.0015754757914692163 score: 1.0
2021-08-08 04:02:01,530 | train | INFO | Epoch 4 train batch 82/450: 1312/7200 mean loss: 0.0017346303211525083 score: 0.7995098039215687
2021-08-08 04:02:02,344 | train | INFO | Epoch 4 train batch 83/450: 1328/7200 mean loss: 0.0016129135619848967 score: 0.9810924369747899
2021-08-08 04:02:03,128 | train | INFO | Epoch 4 train batch 84/450: 1344/7200 mean loss: 0.0015960392775014043 score: 0.9963235294117647
2021-08-08 04:02:03,924 | train | INFO | Epoch 4 train batch 85/450: 1360/7200 mean loss: 0.0013731203507632017 score: 1.0
2021-08-08 04:02:04,713 | train | INFO | Epoch 4 train batch 86/450: 1376/7200 mean loss: 0.0013363217003643513 score: 0.9963235294117647
2021-08-08 04:02:05,496 | train | INFO | Epoch 4 train batch 87/450: 1392/7200 mean loss: 0.0016422938788309693 score: 1.0
2021-08-08 04:02:06,315 | train | INFO | Epoch 4 train batch 88/450: 1408/7200 mean loss: 0.001647680182941258 score: 0.9963235294117647
2021-08-08 04:02:07,147 | train | INFO | Epoch 4 train batch 89/450: 1424/7200 mean loss: 0.001526208478026092 score: 0.9593137254901961
2021-08-08 04:02:07,948 | train | INFO | Epoch 4 train batch 90/450: 1440/7200 mean loss: 0.0016962835798040032 score: 0.9963235294117647
2021-08-08 04:02:08,730 | train | INFO | Epoch 4 train batch 91/450: 1456/7200 mean loss: 0.0016506626270711422 score: 1.0
2021-08-08 04:02:09,502 | train | INFO | Epoch 4 train batch 92/450: 1472/7200 mean loss: 0.0016510533168911934 score: 0.9915966386554622
2021-08-08 04:02:10,283 | train | INFO | Epoch 4 train batch 93/450: 1488/7200 mean loss: 0.0015928263310343027 score: 1.0
2021-08-08 04:02:11,102 | train | INFO | Epoch 4 train batch 94/450: 1504/7200 mean loss: 0.001656905747950077 score: 1.0
2021-08-08 04:02:11,902 | train | INFO | Epoch 4 train batch 95/450: 1520/7200 mean loss: 0.0015088594518601894 score: 1.0
2021-08-08 04:02:12,742 | train | INFO | Epoch 4 train batch 96/450: 1536/7200 mean loss: 0.0015172210987657309 score: 1.0
2021-08-08 04:02:13,524 | train | INFO | Epoch 4 train batch 97/450: 1552/7200 mean loss: 0.0016437774756923318 score: 1.0
2021-08-08 04:02:14,338 | train | INFO | Epoch 4 train batch 98/450: 1568/7200 mean loss: 0.0015421062707901 score: 1.0
2021-08-08 04:02:15,148 | train | INFO | Epoch 4 train batch 99/450: 1584/7200 mean loss: 0.001677312538959086 score: 1.0
2021-08-08 04:02:15,928 | train | INFO | Epoch 4 train batch 100/450: 1600/7200 mean loss: 0.0015374632785096765 score: 0.9963235294117647
2021-08-08 04:02:16,728 | train | INFO | Epoch 4 train batch 101/450: 1616/7200 mean loss: 0.0014681253815069795 score: 1.0
2021-08-08 04:02:17,530 | train | INFO | Epoch 4 train batch 102/450: 1632/7200 mean loss: 0.001565549406222999 score: 1.0
2021-08-08 04:02:18,310 | train | INFO | Epoch 4 train batch 103/450: 1648/7200 mean loss: 0.0015920567093417048 score: 1.0
2021-08-08 04:02:19,088 | train | INFO | Epoch 4 train batch 104/450: 1664/7200 mean loss: 0.0016311568906530738 score: 1.0
2021-08-08 04:02:19,890 | train | INFO | Epoch 4 train batch 105/450: 1680/7200 mean loss: 0.0014832072192803025 score: 1.0
2021-08-08 04:02:20,683 | train | INFO | Epoch 4 train batch 106/450: 1696/7200 mean loss: 0.0014384613605216146 score: 0.9963235294117647
2021-08-08 04:02:21,502 | train | INFO | Epoch 4 train batch 107/450: 1712/7200 mean loss: 0.001546473242342472 score: 1.0
2021-08-08 04:02:22,288 | train | INFO | Epoch 4 train batch 108/450: 1728/7200 mean loss: 0.0017543723806738853 score: 1.0
2021-08-08 04:02:23,075 | train | INFO | Epoch 4 train batch 109/450: 1744/7200 mean loss: 0.0016031286213546991 score: 1.0
2021-08-08 04:02:23,928 | train | INFO | Epoch 4 train batch 110/450: 1760/7200 mean loss: 0.0017576602986082435 score: 0.996078431372549
2021-08-08 04:02:24,763 | train | INFO | Epoch 4 train batch 111/450: 1776/7200 mean loss: 0.0017323828069493175 score: 1.0
2021-08-08 04:02:25,568 | train | INFO | Epoch 4 train batch 112/450: 1792/7200 mean loss: 0.0016554230824112892 score: 1.0
2021-08-08 04:02:26,342 | train | INFO | Epoch 4 train batch 113/450: 1808/7200 mean loss: 0.0016584775876253843 score: 1.0
2021-08-08 04:02:27,148 | train | INFO | Epoch 4 train batch 114/450: 1824/7200 mean loss: 0.0015187810640782118 score: 1.0
2021-08-08 04:02:27,931 | train | INFO | Epoch 4 train batch 115/450: 1840/7200 mean loss: 0.0014127051690593362 score: 0.9632352941176471
2021-08-08 04:02:28,695 | train | INFO | Epoch 4 train batch 116/450: 1856/7200 mean loss: 0.0016442942433059216 score: 1.0
2021-08-08 04:02:29,470 | train | INFO | Epoch 4 train batch 117/450: 1872/7200 mean loss: 0.0018224167870357633 score: 1.0
2021-08-08 04:02:30,269 | train | INFO | Epoch 4 train batch 118/450: 1888/7200 mean loss: 0.0016471007838845253 score: 0.9129901960784315
2021-08-08 04:02:31,041 | train | INFO | Epoch 4 train batch 119/450: 1904/7200 mean loss: 0.001536392723210156 score: 1.0
2021-08-08 04:02:31,871 | train | INFO | Epoch 4 train batch 120/450: 1920/7200 mean loss: 0.0014932669000700116 score: 1.0
2021-08-08 04:02:32,667 | train | INFO | Epoch 4 train batch 121/450: 1936/7200 mean loss: 0.0016208484303206205 score: 0.9924019607843138
2021-08-08 04:02:33,463 | train | INFO | Epoch 4 train batch 122/450: 1952/7200 mean loss: 0.0015905937179923058 score: 1.0
2021-08-08 04:02:34,269 | train | INFO | Epoch 4 train batch 123/450: 1968/7200 mean loss: 0.0017915911739692092 score: 1.0
2021-08-08 04:02:35,074 | train | INFO | Epoch 4 train batch 124/450: 1984/7200 mean loss: 0.0016267418395727873 score: 1.0
2021-08-08 04:02:35,880 | train | INFO | Epoch 4 train batch 125/450: 2000/7200 mean loss: 0.0017307681264355779 score: 1.0
2021-08-08 04:02:36,679 | train | INFO | Epoch 4 train batch 126/450: 2016/7200 mean loss: 0.001581836026161909 score: 0.9963235294117647
2021-08-08 04:02:37,503 | train | INFO | Epoch 4 train batch 127/450: 2032/7200 mean loss: 0.00155358063057065 score: 1.0
2021-08-08 04:02:38,307 | train | INFO | Epoch 4 train batch 128/450: 2048/7200 mean loss: 0.0017781318165361881 score: 0.9963235294117647
2021-08-08 04:02:39,091 | train | INFO | Epoch 4 train batch 129/450: 2064/7200 mean loss: 0.0016554546309635043 score: 1.0
2021-08-08 04:02:39,877 | train | INFO | Epoch 4 train batch 130/450: 2080/7200 mean loss: 0.0015337335644289851 score: 1.0
2021-08-08 04:02:40,657 | train | INFO | Epoch 4 train batch 131/450: 2096/7200 mean loss: 0.0016888856189325452 score: 0.9848039215686275
2021-08-08 04:02:41,443 | train | INFO | Epoch 4 train batch 132/450: 2112/7200 mean loss: 0.001675206352956593 score: 0.9921218487394957
2021-08-08 04:02:42,242 | train | INFO | Epoch 4 train batch 133/450: 2128/7200 mean loss: 0.001489840797148645 score: 1.0
2021-08-08 04:02:43,040 | train | INFO | Epoch 4 train batch 134/450: 2144/7200 mean loss: 0.0015993796987459064 score: 1.0
2021-08-08 04:02:43,842 | train | INFO | Epoch 4 train batch 135/450: 2160/7200 mean loss: 0.0015456206165254116 score: 1.0
2021-08-08 04:02:44,623 | train | INFO | Epoch 4 train batch 136/450: 2176/7200 mean loss: 0.0015567730879411101 score: 1.0
2021-08-08 04:02:45,399 | train | INFO | Epoch 4 train batch 137/450: 2192/7200 mean loss: 0.0015841751592233777 score: 0.8797619047619049
2021-08-08 04:02:46,184 | train | INFO | Epoch 4 train batch 138/450: 2208/7200 mean loss: 0.0016442439518868923 score: 1.0
2021-08-08 04:02:46,996 | train | INFO | Epoch 4 train batch 139/450: 2224/7200 mean loss: 0.001514334580861032 score: 1.0
2021-08-08 04:02:47,890 | train | INFO | Epoch 4 train batch 140/450: 2240/7200 mean loss: 0.0015764638083055615 score: 1.0
2021-08-08 04:02:48,687 | train | INFO | Epoch 4 train batch 141/450: 2256/7200 mean loss: 0.0015380262630060315 score: 1.0
2021-08-08 04:02:49,512 | train | INFO | Epoch 4 train batch 142/450: 2272/7200 mean loss: 0.0016470544505864382 score: 0.9926470588235294
2021-08-08 04:02:50,317 | train | INFO | Epoch 4 train batch 143/450: 2288/7200 mean loss: 0.001623364514671266 score: 0.9779411764705882
2021-08-08 04:02:51,097 | train | INFO | Epoch 4 train batch 144/450: 2304/7200 mean loss: 0.0017057332443073392 score: 1.0
2021-08-08 04:02:51,912 | train | INFO | Epoch 4 train batch 145/450: 2320/7200 mean loss: 0.0015199582558125257 score: 1.0
2021-08-08 04:02:52,716 | train | INFO | Epoch 4 train batch 146/450: 2336/7200 mean loss: 0.0016663476126268506 score: 1.0
2021-08-08 04:02:53,522 | train | INFO | Epoch 4 train batch 147/450: 2352/7200 mean loss: 0.0014915787614881992 score: 1.0
2021-08-08 04:02:54,301 | train | INFO | Epoch 4 train batch 148/450: 2368/7200 mean loss: 0.0016348481876775622 score: 1.0
2021-08-08 04:02:55,105 | train | INFO | Epoch 4 train batch 149/450: 2384/7200 mean loss: 0.00163617345970124 score: 0.9909502262443439
2021-08-08 04:02:55,902 | train | INFO | Epoch 4 train batch 150/450: 2400/7200 mean loss: 0.0015913526294752955 score: 0.9963235294117647
2021-08-08 04:02:56,679 | train | INFO | Epoch 4 train batch 151/450: 2416/7200 mean loss: 0.0015899954596534371 score: 1.0
2021-08-08 04:02:57,477 | train | INFO | Epoch 4 train batch 152/450: 2432/7200 mean loss: 0.0016833475092425942 score: 0.996078431372549
2021-08-08 04:02:58,266 | train | INFO | Epoch 4 train batch 153/450: 2448/7200 mean loss: 0.0017057297518476844 score: 1.0
2021-08-08 04:02:59,092 | train | INFO | Epoch 4 train batch 154/450: 2464/7200 mean loss: 0.0017908643931150436 score: 0.6775210084033613
2021-08-08 04:02:59,893 | train | INFO | Epoch 4 train batch 155/450: 2480/7200 mean loss: 0.0016913671279326081 score: 0.9321078431372549
2021-08-08 04:03:00,675 | train | INFO | Epoch 4 train batch 156/450: 2496/7200 mean loss: 0.0016584341647103429 score: 1.0
2021-08-08 04:03:01,479 | train | INFO | Epoch 4 train batch 157/450: 2512/7200 mean loss: 0.0015548382652923465 score: 1.0
2021-08-08 04:03:02,266 | train | INFO | Epoch 4 train batch 158/450: 2528/7200 mean loss: 0.0017816416220739484 score: 1.0
2021-08-08 04:03:03,093 | train | INFO | Epoch 4 train batch 159/450: 2544/7200 mean loss: 0.0015365410363301635 score: 1.0
2021-08-08 04:03:03,958 | train | INFO | Epoch 4 train batch 160/450: 2560/7200 mean loss: 0.0015879786806181073 score: 1.0
2021-08-08 04:03:04,782 | train | INFO | Epoch 4 train batch 161/450: 2576/7200 mean loss: 0.0016601983224973083 score: 1.0
2021-08-08 04:03:05,571 | train | INFO | Epoch 4 train batch 162/450: 2592/7200 mean loss: 0.0016953458543866873 score: 1.0
2021-08-08 04:03:06,386 | train | INFO | Epoch 4 train batch 163/450: 2608/7200 mean loss: 0.0017514163628220558 score: 1.0
2021-08-08 04:03:07,176 | train | INFO | Epoch 4 train batch 164/450: 2624/7200 mean loss: 0.00158496608491987 score: 1.0
2021-08-08 04:03:07,973 | train | INFO | Epoch 4 train batch 165/450: 2640/7200 mean loss: 0.001706389244645834 score: 1.0
2021-08-08 04:03:08,766 | train | INFO | Epoch 4 train batch 166/450: 2656/7200 mean loss: 0.0016110317083075643 score: 1.0
2021-08-08 04:03:09,581 | train | INFO | Epoch 4 train batch 167/450: 2672/7200 mean loss: 0.0016953888116404414 score: 1.0
2021-08-08 04:03:10,387 | train | INFO | Epoch 4 train batch 168/450: 2688/7200 mean loss: 0.0016583941178396344 score: 1.0
2021-08-08 04:03:11,190 | train | INFO | Epoch 4 train batch 169/450: 2704/7200 mean loss: 0.0014413270400837064 score: 1.0
2021-08-08 04:03:11,970 | train | INFO | Epoch 4 train batch 170/450: 2720/7200 mean loss: 0.0016162539832293987 score: 0.9963235294117647
2021-08-08 04:03:12,790 | train | INFO | Epoch 4 train batch 171/450: 2736/7200 mean loss: 0.0015949144726619124 score: 1.0
2021-08-08 04:03:13,600 | train | INFO | Epoch 4 train batch 172/450: 2752/7200 mean loss: 0.0015988022787496448 score: 0.9963235294117647
2021-08-08 04:03:14,372 | train | INFO | Epoch 4 train batch 173/450: 2768/7200 mean loss: 0.0016114573227241635 score: 1.0
2021-08-08 04:03:15,189 | train | INFO | Epoch 4 train batch 174/450: 2784/7200 mean loss: 0.0015294692711904645 score: 1.0
2021-08-08 04:03:16,005 | train | INFO | Epoch 4 train batch 175/450: 2800/7200 mean loss: 0.0016607155557721853 score: 0.9926470588235294
2021-08-08 04:03:16,784 | train | INFO | Epoch 4 train batch 176/450: 2816/7200 mean loss: 0.0016228199237957597 score: 1.0
2021-08-08 04:03:17,559 | train | INFO | Epoch 4 train batch 177/450: 2832/7200 mean loss: 0.0016870967810973525 score: 1.0
2021-08-08 04:03:18,363 | train | INFO | Epoch 4 train batch 178/450: 2848/7200 mean loss: 0.001603474491275847 score: 0.9963235294117647
2021-08-08 04:03:19,154 | train | INFO | Epoch 4 train batch 179/450: 2864/7200 mean loss: 0.0016801821766421199 score: 0.9926470588235294
2021-08-08 04:03:19,955 | train | INFO | Epoch 4 train batch 180/450: 2880/7200 mean loss: 0.0015287561109289527 score: 1.0
2021-08-08 04:03:20,742 | train | INFO | Epoch 4 train batch 181/450: 2896/7200 mean loss: 0.0015251256991177797 score: 1.0
2021-08-08 04:03:21,523 | train | INFO | Epoch 4 train batch 182/450: 2912/7200 mean loss: 0.001674665487371385 score: 1.0
2021-08-08 04:03:22,301 | train | INFO | Epoch 4 train batch 183/450: 2928/7200 mean loss: 0.0014848619466647506 score: 0.9924019607843138
2021-08-08 04:03:23,078 | train | INFO | Epoch 4 train batch 184/450: 2944/7200 mean loss: 0.001603551208972931 score: 1.0
2021-08-08 04:03:23,861 | train | INFO | Epoch 4 train batch 185/450: 2960/7200 mean loss: 0.0016441142652183771 score: 1.0
2021-08-08 04:03:24,694 | train | INFO | Epoch 4 train batch 186/450: 2976/7200 mean loss: 0.0014389018760994077 score: 1.0
2021-08-08 04:03:25,480 | train | INFO | Epoch 4 train batch 187/450: 2992/7200 mean loss: 0.0016488401452079415 score: 1.0
2021-08-08 04:03:26,252 | train | INFO | Epoch 4 train batch 188/450: 3008/7200 mean loss: 0.0015798765234649181 score: 1.0
2021-08-08 04:03:27,027 | train | INFO | Epoch 4 train batch 189/450: 3024/7200 mean loss: 0.0017345838714390993 score: 1.0
2021-08-08 04:03:27,796 | train | INFO | Epoch 4 train batch 190/450: 3040/7200 mean loss: 0.0017211380181834102 score: 1.0
2021-08-08 04:03:28,566 | train | INFO | Epoch 4 train batch 191/450: 3056/7200 mean loss: 0.0016598872607573867 score: 1.0
2021-08-08 04:03:29,379 | train | INFO | Epoch 4 train batch 192/450: 3072/7200 mean loss: 0.001418532570824027 score: 1.0
2021-08-08 04:03:30,149 | train | INFO | Epoch 4 train batch 193/450: 3088/7200 mean loss: 0.0016355508705601096 score: 1.0
2021-08-08 04:03:30,916 | train | INFO | Epoch 4 train batch 194/450: 3104/7200 mean loss: 0.0015312795294448733 score: 1.0
2021-08-08 04:03:31,698 | train | INFO | Epoch 4 train batch 195/450: 3120/7200 mean loss: 0.0017339333426207304 score: 1.0
2021-08-08 04:03:32,504 | train | INFO | Epoch 4 train batch 196/450: 3136/7200 mean loss: 0.001454717363230884 score: 1.0
2021-08-08 04:03:33,283 | train | INFO | Epoch 4 train batch 197/450: 3152/7200 mean loss: 0.0014396571787074208 score: 1.0
2021-08-08 04:03:34,090 | train | INFO | Epoch 4 train batch 198/450: 3168/7200 mean loss: 0.0015043801395222545 score: 1.0
2021-08-08 04:03:34,880 | train | INFO | Epoch 4 train batch 199/450: 3184/7200 mean loss: 0.0016979299252852798 score: 0.996078431372549
2021-08-08 04:03:35,648 | train | INFO | Epoch 4 train batch 200/450: 3200/7200 mean loss: 0.001563285943120718 score: 0.9963235294117647
2021-08-08 04:03:36,440 | train | INFO | Epoch 4 train batch 201/450: 3216/7200 mean loss: 0.001865105819888413 score: 1.0
2021-08-08 04:03:37,249 | train | INFO | Epoch 4 train batch 202/450: 3232/7200 mean loss: 0.0015911421505734324 score: 1.0
2021-08-08 04:03:38,034 | train | INFO | Epoch 4 train batch 203/450: 3248/7200 mean loss: 0.0015564585337415338 score: 1.0
2021-08-08 04:03:38,962 | train | INFO | Epoch 4 train batch 204/450: 3264/7200 mean loss: 0.0015578081365674734 score: 1.0
2021-08-08 04:03:39,866 | train | INFO | Epoch 4 train batch 205/450: 3280/7200 mean loss: 0.0016530028078705072 score: 1.0
2021-08-08 04:03:40,676 | train | INFO | Epoch 4 train batch 206/450: 3296/7200 mean loss: 0.0015660207718610764 score: 0.9816176470588235
2021-08-08 04:03:41,452 | train | INFO | Epoch 4 train batch 207/450: 3312/7200 mean loss: 0.0017167733749374747 score: 0.9926470588235294
2021-08-08 04:03:42,268 | train | INFO | Epoch 4 train batch 208/450: 3328/7200 mean loss: 0.0015464170137420297 score: 1.0
2021-08-08 04:03:43,039 | train | INFO | Epoch 4 train batch 209/450: 3344/7200 mean loss: 0.0017175476532429457 score: 1.0
2021-08-08 04:03:43,846 | train | INFO | Epoch 4 train batch 210/450: 3360/7200 mean loss: 0.0015195492887869477 score: 1.0
2021-08-08 04:03:44,615 | train | INFO | Epoch 4 train batch 211/450: 3376/7200 mean loss: 0.0016797580756247044 score: 0.9816176470588235
2021-08-08 04:03:45,415 | train | INFO | Epoch 4 train batch 212/450: 3392/7200 mean loss: 0.001745904446579516 score: 0.9663865546218486
2021-08-08 04:03:46,187 | train | INFO | Epoch 4 train batch 213/450: 3408/7200 mean loss: 0.0014390063006430864 score: 1.0
2021-08-08 04:03:46,995 | train | INFO | Epoch 4 train batch 214/450: 3424/7200 mean loss: 0.0014888709411025047 score: 1.0
2021-08-08 04:03:47,794 | train | INFO | Epoch 4 train batch 215/450: 3440/7200 mean loss: 0.0017202964518219233 score: 1.0
2021-08-08 04:03:48,585 | train | INFO | Epoch 4 train batch 216/450: 3456/7200 mean loss: 0.0016928062541410327 score: 0.8199929971988796
2021-08-08 04:03:49,460 | train | INFO | Epoch 4 train batch 217/450: 3472/7200 mean loss: 0.0017093131318688393 score: 0.9887254901960785
2021-08-08 04:03:50,253 | train | INFO | Epoch 4 train batch 218/450: 3488/7200 mean loss: 0.0016540240030735731 score: 1.0
2021-08-08 04:03:51,065 | train | INFO | Epoch 4 train batch 219/450: 3504/7200 mean loss: 0.0016827714862301946 score: 1.0
2021-08-08 04:03:51,890 | train | INFO | Epoch 4 train batch 220/450: 3520/7200 mean loss: 0.0016411804826930165 score: 1.0
2021-08-08 04:03:52,669 | train | INFO | Epoch 4 train batch 221/450: 3536/7200 mean loss: 0.0018248440464958549 score: 1.0
2021-08-08 04:03:53,455 | train | INFO | Epoch 4 train batch 222/450: 3552/7200 mean loss: 0.001545999781228602 score: 1.0
2021-08-08 04:03:54,221 | train | INFO | Epoch 4 train batch 223/450: 3568/7200 mean loss: 0.0014908575685694814 score: 1.0
2021-08-08 04:03:55,034 | train | INFO | Epoch 4 train batch 224/450: 3584/7200 mean loss: 0.0016716906102374196 score: 1.0
2021-08-08 04:03:55,822 | train | INFO | Epoch 4 train batch 225/450: 3600/7200 mean loss: 0.0016868020175024867 score: 1.0
2021-08-08 04:03:56,614 | train | INFO | Epoch 4 train batch 226/450: 3616/7200 mean loss: 0.0016370606608688831 score: 1.0
2021-08-08 04:03:57,400 | train | INFO | Epoch 4 train batch 227/450: 3632/7200 mean loss: 0.0016447934322059155 score: 1.0
2021-08-08 04:03:58,182 | train | INFO | Epoch 4 train batch 228/450: 3648/7200 mean loss: 0.0016529319109395146 score: 1.0
2021-08-08 04:03:58,961 | train | INFO | Epoch 4 train batch 229/450: 3664/7200 mean loss: 0.0017026414861902595 score: 1.0
2021-08-08 04:03:59,736 | train | INFO | Epoch 4 train batch 230/450: 3680/7200 mean loss: 0.0015388868050649762 score: 1.0
2021-08-08 04:04:00,549 | train | INFO | Epoch 4 train batch 231/450: 3696/7200 mean loss: 0.001593295601196587 score: 1.0
2021-08-08 04:04:01,323 | train | INFO | Epoch 4 train batch 232/450: 3712/7200 mean loss: 0.0014761603670194745 score: 1.0
2021-08-08 04:04:02,114 | train | INFO | Epoch 4 train batch 233/450: 3728/7200 mean loss: 0.001664792071096599 score: 0.9887254901960785
2021-08-08 04:04:02,897 | train | INFO | Epoch 4 train batch 234/450: 3744/7200 mean loss: 0.0015285070985555649 score: 0.9926470588235294
2021-08-08 04:04:03,676 | train | INFO | Epoch 4 train batch 235/450: 3760/7200 mean loss: 0.0014705461217090487 score: 1.0
2021-08-08 04:04:04,451 | train | INFO | Epoch 4 train batch 236/450: 3776/7200 mean loss: 0.0013287003384903073 score: 1.0
2021-08-08 04:04:05,264 | train | INFO | Epoch 4 train batch 237/450: 3792/7200 mean loss: 0.0014203719329088926 score: 1.0
2021-08-08 04:04:06,061 | train | INFO | Epoch 4 train batch 238/450: 3808/7200 mean loss: 0.0014690010575577617 score: 0.9926470588235294
2021-08-08 04:04:06,858 | train | INFO | Epoch 4 train batch 239/450: 3824/7200 mean loss: 0.0016137866768985987 score: 0.9963235294117647
2021-08-08 04:04:07,674 | train | INFO | Epoch 4 train batch 240/450: 3840/7200 mean loss: 0.0016551745356991887 score: 1.0
2021-08-08 04:04:08,459 | train | INFO | Epoch 4 train batch 241/450: 3856/7200 mean loss: 0.0015342873521149158 score: 1.0
2021-08-08 04:04:09,325 | train | INFO | Epoch 4 train batch 242/450: 3872/7200 mean loss: 0.0014894470805302262 score: 0.9963235294117647
2021-08-08 04:04:10,118 | train | INFO | Epoch 4 train batch 243/450: 3888/7200 mean loss: 0.0016414215788245201 score: 1.0
2021-08-08 04:04:10,922 | train | INFO | Epoch 4 train batch 244/450: 3904/7200 mean loss: 0.0016889170510694385 score: 1.0
2021-08-08 04:04:11,701 | train | INFO | Epoch 4 train batch 245/450: 3920/7200 mean loss: 0.0014657696010544896 score: 1.0
2021-08-08 04:04:12,511 | train | INFO | Epoch 4 train batch 246/450: 3936/7200 mean loss: 0.0016298192786052823 score: 0.9882002801120447
2021-08-08 04:04:13,287 | train | INFO | Epoch 4 train batch 247/450: 3952/7200 mean loss: 0.0016223568236455321 score: 1.0
2021-08-08 04:04:14,062 | train | INFO | Epoch 4 train batch 248/450: 3968/7200 mean loss: 0.0015713159227743745 score: 0.9734162895927602
2021-08-08 04:04:14,837 | train | INFO | Epoch 4 train batch 249/450: 3984/7200 mean loss: 0.001453230855986476 score: 1.0
2021-08-08 04:04:15,622 | train | INFO | Epoch 4 train batch 250/450: 4000/7200 mean loss: 0.0015180312329903245 score: 0.9963235294117647
2021-08-08 04:04:16,426 | train | INFO | Epoch 4 train batch 251/450: 4016/7200 mean loss: 0.001680933521129191 score: 1.0
2021-08-08 04:04:17,233 | train | INFO | Epoch 4 train batch 252/450: 4032/7200 mean loss: 0.001595742884092033 score: 0.9742647058823529
2021-08-08 04:04:18,025 | train | INFO | Epoch 4 train batch 253/450: 4048/7200 mean loss: 0.0015646375250071287 score: 1.0
2021-08-08 04:04:18,819 | train | INFO | Epoch 4 train batch 254/450: 4064/7200 mean loss: 0.0015887311892583966 score: 1.0
2021-08-08 04:04:19,627 | train | INFO | Epoch 4 train batch 255/450: 4080/7200 mean loss: 0.0016814445843920112 score: 1.0
2021-08-08 04:04:20,412 | train | INFO | Epoch 4 train batch 256/450: 4096/7200 mean loss: 0.001654192223213613 score: 1.0
2021-08-08 04:04:21,220 | train | INFO | Epoch 4 train batch 257/450: 4112/7200 mean loss: 0.0014817669289186597 score: 1.0
2021-08-08 04:04:22,019 | train | INFO | Epoch 4 train batch 258/450: 4128/7200 mean loss: 0.0014997238758951426 score: 1.0
2021-08-08 04:04:22,799 | train | INFO | Epoch 4 train batch 259/450: 4144/7200 mean loss: 0.001406563911587 score: 1.0
2021-08-08 04:04:23,577 | train | INFO | Epoch 4 train batch 260/450: 4160/7200 mean loss: 0.001696201041340828 score: 1.0
2021-08-08 04:04:24,353 | train | INFO | Epoch 4 train batch 261/450: 4176/7200 mean loss: 0.0016931479331105947 score: 1.0
2021-08-08 04:04:25,123 | train | INFO | Epoch 4 train batch 262/450: 4192/7200 mean loss: 0.0015954832779243588 score: 1.0
2021-08-08 04:04:25,924 | train | INFO | Epoch 4 train batch 263/450: 4208/7200 mean loss: 0.0015998048475012183 score: 0.9406512605042017
2021-08-08 04:04:26,699 | train | INFO | Epoch 4 train batch 264/450: 4224/7200 mean loss: 0.001554829184897244 score: 1.0
2021-08-08 04:04:27,498 | train | INFO | Epoch 4 train batch 265/450: 4240/7200 mean loss: 0.0015403233701363206 score: 1.0
2021-08-08 04:04:28,292 | train | INFO | Epoch 4 train batch 266/450: 4256/7200 mean loss: 0.0014572145882993937 score: 0.9926470588235294
2021-08-08 04:04:29,065 | train | INFO | Epoch 4 train batch 267/450: 4272/7200 mean loss: 0.0015671844594180584 score: 0.9889705882352942
2021-08-08 04:04:29,850 | train | INFO | Epoch 4 train batch 268/450: 4288/7200 mean loss: 0.0015790751203894615 score: 1.0
2021-08-08 04:04:30,651 | train | INFO | Epoch 4 train batch 269/450: 4304/7200 mean loss: 0.0017354622250422835 score: 1.0
2021-08-08 04:04:31,463 | train | INFO | Epoch 4 train batch 270/450: 4320/7200 mean loss: 0.001594529370777309 score: 1.0
2021-08-08 04:04:32,245 | train | INFO | Epoch 4 train batch 271/450: 4336/7200 mean loss: 0.0017155626555904746 score: 1.0
2021-08-08 04:04:33,057 | train | INFO | Epoch 4 train batch 272/450: 4352/7200 mean loss: 0.0018014343222603202 score: 0.9963235294117647
2021-08-08 04:04:33,888 | train | INFO | Epoch 4 train batch 273/450: 4368/7200 mean loss: 0.0017584525048732758 score: 1.0
2021-08-08 04:04:34,663 | train | INFO | Epoch 4 train batch 274/450: 4384/7200 mean loss: 0.001644497155211866 score: 1.0
2021-08-08 04:04:35,436 | train | INFO | Epoch 4 train batch 275/450: 4400/7200 mean loss: 0.0017002527602016926 score: 1.0
2021-08-08 04:04:36,232 | train | INFO | Epoch 4 train batch 276/450: 4416/7200 mean loss: 0.0015582072082906961 score: 1.0
2021-08-08 04:04:37,028 | train | INFO | Epoch 4 train batch 277/450: 4432/7200 mean loss: 0.0015518547734245658 score: 1.0
2021-08-08 04:04:37,831 | train | INFO | Epoch 4 train batch 278/450: 4448/7200 mean loss: 0.001569434185512364 score: 1.0
2021-08-08 04:04:38,632 | train | INFO | Epoch 4 train batch 279/450: 4464/7200 mean loss: 0.0014166190521791577 score: 1.0
2021-08-08 04:04:39,444 | train | INFO | Epoch 4 train batch 280/450: 4480/7200 mean loss: 0.0015459107235074043 score: 1.0
2021-08-08 04:04:40,222 | train | INFO | Epoch 4 train batch 281/450: 4496/7200 mean loss: 0.0016128988936543465 score: 0.9963235294117647
2021-08-08 04:04:41,021 | train | INFO | Epoch 4 train batch 282/450: 4512/7200 mean loss: 0.0016714819939807057 score: 1.0
2021-08-08 04:04:41,801 | train | INFO | Epoch 4 train batch 283/450: 4528/7200 mean loss: 0.0016015018336474895 score: 1.0
2021-08-08 04:04:42,620 | train | INFO | Epoch 4 train batch 284/450: 4544/7200 mean loss: 0.0017203871393576264 score: 1.0
2021-08-08 04:04:43,428 | train | INFO | Epoch 4 train batch 285/450: 4560/7200 mean loss: 0.0015536501305177808 score: 1.0
2021-08-08 04:04:44,232 | train | INFO | Epoch 4 train batch 286/450: 4576/7200 mean loss: 0.0016633500345051289 score: 0.996078431372549
2021-08-08 04:04:45,012 | train | INFO | Epoch 4 train batch 287/450: 4592/7200 mean loss: 0.0017267200164496899 score: 1.0
2021-08-08 04:04:45,784 | train | INFO | Epoch 4 train batch 288/450: 4608/7200 mean loss: 0.0016436714213341475 score: 1.0
2021-08-08 04:04:46,560 | train | INFO | Epoch 4 train batch 289/450: 4624/7200 mean loss: 0.0016918248729780316 score: 1.0
2021-08-08 04:04:47,367 | train | INFO | Epoch 4 train batch 290/450: 4640/7200 mean loss: 0.0015498863067477942 score: 0.9924019607843138
2021-08-08 04:04:48,195 | train | INFO | Epoch 4 train batch 291/450: 4656/7200 mean loss: 0.0016571651212871075 score: 0.9963235294117647
2021-08-08 04:04:48,969 | train | INFO | Epoch 4 train batch 292/450: 4672/7200 mean loss: 0.0016821494791656733 score: 1.0
2021-08-08 04:04:49,812 | train | INFO | Epoch 4 train batch 293/450: 4688/7200 mean loss: 0.0017179632559418678 score: 0.9693627450980393
2021-08-08 04:04:50,585 | train | INFO | Epoch 4 train batch 294/450: 4704/7200 mean loss: 0.0014751419657841325 score: 1.0
2021-08-08 04:04:51,359 | train | INFO | Epoch 4 train batch 295/450: 4720/7200 mean loss: 0.0016901333583518863 score: 1.0
2021-08-08 04:04:52,131 | train | INFO | Epoch 4 train batch 296/450: 4736/7200 mean loss: 0.001558204647153616 score: 1.0
2021-08-08 04:04:52,930 | train | INFO | Epoch 4 train batch 297/450: 4752/7200 mean loss: 0.0014981536660343409 score: 1.0
2021-08-08 04:04:53,765 | train | INFO | Epoch 4 train batch 298/450: 4768/7200 mean loss: 0.0014600408030673862 score: 1.0
2021-08-08 04:04:54,539 | train | INFO | Epoch 4 train batch 299/450: 4784/7200 mean loss: 0.0015087516512721777 score: 1.0
2021-08-08 04:04:55,304 | train | INFO | Epoch 4 train batch 300/450: 4800/7200 mean loss: 0.0015487979399040341 score: 1.0
2021-08-08 04:04:56,072 | train | INFO | Epoch 4 train batch 301/450: 4816/7200 mean loss: 0.0016344754258170724 score: 0.995475113122172
2021-08-08 04:04:56,990 | train | INFO | Epoch 4 train batch 302/450: 4832/7200 mean loss: 0.0015690887812525034 score: 1.0
2021-08-08 04:04:57,794 | train | INFO | Epoch 4 train batch 303/450: 4848/7200 mean loss: 0.001564422040246427 score: 1.0
2021-08-08 04:04:58,561 | train | INFO | Epoch 4 train batch 304/450: 4864/7200 mean loss: 0.0016160063678398728 score: 1.0
2021-08-08 04:04:59,347 | train | INFO | Epoch 4 train batch 305/450: 4880/7200 mean loss: 0.0015490559162572026 score: 1.0
2021-08-08 04:05:00,126 | train | INFO | Epoch 4 train batch 306/450: 4896/7200 mean loss: 0.0017113591311499476 score: 1.0
2021-08-08 04:05:00,924 | train | INFO | Epoch 4 train batch 307/450: 4912/7200 mean loss: 0.0015379951801151037 score: 1.0
2021-08-08 04:05:01,727 | train | INFO | Epoch 4 train batch 308/450: 4928/7200 mean loss: 0.0017629944486543536 score: 0.9813725490196079
2021-08-08 04:05:02,603 | train | INFO | Epoch 4 train batch 309/450: 4944/7200 mean loss: 0.001619648770429194 score: 1.0
2021-08-08 04:05:03,485 | train | INFO | Epoch 4 train batch 310/450: 4960/7200 mean loss: 0.0016025048680603504 score: 1.0
2021-08-08 04:05:04,268 | train | INFO | Epoch 4 train batch 311/450: 4976/7200 mean loss: 0.0017017496284097433 score: 1.0
2021-08-08 04:05:05,055 | train | INFO | Epoch 4 train batch 312/450: 4992/7200 mean loss: 0.001566920429468155 score: 0.9882002801120447
2021-08-08 04:05:05,843 | train | INFO | Epoch 4 train batch 313/450: 5008/7200 mean loss: 0.001497649704106152 score: 1.0
2021-08-08 04:05:06,615 | train | INFO | Epoch 4 train batch 314/450: 5024/7200 mean loss: 0.0013981452211737633 score: 1.0
2021-08-08 04:05:07,437 | train | INFO | Epoch 4 train batch 315/450: 5040/7200 mean loss: 0.0017816061154007912 score: 0.9889705882352942
2021-08-08 04:05:08,238 | train | INFO | Epoch 4 train batch 316/450: 5056/7200 mean loss: 0.0014690327225252986 score: 1.0
2021-08-08 04:05:09,054 | train | INFO | Epoch 4 train batch 317/450: 5072/7200 mean loss: 0.0014549719635397196 score: 1.0
2021-08-08 04:05:09,823 | train | INFO | Epoch 4 train batch 318/450: 5088/7200 mean loss: 0.0016054093139246106 score: 1.0
2021-08-08 04:05:10,619 | train | INFO | Epoch 4 train batch 319/450: 5104/7200 mean loss: 0.0017938604578375816 score: 0.9963235294117647
2021-08-08 04:05:11,522 | train | INFO | Epoch 4 train batch 320/450: 5120/7200 mean loss: 0.0018643898656591773 score: 1.0
2021-08-08 04:05:12,334 | train | INFO | Epoch 4 train batch 321/450: 5136/7200 mean loss: 0.0017326035303995013 score: 0.9372549019607843
2021-08-08 04:05:13,120 | train | INFO | Epoch 4 train batch 322/450: 5152/7200 mean loss: 0.0018280784133821726 score: 1.0
2021-08-08 04:05:13,909 | train | INFO | Epoch 4 train batch 323/450: 5168/7200 mean loss: 0.0016388643998652697 score: 1.0
2021-08-08 04:05:14,678 | train | INFO | Epoch 4 train batch 324/450: 5184/7200 mean loss: 0.0016990115400403738 score: 1.0
2021-08-08 04:05:15,453 | train | INFO | Epoch 4 train batch 325/450: 5200/7200 mean loss: 0.0016606496647000313 score: 0.9740196078431372
2021-08-08 04:05:16,266 | train | INFO | Epoch 4 train batch 326/450: 5216/7200 mean loss: 0.0015857615508139133 score: 1.0
2021-08-08 04:05:17,094 | train | INFO | Epoch 4 train batch 327/450: 5232/7200 mean loss: 0.0015840852865949273 score: 0.9926470588235294
2021-08-08 04:05:17,893 | train | INFO | Epoch 4 train batch 328/450: 5248/7200 mean loss: 0.0016150998417288065 score: 1.0
2021-08-08 04:05:18,715 | train | INFO | Epoch 4 train batch 329/450: 5264/7200 mean loss: 0.0015021561412140727 score: 0.9963235294117647
2021-08-08 04:05:19,490 | train | INFO | Epoch 4 train batch 330/450: 5280/7200 mean loss: 0.001435962738469243 score: 0.9811274509803922
2021-08-08 04:05:20,266 | train | INFO | Epoch 4 train batch 331/450: 5296/7200 mean loss: 0.001521014841273427 score: 1.0
2021-08-08 04:05:21,068 | train | INFO | Epoch 4 train batch 332/450: 5312/7200 mean loss: 0.0015805379953235388 score: 1.0
2021-08-08 04:05:21,892 | train | INFO | Epoch 4 train batch 333/450: 5328/7200 mean loss: 0.001571136643178761 score: 1.0
2021-08-08 04:05:22,667 | train | INFO | Epoch 4 train batch 334/450: 5344/7200 mean loss: 0.0015108080115169287 score: 0.9417717086834735
2021-08-08 04:05:23,525 | train | INFO | Epoch 4 train batch 335/450: 5360/7200 mean loss: 0.0014974065124988556 score: 1.0
2021-08-08 04:05:24,315 | train | INFO | Epoch 4 train batch 336/450: 5376/7200 mean loss: 0.001541576930321753 score: 1.0
2021-08-08 04:05:25,097 | train | INFO | Epoch 4 train batch 337/450: 5392/7200 mean loss: 0.001555439317598939 score: 0.9926470588235294
2021-08-08 04:05:25,869 | train | INFO | Epoch 4 train batch 338/450: 5408/7200 mean loss: 0.0015525245107710361 score: 0.996078431372549
2021-08-08 04:05:26,678 | train | INFO | Epoch 4 train batch 339/450: 5424/7200 mean loss: 0.001416842802427709 score: 1.0
2021-08-08 04:05:27,474 | train | INFO | Epoch 4 train batch 340/450: 5440/7200 mean loss: 0.0016248981701210141 score: 1.0
2021-08-08 04:05:28,309 | train | INFO | Epoch 4 train batch 341/450: 5456/7200 mean loss: 0.0016019156901165843 score: 0.9632352941176471
2021-08-08 04:05:29,128 | train | INFO | Epoch 4 train batch 342/450: 5472/7200 mean loss: 0.0017369186971336603 score: 1.0
2021-08-08 04:05:29,926 | train | INFO | Epoch 4 train batch 343/450: 5488/7200 mean loss: 0.0016534762689843774 score: 1.0
2021-08-08 04:05:30,738 | train | INFO | Epoch 4 train batch 344/450: 5504/7200 mean loss: 0.001720594009384513 score: 1.0
2021-08-08 04:05:31,547 | train | INFO | Epoch 4 train batch 345/450: 5520/7200 mean loss: 0.0016276875976473093 score: 1.0
2021-08-08 04:05:32,334 | train | INFO | Epoch 4 train batch 346/450: 5536/7200 mean loss: 0.0015887225745245814 score: 0.9850490196078432
2021-08-08 04:05:33,138 | train | INFO | Epoch 4 train batch 347/450: 5552/7200 mean loss: 0.001790328649803996 score: 1.0
2021-08-08 04:05:33,950 | train | INFO | Epoch 4 train batch 348/450: 5568/7200 mean loss: 0.0016509615816175938 score: 1.0
2021-08-08 04:05:34,726 | train | INFO | Epoch 4 train batch 349/450: 5584/7200 mean loss: 0.0014750264817848802 score: 1.0
2021-08-08 04:05:35,520 | train | INFO | Epoch 4 train batch 350/450: 5600/7200 mean loss: 0.0015300556551665068 score: 0.996078431372549
2021-08-08 04:05:36,302 | train | INFO | Epoch 4 train batch 351/450: 5616/7200 mean loss: 0.001644354546442628 score: 0.9963235294117647
2021-08-08 04:05:37,104 | train | INFO | Epoch 4 train batch 352/450: 5632/7200 mean loss: 0.0015194922452792525 score: 1.0
2021-08-08 04:05:37,906 | train | INFO | Epoch 4 train batch 353/450: 5648/7200 mean loss: 0.0016543810488656163 score: 1.0
2021-08-08 04:05:38,686 | train | INFO | Epoch 4 train batch 354/450: 5664/7200 mean loss: 0.0014956343220546842 score: 0.9963235294117647
2021-08-08 04:05:39,488 | train | INFO | Epoch 4 train batch 355/450: 5680/7200 mean loss: 0.0017481158720329404 score: 1.0
2021-08-08 04:05:40,265 | train | INFO | Epoch 4 train batch 356/450: 5696/7200 mean loss: 0.0014441931853070855 score: 1.0
2021-08-08 04:05:41,068 | train | INFO | Epoch 4 train batch 357/450: 5712/7200 mean loss: 0.0014897153014317155 score: 0.996078431372549
2021-08-08 04:05:41,868 | train | INFO | Epoch 4 train batch 358/450: 5728/7200 mean loss: 0.0015475443797186017 score: 1.0
2021-08-08 04:05:42,644 | train | INFO | Epoch 4 train batch 359/450: 5744/7200 mean loss: 0.001700941356830299 score: 1.0
2021-08-08 04:05:43,474 | train | INFO | Epoch 4 train batch 360/450: 5760/7200 mean loss: 0.0016483374638482928 score: 1.0
2021-08-08 04:05:44,302 | train | INFO | Epoch 4 train batch 361/450: 5776/7200 mean loss: 0.0015546686481684446 score: 1.0
2021-08-08 04:05:45,091 | train | INFO | Epoch 4 train batch 362/450: 5792/7200 mean loss: 0.0015689575811848044 score: 0.9742647058823529
2021-08-08 04:05:45,858 | train | INFO | Epoch 4 train batch 363/450: 5808/7200 mean loss: 0.0015520836459472775 score: 1.0
2021-08-08 04:05:46,635 | train | INFO | Epoch 4 train batch 364/450: 5824/7200 mean loss: 0.0015610428526997566 score: 1.0
2021-08-08 04:05:47,427 | train | INFO | Epoch 4 train batch 365/450: 5840/7200 mean loss: 0.0017094548093155026 score: 1.0
2021-08-08 04:05:48,243 | train | INFO | Epoch 4 train batch 366/450: 5856/7200 mean loss: 0.0015588003443554044 score: 1.0
2021-08-08 04:05:49,027 | train | INFO | Epoch 4 train batch 367/450: 5872/7200 mean loss: 0.0015656984178349376 score: 0.9666666666666667
2021-08-08 04:05:49,805 | train | INFO | Epoch 4 train batch 368/450: 5888/7200 mean loss: 0.0015558116137981415 score: 0.8504901960784315
2021-08-08 04:05:50,663 | train | INFO | Epoch 4 train batch 369/450: 5904/7200 mean loss: 0.0016280009876936674 score: 0.996078431372549
2021-08-08 04:05:51,501 | train | INFO | Epoch 4 train batch 370/450: 5920/7200 mean loss: 0.0018326842691749334 score: 0.9223039215686275
2021-08-08 04:05:52,328 | train | INFO | Epoch 4 train batch 371/450: 5936/7200 mean loss: 0.0016252632485702634 score: 0.969607843137255
2021-08-08 04:05:53,097 | train | INFO | Epoch 4 train batch 372/450: 5952/7200 mean loss: 0.0014469650341197848 score: 1.0
2021-08-08 04:05:53,867 | train | INFO | Epoch 4 train batch 373/450: 5968/7200 mean loss: 0.0017399179050698876 score: 1.0
2021-08-08 04:05:54,641 | train | INFO | Epoch 4 train batch 374/450: 5984/7200 mean loss: 0.0016487379325553775 score: 0.996078431372549
2021-08-08 04:05:55,428 | train | INFO | Epoch 4 train batch 375/450: 6000/7200 mean loss: 0.0014918638626113534 score: 1.0
2021-08-08 04:05:56,199 | train | INFO | Epoch 4 train batch 376/450: 6016/7200 mean loss: 0.0015973416157066822 score: 0.9889705882352942
2021-08-08 04:05:56,996 | train | INFO | Epoch 4 train batch 377/450: 6032/7200 mean loss: 0.0016172557370737195 score: 0.9926470588235294
2021-08-08 04:05:57,814 | train | INFO | Epoch 4 train batch 378/450: 6048/7200 mean loss: 0.001545662758871913 score: 1.0
2021-08-08 04:05:58,583 | train | INFO | Epoch 4 train batch 379/450: 6064/7200 mean loss: 0.001501288847066462 score: 1.0
2021-08-08 04:05:59,383 | train | INFO | Epoch 4 train batch 380/450: 6080/7200 mean loss: 0.0015773895429447293 score: 1.0
2021-08-08 04:06:00,271 | train | INFO | Epoch 4 train batch 381/450: 6096/7200 mean loss: 0.0016193746123462915 score: 0.9409313725490196
2021-08-08 04:06:01,086 | train | INFO | Epoch 4 train batch 382/450: 6112/7200 mean loss: 0.001583995413966477 score: 1.0
2021-08-08 04:06:01,875 | train | INFO | Epoch 4 train batch 383/450: 6128/7200 mean loss: 0.0015468253986909986 score: 0.9768907563025211
2021-08-08 04:06:02,710 | train | INFO | Epoch 4 train batch 384/450: 6144/7200 mean loss: 0.001741251558996737 score: 1.0
2021-08-08 04:06:03,501 | train | INFO | Epoch 4 train batch 385/450: 6160/7200 mean loss: 0.0016363405156880617 score: 1.0
2021-08-08 04:06:04,280 | train | INFO | Epoch 4 train batch 386/450: 6176/7200 mean loss: 0.0017357587348669767 score: 1.0
2021-08-08 04:06:05,060 | train | INFO | Epoch 4 train batch 387/450: 6192/7200 mean loss: 0.001559394528158009 score: 1.0
2021-08-08 04:06:05,879 | train | INFO | Epoch 4 train batch 388/450: 6208/7200 mean loss: 0.0017132962821051478 score: 0.9842436974789917
2021-08-08 04:06:06,680 | train | INFO | Epoch 4 train batch 389/450: 6224/7200 mean loss: 0.0017264450434595346 score: 1.0
2021-08-08 04:06:07,476 | train | INFO | Epoch 4 train batch 390/450: 6240/7200 mean loss: 0.0013896950986236334 score: 1.0
2021-08-08 04:06:08,282 | train | INFO | Epoch 4 train batch 391/450: 6256/7200 mean loss: 0.0015455821994692087 score: 1.0
2021-08-08 04:06:09,099 | train | INFO | Epoch 4 train batch 392/450: 6272/7200 mean loss: 0.0016020333860069513 score: 1.0
2021-08-08 04:06:09,896 | train | INFO | Epoch 4 train batch 393/450: 6288/7200 mean loss: 0.0014783546794205904 score: 1.0
2021-08-08 04:06:10,682 | train | INFO | Epoch 4 train batch 394/450: 6304/7200 mean loss: 0.0014801243087276816 score: 0.996078431372549
2021-08-08 04:06:11,456 | train | INFO | Epoch 4 train batch 395/450: 6320/7200 mean loss: 0.001385933835990727 score: 1.0
2021-08-08 04:06:12,251 | train | INFO | Epoch 4 train batch 396/450: 6336/7200 mean loss: 0.001481459359638393 score: 0.9963235294117647
2021-08-08 04:06:13,074 | train | INFO | Epoch 4 train batch 397/450: 6352/7200 mean loss: 0.0015302819665521383 score: 1.0
2021-08-08 04:06:13,859 | train | INFO | Epoch 4 train batch 398/450: 6368/7200 mean loss: 0.0016313041560351849 score: 1.0
2021-08-08 04:06:14,657 | train | INFO | Epoch 4 train batch 399/450: 6384/7200 mean loss: 0.0016448202077299356 score: 1.0
2021-08-08 04:06:15,436 | train | INFO | Epoch 4 train batch 400/450: 6400/7200 mean loss: 0.0014604987809434533 score: 1.0
2021-08-08 04:06:16,213 | train | INFO | Epoch 4 train batch 401/450: 6416/7200 mean loss: 0.001516238902695477 score: 0.9926470588235294
2021-08-08 04:06:16,994 | train | INFO | Epoch 4 train batch 402/450: 6432/7200 mean loss: 0.0015541828470304608 score: 0.9963235294117647
2021-08-08 04:06:17,763 | train | INFO | Epoch 4 train batch 403/450: 6448/7200 mean loss: 0.0015241819201037288 score: 1.0
2021-08-08 04:06:18,573 | train | INFO | Epoch 4 train batch 404/450: 6464/7200 mean loss: 0.0016668376047164202 score: 0.9889705882352942
2021-08-08 04:06:19,351 | train | INFO | Epoch 4 train batch 405/450: 6480/7200 mean loss: 0.0015589345712214708 score: 0.9963235294117647
2021-08-08 04:06:20,154 | train | INFO | Epoch 4 train batch 406/450: 6496/7200 mean loss: 0.0016214651986956596 score: 1.0
2021-08-08 04:06:20,928 | train | INFO | Epoch 4 train batch 407/450: 6512/7200 mean loss: 0.0015980718890205026 score: 1.0
2021-08-08 04:06:21,823 | train | INFO | Epoch 4 train batch 408/450: 6528/7200 mean loss: 0.0014642785536125302 score: 1.0
2021-08-08 04:06:22,602 | train | INFO | Epoch 4 train batch 409/450: 6544/7200 mean loss: 0.001590962172485888 score: 1.0
2021-08-08 04:06:23,373 | train | INFO | Epoch 4 train batch 410/450: 6560/7200 mean loss: 0.0014866398414596915 score: 1.0
2021-08-08 04:06:24,156 | train | INFO | Epoch 4 train batch 411/450: 6576/7200 mean loss: 0.0014992645010352135 score: 1.0
2021-08-08 04:06:24,951 | train | INFO | Epoch 4 train batch 412/450: 6592/7200 mean loss: 0.001533003174699843 score: 1.0
2021-08-08 04:06:25,764 | train | INFO | Epoch 4 train batch 413/450: 6608/7200 mean loss: 0.0015078585129231215 score: 0.9926470588235294
2021-08-08 04:06:26,569 | train | INFO | Epoch 4 train batch 414/450: 6624/7200 mean loss: 0.001712149241939187 score: 0.9889705882352942
2021-08-08 04:06:27,357 | train | INFO | Epoch 4 train batch 415/450: 6640/7200 mean loss: 0.0016773476963862777 score: 1.0
2021-08-08 04:06:28,134 | train | INFO | Epoch 4 train batch 416/450: 6656/7200 mean loss: 0.0015327420551329851 score: 1.0
2021-08-08 04:06:28,907 | train | INFO | Epoch 4 train batch 417/450: 6672/7200 mean loss: 0.0016315821558237076 score: 1.0
2021-08-08 04:06:29,690 | train | INFO | Epoch 4 train batch 418/450: 6688/7200 mean loss: 0.0017122060526162386 score: 0.9887254901960785
2021-08-08 04:06:30,503 | train | INFO | Epoch 4 train batch 419/450: 6704/7200 mean loss: 0.0016086642863228917 score: 1.0
2021-08-08 04:06:31,281 | train | INFO | Epoch 4 train batch 420/450: 6720/7200 mean loss: 0.0017632198287174106 score: 1.0
2021-08-08 04:06:32,062 | train | INFO | Epoch 4 train batch 421/450: 6736/7200 mean loss: 0.0016882666386663914 score: 1.0
2021-08-08 04:06:32,834 | train | INFO | Epoch 4 train batch 422/450: 6752/7200 mean loss: 0.0015593416756018996 score: 1.0
2021-08-08 04:06:33,619 | train | INFO | Epoch 4 train batch 423/450: 6768/7200 mean loss: 0.001562920748256147 score: 0.9887254901960785
2021-08-08 04:06:34,418 | train | INFO | Epoch 4 train batch 424/450: 6784/7200 mean loss: 0.001721674227155745 score: 1.0
2021-08-08 04:06:35,195 | train | INFO | Epoch 4 train batch 425/450: 6800/7200 mean loss: 0.001683639595285058 score: 1.0
2021-08-08 04:06:35,973 | train | INFO | Epoch 4 train batch 426/450: 6816/7200 mean loss: 0.001584780984558165 score: 1.0
2021-08-08 04:06:36,809 | train | INFO | Epoch 4 train batch 427/450: 6832/7200 mean loss: 0.0016562819946557283 score: 1.0
2021-08-08 04:06:37,581 | train | INFO | Epoch 4 train batch 428/450: 6848/7200 mean loss: 0.0015390964690595865 score: 1.0
2021-08-08 04:06:38,383 | train | INFO | Epoch 4 train batch 429/450: 6864/7200 mean loss: 0.001676822081208229 score: 0.9924019607843138
2021-08-08 04:06:39,207 | train | INFO | Epoch 4 train batch 430/450: 6880/7200 mean loss: 0.001832115463912487 score: 0.996078431372549
2021-08-08 04:06:39,986 | train | INFO | Epoch 4 train batch 431/450: 6896/7200 mean loss: 0.001633268198929727 score: 1.0
2021-08-08 04:06:40,767 | train | INFO | Epoch 4 train batch 432/450: 6912/7200 mean loss: 0.00145900493953377 score: 1.0
2021-08-08 04:06:41,577 | train | INFO | Epoch 4 train batch 433/450: 6928/7200 mean loss: 0.001576162758283317 score: 1.0
2021-08-08 04:06:42,483 | train | INFO | Epoch 4 train batch 434/450: 6944/7200 mean loss: 0.0015731299063190818 score: 1.0
2021-08-08 04:06:43,326 | train | INFO | Epoch 4 train batch 435/450: 6960/7200 mean loss: 0.001534779672510922 score: 1.0
2021-08-08 04:06:44,101 | train | INFO | Epoch 4 train batch 436/450: 6976/7200 mean loss: 0.001399247208610177 score: 1.0
2021-08-08 04:06:44,910 | train | INFO | Epoch 4 train batch 437/450: 6992/7200 mean loss: 0.0016022237250581384 score: 0.9845588235294118
2021-08-08 04:06:45,685 | train | INFO | Epoch 4 train batch 438/450: 7008/7200 mean loss: 0.0018198200268670917 score: 1.0
2021-08-08 04:06:46,460 | train | INFO | Epoch 4 train batch 439/450: 7024/7200 mean loss: 0.0016474103322252631 score: 0.9926470588235294
2021-08-08 04:06:47,235 | train | INFO | Epoch 4 train batch 440/450: 7040/7200 mean loss: 0.0016256336821243167 score: 0.9443627450980392
2021-08-08 04:06:48,009 | train | INFO | Epoch 4 train batch 441/450: 7056/7200 mean loss: 0.0015298710204660892 score: 1.0
2021-08-08 04:06:48,779 | train | INFO | Epoch 4 train batch 442/450: 7072/7200 mean loss: 0.0016994359903037548 score: 1.0
2021-08-08 04:06:49,551 | train | INFO | Epoch 4 train batch 443/450: 7088/7200 mean loss: 0.001532745431177318 score: 1.0
2021-08-08 04:06:50,317 | train | INFO | Epoch 4 train batch 444/450: 7104/7200 mean loss: 0.0015783453127369285 score: 0.7999999999999999
2021-08-08 04:06:51,093 | train | INFO | Epoch 4 train batch 445/450: 7120/7200 mean loss: 0.0015353462658822536 score: 1.0
2021-08-08 04:06:51,867 | train | INFO | Epoch 4 train batch 446/450: 7136/7200 mean loss: 0.0015214165905490518 score: 1.0
2021-08-08 04:06:52,641 | train | INFO | Epoch 4 train batch 447/450: 7152/7200 mean loss: 0.0015795993385836482 score: 1.0
2021-08-08 04:06:53,423 | train | INFO | Epoch 4 train batch 448/450: 7168/7200 mean loss: 0.001499187434092164 score: 1.0
2021-08-08 04:06:54,194 | train | INFO | Epoch 4 train batch 449/450: 7184/7200 mean loss: 0.0014528780011460185 score: 0.9963235294117647
2021-08-08 04:06:54,344 | train | INFO | Epoch 4, Train, Mean loss: 0.025646196148461767, Score: 0.9924754782254783
2021-08-08 04:06:55,880 | train | INFO | Epoch 4 validation batch 0/113: 0/1800 mean loss: 0.001180297345854342 score: 1.0
2021-08-08 04:06:56,145 | train | INFO | Epoch 4 validation batch 1/113: 16/1800 mean loss: 0.0011690924875438213 score: 0.9889705882352942
2021-08-08 04:06:56,398 | train | INFO | Epoch 4 validation batch 2/113: 32/1800 mean loss: 0.0013996498892083764 score: 1.0
2021-08-08 04:06:56,643 | train | INFO | Epoch 4 validation batch 3/113: 48/1800 mean loss: 0.0013149090809747577 score: 1.0
2021-08-08 04:06:56,877 | train | INFO | Epoch 4 validation batch 4/113: 64/1800 mean loss: 0.0011627767235040665 score: 1.0
2021-08-08 04:06:57,116 | train | INFO | Epoch 4 validation batch 5/113: 80/1800 mean loss: 0.001188289956189692 score: 1.0
2021-08-08 04:06:57,349 | train | INFO | Epoch 4 validation batch 6/113: 96/1800 mean loss: 0.0011579274432733655 score: 1.0
2021-08-08 04:06:57,583 | train | INFO | Epoch 4 validation batch 7/113: 112/1800 mean loss: 0.0012834126828238368 score: 1.0
2021-08-08 04:06:57,821 | train | INFO | Epoch 4 validation batch 8/113: 128/1800 mean loss: 0.0012505108024924994 score: 1.0
2021-08-08 04:06:58,070 | train | INFO | Epoch 4 validation batch 9/113: 144/1800 mean loss: 0.001178613631054759 score: 1.0
2021-08-08 04:06:58,318 | train | INFO | Epoch 4 validation batch 10/113: 160/1800 mean loss: 0.0011941345874220133 score: 0.9816176470588235
2021-08-08 04:06:58,564 | train | INFO | Epoch 4 validation batch 11/113: 176/1800 mean loss: 0.0013017553137615323 score: 0.9963235294117647
2021-08-08 04:06:58,796 | train | INFO | Epoch 4 validation batch 12/113: 192/1800 mean loss: 0.0011868939036503434 score: 1.0
2021-08-08 04:06:59,028 | train | INFO | Epoch 4 validation batch 13/113: 208/1800 mean loss: 0.0011891655158251524 score: 1.0
2021-08-08 04:06:59,293 | train | INFO | Epoch 4 validation batch 14/113: 224/1800 mean loss: 0.0011159487767145038 score: 1.0
2021-08-08 04:06:59,527 | train | INFO | Epoch 4 validation batch 15/113: 240/1800 mean loss: 0.0011699881870299578 score: 1.0
2021-08-08 04:06:59,770 | train | INFO | Epoch 4 validation batch 16/113: 256/1800 mean loss: 0.001184352207928896 score: 1.0
2021-08-08 04:07:00,004 | train | INFO | Epoch 4 validation batch 17/113: 272/1800 mean loss: 0.0012978484155610204 score: 1.0
2021-08-08 04:07:00,236 | train | INFO | Epoch 4 validation batch 18/113: 288/1800 mean loss: 0.001038184273056686 score: 1.0
2021-08-08 04:07:00,467 | train | INFO | Epoch 4 validation batch 19/113: 304/1800 mean loss: 0.001176307094283402 score: 1.0
2021-08-08 04:07:00,714 | train | INFO | Epoch 4 validation batch 20/113: 320/1800 mean loss: 0.0012905183248221874 score: 0.9887254901960785
2021-08-08 04:07:00,969 | train | INFO | Epoch 4 validation batch 21/113: 336/1800 mean loss: 0.0011658822186291218 score: 1.0
2021-08-08 04:07:01,217 | train | INFO | Epoch 4 validation batch 22/113: 352/1800 mean loss: 0.0011330462293699384 score: 1.0
2021-08-08 04:07:01,448 | train | INFO | Epoch 4 validation batch 23/113: 368/1800 mean loss: 0.0011123737785965204 score: 1.0
2021-08-08 04:07:01,679 | train | INFO | Epoch 4 validation batch 24/113: 384/1800 mean loss: 0.0011502639390528202 score: 1.0
2021-08-08 04:07:01,930 | train | INFO | Epoch 4 validation batch 25/113: 400/1800 mean loss: 0.001265626517124474 score: 1.0
2021-08-08 04:07:02,198 | train | INFO | Epoch 4 validation batch 26/113: 416/1800 mean loss: 0.0011397834168747067 score: 1.0
2021-08-08 04:07:02,443 | train | INFO | Epoch 4 validation batch 27/113: 432/1800 mean loss: 0.0012997046578675508 score: 1.0
2021-08-08 04:07:02,678 | train | INFO | Epoch 4 validation batch 28/113: 448/1800 mean loss: 0.0011669039959087968 score: 1.0
2021-08-08 04:07:02,910 | train | INFO | Epoch 4 validation batch 29/113: 464/1800 mean loss: 0.0011944756843149662 score: 1.0
2021-08-08 04:07:03,143 | train | INFO | Epoch 4 validation batch 30/113: 480/1800 mean loss: 0.001218327321112156 score: 0.9926470588235294
2021-08-08 04:07:03,402 | train | INFO | Epoch 4 validation batch 31/113: 496/1800 mean loss: 0.0011409423314034939 score: 1.0
2021-08-08 04:07:03,638 | train | INFO | Epoch 4 validation batch 32/113: 512/1800 mean loss: 0.0011773599544540048 score: 0.9926470588235294
2021-08-08 04:07:03,885 | train | INFO | Epoch 4 validation batch 33/113: 528/1800 mean loss: 0.001131566008552909 score: 1.0
2021-08-08 04:07:04,116 | train | INFO | Epoch 4 validation batch 34/113: 544/1800 mean loss: 0.0009534392156638205 score: 1.0
2021-08-08 04:07:04,366 | train | INFO | Epoch 4 validation batch 35/113: 560/1800 mean loss: 0.0013000594917684793 score: 1.0
2021-08-08 04:07:04,597 | train | INFO | Epoch 4 validation batch 36/113: 576/1800 mean loss: 0.0012944468762725592 score: 0.8811274509803922
2021-08-08 04:07:04,839 | train | INFO | Epoch 4 validation batch 37/113: 592/1800 mean loss: 0.0010233494685962796 score: 1.0
2021-08-08 04:07:05,123 | train | INFO | Epoch 4 validation batch 38/113: 608/1800 mean loss: 0.0012438070261850953 score: 1.0
2021-08-08 04:07:05,364 | train | INFO | Epoch 4 validation batch 39/113: 624/1800 mean loss: 0.0011619735741987824 score: 1.0
2021-08-08 04:07:05,597 | train | INFO | Epoch 4 validation batch 40/113: 640/1800 mean loss: 0.0012440127320587635 score: 1.0
2021-08-08 04:07:05,869 | train | INFO | Epoch 4 validation batch 41/113: 656/1800 mean loss: 0.0011477353982627392 score: 1.0
2021-08-08 04:07:06,126 | train | INFO | Epoch 4 validation batch 42/113: 672/1800 mean loss: 0.0011607558699324727 score: 1.0
2021-08-08 04:07:06,380 | train | INFO | Epoch 4 validation batch 43/113: 688/1800 mean loss: 0.0011777665931731462 score: 1.0
2021-08-08 04:07:06,611 | train | INFO | Epoch 4 validation batch 44/113: 704/1800 mean loss: 0.0013704326702281833 score: 0.9632352941176471
2021-08-08 04:07:06,842 | train | INFO | Epoch 4 validation batch 45/113: 720/1800 mean loss: 0.0011959370458498597 score: 1.0
2021-08-08 04:07:07,073 | train | INFO | Epoch 4 validation batch 46/113: 736/1800 mean loss: 0.0011994440574198961 score: 0.9889705882352942
2021-08-08 04:07:07,311 | train | INFO | Epoch 4 validation batch 47/113: 752/1800 mean loss: 0.0011097373208031058 score: 1.0
2021-08-08 04:07:07,570 | train | INFO | Epoch 4 validation batch 48/113: 768/1800 mean loss: 0.0011684164637699723 score: 1.0
2021-08-08 04:07:07,804 | train | INFO | Epoch 4 validation batch 49/113: 784/1800 mean loss: 0.0011852470925077796 score: 1.0
2021-08-08 04:07:08,049 | train | INFO | Epoch 4 validation batch 50/113: 800/1800 mean loss: 0.0011216736165806651 score: 0.9963235294117647
2021-08-08 04:07:08,285 | train | INFO | Epoch 4 validation batch 51/113: 816/1800 mean loss: 0.0012280028313398361 score: 0.9742647058823529
2021-08-08 04:07:08,539 | train | INFO | Epoch 4 validation batch 52/113: 832/1800 mean loss: 0.0012557930313050747 score: 1.0
2021-08-08 04:07:08,787 | train | INFO | Epoch 4 validation batch 53/113: 848/1800 mean loss: 0.0011889751767739654 score: 1.0
2021-08-08 04:07:09,019 | train | INFO | Epoch 4 validation batch 54/113: 864/1800 mean loss: 0.0011532153002917767 score: 1.0
2021-08-08 04:07:09,254 | train | INFO | Epoch 4 validation batch 55/113: 880/1800 mean loss: 0.001233369461260736 score: 1.0
2021-08-08 04:07:09,509 | train | INFO | Epoch 4 validation batch 56/113: 896/1800 mean loss: 0.0011667056242004037 score: 1.0
2021-08-08 04:07:09,777 | train | INFO | Epoch 4 validation batch 57/113: 912/1800 mean loss: 0.0012847043108195066 score: 0.9926470588235294
2021-08-08 04:07:10,026 | train | INFO | Epoch 4 validation batch 58/113: 928/1800 mean loss: 0.0012843974400311708 score: 0.9816176470588235
2021-08-08 04:07:10,274 | train | INFO | Epoch 4 validation batch 59/113: 944/1800 mean loss: 0.0011637323768809438 score: 1.0
2021-08-08 04:07:10,514 | train | INFO | Epoch 4 validation batch 60/113: 960/1800 mean loss: 0.0010088931303471327 score: 1.0
2021-08-08 04:07:10,764 | train | INFO | Epoch 4 validation batch 61/113: 976/1800 mean loss: 0.0010910864220932126 score: 1.0
2021-08-08 04:07:11,006 | train | INFO | Epoch 4 validation batch 62/113: 992/1800 mean loss: 0.0011599445715546608 score: 1.0
2021-08-08 04:07:11,241 | train | INFO | Epoch 4 validation batch 63/113: 1008/1800 mean loss: 0.0011344623053446412 score: 1.0
2021-08-08 04:07:11,475 | train | INFO | Epoch 4 validation batch 64/113: 1024/1800 mean loss: 0.001231259317137301 score: 1.0
2021-08-08 04:07:11,710 | train | INFO | Epoch 4 validation batch 65/113: 1040/1800 mean loss: 0.0011842558160424232 score: 0.9963235294117647
2021-08-08 04:07:11,951 | train | INFO | Epoch 4 validation batch 66/113: 1056/1800 mean loss: 0.0012300115777179599 score: 1.0
2021-08-08 04:07:12,183 | train | INFO | Epoch 4 validation batch 67/113: 1072/1800 mean loss: 0.0012315522180870175 score: 1.0
2021-08-08 04:07:12,417 | train | INFO | Epoch 4 validation batch 68/113: 1088/1800 mean loss: 0.0010285190073773265 score: 1.0
2021-08-08 04:07:12,658 | train | INFO | Epoch 4 validation batch 69/113: 1104/1800 mean loss: 0.0011849363800138235 score: 1.0
2021-08-08 04:07:12,908 | train | INFO | Epoch 4 validation batch 70/113: 1120/1800 mean loss: 0.0012996923178434372 score: 0.9963235294117647
2021-08-08 04:07:13,167 | train | INFO | Epoch 4 validation batch 71/113: 1136/1800 mean loss: 0.001132463337853551 score: 1.0
2021-08-08 04:07:13,406 | train | INFO | Epoch 4 validation batch 72/113: 1152/1800 mean loss: 0.0011501683620736003 score: 1.0
2021-08-08 04:07:13,668 | train | INFO | Epoch 4 validation batch 73/113: 1168/1800 mean loss: 0.001312834327109158 score: 1.0
2021-08-08 04:07:13,907 | train | INFO | Epoch 4 validation batch 74/113: 1184/1800 mean loss: 0.001217535580508411 score: 1.0
2021-08-08 04:07:14,142 | train | INFO | Epoch 4 validation batch 75/113: 1200/1800 mean loss: 0.0011624640319496393 score: 1.0
2021-08-08 04:07:14,373 | train | INFO | Epoch 4 validation batch 76/113: 1216/1800 mean loss: 0.0010869947727769613 score: 1.0
2021-08-08 04:07:14,608 | train | INFO | Epoch 4 validation batch 77/113: 1232/1800 mean loss: 0.0010859103640541434 score: 1.0
2021-08-08 04:07:14,838 | train | INFO | Epoch 4 validation batch 78/113: 1248/1800 mean loss: 0.0012045393232256174 score: 0.9698529411764706
2021-08-08 04:07:15,097 | train | INFO | Epoch 4 validation batch 79/113: 1264/1800 mean loss: 0.0012401564745232463 score: 0.996078431372549
2021-08-08 04:07:15,348 | train | INFO | Epoch 4 validation batch 80/113: 1280/1800 mean loss: 0.0013549975119531155 score: 1.0
2021-08-08 04:07:15,580 | train | INFO | Epoch 4 validation batch 81/113: 1296/1800 mean loss: 0.001196374767459929 score: 1.0
2021-08-08 04:07:15,827 | train | INFO | Epoch 4 validation batch 82/113: 1312/1800 mean loss: 0.0010958572383970022 score: 1.0
2021-08-08 04:07:16,089 | train | INFO | Epoch 4 validation batch 83/113: 1328/1800 mean loss: 0.0012902108719572425 score: 1.0
2021-08-08 04:07:16,370 | train | INFO | Epoch 4 validation batch 84/113: 1344/1800 mean loss: 0.001314140041358769 score: 0.9852941176470589
2021-08-08 04:07:16,608 | train | INFO | Epoch 4 validation batch 85/113: 1360/1800 mean loss: 0.001215964904986322 score: 1.0
2021-08-08 04:07:16,855 | train | INFO | Epoch 4 validation batch 86/113: 1376/1800 mean loss: 0.0014232489047572017 score: 1.0
2021-08-08 04:07:17,110 | train | INFO | Epoch 4 validation batch 87/113: 1392/1800 mean loss: 0.0012834732187911868 score: 1.0
2021-08-08 04:07:17,360 | train | INFO | Epoch 4 validation batch 88/113: 1408/1800 mean loss: 0.0011112082283943892 score: 1.0
2021-08-08 04:07:17,606 | train | INFO | Epoch 4 validation batch 89/113: 1424/1800 mean loss: 0.0010359117295593023 score: 1.0
2021-08-08 04:07:17,840 | train | INFO | Epoch 4 validation batch 90/113: 1440/1800 mean loss: 0.0011595659889280796 score: 1.0
2021-08-08 04:07:18,088 | train | INFO | Epoch 4 validation batch 91/113: 1456/1800 mean loss: 0.0013404411729425192 score: 1.0
2021-08-08 04:07:18,334 | train | INFO | Epoch 4 validation batch 92/113: 1472/1800 mean loss: 0.001215839758515358 score: 1.0
2021-08-08 04:07:18,566 | train | INFO | Epoch 4 validation batch 93/113: 1488/1800 mean loss: 0.0011945582227781415 score: 1.0
2021-08-08 04:07:18,797 | train | INFO | Epoch 4 validation batch 94/113: 1504/1800 mean loss: 0.0012137512676417828 score: 1.0
2021-08-08 04:07:19,042 | train | INFO | Epoch 4 validation batch 95/113: 1520/1800 mean loss: 0.0012566960649564862 score: 1.0
2021-08-08 04:07:19,288 | train | INFO | Epoch 4 validation batch 96/113: 1536/1800 mean loss: 0.0012472857488319278 score: 0.9926470588235294
2021-08-08 04:07:19,543 | train | INFO | Epoch 4 validation batch 97/113: 1552/1800 mean loss: 0.00121393078006804 score: 1.0
2021-08-08 04:07:19,809 | train | INFO | Epoch 4 validation batch 98/113: 1568/1800 mean loss: 0.0011986303143203259 score: 1.0
2021-08-08 04:07:20,066 | train | INFO | Epoch 4 validation batch 99/113: 1584/1800 mean loss: 0.0011619053548201919 score: 1.0
2021-08-08 04:07:20,301 | train | INFO | Epoch 4 validation batch 100/113: 1600/1800 mean loss: 0.0013316329568624496 score: 1.0
2021-08-08 04:07:20,532 | train | INFO | Epoch 4 validation batch 101/113: 1616/1800 mean loss: 0.0011988311307504773 score: 1.0
2021-08-08 04:07:20,765 | train | INFO | Epoch 4 validation batch 102/113: 1632/1800 mean loss: 0.0011346336686983705 score: 1.0
2021-08-08 04:07:20,996 | train | INFO | Epoch 4 validation batch 103/113: 1648/1800 mean loss: 0.001143749919719994 score: 1.0
2021-08-08 04:07:21,227 | train | INFO | Epoch 4 validation batch 104/113: 1664/1800 mean loss: 0.0012389343464747071 score: 1.0
2021-08-08 04:07:21,458 | train | INFO | Epoch 4 validation batch 105/113: 1680/1800 mean loss: 0.0012166156666353345 score: 1.0
2021-08-08 04:07:21,688 | train | INFO | Epoch 4 validation batch 106/113: 1696/1800 mean loss: 0.0012527343351393938 score: 1.0
2021-08-08 04:07:21,919 | train | INFO | Epoch 4 validation batch 107/113: 1712/1800 mean loss: 0.0013540241634473205 score: 1.0
2021-08-08 04:07:22,149 | train | INFO | Epoch 4 validation batch 108/113: 1728/1800 mean loss: 0.00135941116604954 score: 1.0
2021-08-08 04:07:22,380 | train | INFO | Epoch 4 validation batch 109/113: 1744/1800 mean loss: 0.0013282422441989183 score: 1.0
2021-08-08 04:07:22,615 | train | INFO | Epoch 4 validation batch 110/113: 1760/1800 mean loss: 0.0011164011666551232 score: 1.0
2021-08-08 04:07:22,846 | train | INFO | Epoch 4 validation batch 111/113: 1776/1800 mean loss: 0.001206895336508751 score: 1.0
2021-08-08 04:07:23,011 | train | INFO | Epoch 4 validation batch 112/113: 1792/1800 mean loss: 0.0010357433930039406 score: 1.0
2021-08-08 04:07:23,174 | train | INFO | Epoch 4, Validation, Mean loss: 0.019194829590882347, Score: 0.9969525420787784
2021-08-08 04:07:23,175 | train | INFO | Write row 4
2021-08-08 04:07:25,868 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:07:25,872 | train | INFO | Update best record row 5, checkpoints 0.02064959108170155 -> 0.019194829590882347
2021-08-08 04:07:27,929 | train | INFO | Epoch 5 train batch 0/450: 0/7200 mean loss: 0.0015247635310515761 score: 1.0
2021-08-08 04:07:28,713 | train | INFO | Epoch 5 train batch 1/450: 16/7200 mean loss: 0.0014360712375491858 score: 1.0
2021-08-08 04:07:29,512 | train | INFO | Epoch 5 train batch 2/450: 32/7200 mean loss: 0.0013390843523666263 score: 1.0
2021-08-08 04:07:30,305 | train | INFO | Epoch 5 train batch 3/450: 48/7200 mean loss: 0.001440150081180036 score: 1.0
2021-08-08 04:07:31,084 | train | INFO | Epoch 5 train batch 4/450: 64/7200 mean loss: 0.0014039764646440744 score: 1.0
2021-08-08 04:07:31,867 | train | INFO | Epoch 5 train batch 5/450: 80/7200 mean loss: 0.0014877921203151345 score: 1.0
2021-08-08 04:07:32,720 | train | INFO | Epoch 5 train batch 6/450: 96/7200 mean loss: 0.0016330491052940488 score: 1.0
2021-08-08 04:07:33,541 | train | INFO | Epoch 5 train batch 7/450: 112/7200 mean loss: 0.0015852798242121935 score: 0.9921568627450981
2021-08-08 04:07:34,318 | train | INFO | Epoch 5 train batch 8/450: 128/7200 mean loss: 0.0015001361025497317 score: 1.0
2021-08-08 04:07:35,098 | train | INFO | Epoch 5 train batch 9/450: 144/7200 mean loss: 0.001627759076654911 score: 1.0
2021-08-08 04:07:35,938 | train | INFO | Epoch 5 train batch 10/450: 160/7200 mean loss: 0.0016990862786769867 score: 1.0
2021-08-08 04:07:36,715 | train | INFO | Epoch 5 train batch 11/450: 176/7200 mean loss: 0.001581926248036325 score: 0.996078431372549
2021-08-08 04:07:37,546 | train | INFO | Epoch 5 train batch 12/450: 192/7200 mean loss: 0.0015455316752195358 score: 1.0
2021-08-08 04:07:38,346 | train | INFO | Epoch 5 train batch 13/450: 208/7200 mean loss: 0.0016045505180954933 score: 1.0
2021-08-08 04:07:39,168 | train | INFO | Epoch 5 train batch 14/450: 224/7200 mean loss: 0.0014594541862607002 score: 1.0
2021-08-08 04:07:39,954 | train | INFO | Epoch 5 train batch 15/450: 240/7200 mean loss: 0.0015003110747784376 score: 1.0
2021-08-08 04:07:40,740 | train | INFO | Epoch 5 train batch 16/450: 256/7200 mean loss: 0.0014868587022647262 score: 0.9963235294117647
2021-08-08 04:07:41,528 | train | INFO | Epoch 5 train batch 17/450: 272/7200 mean loss: 0.0015527465147897601 score: 1.0
2021-08-08 04:07:42,339 | train | INFO | Epoch 5 train batch 18/450: 288/7200 mean loss: 0.0016084042144939303 score: 1.0
2021-08-08 04:07:43,217 | train | INFO | Epoch 5 train batch 19/450: 304/7200 mean loss: 0.0018477394478395581 score: 0.9921218487394957
2021-08-08 04:07:44,033 | train | INFO | Epoch 5 train batch 20/450: 320/7200 mean loss: 0.0016730836359784007 score: 1.0
2021-08-08 04:07:44,827 | train | INFO | Epoch 5 train batch 21/450: 336/7200 mean loss: 0.001692187157459557 score: 1.0
2021-08-08 04:07:45,619 | train | INFO | Epoch 5 train batch 22/450: 352/7200 mean loss: 0.001532007590867579 score: 0.9963235294117647
2021-08-08 04:07:46,400 | train | INFO | Epoch 5 train batch 23/450: 368/7200 mean loss: 0.001528356340713799 score: 1.0
2021-08-08 04:07:47,184 | train | INFO | Epoch 5 train batch 24/450: 384/7200 mean loss: 0.0016082992078736424 score: 1.0
2021-08-08 04:07:47,974 | train | INFO | Epoch 5 train batch 25/450: 400/7200 mean loss: 0.0015826232265681028 score: 0.9813725490196079
2021-08-08 04:07:48,758 | train | INFO | Epoch 5 train batch 26/450: 416/7200 mean loss: 0.0016310812206938863 score: 1.0
2021-08-08 04:07:49,535 | train | INFO | Epoch 5 train batch 27/450: 432/7200 mean loss: 0.0016968619311228395 score: 0.9887254901960785
2021-08-08 04:07:50,312 | train | INFO | Epoch 5 train batch 28/450: 448/7200 mean loss: 0.0015151117695495486 score: 1.0
2021-08-08 04:07:51,122 | train | INFO | Epoch 5 train batch 29/450: 464/7200 mean loss: 0.0016088507836684585 score: 1.0
2021-08-08 04:07:51,932 | train | INFO | Epoch 5 train batch 30/450: 480/7200 mean loss: 0.0016390765085816383 score: 1.0
2021-08-08 04:07:52,709 | train | INFO | Epoch 5 train batch 31/450: 496/7200 mean loss: 0.0014871882740408182 score: 0.9963235294117647
2021-08-08 04:07:53,521 | train | INFO | Epoch 5 train batch 32/450: 512/7200 mean loss: 0.001556136179715395 score: 1.0
2021-08-08 04:07:54,333 | train | INFO | Epoch 5 train batch 33/450: 528/7200 mean loss: 0.0015347424196079373 score: 1.0
2021-08-08 04:07:55,138 | train | INFO | Epoch 5 train batch 34/450: 544/7200 mean loss: 0.0015882070874795318 score: 1.0
2021-08-08 04:07:55,915 | train | INFO | Epoch 5 train batch 35/450: 560/7200 mean loss: 0.0015372243942692876 score: 1.0
2021-08-08 04:07:56,742 | train | INFO | Epoch 5 train batch 36/450: 576/7200 mean loss: 0.001453246222808957 score: 1.0
2021-08-08 04:07:57,572 | train | INFO | Epoch 5 train batch 37/450: 592/7200 mean loss: 0.0015263761160895228 score: 0.9553921568627451
2021-08-08 04:07:58,391 | train | INFO | Epoch 5 train batch 38/450: 608/7200 mean loss: 0.001551660243421793 score: 0.9887254901960785
2021-08-08 04:07:59,168 | train | INFO | Epoch 5 train batch 39/450: 624/7200 mean loss: 0.0015043453313410282 score: 1.0
2021-08-08 04:08:00,036 | train | INFO | Epoch 5 train batch 40/450: 640/7200 mean loss: 0.0015167800011113286 score: 0.9811274509803922
2021-08-08 04:08:00,821 | train | INFO | Epoch 5 train batch 41/450: 656/7200 mean loss: 0.001507588429376483 score: 1.0
2021-08-08 04:08:01,617 | train | INFO | Epoch 5 train batch 42/450: 672/7200 mean loss: 0.001366288517601788 score: 0.9813725490196079
2021-08-08 04:08:02,433 | train | INFO | Epoch 5 train batch 43/450: 688/7200 mean loss: 0.0015727736754342914 score: 1.0
2021-08-08 04:08:03,242 | train | INFO | Epoch 5 train batch 44/450: 704/7200 mean loss: 0.0014325852971524 score: 1.0
2021-08-08 04:08:04,050 | train | INFO | Epoch 5 train batch 45/450: 720/7200 mean loss: 0.0013753570383414626 score: 0.9926470588235294
2021-08-08 04:08:04,842 | train | INFO | Epoch 5 train batch 46/450: 736/7200 mean loss: 0.001488581532612443 score: 0.969607843137255
2021-08-08 04:08:05,636 | train | INFO | Epoch 5 train batch 47/450: 752/7200 mean loss: 0.0017249631928279996 score: 1.0
2021-08-08 04:08:06,418 | train | INFO | Epoch 5 train batch 48/450: 768/7200 mean loss: 0.001633823150768876 score: 1.0
2021-08-08 04:08:07,193 | train | INFO | Epoch 5 train batch 49/450: 784/7200 mean loss: 0.001430483884178102 score: 0.9926470588235294
2021-08-08 04:08:08,009 | train | INFO | Epoch 5 train batch 50/450: 800/7200 mean loss: 0.001467510825023055 score: 0.9963235294117647
2021-08-08 04:08:08,824 | train | INFO | Epoch 5 train batch 51/450: 816/7200 mean loss: 0.00150973885320127 score: 1.0
2021-08-08 04:08:09,607 | train | INFO | Epoch 5 train batch 52/450: 832/7200 mean loss: 0.001371421036310494 score: 1.0
2021-08-08 04:08:10,429 | train | INFO | Epoch 5 train batch 53/450: 848/7200 mean loss: 0.0016196079086512327 score: 1.0
2021-08-08 04:08:11,270 | train | INFO | Epoch 5 train batch 54/450: 864/7200 mean loss: 0.001521162805147469 score: 1.0
2021-08-08 04:08:12,061 | train | INFO | Epoch 5 train batch 55/450: 880/7200 mean loss: 0.0014731811825186014 score: 0.927450980392157
2021-08-08 04:08:12,835 | train | INFO | Epoch 5 train batch 56/450: 896/7200 mean loss: 0.0014311869163066149 score: 1.0
2021-08-08 04:08:13,636 | train | INFO | Epoch 5 train batch 57/450: 912/7200 mean loss: 0.0014677939470857382 score: 1.0
2021-08-08 04:08:14,419 | train | INFO | Epoch 5 train batch 58/450: 928/7200 mean loss: 0.0015274801990017295 score: 0.9963235294117647
2021-08-08 04:08:15,315 | train | INFO | Epoch 5 train batch 59/450: 944/7200 mean loss: 0.0014805486425757408 score: 1.0
2021-08-08 04:08:16,115 | train | INFO | Epoch 5 train batch 60/450: 960/7200 mean loss: 0.0016292156651616096 score: 1.0
2021-08-08 04:08:16,912 | train | INFO | Epoch 5 train batch 61/450: 976/7200 mean loss: 0.0015725675038993359 score: 1.0
2021-08-08 04:08:17,738 | train | INFO | Epoch 5 train batch 62/450: 992/7200 mean loss: 0.0016278022667393088 score: 1.0
2021-08-08 04:08:18,527 | train | INFO | Epoch 5 train batch 63/450: 1008/7200 mean loss: 0.001513978699222207 score: 1.0
2021-08-08 04:08:19,313 | train | INFO | Epoch 5 train batch 64/450: 1024/7200 mean loss: 0.0015119276940822601 score: 0.9806022408963585
2021-08-08 04:08:20,100 | train | INFO | Epoch 5 train batch 65/450: 1040/7200 mean loss: 0.0014769898261874914 score: 1.0
2021-08-08 04:08:20,867 | train | INFO | Epoch 5 train batch 66/450: 1056/7200 mean loss: 0.0014089063042774796 score: 1.0
2021-08-08 04:08:21,675 | train | INFO | Epoch 5 train batch 67/450: 1072/7200 mean loss: 0.0015229170676320791 score: 1.0
2021-08-08 04:08:22,478 | train | INFO | Epoch 5 train batch 68/450: 1088/7200 mean loss: 0.001491617993451655 score: 0.995798319327731
2021-08-08 04:08:23,258 | train | INFO | Epoch 5 train batch 69/450: 1104/7200 mean loss: 0.001496097189374268 score: 0.9963235294117647
2021-08-08 04:08:24,045 | train | INFO | Epoch 5 train batch 70/450: 1120/7200 mean loss: 0.0015138586750254035 score: 1.0
2021-08-08 04:08:24,883 | train | INFO | Epoch 5 train batch 71/450: 1136/7200 mean loss: 0.0015076561830937862 score: 0.9669117647058824
2021-08-08 04:08:25,709 | train | INFO | Epoch 5 train batch 72/450: 1152/7200 mean loss: 0.0015752563485875726 score: 1.0
2021-08-08 04:08:26,494 | train | INFO | Epoch 5 train batch 73/450: 1168/7200 mean loss: 0.0015391322085633874 score: 1.0
2021-08-08 04:08:27,316 | train | INFO | Epoch 5 train batch 74/450: 1184/7200 mean loss: 0.0015114392153918743 score: 0.9924019607843138
2021-08-08 04:08:28,100 | train | INFO | Epoch 5 train batch 75/450: 1200/7200 mean loss: 0.0015023663872852921 score: 1.0
2021-08-08 04:08:28,887 | train | INFO | Epoch 5 train batch 76/450: 1216/7200 mean loss: 0.0015216742176562548 score: 1.0
2021-08-08 04:08:29,716 | train | INFO | Epoch 5 train batch 77/450: 1232/7200 mean loss: 0.0014569064369425178 score: 0.9924019607843138
2021-08-08 04:08:30,490 | train | INFO | Epoch 5 train batch 78/450: 1248/7200 mean loss: 0.0014308670070022345 score: 1.0
2021-08-08 04:08:31,281 | train | INFO | Epoch 5 train batch 79/450: 1264/7200 mean loss: 0.0015758770750835538 score: 1.0
2021-08-08 04:08:32,059 | train | INFO | Epoch 5 train batch 80/450: 1280/7200 mean loss: 0.0015283406246453524 score: 1.0
2021-08-08 04:08:32,879 | train | INFO | Epoch 5 train batch 81/450: 1296/7200 mean loss: 0.0015107212821021676 score: 0.9926470588235294
2021-08-08 04:08:33,714 | train | INFO | Epoch 5 train batch 82/450: 1312/7200 mean loss: 0.001534680020995438 score: 0.9924019607843138
2021-08-08 04:08:34,550 | train | INFO | Epoch 5 train batch 83/450: 1328/7200 mean loss: 0.0015080999583005905 score: 1.0
2021-08-08 04:08:35,360 | train | INFO | Epoch 5 train batch 84/450: 1344/7200 mean loss: 0.0015047717606648803 score: 0.9887254901960785
2021-08-08 04:08:36,169 | train | INFO | Epoch 5 train batch 85/450: 1360/7200 mean loss: 0.0013057582546025515 score: 1.0
2021-08-08 04:08:36,946 | train | INFO | Epoch 5 train batch 86/450: 1376/7200 mean loss: 0.001485656131990254 score: 1.0
2021-08-08 04:08:37,763 | train | INFO | Epoch 5 train batch 87/450: 1392/7200 mean loss: 0.0014523343415930867 score: 0.9186274509803922
2021-08-08 04:08:38,549 | train | INFO | Epoch 5 train batch 88/450: 1408/7200 mean loss: 0.0015261194203048944 score: 0.9963235294117647
2021-08-08 04:08:39,368 | train | INFO | Epoch 5 train batch 89/450: 1424/7200 mean loss: 0.0015719487564638257 score: 0.9848039215686275
2021-08-08 04:08:40,151 | train | INFO | Epoch 5 train batch 90/450: 1440/7200 mean loss: 0.0015646509127691388 score: 1.0
2021-08-08 04:08:40,936 | train | INFO | Epoch 5 train batch 91/450: 1456/7200 mean loss: 0.0014747751411050558 score: 1.0
2021-08-08 04:08:41,749 | train | INFO | Epoch 5 train batch 92/450: 1472/7200 mean loss: 0.001442942419089377 score: 1.0
2021-08-08 04:08:42,534 | train | INFO | Epoch 5 train batch 93/450: 1488/7200 mean loss: 0.0014244891935959458 score: 0.9963235294117647
2021-08-08 04:08:43,302 | train | INFO | Epoch 5 train batch 94/450: 1504/7200 mean loss: 0.0015740273520350456 score: 1.0
2021-08-08 04:08:44,093 | train | INFO | Epoch 5 train batch 95/450: 1520/7200 mean loss: 0.0016389574157074094 score: 1.0
2021-08-08 04:08:44,909 | train | INFO | Epoch 5 train batch 96/450: 1536/7200 mean loss: 0.0015144682256504893 score: 1.0
2021-08-08 04:08:45,747 | train | INFO | Epoch 5 train batch 97/450: 1552/7200 mean loss: 0.0016338961431756616 score: 0.9695378151260504
2021-08-08 04:08:46,526 | train | INFO | Epoch 5 train batch 98/450: 1568/7200 mean loss: 0.0016174310585483909 score: 1.0
2021-08-08 04:08:47,318 | train | INFO | Epoch 5 train batch 99/450: 1584/7200 mean loss: 0.0014639251166954637 score: 1.0
2021-08-08 04:08:48,094 | train | INFO | Epoch 5 train batch 100/450: 1600/7200 mean loss: 0.0016734922537580132 score: 1.0
2021-08-08 04:08:48,874 | train | INFO | Epoch 5 train batch 101/450: 1616/7200 mean loss: 0.0014444496482610703 score: 1.0
2021-08-08 04:08:49,671 | train | INFO | Epoch 5 train batch 102/450: 1632/7200 mean loss: 0.0013959043426439166 score: 1.0
2021-08-08 04:08:50,455 | train | INFO | Epoch 5 train batch 103/450: 1648/7200 mean loss: 0.0014321209164336324 score: 1.0
2021-08-08 04:08:51,251 | train | INFO | Epoch 5 train batch 104/450: 1664/7200 mean loss: 0.0016434603603556752 score: 1.0
2021-08-08 04:08:52,055 | train | INFO | Epoch 5 train batch 105/450: 1680/7200 mean loss: 0.001422647270374 score: 0.9884803921568628
2021-08-08 04:08:52,861 | train | INFO | Epoch 5 train batch 106/450: 1696/7200 mean loss: 0.0015854487428441644 score: 1.0
2021-08-08 04:08:53,646 | train | INFO | Epoch 5 train batch 107/450: 1712/7200 mean loss: 0.001573292538523674 score: 1.0
2021-08-08 04:08:54,440 | train | INFO | Epoch 5 train batch 108/450: 1728/7200 mean loss: 0.0015631512505933642 score: 1.0
2021-08-08 04:08:55,269 | train | INFO | Epoch 5 train batch 109/450: 1744/7200 mean loss: 0.0016558447387069464 score: 1.0
2021-08-08 04:08:56,069 | train | INFO | Epoch 5 train batch 110/450: 1760/7200 mean loss: 0.0016521660145372152 score: 0.9889705882352942
2021-08-08 04:08:56,844 | train | INFO | Epoch 5 train batch 111/450: 1776/7200 mean loss: 0.0016521398210898042 score: 1.0
2021-08-08 04:08:57,632 | train | INFO | Epoch 5 train batch 112/450: 1792/7200 mean loss: 0.0015797435771673918 score: 1.0
2021-08-08 04:08:58,404 | train | INFO | Epoch 5 train batch 113/450: 1808/7200 mean loss: 0.0015998310409486294 score: 0.9887254901960785
2021-08-08 04:08:59,207 | train | INFO | Epoch 5 train batch 114/450: 1824/7200 mean loss: 0.0015426232712343335 score: 1.0
2021-08-08 04:09:00,025 | train | INFO | Epoch 5 train batch 115/450: 1840/7200 mean loss: 0.001460190978832543 score: 0.6691176470588235
2021-08-08 04:09:00,834 | train | INFO | Epoch 5 train batch 116/450: 1856/7200 mean loss: 0.0015663780504837632 score: 0.9963235294117647
2021-08-08 04:09:01,618 | train | INFO | Epoch 5 train batch 117/450: 1872/7200 mean loss: 0.0014436637284234166 score: 1.0
2021-08-08 04:09:02,424 | train | INFO | Epoch 5 train batch 118/450: 1888/7200 mean loss: 0.0015016566030681133 score: 1.0
2021-08-08 04:09:03,261 | train | INFO | Epoch 5 train batch 119/450: 1904/7200 mean loss: 0.0015762735856696963 score: 0.9742647058823529
2021-08-08 04:09:04,076 | train | INFO | Epoch 5 train batch 120/450: 1920/7200 mean loss: 0.0016035486478358507 score: 0.9926470588235294
2021-08-08 04:09:04,930 | train | INFO | Epoch 5 train batch 121/450: 1936/7200 mean loss: 0.0016170055605471134 score: 1.0
2021-08-08 04:09:05,755 | train | INFO | Epoch 5 train batch 122/450: 1952/7200 mean loss: 0.001425029244273901 score: 1.0
2021-08-08 04:09:06,561 | train | INFO | Epoch 5 train batch 123/450: 1968/7200 mean loss: 0.0013934115413576365 score: 1.0
2021-08-08 04:09:07,349 | train | INFO | Epoch 5 train batch 124/450: 1984/7200 mean loss: 0.00158788007684052 score: 0.921218487394958
2021-08-08 04:09:08,140 | train | INFO | Epoch 5 train batch 125/450: 2000/7200 mean loss: 0.0016389749944210052 score: 0.3130252100840336
2021-08-08 04:09:09,046 | train | INFO | Epoch 5 train batch 126/450: 2016/7200 mean loss: 0.0013499765191227198 score: 1.0
2021-08-08 04:09:09,847 | train | INFO | Epoch 5 train batch 127/450: 2032/7200 mean loss: 0.0014932788908481598 score: 1.0
2021-08-08 04:09:10,627 | train | INFO | Epoch 5 train batch 128/450: 2048/7200 mean loss: 0.0016831806860864162 score: 0.9558823529411765
2021-08-08 04:09:11,435 | train | INFO | Epoch 5 train batch 129/450: 2064/7200 mean loss: 0.0015285784611478448 score: 0.9774509803921569
2021-08-08 04:09:12,218 | train | INFO | Epoch 5 train batch 130/450: 2080/7200 mean loss: 0.0015737153589725494 score: 0.9924019607843138
2021-08-08 04:09:13,028 | train | INFO | Epoch 5 train batch 131/450: 2096/7200 mean loss: 0.001413470832630992 score: 0.9924019607843138
2021-08-08 04:09:13,832 | train | INFO | Epoch 5 train batch 132/450: 2112/7200 mean loss: 0.001564766513183713 score: 0.9963235294117647
2021-08-08 04:09:14,693 | train | INFO | Epoch 5 train batch 133/450: 2128/7200 mean loss: 0.0015485092299059033 score: 1.0
2021-08-08 04:09:15,505 | train | INFO | Epoch 5 train batch 134/450: 2144/7200 mean loss: 0.001564876060001552 score: 1.0
2021-08-08 04:09:16,324 | train | INFO | Epoch 5 train batch 135/450: 2160/7200 mean loss: 0.0014266736106947064 score: 1.0
2021-08-08 04:09:17,113 | train | INFO | Epoch 5 train batch 136/450: 2176/7200 mean loss: 0.001447053742595017 score: 0.861764705882353
2021-08-08 04:09:17,900 | train | INFO | Epoch 5 train batch 137/450: 2192/7200 mean loss: 0.001784968189895153 score: 1.0
2021-08-08 04:09:18,706 | train | INFO | Epoch 5 train batch 138/450: 2208/7200 mean loss: 0.001597201800905168 score: 1.0
2021-08-08 04:09:19,480 | train | INFO | Epoch 5 train batch 139/450: 2224/7200 mean loss: 0.0015677224146202207 score: 0.9446078431372549
2021-08-08 04:09:20,251 | train | INFO | Epoch 5 train batch 140/450: 2240/7200 mean loss: 0.0014404414687305689 score: 1.0
2021-08-08 04:09:21,045 | train | INFO | Epoch 5 train batch 141/450: 2256/7200 mean loss: 0.0014355938183143735 score: 1.0
2021-08-08 04:09:21,827 | train | INFO | Epoch 5 train batch 142/450: 2272/7200 mean loss: 0.0014523129211738706 score: 0.9963235294117647
2021-08-08 04:09:22,640 | train | INFO | Epoch 5 train batch 143/450: 2288/7200 mean loss: 0.001467852620407939 score: 1.0
2021-08-08 04:09:23,413 | train | INFO | Epoch 5 train batch 144/450: 2304/7200 mean loss: 0.0015890515642240644 score: 1.0
2021-08-08 04:09:24,185 | train | INFO | Epoch 5 train batch 145/450: 2320/7200 mean loss: 0.001615051063708961 score: 1.0
2021-08-08 04:09:24,987 | train | INFO | Epoch 5 train batch 146/450: 2336/7200 mean loss: 0.001581336953677237 score: 1.0
2021-08-08 04:09:25,772 | train | INFO | Epoch 5 train batch 147/450: 2352/7200 mean loss: 0.0014089826727285981 score: 0.9963235294117647
2021-08-08 04:09:26,574 | train | INFO | Epoch 5 train batch 148/450: 2368/7200 mean loss: 0.0014332536375150084 score: 1.0
2021-08-08 04:09:27,384 | train | INFO | Epoch 5 train batch 149/450: 2384/7200 mean loss: 0.001732237171381712 score: 1.0
2021-08-08 04:09:28,217 | train | INFO | Epoch 5 train batch 150/450: 2400/7200 mean loss: 0.0018611653940752149 score: 0.9884453781512604
2021-08-08 04:09:29,015 | train | INFO | Epoch 5 train batch 151/450: 2416/7200 mean loss: 0.0017187625635415316 score: 0.9845588235294118
2021-08-08 04:09:29,823 | train | INFO | Epoch 5 train batch 152/450: 2432/7200 mean loss: 0.0016783964820206165 score: 1.0
2021-08-08 04:09:30,613 | train | INFO | Epoch 5 train batch 153/450: 2448/7200 mean loss: 0.0015198301989585161 score: 0.9926470588235294
2021-08-08 04:09:31,398 | train | INFO | Epoch 5 train batch 154/450: 2464/7200 mean loss: 0.001628344994969666 score: 0.9448529411764706
2021-08-08 04:09:32,194 | train | INFO | Epoch 5 train batch 155/450: 2480/7200 mean loss: 0.0015747285215184093 score: 1.0
2021-08-08 04:09:32,958 | train | INFO | Epoch 5 train batch 156/450: 2496/7200 mean loss: 0.0015094424597918987 score: 1.0
2021-08-08 04:09:33,779 | train | INFO | Epoch 5 train batch 157/450: 2512/7200 mean loss: 0.0015538455918431282 score: 0.8477941176470588
2021-08-08 04:09:34,578 | train | INFO | Epoch 5 train batch 158/450: 2528/7200 mean loss: 0.0016086602117866278 score: 0.9921568627450981
2021-08-08 04:09:35,344 | train | INFO | Epoch 5 train batch 159/450: 2544/7200 mean loss: 0.0015469923382624984 score: 1.0
2021-08-08 04:09:36,131 | train | INFO | Epoch 5 train batch 160/450: 2560/7200 mean loss: 0.0015644663944840431 score: 1.0
2021-08-08 04:09:36,940 | train | INFO | Epoch 5 train batch 161/450: 2576/7200 mean loss: 0.001628260244615376 score: 1.0
2021-08-08 04:09:37,719 | train | INFO | Epoch 5 train batch 162/450: 2592/7200 mean loss: 0.0017063082195818424 score: 1.0
2021-08-08 04:09:38,495 | train | INFO | Epoch 5 train batch 163/450: 2608/7200 mean loss: 0.0013951431028544903 score: 1.0
2021-08-08 04:09:39,269 | train | INFO | Epoch 5 train batch 164/450: 2624/7200 mean loss: 0.0016303819138556719 score: 0.9693627450980393
2021-08-08 04:09:40,043 | train | INFO | Epoch 5 train batch 165/450: 2640/7200 mean loss: 0.001697047846391797 score: 0.9887254901960785
2021-08-08 04:09:40,869 | train | INFO | Epoch 5 train batch 166/450: 2656/7200 mean loss: 0.0014986536698415875 score: 1.0
2021-08-08 04:09:41,682 | train | INFO | Epoch 5 train batch 167/450: 2672/7200 mean loss: 0.0016237787203863263 score: 1.0
2021-08-08 04:09:42,495 | train | INFO | Epoch 5 train batch 168/450: 2688/7200 mean loss: 0.001567238592542708 score: 1.0
2021-08-08 04:09:43,276 | train | INFO | Epoch 5 train batch 169/450: 2704/7200 mean loss: 0.0016921206843107939 score: 0.9816176470588235
2021-08-08 04:09:44,058 | train | INFO | Epoch 5 train batch 170/450: 2720/7200 mean loss: 0.001409650081768632 score: 0.9816176470588235
2021-08-08 04:09:44,844 | train | INFO | Epoch 5 train batch 171/450: 2736/7200 mean loss: 0.0014201728627085686 score: 1.0
2021-08-08 04:09:45,688 | train | INFO | Epoch 5 train batch 172/450: 2752/7200 mean loss: 0.0013903235085308552 score: 1.0
2021-08-08 04:09:46,555 | train | INFO | Epoch 5 train batch 173/450: 2768/7200 mean loss: 0.0014324415242299438 score: 1.0
2021-08-08 04:09:47,354 | train | INFO | Epoch 5 train batch 174/450: 2784/7200 mean loss: 0.0015200629131868482 score: 1.0
2021-08-08 04:09:48,130 | train | INFO | Epoch 5 train batch 175/450: 2800/7200 mean loss: 0.0016267914324998856 score: 1.0
2021-08-08 04:09:48,943 | train | INFO | Epoch 5 train batch 176/450: 2816/7200 mean loss: 0.0015794946812093258 score: 1.0
2021-08-08 04:09:49,756 | train | INFO | Epoch 5 train batch 177/450: 2832/7200 mean loss: 0.0016240874538198113 score: 0.9963235294117647
2021-08-08 04:09:50,541 | train | INFO | Epoch 5 train batch 178/450: 2848/7200 mean loss: 0.0016304226592183113 score: 0.9698529411764706
2021-08-08 04:09:51,355 | train | INFO | Epoch 5 train batch 179/450: 2864/7200 mean loss: 0.0014510148903355002 score: 1.0
2021-08-08 04:09:52,165 | train | INFO | Epoch 5 train batch 180/450: 2880/7200 mean loss: 0.0014438857324421406 score: 0.9921218487394957
2021-08-08 04:09:52,994 | train | INFO | Epoch 5 train batch 181/450: 2896/7200 mean loss: 0.0015964704798534513 score: 1.0
2021-08-08 04:09:53,773 | train | INFO | Epoch 5 train batch 182/450: 2912/7200 mean loss: 0.0014362965011969209 score: 1.0
2021-08-08 04:09:54,566 | train | INFO | Epoch 5 train batch 183/450: 2928/7200 mean loss: 0.001585274119861424 score: 0.9963235294117647
2021-08-08 04:09:55,354 | train | INFO | Epoch 5 train batch 184/450: 2944/7200 mean loss: 0.0016327815828844905 score: 1.0
2021-08-08 04:09:56,136 | train | INFO | Epoch 5 train batch 185/450: 2960/7200 mean loss: 0.0014836463378742337 score: 1.0
2021-08-08 04:09:56,931 | train | INFO | Epoch 5 train batch 186/450: 2976/7200 mean loss: 0.0016419043531641364 score: 0.9816176470588235
2021-08-08 04:09:57,734 | train | INFO | Epoch 5 train batch 187/450: 2992/7200 mean loss: 0.0015838190447539091 score: 0.9963235294117647
2021-08-08 04:09:58,556 | train | INFO | Epoch 5 train batch 188/450: 3008/7200 mean loss: 0.0013900587800890207 score: 1.0
2021-08-08 04:09:59,326 | train | INFO | Epoch 5 train batch 189/450: 3024/7200 mean loss: 0.0016581607051193714 score: 1.0
2021-08-08 04:10:00,106 | train | INFO | Epoch 5 train batch 190/450: 3040/7200 mean loss: 0.001689837547019124 score: 0.9776960784313725
2021-08-08 04:10:00,891 | train | INFO | Epoch 5 train batch 191/450: 3056/7200 mean loss: 0.001555770286358893 score: 1.0
2021-08-08 04:10:01,736 | train | INFO | Epoch 5 train batch 192/450: 3072/7200 mean loss: 0.0013653358910232782 score: 1.0
2021-08-08 04:10:02,537 | train | INFO | Epoch 5 train batch 193/450: 3088/7200 mean loss: 0.0015259215142577887 score: 1.0
2021-08-08 04:10:03,330 | train | INFO | Epoch 5 train batch 194/450: 3104/7200 mean loss: 0.0016249156324192882 score: 1.0
2021-08-08 04:10:04,176 | train | INFO | Epoch 5 train batch 195/450: 3120/7200 mean loss: 0.001341427443549037 score: 1.0
2021-08-08 04:10:04,945 | train | INFO | Epoch 5 train batch 196/450: 3136/7200 mean loss: 0.0015175595181062818 score: 1.0
2021-08-08 04:10:05,751 | train | INFO | Epoch 5 train batch 197/450: 3152/7200 mean loss: 0.0016359492437914014 score: 1.0
2021-08-08 04:10:06,528 | train | INFO | Epoch 5 train batch 198/450: 3168/7200 mean loss: 0.0015602140920236707 score: 1.0
2021-08-08 04:10:07,313 | train | INFO | Epoch 5 train batch 199/450: 3184/7200 mean loss: 0.0014793790178373456 score: 1.0
2021-08-08 04:10:08,088 | train | INFO | Epoch 5 train batch 200/450: 3200/7200 mean loss: 0.0015489638317376375 score: 0.995798319327731
2021-08-08 04:10:08,860 | train | INFO | Epoch 5 train batch 201/450: 3216/7200 mean loss: 0.0014921597903594375 score: 1.0
2021-08-08 04:10:09,678 | train | INFO | Epoch 5 train batch 202/450: 3232/7200 mean loss: 0.001442252891138196 score: 1.0
2021-08-08 04:10:10,460 | train | INFO | Epoch 5 train batch 203/450: 3248/7200 mean loss: 0.0015976324211806059 score: 0.996078431372549
2021-08-08 04:10:11,247 | train | INFO | Epoch 5 train batch 204/450: 3264/7200 mean loss: 0.0014018536312505603 score: 1.0
2021-08-08 04:10:12,028 | train | INFO | Epoch 5 train batch 205/450: 3280/7200 mean loss: 0.0014622706221416593 score: 1.0
2021-08-08 04:10:12,826 | train | INFO | Epoch 5 train batch 206/450: 3296/7200 mean loss: 0.001457555335946381 score: 1.0
2021-08-08 04:10:13,603 | train | INFO | Epoch 5 train batch 207/450: 3312/7200 mean loss: 0.0015621823258697987 score: 1.0
2021-08-08 04:10:14,425 | train | INFO | Epoch 5 train batch 208/450: 3328/7200 mean loss: 0.0015055565163493156 score: 1.0
2021-08-08 04:10:15,229 | train | INFO | Epoch 5 train batch 209/450: 3344/7200 mean loss: 0.0014687305083498359 score: 0.5304621848739496
2021-08-08 04:10:16,000 | train | INFO | Epoch 5 train batch 210/450: 3360/7200 mean loss: 0.001493930583819747 score: 1.0
2021-08-08 04:10:16,816 | train | INFO | Epoch 5 train batch 211/450: 3376/7200 mean loss: 0.0016495742602273822 score: 1.0
2021-08-08 04:10:17,590 | train | INFO | Epoch 5 train batch 212/450: 3392/7200 mean loss: 0.0016066371463239193 score: 1.0
2021-08-08 04:10:18,366 | train | INFO | Epoch 5 train batch 213/450: 3408/7200 mean loss: 0.001551945460960269 score: 0.9889705882352942
2021-08-08 04:10:19,155 | train | INFO | Epoch 5 train batch 214/450: 3424/7200 mean loss: 0.0016906594391912222 score: 1.0
2021-08-08 04:10:19,957 | train | INFO | Epoch 5 train batch 215/450: 3440/7200 mean loss: 0.0015557206934317946 score: 1.0
2021-08-08 04:10:20,741 | train | INFO | Epoch 5 train batch 216/450: 3456/7200 mean loss: 0.0017130280612036586 score: 1.0
2021-08-08 04:10:21,540 | train | INFO | Epoch 5 train batch 217/450: 3472/7200 mean loss: 0.0016280487179756165 score: 1.0
2021-08-08 04:10:22,315 | train | INFO | Epoch 5 train batch 218/450: 3488/7200 mean loss: 0.0017067670123651624 score: 1.0
2021-08-08 04:10:23,093 | train | INFO | Epoch 5 train batch 219/450: 3504/7200 mean loss: 0.001622106647118926 score: 1.0
2021-08-08 04:10:23,872 | train | INFO | Epoch 5 train batch 220/450: 3520/7200 mean loss: 0.0018077200511470437 score: 1.0
2021-08-08 04:10:24,683 | train | INFO | Epoch 5 train batch 221/450: 3536/7200 mean loss: 0.0016014608554542065 score: 1.0
2021-08-08 04:10:25,472 | train | INFO | Epoch 5 train batch 222/450: 3552/7200 mean loss: 0.0014861165545880795 score: 1.0
2021-08-08 04:10:26,236 | train | INFO | Epoch 5 train batch 223/450: 3568/7200 mean loss: 0.0016327144112437963 score: 1.0
2021-08-08 04:10:26,997 | train | INFO | Epoch 5 train batch 224/450: 3584/7200 mean loss: 0.001557541429065168 score: 1.0
2021-08-08 04:10:27,802 | train | INFO | Epoch 5 train batch 225/450: 3600/7200 mean loss: 0.0016712683718651533 score: 1.0
2021-08-08 04:10:28,566 | train | INFO | Epoch 5 train batch 226/450: 3616/7200 mean loss: 0.0015133369015529752 score: 1.0
2021-08-08 04:10:29,377 | train | INFO | Epoch 5 train batch 227/450: 3632/7200 mean loss: 0.0015466316835954785 score: 1.0
2021-08-08 04:10:30,144 | train | INFO | Epoch 5 train batch 228/450: 3648/7200 mean loss: 0.001656217034906149 score: 0.9963235294117647
2021-08-08 04:10:30,914 | train | INFO | Epoch 5 train batch 229/450: 3664/7200 mean loss: 0.0014286625664681196 score: 0.9924019607843138
2021-08-08 04:10:31,684 | train | INFO | Epoch 5 train batch 230/450: 3680/7200 mean loss: 0.0014412757009267807 score: 1.0
2021-08-08 04:10:32,457 | train | INFO | Epoch 5 train batch 231/450: 3696/7200 mean loss: 0.0014853209722787142 score: 1.0
2021-08-08 04:10:33,226 | train | INFO | Epoch 5 train batch 232/450: 3712/7200 mean loss: 0.0015316156204789877 score: 1.0
2021-08-08 04:10:34,032 | train | INFO | Epoch 5 train batch 233/450: 3728/7200 mean loss: 0.0015284452820196748 score: 1.0
2021-08-08 04:10:34,817 | train | INFO | Epoch 5 train batch 234/450: 3744/7200 mean loss: 0.0013112189481034875 score: 1.0
2021-08-08 04:10:35,638 | train | INFO | Epoch 5 train batch 235/450: 3760/7200 mean loss: 0.001558372052386403 score: 1.0
2021-08-08 04:10:36,405 | train | INFO | Epoch 5 train batch 236/450: 3776/7200 mean loss: 0.0015656992327421904 score: 0.9848039215686275
2021-08-08 04:10:37,173 | train | INFO | Epoch 5 train batch 237/450: 3792/7200 mean loss: 0.0012977810110896826 score: 1.0
2021-08-08 04:10:37,955 | train | INFO | Epoch 5 train batch 238/450: 3808/7200 mean loss: 0.0016207292210310698 score: 1.0
2021-08-08 04:10:38,728 | train | INFO | Epoch 5 train batch 239/450: 3824/7200 mean loss: 0.0014146743342280388 score: 1.0
2021-08-08 04:10:39,510 | train | INFO | Epoch 5 train batch 240/450: 3840/7200 mean loss: 0.0015756664797663689 score: 1.0
2021-08-08 04:10:40,281 | train | INFO | Epoch 5 train batch 241/450: 3856/7200 mean loss: 0.0016025990480557084 score: 1.0
2021-08-08 04:10:41,072 | train | INFO | Epoch 5 train batch 242/450: 3872/7200 mean loss: 0.0015947399660944939 score: 1.0
2021-08-08 04:10:41,867 | train | INFO | Epoch 5 train batch 243/450: 3888/7200 mean loss: 0.0015171695267781615 score: 1.0
2021-08-08 04:10:42,719 | train | INFO | Epoch 5 train batch 244/450: 3904/7200 mean loss: 0.0015347182052209973 score: 0.9963235294117647
2021-08-08 04:10:43,503 | train | INFO | Epoch 5 train batch 245/450: 3920/7200 mean loss: 0.0015079727163538337 score: 1.0
2021-08-08 04:10:44,277 | train | INFO | Epoch 5 train batch 246/450: 3936/7200 mean loss: 0.0015582434134557843 score: 1.0
2021-08-08 04:10:45,084 | train | INFO | Epoch 5 train batch 247/450: 3952/7200 mean loss: 0.001555294613353908 score: 1.0
2021-08-08 04:10:45,846 | train | INFO | Epoch 5 train batch 248/450: 3968/7200 mean loss: 0.0015351892216131091 score: 0.9963235294117647
2021-08-08 04:10:46,619 | train | INFO | Epoch 5 train batch 249/450: 3984/7200 mean loss: 0.001456010970287025 score: 0.9924019607843138
2021-08-08 04:10:47,441 | train | INFO | Epoch 5 train batch 250/450: 4000/7200 mean loss: 0.001636622124351561 score: 1.0
2021-08-08 04:10:48,228 | train | INFO | Epoch 5 train batch 251/450: 4016/7200 mean loss: 0.001485191285610199 score: 0.9889705882352942
2021-08-08 04:10:49,003 | train | INFO | Epoch 5 train batch 252/450: 4032/7200 mean loss: 0.0015305387787520885 score: 1.0
2021-08-08 04:10:49,781 | train | INFO | Epoch 5 train batch 253/450: 4048/7200 mean loss: 0.0016269446350634098 score: 1.0
2021-08-08 04:10:50,577 | train | INFO | Epoch 5 train batch 254/450: 4064/7200 mean loss: 0.0015029058558866382 score: 0.9963235294117647
2021-08-08 04:10:51,356 | train | INFO | Epoch 5 train batch 255/450: 4080/7200 mean loss: 0.0016355797415599227 score: 0.9411764705882353
2021-08-08 04:10:52,131 | train | INFO | Epoch 5 train batch 256/450: 4096/7200 mean loss: 0.0016008950769901276 score: 1.0
2021-08-08 04:10:52,909 | train | INFO | Epoch 5 train batch 257/450: 4112/7200 mean loss: 0.0017477619694545865 score: 0.996078431372549
2021-08-08 04:10:53,687 | train | INFO | Epoch 5 train batch 258/450: 4128/7200 mean loss: 0.0015527891227975488 score: 1.0
2021-08-08 04:10:54,472 | train | INFO | Epoch 5 train batch 259/450: 4144/7200 mean loss: 0.0014502749545499682 score: 1.0
2021-08-08 04:10:55,259 | train | INFO | Epoch 5 train batch 260/450: 4160/7200 mean loss: 0.0014038875233381987 score: 1.0
2021-08-08 04:10:56,037 | train | INFO | Epoch 5 train batch 261/450: 4176/7200 mean loss: 0.0015408470062538981 score: 1.0
2021-08-08 04:10:56,813 | train | INFO | Epoch 5 train batch 262/450: 4192/7200 mean loss: 0.0014664604095742106 score: 1.0
2021-08-08 04:10:57,633 | train | INFO | Epoch 5 train batch 263/450: 4208/7200 mean loss: 0.0015496473060920835 score: 1.0
2021-08-08 04:10:58,432 | train | INFO | Epoch 5 train batch 264/450: 4224/7200 mean loss: 0.001475319149903953 score: 1.0
2021-08-08 04:10:59,221 | train | INFO | Epoch 5 train batch 265/450: 4240/7200 mean loss: 0.0016733604716137052 score: 1.0
2021-08-08 04:11:00,029 | train | INFO | Epoch 5 train batch 266/450: 4256/7200 mean loss: 0.001478518359363079 score: 1.0
2021-08-08 04:11:00,802 | train | INFO | Epoch 5 train batch 267/450: 4272/7200 mean loss: 0.0015673316083848476 score: 1.0
2021-08-08 04:11:01,591 | train | INFO | Epoch 5 train batch 268/450: 4288/7200 mean loss: 0.001702163484878838 score: 1.0
2021-08-08 04:11:02,373 | train | INFO | Epoch 5 train batch 269/450: 4304/7200 mean loss: 0.0013104694662615657 score: 0.9926470588235294
2021-08-08 04:11:03,146 | train | INFO | Epoch 5 train batch 270/450: 4320/7200 mean loss: 0.0015975241549313068 score: 0.9963235294117647
2021-08-08 04:11:03,937 | train | INFO | Epoch 5 train batch 271/450: 4336/7200 mean loss: 0.0016667020972818136 score: 1.0
2021-08-08 04:11:04,717 | train | INFO | Epoch 5 train batch 272/450: 4352/7200 mean loss: 0.0016111350851133466 score: 0.9924019607843138
2021-08-08 04:11:05,489 | train | INFO | Epoch 5 train batch 273/450: 4368/7200 mean loss: 0.0017139631090685725 score: 1.0
2021-08-08 04:11:06,266 | train | INFO | Epoch 5 train batch 274/450: 4384/7200 mean loss: 0.0017074656207114458 score: 1.0
2021-08-08 04:11:07,043 | train | INFO | Epoch 5 train batch 275/450: 4400/7200 mean loss: 0.001809905399568379 score: 0.9742647058823529
2021-08-08 04:11:07,834 | train | INFO | Epoch 5 train batch 276/450: 4416/7200 mean loss: 0.0015717350179329515 score: 1.0
2021-08-08 04:11:08,618 | train | INFO | Epoch 5 train batch 277/450: 4432/7200 mean loss: 0.0014276180882006884 score: 1.0
2021-08-08 04:11:09,394 | train | INFO | Epoch 5 train batch 278/450: 4448/7200 mean loss: 0.0016640115063637495 score: 1.0
2021-08-08 04:11:10,185 | train | INFO | Epoch 5 train batch 279/450: 4464/7200 mean loss: 0.0015659361379221082 score: 0.996078431372549
2021-08-08 04:11:10,966 | train | INFO | Epoch 5 train batch 280/450: 4480/7200 mean loss: 0.0017101801931858063 score: 1.0
2021-08-08 04:11:11,751 | train | INFO | Epoch 5 train batch 281/450: 4496/7200 mean loss: 0.0016683446010574698 score: 1.0
2021-08-08 04:11:12,529 | train | INFO | Epoch 5 train batch 282/450: 4512/7200 mean loss: 0.001532002817839384 score: 0.9963235294117647
2021-08-08 04:11:13,419 | train | INFO | Epoch 5 train batch 283/450: 4528/7200 mean loss: 0.001563217374496162 score: 1.0
2021-08-08 04:11:14,297 | train | INFO | Epoch 5 train batch 284/450: 4544/7200 mean loss: 0.001600392977707088 score: 1.0
2021-08-08 04:11:15,115 | train | INFO | Epoch 5 train batch 285/450: 4560/7200 mean loss: 0.0016015337314456701 score: 0.9963235294117647
2021-08-08 04:11:15,883 | train | INFO | Epoch 5 train batch 286/450: 4576/7200 mean loss: 0.0015220529166981578 score: 1.0
2021-08-08 04:11:16,762 | train | INFO | Epoch 5 train batch 287/450: 4592/7200 mean loss: 0.0015687112463638186 score: 1.0
2021-08-08 04:11:17,564 | train | INFO | Epoch 5 train batch 288/450: 4608/7200 mean loss: 0.0016285724705085158 score: 0.9926470588235294
2021-08-08 04:11:18,367 | train | INFO | Epoch 5 train batch 289/450: 4624/7200 mean loss: 0.0014822346856817603 score: 1.0
2021-08-08 04:11:19,149 | train | INFO | Epoch 5 train batch 290/450: 4640/7200 mean loss: 0.0015697075286880136 score: 0.996078431372549
2021-08-08 04:11:19,967 | train | INFO | Epoch 5 train batch 291/450: 4656/7200 mean loss: 0.0016006719088181853 score: 0.8213235294117647
2021-08-08 04:11:20,746 | train | INFO | Epoch 5 train batch 292/450: 4672/7200 mean loss: 0.0016378352884203196 score: 0.9884803921568628
2021-08-08 04:11:21,531 | train | INFO | Epoch 5 train batch 293/450: 4688/7200 mean loss: 0.0014451475581154227 score: 1.0
2021-08-08 04:11:22,298 | train | INFO | Epoch 5 train batch 294/450: 4704/7200 mean loss: 0.001656592939980328 score: 1.0
2021-08-08 04:11:23,095 | train | INFO | Epoch 5 train batch 295/450: 4720/7200 mean loss: 0.0017041171668097377 score: 1.0
2021-08-08 04:11:23,893 | train | INFO | Epoch 5 train batch 296/450: 4736/7200 mean loss: 0.0015696589834988117 score: 1.0
2021-08-08 04:11:24,656 | train | INFO | Epoch 5 train batch 297/450: 4752/7200 mean loss: 0.0015771869802847505 score: 0.9963235294117647
2021-08-08 04:11:25,443 | train | INFO | Epoch 5 train batch 298/450: 4768/7200 mean loss: 0.0016568118007853627 score: 1.0
2021-08-08 04:11:26,226 | train | INFO | Epoch 5 train batch 299/450: 4784/7200 mean loss: 0.0014405003748834133 score: 1.0
2021-08-08 04:11:26,989 | train | INFO | Epoch 5 train batch 300/450: 4800/7200 mean loss: 0.001732112723402679 score: 1.0
2021-08-08 04:11:27,755 | train | INFO | Epoch 5 train batch 301/450: 4816/7200 mean loss: 0.0014330008998513222 score: 1.0
2021-08-08 04:11:28,667 | train | INFO | Epoch 5 train batch 302/450: 4832/7200 mean loss: 0.0016394667327404022 score: 1.0
2021-08-08 04:11:29,437 | train | INFO | Epoch 5 train batch 303/450: 4848/7200 mean loss: 0.001559812924824655 score: 1.0
2021-08-08 04:11:30,281 | train | INFO | Epoch 5 train batch 304/450: 4864/7200 mean loss: 0.001691520563326776 score: 0.9963235294117647
2021-08-08 04:11:31,125 | train | INFO | Epoch 5 train batch 305/450: 4880/7200 mean loss: 0.0015102706383913755 score: 0.9963235294117647
2021-08-08 04:11:31,896 | train | INFO | Epoch 5 train batch 306/450: 4896/7200 mean loss: 0.0014214720577001572 score: 1.0
2021-08-08 04:11:32,669 | train | INFO | Epoch 5 train batch 307/450: 4912/7200 mean loss: 0.0015986236976459622 score: 1.0
2021-08-08 04:11:33,468 | train | INFO | Epoch 5 train batch 308/450: 4928/7200 mean loss: 0.0016777742421254516 score: 1.0
2021-08-08 04:11:34,237 | train | INFO | Epoch 5 train batch 309/450: 4944/7200 mean loss: 0.0016820329474285245 score: 1.0
2021-08-08 04:11:35,006 | train | INFO | Epoch 5 train batch 310/450: 4960/7200 mean loss: 0.001815899508073926 score: 0.9963235294117647
2021-08-08 04:11:35,817 | train | INFO | Epoch 5 train batch 311/450: 4976/7200 mean loss: 0.001648745033890009 score: 0.9921568627450981
2021-08-08 04:11:36,596 | train | INFO | Epoch 5 train batch 312/450: 4992/7200 mean loss: 0.0015235105529427528 score: 0.9963235294117647
2021-08-08 04:11:37,368 | train | INFO | Epoch 5 train batch 313/450: 5008/7200 mean loss: 0.0014391137519851327 score: 1.0
2021-08-08 04:11:38,148 | train | INFO | Epoch 5 train batch 314/450: 5024/7200 mean loss: 0.0015798748936504126 score: 1.0
2021-08-08 04:11:38,922 | train | INFO | Epoch 5 train batch 315/450: 5040/7200 mean loss: 0.0013585664564743638 score: 1.0
2021-08-08 04:11:39,712 | train | INFO | Epoch 5 train batch 316/450: 5056/7200 mean loss: 0.0014938473468646407 score: 1.0
2021-08-08 04:11:40,507 | train | INFO | Epoch 5 train batch 317/450: 5072/7200 mean loss: 0.0014871795428916812 score: 1.0
2021-08-08 04:11:41,281 | train | INFO | Epoch 5 train batch 318/450: 5088/7200 mean loss: 0.0017208720091730356 score: 1.0
2021-08-08 04:11:42,050 | train | INFO | Epoch 5 train batch 319/450: 5104/7200 mean loss: 0.0016115265898406506 score: 1.0
2021-08-08 04:11:42,871 | train | INFO | Epoch 5 train batch 320/450: 5120/7200 mean loss: 0.0017891816096380353 score: 0.9926470588235294
2021-08-08 04:11:43,684 | train | INFO | Epoch 5 train batch 321/450: 5136/7200 mean loss: 0.0016529547283425927 score: 1.0
2021-08-08 04:11:44,455 | train | INFO | Epoch 5 train batch 322/450: 5152/7200 mean loss: 0.0017429593717679381 score: 0.9924019607843138
2021-08-08 04:11:45,231 | train | INFO | Epoch 5 train batch 323/450: 5168/7200 mean loss: 0.0016900827176868916 score: 1.0
2021-08-08 04:11:46,043 | train | INFO | Epoch 5 train batch 324/450: 5184/7200 mean loss: 0.0014036815846338868 score: 1.0
2021-08-08 04:11:46,820 | train | INFO | Epoch 5 train batch 325/450: 5200/7200 mean loss: 0.001578165334649384 score: 1.0
2021-08-08 04:11:47,608 | train | INFO | Epoch 5 train batch 326/450: 5216/7200 mean loss: 0.001469468348659575 score: 0.8842787114845939
2021-08-08 04:11:48,410 | train | INFO | Epoch 5 train batch 327/450: 5232/7200 mean loss: 0.001436903141438961 score: 1.0
2021-08-08 04:11:49,183 | train | INFO | Epoch 5 train batch 328/450: 5248/7200 mean loss: 0.0015883850865066051 score: 0.9926470588235294
2021-08-08 04:11:49,973 | train | INFO | Epoch 5 train batch 329/450: 5264/7200 mean loss: 0.0014743063366040587 score: 1.0
2021-08-08 04:11:50,771 | train | INFO | Epoch 5 train batch 330/450: 5280/7200 mean loss: 0.0014059472596272826 score: 1.0
2021-08-08 04:11:51,626 | train | INFO | Epoch 5 train batch 331/450: 5296/7200 mean loss: 0.0015499399742111564 score: 1.0
2021-08-08 04:11:52,457 | train | INFO | Epoch 5 train batch 332/450: 5312/7200 mean loss: 0.0015993403503671288 score: 1.0
2021-08-08 04:11:53,264 | train | INFO | Epoch 5 train batch 333/450: 5328/7200 mean loss: 0.0015810042386874557 score: 1.0
2021-08-08 04:11:54,042 | train | INFO | Epoch 5 train batch 334/450: 5344/7200 mean loss: 0.0013998589711263776 score: 1.0
2021-08-08 04:11:54,856 | train | INFO | Epoch 5 train batch 335/450: 5360/7200 mean loss: 0.0015258698258548975 score: 1.0
2021-08-08 04:11:55,632 | train | INFO | Epoch 5 train batch 336/450: 5376/7200 mean loss: 0.0015718312934041023 score: 1.0
2021-08-08 04:11:56,397 | train | INFO | Epoch 5 train batch 337/450: 5392/7200 mean loss: 0.0015713284956291318 score: 1.0
2021-08-08 04:11:57,207 | train | INFO | Epoch 5 train batch 338/450: 5408/7200 mean loss: 0.0015074732946231961 score: 1.0
2021-08-08 04:11:57,989 | train | INFO | Epoch 5 train batch 339/450: 5424/7200 mean loss: 0.0014717552112415433 score: 0.996078431372549
2021-08-08 04:11:58,787 | train | INFO | Epoch 5 train batch 340/450: 5440/7200 mean loss: 0.0015602476196363568 score: 0.9811274509803922
2021-08-08 04:11:59,607 | train | INFO | Epoch 5 train batch 341/450: 5456/7200 mean loss: 0.00152344920206815 score: 1.0
2021-08-08 04:12:00,435 | train | INFO | Epoch 5 train batch 342/450: 5472/7200 mean loss: 0.001551273395307362 score: 0.9963235294117647
2021-08-08 04:12:01,205 | train | INFO | Epoch 5 train batch 343/450: 5488/7200 mean loss: 0.0014848216669633985 score: 1.0
2021-08-08 04:12:02,004 | train | INFO | Epoch 5 train batch 344/450: 5504/7200 mean loss: 0.001693244674243033 score: 0.9926470588235294
2021-08-08 04:12:02,800 | train | INFO | Epoch 5 train batch 345/450: 5520/7200 mean loss: 0.0015645601088181138 score: 1.0
2021-08-08 04:12:03,605 | train | INFO | Epoch 5 train batch 346/450: 5536/7200 mean loss: 0.0015590230468660593 score: 1.0
2021-08-08 04:12:04,389 | train | INFO | Epoch 5 train batch 347/450: 5552/7200 mean loss: 0.0015439869603142142 score: 1.0
2021-08-08 04:12:05,208 | train | INFO | Epoch 5 train batch 348/450: 5568/7200 mean loss: 0.0016203075647354126 score: 1.0
2021-08-08 04:12:06,007 | train | INFO | Epoch 5 train batch 349/450: 5584/7200 mean loss: 0.0017685771454125643 score: 1.0
2021-08-08 04:12:06,823 | train | INFO | Epoch 5 train batch 350/450: 5600/7200 mean loss: 0.0014331229031085968 score: 1.0
2021-08-08 04:12:07,596 | train | INFO | Epoch 5 train batch 351/450: 5616/7200 mean loss: 0.0017492147162556648 score: 1.0
2021-08-08 04:12:08,367 | train | INFO | Epoch 5 train batch 352/450: 5632/7200 mean loss: 0.001614739652723074 score: 1.0
2021-08-08 04:12:09,190 | train | INFO | Epoch 5 train batch 353/450: 5648/7200 mean loss: 0.0015814307844266295 score: 1.0
2021-08-08 04:12:09,991 | train | INFO | Epoch 5 train batch 354/450: 5664/7200 mean loss: 0.0015167294768616557 score: 0.9963235294117647
2021-08-08 04:12:10,889 | train | INFO | Epoch 5 train batch 355/450: 5680/7200 mean loss: 0.0016156126512214541 score: 1.0
2021-08-08 04:12:11,672 | train | INFO | Epoch 5 train batch 356/450: 5696/7200 mean loss: 0.0013732268707826734 score: 0.9313725490196079
2021-08-08 04:12:12,557 | train | INFO | Epoch 5 train batch 357/450: 5712/7200 mean loss: 0.0014070222387090325 score: 1.0
2021-08-08 04:12:13,341 | train | INFO | Epoch 5 train batch 358/450: 5728/7200 mean loss: 0.0015705536352470517 score: 1.0
2021-08-08 04:12:14,156 | train | INFO | Epoch 5 train batch 359/450: 5744/7200 mean loss: 0.0014944938011467457 score: 0.9963235294117647
2021-08-08 04:12:14,961 | train | INFO | Epoch 5 train batch 360/450: 5760/7200 mean loss: 0.0014925573486834764 score: 1.0
2021-08-08 04:12:15,774 | train | INFO | Epoch 5 train batch 361/450: 5776/7200 mean loss: 0.001584140583872795 score: 1.0
2021-08-08 04:12:16,573 | train | INFO | Epoch 5 train batch 362/450: 5792/7200 mean loss: 0.0016552404267713428 score: 0.995798319327731
2021-08-08 04:12:17,395 | train | INFO | Epoch 5 train batch 363/450: 5808/7200 mean loss: 0.0015903147868812084 score: 0.9926470588235294
2021-08-08 04:12:18,165 | train | INFO | Epoch 5 train batch 364/450: 5824/7200 mean loss: 0.0014148105401545763 score: 1.0
2021-08-08 04:12:18,942 | train | INFO | Epoch 5 train batch 365/450: 5840/7200 mean loss: 0.0014965393347665668 score: 1.0
2021-08-08 04:12:19,765 | train | INFO | Epoch 5 train batch 366/450: 5856/7200 mean loss: 0.0016032643616199493 score: 1.0
2021-08-08 04:12:20,573 | train | INFO | Epoch 5 train batch 367/450: 5872/7200 mean loss: 0.0015951424138620496 score: 1.0
2021-08-08 04:12:21,403 | train | INFO | Epoch 5 train batch 368/450: 5888/7200 mean loss: 0.0016741056460887194 score: 1.0
2021-08-08 04:12:22,206 | train | INFO | Epoch 5 train batch 369/450: 5904/7200 mean loss: 0.0015268161660060287 score: 1.0
2021-08-08 04:12:23,015 | train | INFO | Epoch 5 train batch 370/450: 5920/7200 mean loss: 0.0015090641099959612 score: 1.0
2021-08-08 04:12:23,785 | train | INFO | Epoch 5 train batch 371/450: 5936/7200 mean loss: 0.0015451342333108187 score: 1.0
2021-08-08 04:12:24,565 | train | INFO | Epoch 5 train batch 372/450: 5952/7200 mean loss: 0.0014381110668182373 score: 0.9963235294117647
2021-08-08 04:12:25,360 | train | INFO | Epoch 5 train batch 373/450: 5968/7200 mean loss: 0.0015518451109528542 score: 1.0
2021-08-08 04:12:26,164 | train | INFO | Epoch 5 train batch 374/450: 5984/7200 mean loss: 0.0014426996931433678 score: 1.0
2021-08-08 04:12:26,989 | train | INFO | Epoch 5 train batch 375/450: 6000/7200 mean loss: 0.001549957669340074 score: 1.0
2021-08-08 04:12:27,785 | train | INFO | Epoch 5 train batch 376/450: 6016/7200 mean loss: 0.0014898667577654123 score: 0.9963235294117647
2021-08-08 04:12:28,575 | train | INFO | Epoch 5 train batch 377/450: 6032/7200 mean loss: 0.0015796099323779345 score: 1.0
2021-08-08 04:12:29,377 | train | INFO | Epoch 5 train batch 378/450: 6048/7200 mean loss: 0.0014910330064594746 score: 1.0
2021-08-08 04:12:30,149 | train | INFO | Epoch 5 train batch 379/450: 6064/7200 mean loss: 0.0015202081995084882 score: 1.0
2021-08-08 04:12:30,946 | train | INFO | Epoch 5 train batch 380/450: 6080/7200 mean loss: 0.0016997134080156684 score: 1.0
2021-08-08 04:12:31,757 | train | INFO | Epoch 5 train batch 381/450: 6096/7200 mean loss: 0.0015509874792769551 score: 1.0
2021-08-08 04:12:32,571 | train | INFO | Epoch 5 train batch 382/450: 6112/7200 mean loss: 0.0015404439764097333 score: 1.0
2021-08-08 04:12:33,372 | train | INFO | Epoch 5 train batch 383/450: 6128/7200 mean loss: 0.001567408791743219 score: 1.0
2021-08-08 04:12:34,166 | train | INFO | Epoch 5 train batch 384/450: 6144/7200 mean loss: 0.0016255158698186278 score: 0.9926470588235294
2021-08-08 04:12:34,957 | train | INFO | Epoch 5 train batch 385/450: 6160/7200 mean loss: 0.0015739287482574582 score: 0.9852941176470589
2021-08-08 04:12:35,766 | train | INFO | Epoch 5 train batch 386/450: 6176/7200 mean loss: 0.0016489204717800021 score: 0.970343137254902
2021-08-08 04:12:36,550 | train | INFO | Epoch 5 train batch 387/450: 6192/7200 mean loss: 0.0016831503016874194 score: 1.0
2021-08-08 04:12:37,331 | train | INFO | Epoch 5 train batch 388/450: 6208/7200 mean loss: 0.0016168870497494936 score: 1.0
2021-08-08 04:12:38,135 | train | INFO | Epoch 5 train batch 389/450: 6224/7200 mean loss: 0.0016272208886221051 score: 1.0
2021-08-08 04:12:38,959 | train | INFO | Epoch 5 train batch 390/450: 6240/7200 mean loss: 0.0014660131419077516 score: 1.0
2021-08-08 04:12:39,741 | train | INFO | Epoch 5 train batch 391/450: 6256/7200 mean loss: 0.001427996437996626 score: 0.9926470588235294
2021-08-08 04:12:40,565 | train | INFO | Epoch 5 train batch 392/450: 6272/7200 mean loss: 0.0015201440546661615 score: 1.0
2021-08-08 04:12:41,341 | train | INFO | Epoch 5 train batch 393/450: 6288/7200 mean loss: 0.001437328290194273 score: 1.0
2021-08-08 04:12:42,152 | train | INFO | Epoch 5 train batch 394/450: 6304/7200 mean loss: 0.0013430732069537044 score: 1.0
2021-08-08 04:12:42,929 | train | INFO | Epoch 5 train batch 395/450: 6320/7200 mean loss: 0.001316339592449367 score: 1.0
2021-08-08 04:12:43,703 | train | INFO | Epoch 5 train batch 396/450: 6336/7200 mean loss: 0.0014157575787976384 score: 1.0
2021-08-08 04:12:44,501 | train | INFO | Epoch 5 train batch 397/450: 6352/7200 mean loss: 0.0014507395680993795 score: 1.0
2021-08-08 04:12:45,277 | train | INFO | Epoch 5 train batch 398/450: 6368/7200 mean loss: 0.0015533013502135873 score: 0.9811274509803922
2021-08-08 04:12:46,056 | train | INFO | Epoch 5 train batch 399/450: 6384/7200 mean loss: 0.0014527328312397003 score: 1.0
2021-08-08 04:12:46,860 | train | INFO | Epoch 5 train batch 400/450: 6400/7200 mean loss: 0.0017060453537851572 score: 1.0
2021-08-08 04:12:47,654 | train | INFO | Epoch 5 train batch 401/450: 6416/7200 mean loss: 0.001594178145751357 score: 0.9963235294117647
2021-08-08 04:12:48,430 | train | INFO | Epoch 5 train batch 402/450: 6432/7200 mean loss: 0.0012450627982616425 score: 0.996078431372549
2021-08-08 04:12:49,232 | train | INFO | Epoch 5 train batch 403/450: 6448/7200 mean loss: 0.0016327063785865903 score: 1.0
2021-08-08 04:12:50,004 | train | INFO | Epoch 5 train batch 404/450: 6464/7200 mean loss: 0.0016286482568830252 score: 1.0
2021-08-08 04:12:50,774 | train | INFO | Epoch 5 train batch 405/450: 6480/7200 mean loss: 0.0014192346716299653 score: 0.9137443438914028
2021-08-08 04:12:51,566 | train | INFO | Epoch 5 train batch 406/450: 6496/7200 mean loss: 0.0015607340028509498 score: 1.0
2021-08-08 04:12:52,392 | train | INFO | Epoch 5 train batch 407/450: 6512/7200 mean loss: 0.001658974913880229 score: 0.9068627450980392
2021-08-08 04:12:53,168 | train | INFO | Epoch 5 train batch 408/450: 6528/7200 mean loss: 0.0013680915581062436 score: 1.0
2021-08-08 04:12:53,981 | train | INFO | Epoch 5 train batch 409/450: 6544/7200 mean loss: 0.0013683708384633064 score: 0.9963235294117647
2021-08-08 04:12:54,770 | train | INFO | Epoch 5 train batch 410/450: 6560/7200 mean loss: 0.0013179723173379898 score: 1.0
2021-08-08 04:12:55,556 | train | INFO | Epoch 5 train batch 411/450: 6576/7200 mean loss: 0.0016972130397334695 score: 0.9963235294117647
2021-08-08 04:12:56,333 | train | INFO | Epoch 5 train batch 412/450: 6592/7200 mean loss: 0.0013284779852256179 score: 0.9816176470588235
2021-08-08 04:12:57,305 | train | INFO | Epoch 5 train batch 413/450: 6608/7200 mean loss: 0.0013740216381847858 score: 1.0
2021-08-08 04:12:58,142 | train | INFO | Epoch 5 train batch 414/450: 6624/7200 mean loss: 0.0014162505976855755 score: 1.0
2021-08-08 04:12:58,929 | train | INFO | Epoch 5 train batch 415/450: 6640/7200 mean loss: 0.0015569519018754363 score: 1.0
2021-08-08 04:12:59,713 | train | INFO | Epoch 5 train batch 416/450: 6656/7200 mean loss: 0.0015560304746031761 score: 1.0
2021-08-08 04:13:00,490 | train | INFO | Epoch 5 train batch 417/450: 6672/7200 mean loss: 0.0016434660647064447 score: 0.9926470588235294
2021-08-08 04:13:01,273 | train | INFO | Epoch 5 train batch 418/450: 6688/7200 mean loss: 0.0015694386092945933 score: 1.0
2021-08-08 04:13:02,058 | train | INFO | Epoch 5 train batch 419/450: 6704/7200 mean loss: 0.0015694651519879699 score: 1.0
2021-08-08 04:13:02,846 | train | INFO | Epoch 5 train batch 420/450: 6720/7200 mean loss: 0.0015633120201528072 score: 1.0
2021-08-08 04:13:03,643 | train | INFO | Epoch 5 train batch 421/450: 6736/7200 mean loss: 0.0015432536602020264 score: 0.996078431372549
2021-08-08 04:13:04,422 | train | INFO | Epoch 5 train batch 422/450: 6752/7200 mean loss: 0.0014234480913728476 score: 1.0
2021-08-08 04:13:05,202 | train | INFO | Epoch 5 train batch 423/450: 6768/7200 mean loss: 0.001609348924830556 score: 1.0
2021-08-08 04:13:06,012 | train | INFO | Epoch 5 train batch 424/450: 6784/7200 mean loss: 0.0016156050842255354 score: 1.0
2021-08-08 04:13:06,789 | train | INFO | Epoch 5 train batch 425/450: 6800/7200 mean loss: 0.0015449048951268196 score: 1.0
2021-08-08 04:13:07,587 | train | INFO | Epoch 5 train batch 426/450: 6816/7200 mean loss: 0.0015023245941847563 score: 1.0
2021-08-08 04:13:08,409 | train | INFO | Epoch 5 train batch 427/450: 6832/7200 mean loss: 0.0017139231786131859 score: 0.9666666666666667
2021-08-08 04:13:09,196 | train | INFO | Epoch 5 train batch 428/450: 6848/7200 mean loss: 0.001452416181564331 score: 1.0
2021-08-08 04:13:09,979 | train | INFO | Epoch 5 train batch 429/450: 6864/7200 mean loss: 0.001587002188898623 score: 1.0
2021-08-08 04:13:10,793 | train | INFO | Epoch 5 train batch 430/450: 6880/7200 mean loss: 0.0015783781418576837 score: 1.0
2021-08-08 04:13:11,582 | train | INFO | Epoch 5 train batch 431/450: 6896/7200 mean loss: 0.001759913982823491 score: 0.9522058823529411
2021-08-08 04:13:12,357 | train | INFO | Epoch 5 train batch 432/450: 6912/7200 mean loss: 0.0014696057187393308 score: 1.0
2021-08-08 04:13:13,124 | train | INFO | Epoch 5 train batch 433/450: 6928/7200 mean loss: 0.0015426876489073038 score: 0.9963235294117647
2021-08-08 04:13:13,925 | train | INFO | Epoch 5 train batch 434/450: 6944/7200 mean loss: 0.0016350506339222193 score: 1.0
2021-08-08 04:13:14,695 | train | INFO | Epoch 5 train batch 435/450: 6960/7200 mean loss: 0.001511867973022163 score: 1.0
2021-08-08 04:13:15,500 | train | INFO | Epoch 5 train batch 436/450: 6976/7200 mean loss: 0.0014887256547808647 score: 1.0
2021-08-08 04:13:16,276 | train | INFO | Epoch 5 train batch 437/450: 6992/7200 mean loss: 0.0015953900292515755 score: 1.0
2021-08-08 04:13:17,053 | train | INFO | Epoch 5 train batch 438/450: 7008/7200 mean loss: 0.001721485867165029 score: 1.0
2021-08-08 04:13:17,818 | train | INFO | Epoch 5 train batch 439/450: 7024/7200 mean loss: 0.0015990199754014611 score: 0.9926470588235294
2021-08-08 04:13:18,584 | train | INFO | Epoch 5 train batch 440/450: 7040/7200 mean loss: 0.0016240986296907067 score: 0.9921218487394957
2021-08-08 04:13:19,372 | train | INFO | Epoch 5 train batch 441/450: 7056/7200 mean loss: 0.001673431950621307 score: 0.9816176470588235
2021-08-08 04:13:20,148 | train | INFO | Epoch 5 train batch 442/450: 7072/7200 mean loss: 0.0016319039277732372 score: 1.0
2021-08-08 04:13:20,912 | train | INFO | Epoch 5 train batch 443/450: 7088/7200 mean loss: 0.0017273492412641644 score: 0.7791666666666667
2021-08-08 04:13:21,677 | train | INFO | Epoch 5 train batch 444/450: 7104/7200 mean loss: 0.001437427825294435 score: 1.0
2021-08-08 04:13:22,442 | train | INFO | Epoch 5 train batch 445/450: 7120/7200 mean loss: 0.00141145137604326 score: 1.0
2021-08-08 04:13:23,209 | train | INFO | Epoch 5 train batch 446/450: 7136/7200 mean loss: 0.0013822218170389533 score: 1.0
2021-08-08 04:13:23,983 | train | INFO | Epoch 5 train batch 447/450: 7152/7200 mean loss: 0.0015011403011158109 score: 1.0
2021-08-08 04:13:24,757 | train | INFO | Epoch 5 train batch 448/450: 7168/7200 mean loss: 0.0013291117502376437 score: 1.0
2021-08-08 04:13:25,526 | train | INFO | Epoch 5 train batch 449/450: 7184/7200 mean loss: 0.0014072188641875982 score: 1.0
2021-08-08 04:13:25,676 | train | INFO | Epoch 5, Train, Mean loss: 0.024748336780402395, Score: 0.9906985324044146
2021-08-08 04:13:27,074 | train | INFO | Epoch 5 validation batch 0/113: 0/1800 mean loss: 0.0010882150381803513 score: 1.0
2021-08-08 04:13:27,318 | train | INFO | Epoch 5 validation batch 1/113: 16/1800 mean loss: 0.0010798125294968486 score: 0.9926470588235294
2021-08-08 04:13:27,549 | train | INFO | Epoch 5 validation batch 2/113: 32/1800 mean loss: 0.0013642562553286552 score: 1.0
2021-08-08 04:13:27,795 | train | INFO | Epoch 5 validation batch 3/113: 48/1800 mean loss: 0.0012501877499744296 score: 1.0
2021-08-08 04:13:28,043 | train | INFO | Epoch 5 validation batch 4/113: 64/1800 mean loss: 0.0010893933940678835 score: 1.0
2021-08-08 04:13:28,301 | train | INFO | Epoch 5 validation batch 5/113: 80/1800 mean loss: 0.0010985223343595862 score: 1.0
2021-08-08 04:13:28,542 | train | INFO | Epoch 5 validation batch 6/113: 96/1800 mean loss: 0.0010654745856299996 score: 1.0
2021-08-08 04:13:28,773 | train | INFO | Epoch 5 validation batch 7/113: 112/1800 mean loss: 0.001226666383445263 score: 1.0
2021-08-08 04:13:29,004 | train | INFO | Epoch 5 validation batch 8/113: 128/1800 mean loss: 0.0011759770568460226 score: 1.0
2021-08-08 04:13:29,255 | train | INFO | Epoch 5 validation batch 9/113: 144/1800 mean loss: 0.001108607742935419 score: 1.0
2021-08-08 04:13:29,488 | train | INFO | Epoch 5 validation batch 10/113: 160/1800 mean loss: 0.0011604147730395198 score: 0.9816176470588235
2021-08-08 04:13:29,721 | train | INFO | Epoch 5 validation batch 11/113: 176/1800 mean loss: 0.0012310153106227517 score: 0.9926470588235294
2021-08-08 04:13:29,997 | train | INFO | Epoch 5 validation batch 12/113: 192/1800 mean loss: 0.0011426000855863094 score: 1.0
2021-08-08 04:13:30,281 | train | INFO | Epoch 5 validation batch 13/113: 208/1800 mean loss: 0.0010899045737460256 score: 1.0
2021-08-08 04:13:30,515 | train | INFO | Epoch 5 validation batch 14/113: 224/1800 mean loss: 0.0010021647904068232 score: 1.0
2021-08-08 04:13:30,749 | train | INFO | Epoch 5 validation batch 15/113: 240/1800 mean loss: 0.001109410310164094 score: 1.0
2021-08-08 04:13:30,981 | train | INFO | Epoch 5 validation batch 16/113: 256/1800 mean loss: 0.0011192590463906527 score: 1.0
2021-08-08 04:13:31,229 | train | INFO | Epoch 5 validation batch 17/113: 272/1800 mean loss: 0.0012511280365288258 score: 1.0
2021-08-08 04:13:31,460 | train | INFO | Epoch 5 validation batch 18/113: 288/1800 mean loss: 0.0009436916443519294 score: 1.0
2021-08-08 04:13:31,691 | train | INFO | Epoch 5 validation batch 19/113: 304/1800 mean loss: 0.001122863031923771 score: 1.0
2021-08-08 04:13:31,923 | train | INFO | Epoch 5 validation batch 20/113: 320/1800 mean loss: 0.0012357212835922837 score: 0.9887254901960785
2021-08-08 04:13:32,176 | train | INFO | Epoch 5 validation batch 21/113: 336/1800 mean loss: 0.0010747070191428065 score: 1.0
2021-08-08 04:13:32,417 | train | INFO | Epoch 5 validation batch 22/113: 352/1800 mean loss: 0.001051684026606381 score: 1.0
2021-08-08 04:13:32,661 | train | INFO | Epoch 5 validation batch 23/113: 368/1800 mean loss: 0.0010415182914584875 score: 1.0
2021-08-08 04:13:32,892 | train | INFO | Epoch 5 validation batch 24/113: 384/1800 mean loss: 0.0010730725480243564 score: 1.0
2021-08-08 04:13:33,136 | train | INFO | Epoch 5 validation batch 25/113: 400/1800 mean loss: 0.0011871039168909192 score: 1.0
2021-08-08 04:13:33,371 | train | INFO | Epoch 5 validation batch 26/113: 416/1800 mean loss: 0.0010231089545413852 score: 1.0
2021-08-08 04:13:33,601 | train | INFO | Epoch 5 validation batch 27/113: 432/1800 mean loss: 0.0012159186881035566 score: 1.0
2021-08-08 04:13:33,846 | train | INFO | Epoch 5 validation batch 28/113: 448/1800 mean loss: 0.0011268352391198277 score: 1.0
2021-08-08 04:13:34,104 | train | INFO | Epoch 5 validation batch 29/113: 464/1800 mean loss: 0.0011259125312790275 score: 1.0
2021-08-08 04:13:34,345 | train | INFO | Epoch 5 validation batch 30/113: 480/1800 mean loss: 0.0011449086014181376 score: 1.0
2021-08-08 04:13:34,574 | train | INFO | Epoch 5 validation batch 31/113: 496/1800 mean loss: 0.0010644755093380809 score: 1.0
2021-08-08 04:13:34,804 | train | INFO | Epoch 5 validation batch 32/113: 512/1800 mean loss: 0.0011095470981672406 score: 0.9926470588235294
2021-08-08 04:13:35,054 | train | INFO | Epoch 5 validation batch 33/113: 528/1800 mean loss: 0.0010341560700908303 score: 1.0
2021-08-08 04:13:35,305 | train | INFO | Epoch 5 validation batch 34/113: 544/1800 mean loss: 0.0008581187576055527 score: 1.0
2021-08-08 04:13:35,546 | train | INFO | Epoch 5 validation batch 35/113: 560/1800 mean loss: 0.0012196358293294907 score: 1.0
2021-08-08 04:13:35,793 | train | INFO | Epoch 5 validation batch 36/113: 576/1800 mean loss: 0.001211286406032741 score: 0.9107843137254903
2021-08-08 04:13:36,024 | train | INFO | Epoch 5 validation batch 37/113: 592/1800 mean loss: 0.0009270377340726554 score: 1.0
2021-08-08 04:13:36,255 | train | INFO | Epoch 5 validation batch 38/113: 608/1800 mean loss: 0.001176523626782 score: 1.0
2021-08-08 04:13:36,499 | train | INFO | Epoch 5 validation batch 39/113: 624/1800 mean loss: 0.001086766947992146 score: 1.0
2021-08-08 04:13:36,733 | train | INFO | Epoch 5 validation batch 40/113: 640/1800 mean loss: 0.0011627769563347101 score: 1.0
2021-08-08 04:13:36,966 | train | INFO | Epoch 5 validation batch 41/113: 656/1800 mean loss: 0.0010544691467657685 score: 1.0
2021-08-08 04:13:37,197 | train | INFO | Epoch 5 validation batch 42/113: 672/1800 mean loss: 0.00108369963709265 score: 1.0
2021-08-08 04:13:37,459 | train | INFO | Epoch 5 validation batch 43/113: 688/1800 mean loss: 0.0011014352785423398 score: 1.0
2021-08-08 04:13:37,690 | train | INFO | Epoch 5 validation batch 44/113: 704/1800 mean loss: 0.00132792501244694 score: 0.9669117647058824
2021-08-08 04:13:37,933 | train | INFO | Epoch 5 validation batch 45/113: 720/1800 mean loss: 0.0011449474841356277 score: 1.0
2021-08-08 04:13:38,177 | train | INFO | Epoch 5 validation batch 46/113: 736/1800 mean loss: 0.0011341830249875784 score: 0.9889705882352942
2021-08-08 04:13:38,419 | train | INFO | Epoch 5 validation batch 47/113: 752/1800 mean loss: 0.0010241103591397405 score: 1.0
2021-08-08 04:13:38,651 | train | INFO | Epoch 5 validation batch 48/113: 768/1800 mean loss: 0.0010720838326960802 score: 1.0
2021-08-08 04:13:38,897 | train | INFO | Epoch 5 validation batch 49/113: 784/1800 mean loss: 0.0011188331991434097 score: 1.0
2021-08-08 04:13:39,128 | train | INFO | Epoch 5 validation batch 50/113: 800/1800 mean loss: 0.0010472621070221066 score: 0.9963235294117647
2021-08-08 04:13:39,378 | train | INFO | Epoch 5 validation batch 51/113: 816/1800 mean loss: 0.0011663443874567747 score: 0.9889705882352942
2021-08-08 04:13:39,610 | train | INFO | Epoch 5 validation batch 52/113: 832/1800 mean loss: 0.001160666812211275 score: 1.0
2021-08-08 04:13:39,863 | train | INFO | Epoch 5 validation batch 53/113: 848/1800 mean loss: 0.00110060244332999 score: 1.0
2021-08-08 04:13:40,112 | train | INFO | Epoch 5 validation batch 54/113: 864/1800 mean loss: 0.0010724134044721723 score: 1.0
2021-08-08 04:13:40,358 | train | INFO | Epoch 5 validation batch 55/113: 880/1800 mean loss: 0.0011519943363964558 score: 1.0
2021-08-08 04:13:40,591 | train | INFO | Epoch 5 validation batch 56/113: 896/1800 mean loss: 0.0010826211655512452 score: 1.0
2021-08-08 04:13:40,825 | train | INFO | Epoch 5 validation batch 57/113: 912/1800 mean loss: 0.0012279367074370384 score: 1.0
2021-08-08 04:13:41,058 | train | INFO | Epoch 5 validation batch 58/113: 928/1800 mean loss: 0.0012081246823072433 score: 0.9816176470588235
2021-08-08 04:13:41,293 | train | INFO | Epoch 5 validation batch 59/113: 944/1800 mean loss: 0.001086025033146143 score: 1.0
2021-08-08 04:13:41,533 | train | INFO | Epoch 5 validation batch 60/113: 960/1800 mean loss: 0.0009536319994367659 score: 1.0
2021-08-08 04:13:41,784 | train | INFO | Epoch 5 validation batch 61/113: 976/1800 mean loss: 0.001027255435474217 score: 1.0
2021-08-08 04:13:42,063 | train | INFO | Epoch 5 validation batch 62/113: 992/1800 mean loss: 0.0010768257780000567 score: 1.0
2021-08-08 04:13:42,311 | train | INFO | Epoch 5 validation batch 63/113: 1008/1800 mean loss: 0.0010464913211762905 score: 1.0
2021-08-08 04:13:42,544 | train | INFO | Epoch 5 validation batch 64/113: 1024/1800 mean loss: 0.0011625366751104593 score: 1.0
2021-08-08 04:13:42,784 | train | INFO | Epoch 5 validation batch 65/113: 1040/1800 mean loss: 0.0011297183809801936 score: 1.0
2021-08-08 04:13:43,036 | train | INFO | Epoch 5 validation batch 66/113: 1056/1800 mean loss: 0.0011475912760943174 score: 0.9963235294117647
2021-08-08 04:13:43,268 | train | INFO | Epoch 5 validation batch 67/113: 1072/1800 mean loss: 0.0012004744494333863 score: 1.0
2021-08-08 04:13:43,516 | train | INFO | Epoch 5 validation batch 68/113: 1088/1800 mean loss: 0.0009669421706348658 score: 1.0
2021-08-08 04:13:43,748 | train | INFO | Epoch 5 validation batch 69/113: 1104/1800 mean loss: 0.0010948553681373596 score: 1.0
2021-08-08 04:13:43,979 | train | INFO | Epoch 5 validation batch 70/113: 1120/1800 mean loss: 0.0012232769513502717 score: 0.9926470588235294
2021-08-08 04:13:44,211 | train | INFO | Epoch 5 validation batch 71/113: 1136/1800 mean loss: 0.0010478213662281632 score: 1.0
2021-08-08 04:13:44,478 | train | INFO | Epoch 5 validation batch 72/113: 1152/1800 mean loss: 0.0010709271300584078 score: 1.0
2021-08-08 04:13:44,727 | train | INFO | Epoch 5 validation batch 73/113: 1168/1800 mean loss: 0.0012683800887316465 score: 1.0
2021-08-08 04:13:44,958 | train | INFO | Epoch 5 validation batch 74/113: 1184/1800 mean loss: 0.0011499858228489757 score: 1.0
2021-08-08 04:13:45,234 | train | INFO | Epoch 5 validation batch 75/113: 1200/1800 mean loss: 0.0010628965683281422 score: 1.0
2021-08-08 04:13:45,464 | train | INFO | Epoch 5 validation batch 76/113: 1216/1800 mean loss: 0.0009862059960141778 score: 1.0
2021-08-08 04:13:45,694 | train | INFO | Epoch 5 validation batch 77/113: 1232/1800 mean loss: 0.0009885146282613277 score: 1.0
2021-08-08 04:13:45,930 | train | INFO | Epoch 5 validation batch 78/113: 1248/1800 mean loss: 0.0011248280061408877 score: 0.9730042016806723
2021-08-08 04:13:46,168 | train | INFO | Epoch 5 validation batch 79/113: 1264/1800 mean loss: 0.001189586822874844 score: 0.9921568627450981
2021-08-08 04:13:46,422 | train | INFO | Epoch 5 validation batch 80/113: 1280/1800 mean loss: 0.0013044476509094238 score: 1.0
2021-08-08 04:13:46,659 | train | INFO | Epoch 5 validation batch 81/113: 1296/1800 mean loss: 0.0010991591261699796 score: 1.0
2021-08-08 04:13:46,888 | train | INFO | Epoch 5 validation batch 82/113: 1312/1800 mean loss: 0.001044404343701899 score: 1.0
2021-08-08 04:13:47,119 | train | INFO | Epoch 5 validation batch 83/113: 1328/1800 mean loss: 0.0012289363658055663 score: 1.0
2021-08-08 04:13:47,372 | train | INFO | Epoch 5 validation batch 84/113: 1344/1800 mean loss: 0.0012503396719694138 score: 0.9816176470588235
2021-08-08 04:13:47,606 | train | INFO | Epoch 5 validation batch 85/113: 1360/1800 mean loss: 0.0011782321380451322 score: 1.0
2021-08-08 04:13:47,838 | train | INFO | Epoch 5 validation batch 86/113: 1376/1800 mean loss: 0.0013690568739548326 score: 1.0
2021-08-08 04:13:48,084 | train | INFO | Epoch 5 validation batch 87/113: 1392/1800 mean loss: 0.0012381515698507428 score: 1.0
2021-08-08 04:13:48,323 | train | INFO | Epoch 5 validation batch 88/113: 1408/1800 mean loss: 0.0010818012524396181 score: 1.0
2021-08-08 04:13:48,580 | train | INFO | Epoch 5 validation batch 89/113: 1424/1800 mean loss: 0.0009738907101564109 score: 1.0
2021-08-08 04:13:48,811 | train | INFO | Epoch 5 validation batch 90/113: 1440/1800 mean loss: 0.001089498633518815 score: 1.0
2021-08-08 04:13:49,043 | train | INFO | Epoch 5 validation batch 91/113: 1456/1800 mean loss: 0.0013010288821533322 score: 1.0
2021-08-08 04:13:49,273 | train | INFO | Epoch 5 validation batch 92/113: 1472/1800 mean loss: 0.0011334746377542615 score: 1.0
2021-08-08 04:13:49,505 | train | INFO | Epoch 5 validation batch 93/113: 1488/1800 mean loss: 0.001112486468628049 score: 1.0
2021-08-08 04:13:49,746 | train | INFO | Epoch 5 validation batch 94/113: 1504/1800 mean loss: 0.0011183556634932756 score: 1.0
2021-08-08 04:13:49,987 | train | INFO | Epoch 5 validation batch 95/113: 1520/1800 mean loss: 0.00117377785500139 score: 1.0
2021-08-08 04:13:50,218 | train | INFO | Epoch 5 validation batch 96/113: 1536/1800 mean loss: 0.0011989225167781115 score: 0.9926470588235294
2021-08-08 04:13:50,466 | train | INFO | Epoch 5 validation batch 97/113: 1552/1800 mean loss: 0.0011355732567608356 score: 1.0
2021-08-08 04:13:50,703 | train | INFO | Epoch 5 validation batch 98/113: 1568/1800 mean loss: 0.0011360134230926633 score: 1.0
2021-08-08 04:13:50,941 | train | INFO | Epoch 5 validation batch 99/113: 1584/1800 mean loss: 0.0010532538872212172 score: 1.0
2021-08-08 04:13:51,189 | train | INFO | Epoch 5 validation batch 100/113: 1600/1800 mean loss: 0.0012840221170336008 score: 1.0
2021-08-08 04:13:51,421 | train | INFO | Epoch 5 validation batch 101/113: 1616/1800 mean loss: 0.0011074540670961142 score: 1.0
2021-08-08 04:13:51,652 | train | INFO | Epoch 5 validation batch 102/113: 1632/1800 mean loss: 0.0010492493165656924 score: 1.0
2021-08-08 04:13:51,883 | train | INFO | Epoch 5 validation batch 103/113: 1648/1800 mean loss: 0.0010623985435813665 score: 1.0
2021-08-08 04:13:52,113 | train | INFO | Epoch 5 validation batch 104/113: 1664/1800 mean loss: 0.0011893785558640957 score: 1.0
2021-08-08 04:13:52,344 | train | INFO | Epoch 5 validation batch 105/113: 1680/1800 mean loss: 0.0011471551842987537 score: 1.0
2021-08-08 04:13:52,575 | train | INFO | Epoch 5 validation batch 106/113: 1696/1800 mean loss: 0.0011531973723322153 score: 1.0
2021-08-08 04:13:52,806 | train | INFO | Epoch 5 validation batch 107/113: 1712/1800 mean loss: 0.0013597514480352402 score: 1.0
2021-08-08 04:13:53,037 | train | INFO | Epoch 5 validation batch 108/113: 1728/1800 mean loss: 0.0013172387843951583 score: 1.0
2021-08-08 04:13:53,268 | train | INFO | Epoch 5 validation batch 109/113: 1744/1800 mean loss: 0.001263254671357572 score: 1.0
2021-08-08 04:13:53,499 | train | INFO | Epoch 5 validation batch 110/113: 1760/1800 mean loss: 0.0010180661920458078 score: 1.0
2021-08-08 04:13:53,730 | train | INFO | Epoch 5 validation batch 111/113: 1776/1800 mean loss: 0.0011225549969822168 score: 1.0
2021-08-08 04:13:53,894 | train | INFO | Epoch 5 validation batch 112/113: 1792/1800 mean loss: 0.0009605300729162991 score: 1.0
2021-08-08 04:13:54,037 | train | INFO | Epoch 5, Validation, Mean loss: 0.01804033433606403, Score: 0.9974359212711632
2021-08-08 04:13:54,037 | train | INFO | Write row 5
2021-08-08 04:13:56,773 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:13:56,776 | train | INFO | Update best record row 6, checkpoints 0.019194829590882347 -> 0.01804033433606403
2021-08-08 04:13:58,736 | train | INFO | Epoch 6 train batch 0/450: 0/7200 mean loss: 0.0013998025096952915 score: 1.0
2021-08-08 04:13:59,572 | train | INFO | Epoch 6 train batch 1/450: 16/7200 mean loss: 0.0014100593980401754 score: 0.9963235294117647
2021-08-08 04:14:00,359 | train | INFO | Epoch 6 train batch 2/450: 32/7200 mean loss: 0.001579679548740387 score: 1.0
2021-08-08 04:14:01,177 | train | INFO | Epoch 6 train batch 3/450: 48/7200 mean loss: 0.0015186776872724295 score: 0.9924019607843138
2021-08-08 04:14:02,005 | train | INFO | Epoch 6 train batch 4/450: 64/7200 mean loss: 0.0012609371915459633 score: 1.0
2021-08-08 04:14:02,870 | train | INFO | Epoch 6 train batch 5/450: 80/7200 mean loss: 0.0014859323855489492 score: 1.0
2021-08-08 04:14:03,671 | train | INFO | Epoch 6 train batch 6/450: 96/7200 mean loss: 0.0015161456540226936 score: 1.0
2021-08-08 04:14:04,452 | train | INFO | Epoch 6 train batch 7/450: 112/7200 mean loss: 0.0017006841953843832 score: 1.0
2021-08-08 04:14:05,237 | train | INFO | Epoch 6 train batch 8/450: 128/7200 mean loss: 0.0014669632073491812 score: 0.9852941176470589
2021-08-08 04:14:06,036 | train | INFO | Epoch 6 train batch 9/450: 144/7200 mean loss: 0.001624532276764512 score: 1.0
2021-08-08 04:14:06,870 | train | INFO | Epoch 6 train batch 10/450: 160/7200 mean loss: 0.0013784522889181972 score: 1.0
2021-08-08 04:14:07,692 | train | INFO | Epoch 6 train batch 11/450: 176/7200 mean loss: 0.0014269493985921144 score: 1.0
2021-08-08 04:14:08,508 | train | INFO | Epoch 6 train batch 12/450: 192/7200 mean loss: 0.0014344908995553851 score: 0.995798319327731
2021-08-08 04:14:09,280 | train | INFO | Epoch 6 train batch 13/450: 208/7200 mean loss: 0.001448183786123991 score: 1.0
2021-08-08 04:14:10,150 | train | INFO | Epoch 6 train batch 14/450: 224/7200 mean loss: 0.0015835602534934878 score: 1.0
2021-08-08 04:14:10,941 | train | INFO | Epoch 6 train batch 15/450: 240/7200 mean loss: 0.001541268895380199 score: 0.7536764705882353
2021-08-08 04:14:11,748 | train | INFO | Epoch 6 train batch 16/450: 256/7200 mean loss: 0.001574601628817618 score: 1.0
2021-08-08 04:14:12,561 | train | INFO | Epoch 6 train batch 17/450: 272/7200 mean loss: 0.0015532871475443244 score: 1.0
2021-08-08 04:14:13,356 | train | INFO | Epoch 6 train batch 18/450: 288/7200 mean loss: 0.0014576552202925086 score: 0.9963235294117647
2021-08-08 04:14:14,134 | train | INFO | Epoch 6 train batch 19/450: 304/7200 mean loss: 0.00159369851462543 score: 1.0
2021-08-08 04:14:14,920 | train | INFO | Epoch 6 train batch 20/450: 320/7200 mean loss: 0.0015186140080913901 score: 0.9963235294117647
2021-08-08 04:14:15,698 | train | INFO | Epoch 6 train batch 21/450: 336/7200 mean loss: 0.001462394604459405 score: 1.0
2021-08-08 04:14:16,468 | train | INFO | Epoch 6 train batch 22/450: 352/7200 mean loss: 0.0015495222760364413 score: 1.0
2021-08-08 04:14:17,262 | train | INFO | Epoch 6 train batch 23/450: 368/7200 mean loss: 0.00166366808116436 score: 1.0
2021-08-08 04:14:18,072 | train | INFO | Epoch 6 train batch 24/450: 384/7200 mean loss: 0.001627476536668837 score: 1.0
2021-08-08 04:14:18,850 | train | INFO | Epoch 6 train batch 25/450: 400/7200 mean loss: 0.001436536549590528 score: 1.0
2021-08-08 04:14:19,635 | train | INFO | Epoch 6 train batch 26/450: 416/7200 mean loss: 0.0016256306553259492 score: 1.0
2021-08-08 04:14:20,408 | train | INFO | Epoch 6 train batch 27/450: 432/7200 mean loss: 0.0015812193742021918 score: 0.9779411764705882
2021-08-08 04:14:21,194 | train | INFO | Epoch 6 train batch 28/450: 448/7200 mean loss: 0.001732888980768621 score: 1.0
2021-08-08 04:14:22,024 | train | INFO | Epoch 6 train batch 29/450: 464/7200 mean loss: 0.001577015733346343 score: 1.0
2021-08-08 04:14:22,838 | train | INFO | Epoch 6 train batch 30/450: 480/7200 mean loss: 0.001643613213673234 score: 1.0
2021-08-08 04:14:23,646 | train | INFO | Epoch 6 train batch 31/450: 496/7200 mean loss: 0.0015164396027103066 score: 1.0
2021-08-08 04:14:24,434 | train | INFO | Epoch 6 train batch 32/450: 512/7200 mean loss: 0.0015271931188181043 score: 1.0
2021-08-08 04:14:25,226 | train | INFO | Epoch 6 train batch 33/450: 528/7200 mean loss: 0.0016383157344534993 score: 1.0
2021-08-08 04:14:26,065 | train | INFO | Epoch 6 train batch 34/450: 544/7200 mean loss: 0.0018263834062963724 score: 0.9963235294117647
2021-08-08 04:14:26,849 | train | INFO | Epoch 6 train batch 35/450: 560/7200 mean loss: 0.00165980972815305 score: 1.0
2021-08-08 04:14:27,676 | train | INFO | Epoch 6 train batch 36/450: 576/7200 mean loss: 0.0014566108584403992 score: 1.0
2021-08-08 04:14:28,479 | train | INFO | Epoch 6 train batch 37/450: 592/7200 mean loss: 0.0014896817738190293 score: 1.0
2021-08-08 04:14:29,252 | train | INFO | Epoch 6 train batch 38/450: 608/7200 mean loss: 0.0013527288101613522 score: 0.9926470588235294
2021-08-08 04:14:30,075 | train | INFO | Epoch 6 train batch 39/450: 624/7200 mean loss: 0.0014243829064071178 score: 1.0
2021-08-08 04:14:30,849 | train | INFO | Epoch 6 train batch 40/450: 640/7200 mean loss: 0.0014781627105548978 score: 0.9963235294117647
2021-08-08 04:14:31,615 | train | INFO | Epoch 6 train batch 41/450: 656/7200 mean loss: 0.0014361300272867084 score: 1.0
2021-08-08 04:14:32,396 | train | INFO | Epoch 6 train batch 42/450: 672/7200 mean loss: 0.001538196112960577 score: 1.0
2021-08-08 04:14:33,167 | train | INFO | Epoch 6 train batch 43/450: 688/7200 mean loss: 0.00143837567884475 score: 0.9963235294117647
2021-08-08 04:14:33,981 | train | INFO | Epoch 6 train batch 44/450: 704/7200 mean loss: 0.001370626618154347 score: 1.0
2021-08-08 04:14:34,782 | train | INFO | Epoch 6 train batch 45/450: 720/7200 mean loss: 0.0014925356954336166 score: 1.0
2021-08-08 04:14:35,590 | train | INFO | Epoch 6 train batch 46/450: 736/7200 mean loss: 0.001445187022909522 score: 1.0
2021-08-08 04:14:36,403 | train | INFO | Epoch 6 train batch 47/450: 752/7200 mean loss: 0.0015395875088870525 score: 1.0
2021-08-08 04:14:37,205 | train | INFO | Epoch 6 train batch 48/450: 768/7200 mean loss: 0.0015011730138212442 score: 0.9622549019607843
2021-08-08 04:14:37,977 | train | INFO | Epoch 6 train batch 49/450: 784/7200 mean loss: 0.0015117349103093147 score: 1.0
2021-08-08 04:14:38,754 | train | INFO | Epoch 6 train batch 50/450: 800/7200 mean loss: 0.0014325656229630113 score: 1.0
2021-08-08 04:14:39,560 | train | INFO | Epoch 6 train batch 51/450: 816/7200 mean loss: 0.0014526695013046265 score: 1.0
2021-08-08 04:14:40,380 | train | INFO | Epoch 6 train batch 52/450: 832/7200 mean loss: 0.001363035524263978 score: 1.0
2021-08-08 04:14:41,171 | train | INFO | Epoch 6 train batch 53/450: 848/7200 mean loss: 0.0013601694954559207 score: 1.0
2021-08-08 04:14:41,975 | train | INFO | Epoch 6 train batch 54/450: 864/7200 mean loss: 0.001440252992324531 score: 1.0
2021-08-08 04:14:42,798 | train | INFO | Epoch 6 train batch 55/450: 880/7200 mean loss: 0.0014166533946990967 score: 0.996078431372549
2021-08-08 04:14:43,570 | train | INFO | Epoch 6 train batch 56/450: 896/7200 mean loss: 0.0013755466789007187 score: 1.0
2021-08-08 04:14:44,338 | train | INFO | Epoch 6 train batch 57/450: 912/7200 mean loss: 0.001352591090835631 score: 1.0
2021-08-08 04:14:45,224 | train | INFO | Epoch 6 train batch 58/450: 928/7200 mean loss: 0.0015056682750582695 score: 1.0
2021-08-08 04:14:46,119 | train | INFO | Epoch 6 train batch 59/450: 944/7200 mean loss: 0.0013170897727832198 score: 0.9847689075630252
2021-08-08 04:14:46,946 | train | INFO | Epoch 6 train batch 60/450: 960/7200 mean loss: 0.0015677482588216662 score: 1.0
2021-08-08 04:14:47,740 | train | INFO | Epoch 6 train batch 61/450: 976/7200 mean loss: 0.0015794128412380815 score: 1.0
2021-08-08 04:14:48,518 | train | INFO | Epoch 6 train batch 62/450: 992/7200 mean loss: 0.001713076839223504 score: 1.0
2021-08-08 04:14:49,299 | train | INFO | Epoch 6 train batch 63/450: 1008/7200 mean loss: 0.0014710279647260904 score: 1.0
2021-08-08 04:14:50,076 | train | INFO | Epoch 6 train batch 64/450: 1024/7200 mean loss: 0.0017452497268095613 score: 0.9924019607843138
2021-08-08 04:14:50,891 | train | INFO | Epoch 6 train batch 65/450: 1040/7200 mean loss: 0.001726619084365666 score: 0.9517156862745099
2021-08-08 04:14:51,782 | train | INFO | Epoch 6 train batch 66/450: 1056/7200 mean loss: 0.0014017859939485788 score: 0.9924019607843138
2021-08-08 04:14:52,565 | train | INFO | Epoch 6 train batch 67/450: 1072/7200 mean loss: 0.0014696825528517365 score: 1.0
2021-08-08 04:14:53,356 | train | INFO | Epoch 6 train batch 68/450: 1088/7200 mean loss: 0.0014247384387999773 score: 1.0
2021-08-08 04:14:54,168 | train | INFO | Epoch 6 train batch 69/450: 1104/7200 mean loss: 0.0015459934948012233 score: 1.0
2021-08-08 04:14:54,931 | train | INFO | Epoch 6 train batch 70/450: 1120/7200 mean loss: 0.0015967569779604673 score: 0.9963235294117647
2021-08-08 04:14:55,719 | train | INFO | Epoch 6 train batch 71/450: 1136/7200 mean loss: 0.001213299809023738 score: 0.996078431372549
2021-08-08 04:14:56,624 | train | INFO | Epoch 6 train batch 72/450: 1152/7200 mean loss: 0.0013238422106951475 score: 1.0
2021-08-08 04:14:57,404 | train | INFO | Epoch 6 train batch 73/450: 1168/7200 mean loss: 0.0014557455433532596 score: 1.0
2021-08-08 04:14:58,221 | train | INFO | Epoch 6 train batch 74/450: 1184/7200 mean loss: 0.0015284968540072441 score: 1.0
2021-08-08 04:14:59,037 | train | INFO | Epoch 6 train batch 75/450: 1200/7200 mean loss: 0.001488995272666216 score: 1.0
2021-08-08 04:14:59,856 | train | INFO | Epoch 6 train batch 76/450: 1216/7200 mean loss: 0.0016316466499119997 score: 1.0
2021-08-08 04:15:00,633 | train | INFO | Epoch 6 train batch 77/450: 1232/7200 mean loss: 0.0014616282423958182 score: 1.0
2021-08-08 04:15:01,417 | train | INFO | Epoch 6 train batch 78/450: 1248/7200 mean loss: 0.00152429542504251 score: 0.9963235294117647
2021-08-08 04:15:02,219 | train | INFO | Epoch 6 train batch 79/450: 1264/7200 mean loss: 0.0014153934316709638 score: 1.0
2021-08-08 04:15:02,999 | train | INFO | Epoch 6 train batch 80/450: 1280/7200 mean loss: 0.00147661950904876 score: 1.0
2021-08-08 04:15:03,827 | train | INFO | Epoch 6 train batch 81/450: 1296/7200 mean loss: 0.0016414365964010358 score: 1.0
2021-08-08 04:15:04,605 | train | INFO | Epoch 6 train batch 82/450: 1312/7200 mean loss: 0.0014683374902233481 score: 0.9805672268907564
2021-08-08 04:15:05,375 | train | INFO | Epoch 6 train batch 83/450: 1328/7200 mean loss: 0.0016084305243566632 score: 0.9622549019607843
2021-08-08 04:15:06,176 | train | INFO | Epoch 6 train batch 84/450: 1344/7200 mean loss: 0.0013700197450816631 score: 1.0
2021-08-08 04:15:06,985 | train | INFO | Epoch 6 train batch 85/450: 1360/7200 mean loss: 0.0014309912221506238 score: 1.0
2021-08-08 04:15:07,771 | train | INFO | Epoch 6 train batch 86/450: 1376/7200 mean loss: 0.0015565176727250218 score: 1.0
2021-08-08 04:15:08,626 | train | INFO | Epoch 6 train batch 87/450: 1392/7200 mean loss: 0.0014337028842419386 score: 1.0
2021-08-08 04:15:09,485 | train | INFO | Epoch 6 train batch 88/450: 1408/7200 mean loss: 0.0013394703855738044 score: 0.9924019607843138
2021-08-08 04:15:10,309 | train | INFO | Epoch 6 train batch 89/450: 1424/7200 mean loss: 0.001601130818016827 score: 0.9926470588235294
2021-08-08 04:15:11,091 | train | INFO | Epoch 6 train batch 90/450: 1440/7200 mean loss: 0.0013369456864893436 score: 0.9963235294117647
2021-08-08 04:15:11,888 | train | INFO | Epoch 6 train batch 91/450: 1456/7200 mean loss: 0.0015732008032500744 score: 0.9852941176470589
2021-08-08 04:15:12,672 | train | INFO | Epoch 6 train batch 92/450: 1472/7200 mean loss: 0.0016234265640377998 score: 1.0
2021-08-08 04:15:13,480 | train | INFO | Epoch 6 train batch 93/450: 1488/7200 mean loss: 0.0014961244305595756 score: 0.9926470588235294
2021-08-08 04:15:14,274 | train | INFO | Epoch 6 train batch 94/450: 1504/7200 mean loss: 0.0015179994516074657 score: 1.0
2021-08-08 04:15:15,082 | train | INFO | Epoch 6 train batch 95/450: 1520/7200 mean loss: 0.0015200445195659995 score: 1.0
2021-08-08 04:15:15,847 | train | INFO | Epoch 6 train batch 96/450: 1536/7200 mean loss: 0.0015842663124203682 score: 1.0
2021-08-08 04:15:16,680 | train | INFO | Epoch 6 train batch 97/450: 1552/7200 mean loss: 0.0013487708056345582 score: 0.9779411764705882
2021-08-08 04:15:17,474 | train | INFO | Epoch 6 train batch 98/450: 1568/7200 mean loss: 0.0014770879643037915 score: 0.8997549019607843
2021-08-08 04:15:18,307 | train | INFO | Epoch 6 train batch 99/450: 1584/7200 mean loss: 0.0014846380800008774 score: 1.0
2021-08-08 04:15:19,109 | train | INFO | Epoch 6 train batch 100/450: 1600/7200 mean loss: 0.001609303173609078 score: 1.0
2021-08-08 04:15:19,895 | train | INFO | Epoch 6 train batch 101/450: 1616/7200 mean loss: 0.0015974119305610657 score: 1.0
2021-08-08 04:15:20,684 | train | INFO | Epoch 6 train batch 102/450: 1632/7200 mean loss: 0.001400717650540173 score: 0.7497549019607843
2021-08-08 04:15:21,492 | train | INFO | Epoch 6 train batch 103/450: 1648/7200 mean loss: 0.0015084180049598217 score: 1.0
2021-08-08 04:15:22,316 | train | INFO | Epoch 6 train batch 104/450: 1664/7200 mean loss: 0.0015102698234841228 score: 1.0
2021-08-08 04:15:23,120 | train | INFO | Epoch 6 train batch 105/450: 1680/7200 mean loss: 0.0014852483291178942 score: 1.0
2021-08-08 04:15:23,920 | train | INFO | Epoch 6 train batch 106/450: 1696/7200 mean loss: 0.0015202409122139215 score: 0.9963235294117647
2021-08-08 04:15:24,698 | train | INFO | Epoch 6 train batch 107/450: 1712/7200 mean loss: 0.0015238011255860329 score: 1.0
2021-08-08 04:15:25,511 | train | INFO | Epoch 6 train batch 108/450: 1728/7200 mean loss: 0.0017914181808009744 score: 1.0
2021-08-08 04:15:26,280 | train | INFO | Epoch 6 train batch 109/450: 1744/7200 mean loss: 0.0017295072320848703 score: 0.9843137254901961
2021-08-08 04:15:27,070 | train | INFO | Epoch 6 train batch 110/450: 1760/7200 mean loss: 0.0016067135147750378 score: 1.0
2021-08-08 04:15:27,860 | train | INFO | Epoch 6 train batch 111/450: 1776/7200 mean loss: 0.0015978551236912608 score: 1.0
2021-08-08 04:15:28,646 | train | INFO | Epoch 6 train batch 112/450: 1792/7200 mean loss: 0.0016830993117764592 score: 1.0
2021-08-08 04:15:29,431 | train | INFO | Epoch 6 train batch 113/450: 1808/7200 mean loss: 0.0016026337398216128 score: 1.0
2021-08-08 04:15:30,238 | train | INFO | Epoch 6 train batch 114/450: 1824/7200 mean loss: 0.001395586645230651 score: 0.9963235294117647
2021-08-08 04:15:31,017 | train | INFO | Epoch 6 train batch 115/450: 1840/7200 mean loss: 0.0012436072574928403 score: 1.0
2021-08-08 04:15:31,831 | train | INFO | Epoch 6 train batch 116/450: 1856/7200 mean loss: 0.001431826502084732 score: 1.0
2021-08-08 04:15:32,732 | train | INFO | Epoch 6 train batch 117/450: 1872/7200 mean loss: 0.0013942933874204755 score: 1.0
2021-08-08 04:15:33,551 | train | INFO | Epoch 6 train batch 118/450: 1888/7200 mean loss: 0.0013721674913540483 score: 0.9776960784313725
2021-08-08 04:15:34,359 | train | INFO | Epoch 6 train batch 119/450: 1904/7200 mean loss: 0.0014455252094194293 score: 1.0
2021-08-08 04:15:35,185 | train | INFO | Epoch 6 train batch 120/450: 1920/7200 mean loss: 0.0016414581332355738 score: 1.0
2021-08-08 04:15:35,992 | train | INFO | Epoch 6 train batch 121/450: 1936/7200 mean loss: 0.0016044055810198188 score: 1.0
2021-08-08 04:15:36,797 | train | INFO | Epoch 6 train batch 122/450: 1952/7200 mean loss: 0.0014623485039919615 score: 1.0
2021-08-08 04:15:37,589 | train | INFO | Epoch 6 train batch 123/450: 1968/7200 mean loss: 0.0015160395996645093 score: 1.0
2021-08-08 04:15:38,379 | train | INFO | Epoch 6 train batch 124/450: 1984/7200 mean loss: 0.0016632365295663476 score: 0.9963235294117647
2021-08-08 04:15:39,158 | train | INFO | Epoch 6 train batch 125/450: 2000/7200 mean loss: 0.0014963303692638874 score: 0.9816176470588235
2021-08-08 04:15:39,933 | train | INFO | Epoch 6 train batch 126/450: 2016/7200 mean loss: 0.0015096092829480767 score: 1.0
2021-08-08 04:15:40,740 | train | INFO | Epoch 6 train batch 127/450: 2032/7200 mean loss: 0.00149411556776613 score: 1.0
2021-08-08 04:15:41,553 | train | INFO | Epoch 6 train batch 128/450: 2048/7200 mean loss: 0.001323964912444353 score: 1.0
2021-08-08 04:15:42,333 | train | INFO | Epoch 6 train batch 129/450: 2064/7200 mean loss: 0.0014303304487839341 score: 0.7323529411764705
2021-08-08 04:15:43,137 | train | INFO | Epoch 6 train batch 130/450: 2080/7200 mean loss: 0.0014808407286182046 score: 1.0
2021-08-08 04:15:43,941 | train | INFO | Epoch 6 train batch 131/450: 2096/7200 mean loss: 0.0014819797361269593 score: 1.0
2021-08-08 04:15:44,719 | train | INFO | Epoch 6 train batch 132/450: 2112/7200 mean loss: 0.0013533239252865314 score: 1.0
2021-08-08 04:15:45,513 | train | INFO | Epoch 6 train batch 133/450: 2128/7200 mean loss: 0.0013166377320885658 score: 1.0
2021-08-08 04:15:46,299 | train | INFO | Epoch 6 train batch 134/450: 2144/7200 mean loss: 0.0012654225574806333 score: 1.0
2021-08-08 04:15:47,073 | train | INFO | Epoch 6 train batch 135/450: 2160/7200 mean loss: 0.0015562884509563446 score: 0.7865196078431372
2021-08-08 04:15:47,888 | train | INFO | Epoch 6 train batch 136/450: 2176/7200 mean loss: 0.0014669930096715689 score: 1.0
2021-08-08 04:15:48,678 | train | INFO | Epoch 6 train batch 137/450: 2192/7200 mean loss: 0.0014143879525363445 score: 1.0
2021-08-08 04:15:49,454 | train | INFO | Epoch 6 train batch 138/450: 2208/7200 mean loss: 0.001751589123159647 score: 1.0
2021-08-08 04:15:50,248 | train | INFO | Epoch 6 train batch 139/450: 2224/7200 mean loss: 0.0013207996962592006 score: 1.0
2021-08-08 04:15:51,063 | train | INFO | Epoch 6 train batch 140/450: 2240/7200 mean loss: 0.001514931907877326 score: 1.0
2021-08-08 04:15:51,835 | train | INFO | Epoch 6 train batch 141/450: 2256/7200 mean loss: 0.0015268541174009442 score: 0.9884803921568628
2021-08-08 04:15:52,644 | train | INFO | Epoch 6 train batch 142/450: 2272/7200 mean loss: 0.0013375423150137067 score: 1.0
2021-08-08 04:15:53,484 | train | INFO | Epoch 6 train batch 143/450: 2288/7200 mean loss: 0.0014738492900505662 score: 1.0
2021-08-08 04:15:54,252 | train | INFO | Epoch 6 train batch 144/450: 2304/7200 mean loss: 0.001459997147321701 score: 1.0
2021-08-08 04:15:55,063 | train | INFO | Epoch 6 train batch 145/450: 2320/7200 mean loss: 0.0015491379890590906 score: 0.9963235294117647
2021-08-08 04:15:55,859 | train | INFO | Epoch 6 train batch 146/450: 2336/7200 mean loss: 0.001632786588743329 score: 0.9887254901960785
2021-08-08 04:15:56,631 | train | INFO | Epoch 6 train batch 147/450: 2352/7200 mean loss: 0.0013192521873861551 score: 0.995798319327731
2021-08-08 04:15:57,408 | train | INFO | Epoch 6 train batch 148/450: 2368/7200 mean loss: 0.0015561924083158374 score: 1.0
2021-08-08 04:15:58,188 | train | INFO | Epoch 6 train batch 149/450: 2384/7200 mean loss: 0.0014600944705307484 score: 1.0
2021-08-08 04:15:58,961 | train | INFO | Epoch 6 train batch 150/450: 2400/7200 mean loss: 0.0015021656872704625 score: 1.0
2021-08-08 04:15:59,761 | train | INFO | Epoch 6 train batch 151/450: 2416/7200 mean loss: 0.0015945088816806674 score: 0.9926470588235294
2021-08-08 04:16:00,537 | train | INFO | Epoch 6 train batch 152/450: 2432/7200 mean loss: 0.0014861461240798235 score: 1.0
2021-08-08 04:16:01,323 | train | INFO | Epoch 6 train batch 153/450: 2448/7200 mean loss: 0.001758648781105876 score: 0.9963235294117647
2021-08-08 04:16:02,119 | train | INFO | Epoch 6 train batch 154/450: 2464/7200 mean loss: 0.0015983508201316 score: 1.0
2021-08-08 04:16:02,921 | train | INFO | Epoch 6 train batch 155/450: 2480/7200 mean loss: 0.0016332990489900112 score: 1.0
2021-08-08 04:16:03,705 | train | INFO | Epoch 6 train batch 156/450: 2496/7200 mean loss: 0.0014851752202957869 score: 1.0
2021-08-08 04:16:04,535 | train | INFO | Epoch 6 train batch 157/450: 2512/7200 mean loss: 0.0014413080643862486 score: 0.9924019607843138
2021-08-08 04:16:05,320 | train | INFO | Epoch 6 train batch 158/450: 2528/7200 mean loss: 0.0018839637050405145 score: 1.0
2021-08-08 04:16:06,131 | train | INFO | Epoch 6 train batch 159/450: 2544/7200 mean loss: 0.0015501593006774783 score: 1.0
2021-08-08 04:16:06,918 | train | INFO | Epoch 6 train batch 160/450: 2560/7200 mean loss: 0.0014783088117837906 score: 0.9805672268907564
2021-08-08 04:16:07,692 | train | INFO | Epoch 6 train batch 161/450: 2576/7200 mean loss: 0.0015275590121746063 score: 1.0
2021-08-08 04:16:08,516 | train | INFO | Epoch 6 train batch 162/450: 2592/7200 mean loss: 0.0016480364138260484 score: 1.0
2021-08-08 04:16:09,303 | train | INFO | Epoch 6 train batch 163/450: 2608/7200 mean loss: 0.0016262115677818656 score: 0.9926470588235294
2021-08-08 04:16:10,079 | train | INFO | Epoch 6 train batch 164/450: 2624/7200 mean loss: 0.001711286953650415 score: 1.0
2021-08-08 04:16:10,873 | train | INFO | Epoch 6 train batch 165/450: 2640/7200 mean loss: 0.001487676752731204 score: 0.9852941176470589
2021-08-08 04:16:11,722 | train | INFO | Epoch 6 train batch 166/450: 2656/7200 mean loss: 0.0016098336782306433 score: 1.0
2021-08-08 04:16:12,496 | train | INFO | Epoch 6 train batch 167/450: 2672/7200 mean loss: 0.001703007728792727 score: 0.9850490196078432
2021-08-08 04:16:13,262 | train | INFO | Epoch 6 train batch 168/450: 2688/7200 mean loss: 0.0016147566493600607 score: 1.0
2021-08-08 04:16:14,058 | train | INFO | Epoch 6 train batch 169/450: 2704/7200 mean loss: 0.0013776890700682998 score: 1.0
2021-08-08 04:16:14,872 | train | INFO | Epoch 6 train batch 170/450: 2720/7200 mean loss: 0.001353970030322671 score: 1.0
2021-08-08 04:16:15,644 | train | INFO | Epoch 6 train batch 171/450: 2736/7200 mean loss: 0.0014492397895082831 score: 1.0
2021-08-08 04:16:16,467 | train | INFO | Epoch 6 train batch 172/450: 2752/7200 mean loss: 0.0016400596359744668 score: 0.9477941176470589
2021-08-08 04:16:17,257 | train | INFO | Epoch 6 train batch 173/450: 2768/7200 mean loss: 0.0015040966682136059 score: 0.8193627450980392
2021-08-08 04:16:18,024 | train | INFO | Epoch 6 train batch 174/450: 2784/7200 mean loss: 0.001651691272854805 score: 1.0
2021-08-08 04:16:18,810 | train | INFO | Epoch 6 train batch 175/450: 2800/7200 mean loss: 0.0016436793375760317 score: 1.0
2021-08-08 04:16:19,605 | train | INFO | Epoch 6 train batch 176/450: 2816/7200 mean loss: 0.0016021644696593285 score: 1.0
2021-08-08 04:16:20,383 | train | INFO | Epoch 6 train batch 177/450: 2832/7200 mean loss: 0.0016559219220653176 score: 1.0
2021-08-08 04:16:21,210 | train | INFO | Epoch 6 train batch 178/450: 2848/7200 mean loss: 0.0016639836831018329 score: 0.9926470588235294
2021-08-08 04:16:22,074 | train | INFO | Epoch 6 train batch 179/450: 2864/7200 mean loss: 0.0014399399515241385 score: 1.0
2021-08-08 04:16:22,858 | train | INFO | Epoch 6 train batch 180/450: 2880/7200 mean loss: 0.0014206767082214355 score: 1.0
2021-08-08 04:16:23,701 | train | INFO | Epoch 6 train batch 181/450: 2896/7200 mean loss: 0.001455598627217114 score: 0.9926470588235294
2021-08-08 04:16:24,487 | train | INFO | Epoch 6 train batch 182/450: 2912/7200 mean loss: 0.0014123589498922229 score: 1.0
2021-08-08 04:16:25,270 | train | INFO | Epoch 6 train batch 183/450: 2928/7200 mean loss: 0.0016919717891141772 score: 0.9887254901960785
2021-08-08 04:16:26,051 | train | INFO | Epoch 6 train batch 184/450: 2944/7200 mean loss: 0.0015535494312644005 score: 0.9926470588235294
2021-08-08 04:16:26,894 | train | INFO | Epoch 6 train batch 185/450: 2960/7200 mean loss: 0.0015011347131803632 score: 1.0
2021-08-08 04:16:27,671 | train | INFO | Epoch 6 train batch 186/450: 2976/7200 mean loss: 0.0015430758940055966 score: 1.0
2021-08-08 04:16:28,449 | train | INFO | Epoch 6 train batch 187/450: 2992/7200 mean loss: 0.001514142146334052 score: 1.0
2021-08-08 04:16:29,251 | train | INFO | Epoch 6 train batch 188/450: 3008/7200 mean loss: 0.0016426497604697943 score: 1.0
2021-08-08 04:16:30,024 | train | INFO | Epoch 6 train batch 189/450: 3024/7200 mean loss: 0.0014894845662638545 score: 1.0
2021-08-08 04:16:30,806 | train | INFO | Epoch 6 train batch 190/450: 3040/7200 mean loss: 0.0014282283373177052 score: 1.0
2021-08-08 04:16:31,647 | train | INFO | Epoch 6 train batch 191/450: 3056/7200 mean loss: 0.0015073237009346485 score: 1.0
2021-08-08 04:16:32,446 | train | INFO | Epoch 6 train batch 192/450: 3072/7200 mean loss: 0.0013291345676407218 score: 1.0
2021-08-08 04:16:33,235 | train | INFO | Epoch 6 train batch 193/450: 3088/7200 mean loss: 0.0015070670051500201 score: 0.9884803921568628
2021-08-08 04:16:34,011 | train | INFO | Epoch 6 train batch 194/450: 3104/7200 mean loss: 0.0014704626519232988 score: 0.9889705882352942
2021-08-08 04:16:34,788 | train | INFO | Epoch 6 train batch 195/450: 3120/7200 mean loss: 0.001214885269291699 score: 1.0
2021-08-08 04:16:35,568 | train | INFO | Epoch 6 train batch 196/450: 3136/7200 mean loss: 0.0013363148318603635 score: 0.9963235294117647
2021-08-08 04:16:36,365 | train | INFO | Epoch 6 train batch 197/450: 3152/7200 mean loss: 0.0015760563546791673 score: 1.0
2021-08-08 04:16:37,157 | train | INFO | Epoch 6 train batch 198/450: 3168/7200 mean loss: 0.0015230708522722125 score: 1.0
2021-08-08 04:16:37,957 | train | INFO | Epoch 6 train batch 199/450: 3184/7200 mean loss: 0.0014782646903768182 score: 1.0
2021-08-08 04:16:38,745 | train | INFO | Epoch 6 train batch 200/450: 3200/7200 mean loss: 0.001526551553979516 score: 0.996078431372549
2021-08-08 04:16:39,521 | train | INFO | Epoch 6 train batch 201/450: 3216/7200 mean loss: 0.001473581767641008 score: 0.9884453781512604
2021-08-08 04:16:40,309 | train | INFO | Epoch 6 train batch 202/450: 3232/7200 mean loss: 0.001541470061056316 score: 1.0
2021-08-08 04:16:41,110 | train | INFO | Epoch 6 train batch 203/450: 3248/7200 mean loss: 0.0013787706848233938 score: 1.0
2021-08-08 04:16:41,902 | train | INFO | Epoch 6 train batch 204/450: 3264/7200 mean loss: 0.0016040540067479014 score: 1.0
2021-08-08 04:16:42,670 | train | INFO | Epoch 6 train batch 205/450: 3280/7200 mean loss: 0.0013325889594852924 score: 1.0
2021-08-08 04:16:43,472 | train | INFO | Epoch 6 train batch 206/450: 3296/7200 mean loss: 0.001508123124949634 score: 0.9889705882352942
2021-08-08 04:16:44,292 | train | INFO | Epoch 6 train batch 207/450: 3312/7200 mean loss: 0.0016416246071457863 score: 0.9811274509803922
2021-08-08 04:16:45,089 | train | INFO | Epoch 6 train batch 208/450: 3328/7200 mean loss: 0.0015196582535281777 score: 1.0
2021-08-08 04:16:45,872 | train | INFO | Epoch 6 train batch 209/450: 3344/7200 mean loss: 0.001484254258684814 score: 1.0
2021-08-08 04:16:46,652 | train | INFO | Epoch 6 train batch 210/450: 3360/7200 mean loss: 0.0013691418571397662 score: 1.0
2021-08-08 04:16:47,465 | train | INFO | Epoch 6 train batch 211/450: 3376/7200 mean loss: 0.0014467710861936212 score: 1.0
2021-08-08 04:16:48,247 | train | INFO | Epoch 6 train batch 212/450: 3392/7200 mean loss: 0.0016779451398178935 score: 0.9963235294117647
2021-08-08 04:16:49,018 | train | INFO | Epoch 6 train batch 213/450: 3408/7200 mean loss: 0.0017202779417857528 score: 1.0
2021-08-08 04:16:49,791 | train | INFO | Epoch 6 train batch 214/450: 3424/7200 mean loss: 0.0015171935083344579 score: 1.0
2021-08-08 04:16:50,577 | train | INFO | Epoch 6 train batch 215/450: 3440/7200 mean loss: 0.0015955251874402165 score: 0.9852941176470589
2021-08-08 04:16:51,357 | train | INFO | Epoch 6 train batch 216/450: 3456/7200 mean loss: 0.0015329634770751 score: 1.0
2021-08-08 04:16:52,130 | train | INFO | Epoch 6 train batch 217/450: 3472/7200 mean loss: 0.0015395227819681168 score: 1.0
2021-08-08 04:16:52,930 | train | INFO | Epoch 6 train batch 218/450: 3488/7200 mean loss: 0.0016385138733312488 score: 0.9889705882352942
2021-08-08 04:16:53,727 | train | INFO | Epoch 6 train batch 219/450: 3504/7200 mean loss: 0.0016659399261698127 score: 1.0
2021-08-08 04:16:54,551 | train | INFO | Epoch 6 train batch 220/450: 3520/7200 mean loss: 0.001783845480531454 score: 0.9522058823529411
2021-08-08 04:16:55,322 | train | INFO | Epoch 6 train batch 221/450: 3536/7200 mean loss: 0.0015219913329929113 score: 0.9926470588235294
2021-08-08 04:16:56,096 | train | INFO | Epoch 6 train batch 222/450: 3552/7200 mean loss: 0.0014489575987681746 score: 0.9889705882352942
2021-08-08 04:16:56,877 | train | INFO | Epoch 6 train batch 223/450: 3568/7200 mean loss: 0.0013241223059594631 score: 1.0
2021-08-08 04:16:57,683 | train | INFO | Epoch 6 train batch 224/450: 3584/7200 mean loss: 0.0014836012851446867 score: 1.0
2021-08-08 04:16:58,478 | train | INFO | Epoch 6 train batch 225/450: 3600/7200 mean loss: 0.0015215352177619934 score: 0.8889705882352942
2021-08-08 04:16:59,278 | train | INFO | Epoch 6 train batch 226/450: 3616/7200 mean loss: 0.0015102720353752375 score: 0.9926470588235294
2021-08-08 04:17:00,088 | train | INFO | Epoch 6 train batch 227/450: 3632/7200 mean loss: 0.0016121098306030035 score: 0.996078431372549
2021-08-08 04:17:00,927 | train | INFO | Epoch 6 train batch 228/450: 3648/7200 mean loss: 0.0013718894915655255 score: 1.0
2021-08-08 04:17:01,716 | train | INFO | Epoch 6 train batch 229/450: 3664/7200 mean loss: 0.0015002009458839893 score: 1.0
2021-08-08 04:17:02,490 | train | INFO | Epoch 6 train batch 230/450: 3680/7200 mean loss: 0.0015149055980145931 score: 0.9705882352941176
2021-08-08 04:17:03,281 | train | INFO | Epoch 6 train batch 231/450: 3696/7200 mean loss: 0.0014587731566280127 score: 1.0
2021-08-08 04:17:04,116 | train | INFO | Epoch 6 train batch 232/450: 3712/7200 mean loss: 0.0015490935184061527 score: 1.0
2021-08-08 04:17:04,935 | train | INFO | Epoch 6 train batch 233/450: 3728/7200 mean loss: 0.0012941915774717927 score: 1.0
2021-08-08 04:17:05,732 | train | INFO | Epoch 6 train batch 234/450: 3744/7200 mean loss: 0.0014939624816179276 score: 0.9963235294117647
2021-08-08 04:17:06,511 | train | INFO | Epoch 6 train batch 235/450: 3760/7200 mean loss: 0.001400474109686911 score: 1.0
2021-08-08 04:17:07,326 | train | INFO | Epoch 6 train batch 236/450: 3776/7200 mean loss: 0.001344082411378622 score: 0.9963235294117647
2021-08-08 04:17:08,104 | train | INFO | Epoch 6 train batch 237/450: 3792/7200 mean loss: 0.0012485345359891653 score: 1.0
2021-08-08 04:17:08,904 | train | INFO | Epoch 6 train batch 238/450: 3808/7200 mean loss: 0.0014064336428418756 score: 1.0
2021-08-08 04:17:09,693 | train | INFO | Epoch 6 train batch 239/450: 3824/7200 mean loss: 0.001296972157433629 score: 1.0
2021-08-08 04:17:10,476 | train | INFO | Epoch 6 train batch 240/450: 3840/7200 mean loss: 0.0014843891840428114 score: 1.0
2021-08-08 04:17:11,250 | train | INFO | Epoch 6 train batch 241/450: 3856/7200 mean loss: 0.001301069394685328 score: 1.0
2021-08-08 04:17:12,064 | train | INFO | Epoch 6 train batch 242/450: 3872/7200 mean loss: 0.001461265841498971 score: 1.0
2021-08-08 04:17:12,883 | train | INFO | Epoch 6 train batch 243/450: 3888/7200 mean loss: 0.0013642655685544014 score: 1.0
2021-08-08 04:17:13,696 | train | INFO | Epoch 6 train batch 244/450: 3904/7200 mean loss: 0.001538358861580491 score: 1.0
2021-08-08 04:17:14,478 | train | INFO | Epoch 6 train batch 245/450: 3920/7200 mean loss: 0.0014639650471508503 score: 1.0
2021-08-08 04:17:15,250 | train | INFO | Epoch 6 train batch 246/450: 3936/7200 mean loss: 0.0013745006872341037 score: 0.9926470588235294
2021-08-08 04:17:16,017 | train | INFO | Epoch 6 train batch 247/450: 3952/7200 mean loss: 0.0014954229118302464 score: 0.9887254901960785
2021-08-08 04:17:16,787 | train | INFO | Epoch 6 train batch 248/450: 3968/7200 mean loss: 0.0014253517147153616 score: 1.0
2021-08-08 04:17:17,562 | train | INFO | Epoch 6 train batch 249/450: 3984/7200 mean loss: 0.0014504553982988 score: 1.0
2021-08-08 04:17:18,397 | train | INFO | Epoch 6 train batch 250/450: 4000/7200 mean loss: 0.0014734689611941576 score: 1.0
2021-08-08 04:17:19,190 | train | INFO | Epoch 6 train batch 251/450: 4016/7200 mean loss: 0.0014988547191023827 score: 1.0
2021-08-08 04:17:19,987 | train | INFO | Epoch 6 train batch 252/450: 4032/7200 mean loss: 0.0015865775058045983 score: 1.0
2021-08-08 04:17:20,765 | train | INFO | Epoch 6 train batch 253/450: 4048/7200 mean loss: 0.0016026860103011131 score: 1.0
2021-08-08 04:17:21,553 | train | INFO | Epoch 6 train batch 254/450: 4064/7200 mean loss: 0.0016140196239575744 score: 1.0
2021-08-08 04:17:22,352 | train | INFO | Epoch 6 train batch 255/450: 4080/7200 mean loss: 0.0015374186914414167 score: 1.0
2021-08-08 04:17:23,127 | train | INFO | Epoch 6 train batch 256/450: 4096/7200 mean loss: 0.0013500405475497246 score: 1.0
2021-08-08 04:17:23,921 | train | INFO | Epoch 6 train batch 257/450: 4112/7200 mean loss: 0.00164484151173383 score: 0.9776960784313725
2021-08-08 04:17:24,698 | train | INFO | Epoch 6 train batch 258/450: 4128/7200 mean loss: 0.0014348347904160619 score: 1.0
2021-08-08 04:17:25,488 | train | INFO | Epoch 6 train batch 259/450: 4144/7200 mean loss: 0.0016186051070690155 score: 0.9963235294117647
2021-08-08 04:17:26,300 | train | INFO | Epoch 6 train batch 260/450: 4160/7200 mean loss: 0.0017039108788594604 score: 1.0
2021-08-08 04:17:27,119 | train | INFO | Epoch 6 train batch 261/450: 4176/7200 mean loss: 0.001603793352842331 score: 1.0
2021-08-08 04:17:27,908 | train | INFO | Epoch 6 train batch 262/450: 4192/7200 mean loss: 0.00152997812256217 score: 0.9889705882352942
2021-08-08 04:17:28,782 | train | INFO | Epoch 6 train batch 263/450: 4208/7200 mean loss: 0.0014313445426523685 score: 1.0
2021-08-08 04:17:29,625 | train | INFO | Epoch 6 train batch 264/450: 4224/7200 mean loss: 0.00157999771181494 score: 1.0
2021-08-08 04:17:30,429 | train | INFO | Epoch 6 train batch 265/450: 4240/7200 mean loss: 0.0017258956795558333 score: 1.0
2021-08-08 04:17:31,210 | train | INFO | Epoch 6 train batch 266/450: 4256/7200 mean loss: 0.0014740446349605918 score: 0.9963235294117647
2021-08-08 04:17:32,016 | train | INFO | Epoch 6 train batch 267/450: 4272/7200 mean loss: 0.0014508727472275496 score: 1.0
2021-08-08 04:17:32,795 | train | INFO | Epoch 6 train batch 268/450: 4288/7200 mean loss: 0.0014057166408747435 score: 0.9401960784313725
2021-08-08 04:17:33,580 | train | INFO | Epoch 6 train batch 269/450: 4304/7200 mean loss: 0.0015658052871003747 score: 0.946218487394958
2021-08-08 04:17:34,362 | train | INFO | Epoch 6 train batch 270/450: 4320/7200 mean loss: 0.001634127926081419 score: 1.0
2021-08-08 04:17:35,162 | train | INFO | Epoch 6 train batch 271/450: 4336/7200 mean loss: 0.0017652971437200904 score: 0.9178221288515407
2021-08-08 04:17:35,974 | train | INFO | Epoch 6 train batch 272/450: 4352/7200 mean loss: 0.001784094492904842 score: 0.9963235294117647
2021-08-08 04:17:36,751 | train | INFO | Epoch 6 train batch 273/450: 4368/7200 mean loss: 0.0017423939425498247 score: 1.0
2021-08-08 04:17:37,550 | train | INFO | Epoch 6 train batch 274/450: 4384/7200 mean loss: 0.0015833417419344187 score: 1.0
2021-08-08 04:17:38,369 | train | INFO | Epoch 6 train batch 275/450: 4400/7200 mean loss: 0.0017445842968299985 score: 1.0
2021-08-08 04:17:39,149 | train | INFO | Epoch 6 train batch 276/450: 4416/7200 mean loss: 0.0014361991779878736 score: 1.0
2021-08-08 04:17:39,940 | train | INFO | Epoch 6 train batch 277/450: 4432/7200 mean loss: 0.001325528253801167 score: 1.0
2021-08-08 04:17:40,736 | train | INFO | Epoch 6 train batch 278/450: 4448/7200 mean loss: 0.001424844260327518 score: 1.0
2021-08-08 04:17:41,550 | train | INFO | Epoch 6 train batch 279/450: 4464/7200 mean loss: 0.0016466552624478936 score: 1.0
2021-08-08 04:17:42,369 | train | INFO | Epoch 6 train batch 280/450: 4480/7200 mean loss: 0.0014367792755365372 score: 1.0
2021-08-08 04:17:43,162 | train | INFO | Epoch 6 train batch 281/450: 4496/7200 mean loss: 0.0013835883000865579 score: 1.0
2021-08-08 04:17:43,987 | train | INFO | Epoch 6 train batch 282/450: 4512/7200 mean loss: 0.0015291778836399317 score: 1.0
2021-08-08 04:17:44,765 | train | INFO | Epoch 6 train batch 283/450: 4528/7200 mean loss: 0.0015822078566998243 score: 1.0
2021-08-08 04:17:45,552 | train | INFO | Epoch 6 train batch 284/450: 4544/7200 mean loss: 0.0014257070142775774 score: 1.0
2021-08-08 04:17:46,360 | train | INFO | Epoch 6 train batch 285/450: 4560/7200 mean loss: 0.001472176518291235 score: 1.0
2021-08-08 04:17:47,148 | train | INFO | Epoch 6 train batch 286/450: 4576/7200 mean loss: 0.001470883609727025 score: 1.0
2021-08-08 04:17:47,941 | train | INFO | Epoch 6 train batch 287/450: 4592/7200 mean loss: 0.0017101141856983304 score: 0.9926470588235294
2021-08-08 04:17:48,728 | train | INFO | Epoch 6 train batch 288/450: 4608/7200 mean loss: 0.0015951504465192556 score: 0.995798319327731
2021-08-08 04:17:49,505 | train | INFO | Epoch 6 train batch 289/450: 4624/7200 mean loss: 0.001486498978920281 score: 0.9963235294117647
2021-08-08 04:17:50,313 | train | INFO | Epoch 6 train batch 290/450: 4640/7200 mean loss: 0.0014539911644533277 score: 0.9963235294117647
2021-08-08 04:17:51,103 | train | INFO | Epoch 6 train batch 291/450: 4656/7200 mean loss: 0.001686183619312942 score: 1.0
2021-08-08 04:17:51,925 | train | INFO | Epoch 6 train batch 292/450: 4672/7200 mean loss: 0.0015427606413140893 score: 1.0
2021-08-08 04:17:52,727 | train | INFO | Epoch 6 train batch 293/450: 4688/7200 mean loss: 0.0015992018161341548 score: 1.0
2021-08-08 04:17:53,532 | train | INFO | Epoch 6 train batch 294/450: 4704/7200 mean loss: 0.0014912865590304136 score: 1.0
2021-08-08 04:17:54,350 | train | INFO | Epoch 6 train batch 295/450: 4720/7200 mean loss: 0.0015213568694889545 score: 1.0
2021-08-08 04:17:55,160 | train | INFO | Epoch 6 train batch 296/450: 4736/7200 mean loss: 0.0014907248551025987 score: 0.996078431372549
2021-08-08 04:17:55,962 | train | INFO | Epoch 6 train batch 297/450: 4752/7200 mean loss: 0.0013818437000736594 score: 0.8602941176470589
2021-08-08 04:17:56,775 | train | INFO | Epoch 6 train batch 298/450: 4768/7200 mean loss: 0.0016029654070734978 score: 0.9963235294117647
2021-08-08 04:17:57,602 | train | INFO | Epoch 6 train batch 299/450: 4784/7200 mean loss: 0.0015473001403734088 score: 1.0
2021-08-08 04:17:58,410 | train | INFO | Epoch 6 train batch 300/450: 4800/7200 mean loss: 0.0015014574164524674 score: 1.0
2021-08-08 04:17:59,190 | train | INFO | Epoch 6 train batch 301/450: 4816/7200 mean loss: 0.0015919565921649337 score: 1.0
2021-08-08 04:18:00,004 | train | INFO | Epoch 6 train batch 302/450: 4832/7200 mean loss: 0.0014440679224207997 score: 0.9926470588235294
2021-08-08 04:18:00,825 | train | INFO | Epoch 6 train batch 303/450: 4848/7200 mean loss: 0.0013577017234638333 score: 1.0
2021-08-08 04:18:01,628 | train | INFO | Epoch 6 train batch 304/450: 4864/7200 mean loss: 0.0015625304076820612 score: 0.9924019607843138
2021-08-08 04:18:02,425 | train | INFO | Epoch 6 train batch 305/450: 4880/7200 mean loss: 0.0015979254385456443 score: 0.996078431372549
2021-08-08 04:18:03,202 | train | INFO | Epoch 6 train batch 306/450: 4896/7200 mean loss: 0.0015387218445539474 score: 1.0
2021-08-08 04:18:04,049 | train | INFO | Epoch 6 train batch 307/450: 4912/7200 mean loss: 0.0015760231763124466 score: 1.0
2021-08-08 04:18:04,882 | train | INFO | Epoch 6 train batch 308/450: 4928/7200 mean loss: 0.0015580251347273588 score: 1.0
2021-08-08 04:18:05,664 | train | INFO | Epoch 6 train batch 309/450: 4944/7200 mean loss: 0.001492020790465176 score: 1.0
2021-08-08 04:18:06,494 | train | INFO | Epoch 6 train batch 310/450: 4960/7200 mean loss: 0.0015299442457035184 score: 1.0
2021-08-08 04:18:07,309 | train | INFO | Epoch 6 train batch 311/450: 4976/7200 mean loss: 0.0016118198400363326 score: 1.0
2021-08-08 04:18:08,087 | train | INFO | Epoch 6 train batch 312/450: 4992/7200 mean loss: 0.0013425472425296903 score: 1.0
2021-08-08 04:18:09,015 | train | INFO | Epoch 6 train batch 313/450: 5008/7200 mean loss: 0.0015637847827747464 score: 1.0
2021-08-08 04:18:09,803 | train | INFO | Epoch 6 train batch 314/450: 5024/7200 mean loss: 0.0016002474585548043 score: 1.0
2021-08-08 04:18:10,584 | train | INFO | Epoch 6 train batch 315/450: 5040/7200 mean loss: 0.0015570665709674358 score: 1.0
2021-08-08 04:18:11,355 | train | INFO | Epoch 6 train batch 316/450: 5056/7200 mean loss: 0.0015122774057090282 score: 1.0
2021-08-08 04:18:12,124 | train | INFO | Epoch 6 train batch 317/450: 5072/7200 mean loss: 0.0015084437327459455 score: 1.0
2021-08-08 04:18:12,919 | train | INFO | Epoch 6 train batch 318/450: 5088/7200 mean loss: 0.0016770875081419945 score: 1.0
2021-08-08 04:18:13,721 | train | INFO | Epoch 6 train batch 319/450: 5104/7200 mean loss: 0.0017091782065108418 score: 0.9963235294117647
2021-08-08 04:18:14,503 | train | INFO | Epoch 6 train batch 320/450: 5120/7200 mean loss: 0.0015831302152946591 score: 1.0
2021-08-08 04:18:15,276 | train | INFO | Epoch 6 train batch 321/450: 5136/7200 mean loss: 0.0016004749340936542 score: 1.0
2021-08-08 04:18:16,067 | train | INFO | Epoch 6 train batch 322/450: 5152/7200 mean loss: 0.0015828515170142055 score: 1.0
2021-08-08 04:18:16,852 | train | INFO | Epoch 6 train batch 323/450: 5168/7200 mean loss: 0.0017560268752276897 score: 0.9889705882352942
2021-08-08 04:18:17,627 | train | INFO | Epoch 6 train batch 324/450: 5184/7200 mean loss: 0.0013700692215934396 score: 0.9924019607843138
2021-08-08 04:18:18,438 | train | INFO | Epoch 6 train batch 325/450: 5200/7200 mean loss: 0.0014647598145529628 score: 1.0
2021-08-08 04:18:19,247 | train | INFO | Epoch 6 train batch 326/450: 5216/7200 mean loss: 0.0014179376885294914 score: 0.7104691876750701
2021-08-08 04:18:20,026 | train | INFO | Epoch 6 train batch 327/450: 5232/7200 mean loss: 0.0013755905674770474 score: 1.0
2021-08-08 04:18:20,859 | train | INFO | Epoch 6 train batch 328/450: 5248/7200 mean loss: 0.001546431565657258 score: 0.9734943977591035
2021-08-08 04:18:21,636 | train | INFO | Epoch 6 train batch 329/450: 5264/7200 mean loss: 0.0014078530948609114 score: 1.0
2021-08-08 04:18:22,460 | train | INFO | Epoch 6 train batch 330/450: 5280/7200 mean loss: 0.00131872424390167 score: 0.996078431372549
2021-08-08 04:18:23,238 | train | INFO | Epoch 6 train batch 331/450: 5296/7200 mean loss: 0.001352136954665184 score: 1.0
2021-08-08 04:18:24,048 | train | INFO | Epoch 6 train batch 332/450: 5312/7200 mean loss: 0.001686316798441112 score: 1.0
2021-08-08 04:18:24,834 | train | INFO | Epoch 6 train batch 333/450: 5328/7200 mean loss: 0.0016550315776839852 score: 1.0
2021-08-08 04:18:25,612 | train | INFO | Epoch 6 train batch 334/450: 5344/7200 mean loss: 0.001467147609218955 score: 1.0
2021-08-08 04:18:26,414 | train | INFO | Epoch 6 train batch 335/450: 5360/7200 mean loss: 0.0015232748119160533 score: 1.0
2021-08-08 04:18:27,185 | train | INFO | Epoch 6 train batch 336/450: 5376/7200 mean loss: 0.0016428541857749224 score: 0.9742647058823529
2021-08-08 04:18:27,988 | train | INFO | Epoch 6 train batch 337/450: 5392/7200 mean loss: 0.0014172380324453115 score: 1.0
2021-08-08 04:18:28,764 | train | INFO | Epoch 6 train batch 338/450: 5408/7200 mean loss: 0.0013872419949620962 score: 1.0
2021-08-08 04:18:29,539 | train | INFO | Epoch 6 train batch 339/450: 5424/7200 mean loss: 0.0015354229835793376 score: 1.0
2021-08-08 04:18:30,317 | train | INFO | Epoch 6 train batch 340/450: 5440/7200 mean loss: 0.0015617787139490247 score: 1.0
2021-08-08 04:18:31,089 | train | INFO | Epoch 6 train batch 341/450: 5456/7200 mean loss: 0.0013344186590984464 score: 1.0
2021-08-08 04:18:31,861 | train | INFO | Epoch 6 train batch 342/450: 5472/7200 mean loss: 0.0017038495279848576 score: 1.0
2021-08-08 04:18:32,738 | train | INFO | Epoch 6 train batch 343/450: 5488/7200 mean loss: 0.0016797006828710437 score: 1.0
2021-08-08 04:18:33,550 | train | INFO | Epoch 6 train batch 344/450: 5504/7200 mean loss: 0.0014416191261261702 score: 1.0
2021-08-08 04:18:34,323 | train | INFO | Epoch 6 train batch 345/450: 5520/7200 mean loss: 0.0015022889710962772 score: 1.0
2021-08-08 04:18:35,103 | train | INFO | Epoch 6 train batch 346/450: 5536/7200 mean loss: 0.0018073891988024116 score: 1.0
2021-08-08 04:18:35,893 | train | INFO | Epoch 6 train batch 347/450: 5552/7200 mean loss: 0.0015503873582929373 score: 0.9889705882352942
2021-08-08 04:18:36,694 | train | INFO | Epoch 6 train batch 348/450: 5568/7200 mean loss: 0.0014065104769542813 score: 1.0
2021-08-08 04:18:37,465 | train | INFO | Epoch 6 train batch 349/450: 5584/7200 mean loss: 0.0015223200898617506 score: 1.0
2021-08-08 04:18:38,235 | train | INFO | Epoch 6 train batch 350/450: 5600/7200 mean loss: 0.0016246690647676587 score: 1.0
2021-08-08 04:18:39,001 | train | INFO | Epoch 6 train batch 351/450: 5616/7200 mean loss: 0.0014028253499418497 score: 1.0
2021-08-08 04:18:39,797 | train | INFO | Epoch 6 train batch 352/450: 5632/7200 mean loss: 0.0015070963418111205 score: 1.0
2021-08-08 04:18:40,564 | train | INFO | Epoch 6 train batch 353/450: 5648/7200 mean loss: 0.0015348868910223246 score: 0.9963235294117647
2021-08-08 04:18:41,353 | train | INFO | Epoch 6 train batch 354/450: 5664/7200 mean loss: 0.001647503930144012 score: 1.0
2021-08-08 04:18:42,170 | train | INFO | Epoch 6 train batch 355/450: 5680/7200 mean loss: 0.0013259650440886617 score: 1.0
2021-08-08 04:18:42,959 | train | INFO | Epoch 6 train batch 356/450: 5696/7200 mean loss: 0.001373537932522595 score: 0.8811274509803921
2021-08-08 04:18:43,773 | train | INFO | Epoch 6 train batch 357/450: 5712/7200 mean loss: 0.001465233159251511 score: 1.0
2021-08-08 04:18:44,551 | train | INFO | Epoch 6 train batch 358/450: 5728/7200 mean loss: 0.0014727734960615635 score: 1.0
2021-08-08 04:18:45,352 | train | INFO | Epoch 6 train batch 359/450: 5744/7200 mean loss: 0.0014790165005251765 score: 1.0
2021-08-08 04:18:46,179 | train | INFO | Epoch 6 train batch 360/450: 5760/7200 mean loss: 0.001538173877634108 score: 1.0
2021-08-08 04:18:46,955 | train | INFO | Epoch 6 train batch 361/450: 5776/7200 mean loss: 0.0015326525317505002 score: 1.0
2021-08-08 04:18:47,739 | train | INFO | Epoch 6 train batch 362/450: 5792/7200 mean loss: 0.0015687559498474002 score: 0.9926470588235294
2021-08-08 04:18:48,521 | train | INFO | Epoch 6 train batch 363/450: 5808/7200 mean loss: 0.001509123481810093 score: 1.0
2021-08-08 04:18:49,305 | train | INFO | Epoch 6 train batch 364/450: 5824/7200 mean loss: 0.001784272026270628 score: 1.0
2021-08-08 04:18:50,081 | train | INFO | Epoch 6 train batch 365/450: 5840/7200 mean loss: 0.0014855522895231843 score: 1.0
2021-08-08 04:18:50,892 | train | INFO | Epoch 6 train batch 366/450: 5856/7200 mean loss: 0.0016331637743860483 score: 0.9850490196078432
2021-08-08 04:18:51,686 | train | INFO | Epoch 6 train batch 367/450: 5872/7200 mean loss: 0.0017292159609496593 score: 1.0
2021-08-08 04:18:52,454 | train | INFO | Epoch 6 train batch 368/450: 5888/7200 mean loss: 0.0015433330554515123 score: 1.0
2021-08-08 04:18:53,223 | train | INFO | Epoch 6 train batch 369/450: 5904/7200 mean loss: 0.0017111171036958694 score: 1.0
2021-08-08 04:18:54,005 | train | INFO | Epoch 6 train batch 370/450: 5920/7200 mean loss: 0.001567115425132215 score: 0.995798319327731
2021-08-08 04:18:54,775 | train | INFO | Epoch 6 train batch 371/450: 5936/7200 mean loss: 0.0015312065370380878 score: 1.0
2021-08-08 04:18:55,549 | train | INFO | Epoch 6 train batch 372/450: 5952/7200 mean loss: 0.0016951850848272443 score: 1.0
2021-08-08 04:18:56,317 | train | INFO | Epoch 6 train batch 373/450: 5968/7200 mean loss: 0.0014020835515111685 score: 0.9889705882352942
2021-08-08 04:18:57,095 | train | INFO | Epoch 6 train batch 374/450: 5984/7200 mean loss: 0.0016600294038653374 score: 1.0
2021-08-08 04:18:57,882 | train | INFO | Epoch 6 train batch 375/450: 6000/7200 mean loss: 0.0015060969162732363 score: 1.0
2021-08-08 04:18:58,650 | train | INFO | Epoch 6 train batch 376/450: 6016/7200 mean loss: 0.0014124084264039993 score: 1.0
2021-08-08 04:18:59,421 | train | INFO | Epoch 6 train batch 377/450: 6032/7200 mean loss: 0.0015201281057670712 score: 0.9887254901960785
2021-08-08 04:19:00,197 | train | INFO | Epoch 6 train batch 378/450: 6048/7200 mean loss: 0.0013686752645298839 score: 0.9887254901960785
2021-08-08 04:19:00,966 | train | INFO | Epoch 6 train batch 379/450: 6064/7200 mean loss: 0.0014504402643069625 score: 0.9921568627450981
2021-08-08 04:19:01,737 | train | INFO | Epoch 6 train batch 380/450: 6080/7200 mean loss: 0.0015592657728120685 score: 1.0
2021-08-08 04:19:02,518 | train | INFO | Epoch 6 train batch 381/450: 6096/7200 mean loss: 0.0013701918069273233 score: 1.0
2021-08-08 04:19:03,295 | train | INFO | Epoch 6 train batch 382/450: 6112/7200 mean loss: 0.0013897735625505447 score: 1.0
2021-08-08 04:19:04,071 | train | INFO | Epoch 6 train batch 383/450: 6128/7200 mean loss: 0.001459730789065361 score: 0.9740196078431372
2021-08-08 04:19:04,847 | train | INFO | Epoch 6 train batch 384/450: 6144/7200 mean loss: 0.001570953638292849 score: 0.996078431372549
2021-08-08 04:19:05,617 | train | INFO | Epoch 6 train batch 385/450: 6160/7200 mean loss: 0.001740301144309342 score: 1.0
2021-08-08 04:19:06,384 | train | INFO | Epoch 6 train batch 386/450: 6176/7200 mean loss: 0.0018215482123196125 score: 1.0
2021-08-08 04:19:07,149 | train | INFO | Epoch 6 train batch 387/450: 6192/7200 mean loss: 0.0015691224252805114 score: 0.9926470588235294
2021-08-08 04:19:07,917 | train | INFO | Epoch 6 train batch 388/450: 6208/7200 mean loss: 0.001600382849574089 score: 1.0
2021-08-08 04:19:08,692 | train | INFO | Epoch 6 train batch 389/450: 6224/7200 mean loss: 0.0015784382121637464 score: 1.0
2021-08-08 04:19:09,469 | train | INFO | Epoch 6 train batch 390/450: 6240/7200 mean loss: 0.0012164600193500519 score: 1.0
2021-08-08 04:19:10,261 | train | INFO | Epoch 6 train batch 391/450: 6256/7200 mean loss: 0.0014554543886333704 score: 0.9926470588235294
2021-08-08 04:19:11,038 | train | INFO | Epoch 6 train batch 392/450: 6272/7200 mean loss: 0.001552464789710939 score: 0.9926470588235294
2021-08-08 04:19:11,814 | train | INFO | Epoch 6 train batch 393/450: 6288/7200 mean loss: 0.0013450935948640108 score: 0.9889705882352942
2021-08-08 04:19:12,587 | train | INFO | Epoch 6 train batch 394/450: 6304/7200 mean loss: 0.001407684525474906 score: 0.9889705882352942
2021-08-08 04:19:13,359 | train | INFO | Epoch 6 train batch 395/450: 6320/7200 mean loss: 0.0014350347919389606 score: 1.0
2021-08-08 04:19:14,131 | train | INFO | Epoch 6 train batch 396/450: 6336/7200 mean loss: 0.0015024890890344977 score: 1.0
2021-08-08 04:19:14,901 | train | INFO | Epoch 6 train batch 397/450: 6352/7200 mean loss: 0.0015973575646057725 score: 1.0
2021-08-08 04:19:15,685 | train | INFO | Epoch 6 train batch 398/450: 6368/7200 mean loss: 0.0015280426014214754 score: 1.0
2021-08-08 04:19:16,458 | train | INFO | Epoch 6 train batch 399/450: 6384/7200 mean loss: 0.0015988958766683936 score: 1.0
2021-08-08 04:19:17,236 | train | INFO | Epoch 6 train batch 400/450: 6400/7200 mean loss: 0.0015515850391238928 score: 1.0
2021-08-08 04:19:18,020 | train | INFO | Epoch 6 train batch 401/450: 6416/7200 mean loss: 0.001516343909315765 score: 0.8477941176470588
2021-08-08 04:19:18,793 | train | INFO | Epoch 6 train batch 402/450: 6432/7200 mean loss: 0.0013508875854313374 score: 1.0
2021-08-08 04:19:19,608 | train | INFO | Epoch 6 train batch 403/450: 6448/7200 mean loss: 0.001395107596181333 score: 1.0
2021-08-08 04:19:20,391 | train | INFO | Epoch 6 train batch 404/450: 6464/7200 mean loss: 0.0016869092360138893 score: 1.0
2021-08-08 04:19:21,175 | train | INFO | Epoch 6 train batch 405/450: 6480/7200 mean loss: 0.0015269231516867876 score: 1.0
2021-08-08 04:19:21,949 | train | INFO | Epoch 6 train batch 406/450: 6496/7200 mean loss: 0.001544303260743618 score: 0.9926470588235294
2021-08-08 04:19:22,735 | train | INFO | Epoch 6 train batch 407/450: 6512/7200 mean loss: 0.0013704353477805853 score: 1.0
2021-08-08 04:19:23,521 | train | INFO | Epoch 6 train batch 408/450: 6528/7200 mean loss: 0.0014281811891123652 score: 1.0
2021-08-08 04:19:24,296 | train | INFO | Epoch 6 train batch 409/450: 6544/7200 mean loss: 0.0015783470589667559 score: 1.0
2021-08-08 04:19:25,086 | train | INFO | Epoch 6 train batch 410/450: 6560/7200 mean loss: 0.001371115678921342 score: 1.0
2021-08-08 04:19:25,894 | train | INFO | Epoch 6 train batch 411/450: 6576/7200 mean loss: 0.0014461815590038896 score: 1.0
2021-08-08 04:19:26,673 | train | INFO | Epoch 6 train batch 412/450: 6592/7200 mean loss: 0.0012637712061405182 score: 0.932975113122172
2021-08-08 04:19:27,449 | train | INFO | Epoch 6 train batch 413/450: 6608/7200 mean loss: 0.001563600730150938 score: 1.0
2021-08-08 04:19:28,224 | train | INFO | Epoch 6 train batch 414/450: 6624/7200 mean loss: 0.001580729614943266 score: 1.0
2021-08-08 04:19:29,011 | train | INFO | Epoch 6 train batch 415/450: 6640/7200 mean loss: 0.001429490395821631 score: 1.0
2021-08-08 04:19:29,778 | train | INFO | Epoch 6 train batch 416/450: 6656/7200 mean loss: 0.0013614973286166787 score: 1.0
2021-08-08 04:19:30,590 | train | INFO | Epoch 6 train batch 417/450: 6672/7200 mean loss: 0.0014934440841898322 score: 0.9813725490196079
2021-08-08 04:19:31,363 | train | INFO | Epoch 6 train batch 418/450: 6688/7200 mean loss: 0.0014254729030653834 score: 1.0
2021-08-08 04:19:32,137 | train | INFO | Epoch 6 train batch 419/450: 6704/7200 mean loss: 0.00155998847912997 score: 1.0
2021-08-08 04:19:32,919 | train | INFO | Epoch 6 train batch 420/450: 6720/7200 mean loss: 0.001450306735932827 score: 0.9889705882352942
2021-08-08 04:19:33,697 | train | INFO | Epoch 6 train batch 421/450: 6736/7200 mean loss: 0.0014498225646093488 score: 1.0
2021-08-08 04:19:34,471 | train | INFO | Epoch 6 train batch 422/450: 6752/7200 mean loss: 0.0015877886908128858 score: 1.0
2021-08-08 04:19:35,263 | train | INFO | Epoch 6 train batch 423/450: 6768/7200 mean loss: 0.0016371390083804727 score: 1.0
2021-08-08 04:19:36,033 | train | INFO | Epoch 6 train batch 424/450: 6784/7200 mean loss: 0.0017577831167727709 score: 0.9889705882352942
2021-08-08 04:19:36,806 | train | INFO | Epoch 6 train batch 425/450: 6800/7200 mean loss: 0.0014623007737100124 score: 0.5884803921568627
2021-08-08 04:19:37,579 | train | INFO | Epoch 6 train batch 426/450: 6816/7200 mean loss: 0.0015840103151276708 score: 0.996078431372549
2021-08-08 04:19:38,381 | train | INFO | Epoch 6 train batch 427/450: 6832/7200 mean loss: 0.001600964111275971 score: 0.9926470588235294
2021-08-08 04:19:39,156 | train | INFO | Epoch 6 train batch 428/450: 6848/7200 mean loss: 0.0015893718227744102 score: 1.0
2021-08-08 04:19:39,958 | train | INFO | Epoch 6 train batch 429/450: 6864/7200 mean loss: 0.0014667012728750706 score: 1.0
2021-08-08 04:19:40,739 | train | INFO | Epoch 6 train batch 430/450: 6880/7200 mean loss: 0.0015105875208973885 score: 1.0
2021-08-08 04:19:41,542 | train | INFO | Epoch 6 train batch 431/450: 6896/7200 mean loss: 0.0016701485728845 score: 1.0
2021-08-08 04:19:42,346 | train | INFO | Epoch 6 train batch 432/450: 6912/7200 mean loss: 0.0016376072308048606 score: 1.0
2021-08-08 04:19:43,147 | train | INFO | Epoch 6 train batch 433/450: 6928/7200 mean loss: 0.001669254619628191 score: 0.9963235294117647
2021-08-08 04:19:44,006 | train | INFO | Epoch 6 train batch 434/450: 6944/7200 mean loss: 0.0016078352928161621 score: 1.0
2021-08-08 04:19:44,816 | train | INFO | Epoch 6 train batch 435/450: 6960/7200 mean loss: 0.001604079152457416 score: 1.0
2021-08-08 04:19:45,599 | train | INFO | Epoch 6 train batch 436/450: 6976/7200 mean loss: 0.0014041542308405042 score: 1.0
2021-08-08 04:19:46,373 | train | INFO | Epoch 6 train batch 437/450: 6992/7200 mean loss: 0.0014151250943541527 score: 1.0
2021-08-08 04:19:47,146 | train | INFO | Epoch 6 train batch 438/450: 7008/7200 mean loss: 0.0017035389319062233 score: 1.0
2021-08-08 04:19:47,923 | train | INFO | Epoch 6 train batch 439/450: 7024/7200 mean loss: 0.0015858443221077323 score: 1.0
2021-08-08 04:19:48,692 | train | INFO | Epoch 6 train batch 440/450: 7040/7200 mean loss: 0.0016210019821301103 score: 1.0
2021-08-08 04:19:49,457 | train | INFO | Epoch 6 train batch 441/450: 7056/7200 mean loss: 0.001556130708195269 score: 0.9926470588235294
2021-08-08 04:19:50,224 | train | INFO | Epoch 6 train batch 442/450: 7072/7200 mean loss: 0.0014594130916520953 score: 1.0
2021-08-08 04:19:50,988 | train | INFO | Epoch 6 train batch 443/450: 7088/7200 mean loss: 0.0014311453560367227 score: 0.9926470588235294
2021-08-08 04:19:51,755 | train | INFO | Epoch 6 train batch 444/450: 7104/7200 mean loss: 0.0015596707817167044 score: 1.0
2021-08-08 04:19:52,521 | train | INFO | Epoch 6 train batch 445/450: 7120/7200 mean loss: 0.001516622374765575 score: 1.0
2021-08-08 04:19:53,287 | train | INFO | Epoch 6 train batch 446/450: 7136/7200 mean loss: 0.001432800549082458 score: 1.0
2021-08-08 04:19:54,054 | train | INFO | Epoch 6 train batch 447/450: 7152/7200 mean loss: 0.0015091222012415528 score: 0.9963235294117647
2021-08-08 04:19:54,823 | train | INFO | Epoch 6 train batch 448/450: 7168/7200 mean loss: 0.0016003170749172568 score: 1.0
2021-08-08 04:19:55,596 | train | INFO | Epoch 6 train batch 449/450: 7184/7200 mean loss: 0.0015337546356022358 score: 1.0
2021-08-08 04:19:55,764 | train | INFO | Epoch 6, Train, Mean loss: 0.024256683877772755, Score: 0.9911720953338601
2021-08-08 04:19:57,211 | train | INFO | Epoch 6 validation batch 0/113: 0/1800 mean loss: 0.0010587767465040088 score: 1.0
2021-08-08 04:19:57,446 | train | INFO | Epoch 6 validation batch 1/113: 16/1800 mean loss: 0.0010765324113890529 score: 0.9926470588235294
2021-08-08 04:19:57,694 | train | INFO | Epoch 6 validation batch 2/113: 32/1800 mean loss: 0.0013485656818374991 score: 1.0
2021-08-08 04:19:57,953 | train | INFO | Epoch 6 validation batch 3/113: 48/1800 mean loss: 0.0011759325861930847 score: 1.0
2021-08-08 04:19:58,198 | train | INFO | Epoch 6 validation batch 4/113: 64/1800 mean loss: 0.0010504736565053463 score: 1.0
2021-08-08 04:19:58,430 | train | INFO | Epoch 6 validation batch 5/113: 80/1800 mean loss: 0.001053975080139935 score: 1.0
2021-08-08 04:19:58,686 | train | INFO | Epoch 6 validation batch 6/113: 96/1800 mean loss: 0.0010215473594143987 score: 1.0
2021-08-08 04:19:58,942 | train | INFO | Epoch 6 validation batch 7/113: 112/1800 mean loss: 0.0011768564581871033 score: 1.0
2021-08-08 04:19:59,173 | train | INFO | Epoch 6 validation batch 8/113: 128/1800 mean loss: 0.0011374505702406168 score: 1.0
2021-08-08 04:19:59,420 | train | INFO | Epoch 6 validation batch 9/113: 144/1800 mean loss: 0.0010731191141530871 score: 1.0
2021-08-08 04:19:59,664 | train | INFO | Epoch 6 validation batch 10/113: 160/1800 mean loss: 0.0011688867816701531 score: 0.9779411764705882
2021-08-08 04:19:59,897 | train | INFO | Epoch 6 validation batch 11/113: 176/1800 mean loss: 0.0011956983944401145 score: 0.9963235294117647
2021-08-08 04:20:00,129 | train | INFO | Epoch 6 validation batch 12/113: 192/1800 mean loss: 0.0011056943330913782 score: 1.0
2021-08-08 04:20:00,360 | train | INFO | Epoch 6 validation batch 13/113: 208/1800 mean loss: 0.0010482032084837556 score: 1.0
2021-08-08 04:20:00,593 | train | INFO | Epoch 6 validation batch 14/113: 224/1800 mean loss: 0.0009709967998787761 score: 1.0
2021-08-08 04:20:00,849 | train | INFO | Epoch 6 validation batch 15/113: 240/1800 mean loss: 0.0010895202867686749 score: 1.0
2021-08-08 04:20:01,093 | train | INFO | Epoch 6 validation batch 16/113: 256/1800 mean loss: 0.0010631693294271827 score: 1.0
2021-08-08 04:20:01,334 | train | INFO | Epoch 6 validation batch 17/113: 272/1800 mean loss: 0.0012161667691543698 score: 1.0
2021-08-08 04:20:01,578 | train | INFO | Epoch 6 validation batch 18/113: 288/1800 mean loss: 0.0008829778525978327 score: 1.0
2021-08-08 04:20:01,811 | train | INFO | Epoch 6 validation batch 19/113: 304/1800 mean loss: 0.0010855637956410646 score: 1.0
2021-08-08 04:20:02,066 | train | INFO | Epoch 6 validation batch 20/113: 320/1800 mean loss: 0.0012146934168413281 score: 0.9887254901960785
2021-08-08 04:20:02,327 | train | INFO | Epoch 6 validation batch 21/113: 336/1800 mean loss: 0.0010270774364471436 score: 1.0
2021-08-08 04:20:02,566 | train | INFO | Epoch 6 validation batch 22/113: 352/1800 mean loss: 0.0010348701616749167 score: 1.0
2021-08-08 04:20:02,817 | train | INFO | Epoch 6 validation batch 23/113: 368/1800 mean loss: 0.0010090552968904376 score: 1.0
2021-08-08 04:20:03,057 | train | INFO | Epoch 6 validation batch 24/113: 384/1800 mean loss: 0.001030223211273551 score: 1.0
2021-08-08 04:20:03,310 | train | INFO | Epoch 6 validation batch 25/113: 400/1800 mean loss: 0.001161682652309537 score: 1.0
2021-08-08 04:20:03,543 | train | INFO | Epoch 6 validation batch 26/113: 416/1800 mean loss: 0.0010013850405812263 score: 1.0
2021-08-08 04:20:03,773 | train | INFO | Epoch 6 validation batch 27/113: 432/1800 mean loss: 0.0011841122759506106 score: 1.0
2021-08-08 04:20:04,058 | train | INFO | Epoch 6 validation batch 28/113: 448/1800 mean loss: 0.0011058986419811845 score: 1.0
2021-08-08 04:20:04,312 | train | INFO | Epoch 6 validation batch 29/113: 464/1800 mean loss: 0.0010856090812012553 score: 1.0
2021-08-08 04:20:04,563 | train | INFO | Epoch 6 validation batch 30/113: 480/1800 mean loss: 0.0011087852763012052 score: 1.0
2021-08-08 04:20:04,829 | train | INFO | Epoch 6 validation batch 31/113: 496/1800 mean loss: 0.001054451335221529 score: 1.0
2021-08-08 04:20:05,064 | train | INFO | Epoch 6 validation batch 32/113: 512/1800 mean loss: 0.0010658970568329096 score: 0.9963235294117647
2021-08-08 04:20:05,297 | train | INFO | Epoch 6 validation batch 33/113: 528/1800 mean loss: 0.0009927843930199742 score: 1.0
2021-08-08 04:20:05,529 | train | INFO | Epoch 6 validation batch 34/113: 544/1800 mean loss: 0.0008399802609346807 score: 1.0
2021-08-08 04:20:05,766 | train | INFO | Epoch 6 validation batch 35/113: 560/1800 mean loss: 0.0012120059691369534 score: 1.0
2021-08-08 04:20:05,998 | train | INFO | Epoch 6 validation batch 36/113: 576/1800 mean loss: 0.0011825611582025886 score: 0.911029411764706
2021-08-08 04:20:06,228 | train | INFO | Epoch 6 validation batch 37/113: 592/1800 mean loss: 0.0009008162305690348 score: 1.0
2021-08-08 04:20:06,459 | train | INFO | Epoch 6 validation batch 38/113: 608/1800 mean loss: 0.0011539154220372438 score: 1.0
2021-08-08 04:20:06,690 | train | INFO | Epoch 6 validation batch 39/113: 624/1800 mean loss: 0.0010573995532467961 score: 1.0
2021-08-08 04:20:06,934 | train | INFO | Epoch 6 validation batch 40/113: 640/1800 mean loss: 0.001136900158599019 score: 1.0
2021-08-08 04:20:07,170 | train | INFO | Epoch 6 validation batch 41/113: 656/1800 mean loss: 0.0010302476584911346 score: 1.0
2021-08-08 04:20:07,430 | train | INFO | Epoch 6 validation batch 42/113: 672/1800 mean loss: 0.0010588127188384533 score: 1.0
2021-08-08 04:20:07,666 | train | INFO | Epoch 6 validation batch 43/113: 688/1800 mean loss: 0.0010633035562932491 score: 1.0
2021-08-08 04:20:07,902 | train | INFO | Epoch 6 validation batch 44/113: 704/1800 mean loss: 0.0013099153293296695 score: 0.9742647058823529
2021-08-08 04:20:08,160 | train | INFO | Epoch 6 validation batch 45/113: 720/1800 mean loss: 0.0010967808775603771 score: 1.0
2021-08-08 04:20:08,410 | train | INFO | Epoch 6 validation batch 46/113: 736/1800 mean loss: 0.0011062666308134794 score: 0.9889705882352942
2021-08-08 04:20:08,661 | train | INFO | Epoch 6 validation batch 47/113: 752/1800 mean loss: 0.000985473277978599 score: 1.0
2021-08-08 04:20:08,909 | train | INFO | Epoch 6 validation batch 48/113: 768/1800 mean loss: 0.001038357033394277 score: 1.0
2021-08-08 04:20:09,142 | train | INFO | Epoch 6 validation batch 49/113: 784/1800 mean loss: 0.0011048534652218223 score: 1.0
2021-08-08 04:20:09,374 | train | INFO | Epoch 6 validation batch 50/113: 800/1800 mean loss: 0.0009972439147531986 score: 1.0
2021-08-08 04:20:09,604 | train | INFO | Epoch 6 validation batch 51/113: 816/1800 mean loss: 0.0011257447768002748 score: 0.9816176470588235
2021-08-08 04:20:09,836 | train | INFO | Epoch 6 validation batch 52/113: 832/1800 mean loss: 0.0011183068854734302 score: 1.0
2021-08-08 04:20:10,078 | train | INFO | Epoch 6 validation batch 53/113: 848/1800 mean loss: 0.0010832498082891107 score: 1.0
2021-08-08 04:20:10,327 | train | INFO | Epoch 6 validation batch 54/113: 864/1800 mean loss: 0.001044563134200871 score: 1.0
2021-08-08 04:20:10,583 | train | INFO | Epoch 6 validation batch 55/113: 880/1800 mean loss: 0.001138917519710958 score: 1.0
2021-08-08 04:20:10,815 | train | INFO | Epoch 6 validation batch 56/113: 896/1800 mean loss: 0.0010701084975153208 score: 1.0
2021-08-08 04:20:11,047 | train | INFO | Epoch 6 validation batch 57/113: 912/1800 mean loss: 0.0011914036003872752 score: 1.0
2021-08-08 04:20:11,279 | train | INFO | Epoch 6 validation batch 58/113: 928/1800 mean loss: 0.0011615032562986016 score: 0.9852941176470589
2021-08-08 04:20:11,515 | train | INFO | Epoch 6 validation batch 59/113: 944/1800 mean loss: 0.0010553813772276044 score: 1.0
2021-08-08 04:20:11,754 | train | INFO | Epoch 6 validation batch 60/113: 960/1800 mean loss: 0.0009176077437587082 score: 1.0
2021-08-08 04:20:11,986 | train | INFO | Epoch 6 validation batch 61/113: 976/1800 mean loss: 0.000972767302300781 score: 1.0
2021-08-08 04:20:12,218 | train | INFO | Epoch 6 validation batch 62/113: 992/1800 mean loss: 0.001028801896609366 score: 1.0
2021-08-08 04:20:12,456 | train | INFO | Epoch 6 validation batch 63/113: 1008/1800 mean loss: 0.0010073898592963815 score: 1.0
2021-08-08 04:20:12,690 | train | INFO | Epoch 6 validation batch 64/113: 1024/1800 mean loss: 0.0011175224790349603 score: 1.0
2021-08-08 04:20:12,924 | train | INFO | Epoch 6 validation batch 65/113: 1040/1800 mean loss: 0.0011002507526427507 score: 1.0
2021-08-08 04:20:13,154 | train | INFO | Epoch 6 validation batch 66/113: 1056/1800 mean loss: 0.0011092580389231443 score: 1.0
2021-08-08 04:20:13,393 | train | INFO | Epoch 6 validation batch 67/113: 1072/1800 mean loss: 0.0011532674543559551 score: 1.0
2021-08-08 04:20:13,662 | train | INFO | Epoch 6 validation batch 68/113: 1088/1800 mean loss: 0.0009385935845784843 score: 1.0
2021-08-08 04:20:13,925 | train | INFO | Epoch 6 validation batch 69/113: 1104/1800 mean loss: 0.0010513573652133346 score: 1.0
2021-08-08 04:20:14,174 | train | INFO | Epoch 6 validation batch 70/113: 1120/1800 mean loss: 0.0012139807222411036 score: 0.9963235294117647
2021-08-08 04:20:14,432 | train | INFO | Epoch 6 validation batch 71/113: 1136/1800 mean loss: 0.001029496779665351 score: 1.0
2021-08-08 04:20:14,666 | train | INFO | Epoch 6 validation batch 72/113: 1152/1800 mean loss: 0.0010135460179299116 score: 1.0
2021-08-08 04:20:14,939 | train | INFO | Epoch 6 validation batch 73/113: 1168/1800 mean loss: 0.0012423035223037004 score: 1.0
2021-08-08 04:20:15,176 | train | INFO | Epoch 6 validation batch 74/113: 1184/1800 mean loss: 0.0011206117924302816 score: 1.0
2021-08-08 04:20:15,423 | train | INFO | Epoch 6 validation batch 75/113: 1200/1800 mean loss: 0.0010254180524498224 score: 1.0
2021-08-08 04:20:15,653 | train | INFO | Epoch 6 validation batch 76/113: 1216/1800 mean loss: 0.0009329167660325766 score: 1.0
2021-08-08 04:20:15,892 | train | INFO | Epoch 6 validation batch 77/113: 1232/1800 mean loss: 0.0009546594228595495 score: 1.0
2021-08-08 04:20:16,136 | train | INFO | Epoch 6 validation batch 78/113: 1248/1800 mean loss: 0.0010709223570302129 score: 0.9850490196078432
2021-08-08 04:20:16,375 | train | INFO | Epoch 6 validation batch 79/113: 1264/1800 mean loss: 0.0011650566011667252 score: 0.9921568627450981
2021-08-08 04:20:16,609 | train | INFO | Epoch 6 validation batch 80/113: 1280/1800 mean loss: 0.0012559870956465602 score: 1.0
2021-08-08 04:20:16,861 | train | INFO | Epoch 6 validation batch 81/113: 1296/1800 mean loss: 0.001074031344614923 score: 1.0
2021-08-08 04:20:17,105 | train | INFO | Epoch 6 validation batch 82/113: 1312/1800 mean loss: 0.0010305230971425772 score: 1.0
2021-08-08 04:20:17,347 | train | INFO | Epoch 6 validation batch 83/113: 1328/1800 mean loss: 0.0012278922367841005 score: 1.0
2021-08-08 04:20:17,580 | train | INFO | Epoch 6 validation batch 84/113: 1344/1800 mean loss: 0.001234166556969285 score: 0.9816176470588235
2021-08-08 04:20:17,812 | train | INFO | Epoch 6 validation batch 85/113: 1360/1800 mean loss: 0.0011589775094762444 score: 1.0
2021-08-08 04:20:18,062 | train | INFO | Epoch 6 validation batch 86/113: 1376/1800 mean loss: 0.0013176222564652562 score: 1.0
2021-08-08 04:20:18,308 | train | INFO | Epoch 6 validation batch 87/113: 1392/1800 mean loss: 0.0012323560658842325 score: 1.0
2021-08-08 04:20:18,555 | train | INFO | Epoch 6 validation batch 88/113: 1408/1800 mean loss: 0.001030137063935399 score: 1.0
2021-08-08 04:20:18,837 | train | INFO | Epoch 6 validation batch 89/113: 1424/1800 mean loss: 0.0009438242996111512 score: 1.0
2021-08-08 04:20:19,083 | train | INFO | Epoch 6 validation batch 90/113: 1440/1800 mean loss: 0.0010565374977886677 score: 1.0
2021-08-08 04:20:19,317 | train | INFO | Epoch 6 validation batch 91/113: 1456/1800 mean loss: 0.0012830357300117612 score: 1.0
2021-08-08 04:20:19,571 | train | INFO | Epoch 6 validation batch 92/113: 1472/1800 mean loss: 0.0010823407210409641 score: 1.0
2021-08-08 04:20:19,818 | train | INFO | Epoch 6 validation batch 93/113: 1488/1800 mean loss: 0.0010821769246831536 score: 1.0
2021-08-08 04:20:20,082 | train | INFO | Epoch 6 validation batch 94/113: 1504/1800 mean loss: 0.0010782784083858132 score: 1.0
2021-08-08 04:20:20,317 | train | INFO | Epoch 6 validation batch 95/113: 1520/1800 mean loss: 0.0011208425275981426 score: 1.0
2021-08-08 04:20:20,553 | train | INFO | Epoch 6 validation batch 96/113: 1536/1800 mean loss: 0.0011664777994155884 score: 0.9963235294117647
2021-08-08 04:20:20,803 | train | INFO | Epoch 6 validation batch 97/113: 1552/1800 mean loss: 0.0010974908946081996 score: 1.0
2021-08-08 04:20:21,050 | train | INFO | Epoch 6 validation batch 98/113: 1568/1800 mean loss: 0.001076715998351574 score: 1.0
2021-08-08 04:20:21,283 | train | INFO | Epoch 6 validation batch 99/113: 1584/1800 mean loss: 0.001042990363202989 score: 1.0
2021-08-08 04:20:21,523 | train | INFO | Epoch 6 validation batch 100/113: 1600/1800 mean loss: 0.0012808000901713967 score: 1.0
2021-08-08 04:20:21,757 | train | INFO | Epoch 6 validation batch 101/113: 1616/1800 mean loss: 0.00106876902282238 score: 1.0
2021-08-08 04:20:21,991 | train | INFO | Epoch 6 validation batch 102/113: 1632/1800 mean loss: 0.00102513050660491 score: 1.0
2021-08-08 04:20:22,224 | train | INFO | Epoch 6 validation batch 103/113: 1648/1800 mean loss: 0.0010484898230060935 score: 1.0
2021-08-08 04:20:22,455 | train | INFO | Epoch 6 validation batch 104/113: 1664/1800 mean loss: 0.0011475885985419154 score: 1.0
2021-08-08 04:20:22,704 | train | INFO | Epoch 6 validation batch 105/113: 1680/1800 mean loss: 0.0011135331587865949 score: 1.0
2021-08-08 04:20:22,936 | train | INFO | Epoch 6 validation batch 106/113: 1696/1800 mean loss: 0.0011238317238166928 score: 1.0
2021-08-08 04:20:23,168 | train | INFO | Epoch 6 validation batch 107/113: 1712/1800 mean loss: 0.001338296104222536 score: 1.0
2021-08-08 04:20:23,399 | train | INFO | Epoch 6 validation batch 108/113: 1728/1800 mean loss: 0.0013126339763402939 score: 1.0
2021-08-08 04:20:23,629 | train | INFO | Epoch 6 validation batch 109/113: 1744/1800 mean loss: 0.001230337074957788 score: 1.0
2021-08-08 04:20:23,860 | train | INFO | Epoch 6 validation batch 110/113: 1760/1800 mean loss: 0.0010047635296359658 score: 1.0
2021-08-08 04:20:24,090 | train | INFO | Epoch 6 validation batch 111/113: 1776/1800 mean loss: 0.001073845662176609 score: 1.0
2021-08-08 04:20:24,253 | train | INFO | Epoch 6 validation batch 112/113: 1792/1800 mean loss: 0.0009539980092085898 score: 1.0
2021-08-08 04:20:24,420 | train | INFO | Epoch 6, Validation, Mean loss: 0.017532147928676772, Score: 0.9977398924171439
2021-08-08 04:20:24,421 | train | INFO | Write row 6
2021-08-08 04:20:27,118 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:20:27,122 | train | INFO | Update best record row 7, checkpoints 0.01804033433606403 -> 0.017532147928676772
2021-08-08 04:20:29,095 | train | INFO | Epoch 7 train batch 0/450: 0/7200 mean loss: 0.0015307081630453467 score: 1.0
2021-08-08 04:20:29,895 | train | INFO | Epoch 7 train batch 1/450: 16/7200 mean loss: 0.0013535465113818645 score: 1.0
2021-08-08 04:20:30,677 | train | INFO | Epoch 7 train batch 2/450: 32/7200 mean loss: 0.0012931055389344692 score: 1.0
2021-08-08 04:20:31,454 | train | INFO | Epoch 7 train batch 3/450: 48/7200 mean loss: 0.0014404673129320145 score: 1.0
2021-08-08 04:20:32,250 | train | INFO | Epoch 7 train batch 4/450: 64/7200 mean loss: 0.0014447879511862993 score: 0.996078431372549
2021-08-08 04:20:33,071 | train | INFO | Epoch 7 train batch 5/450: 80/7200 mean loss: 0.0013646675506606698 score: 1.0
2021-08-08 04:20:33,907 | train | INFO | Epoch 7 train batch 6/450: 96/7200 mean loss: 0.001601910451427102 score: 0.995798319327731
2021-08-08 04:20:34,692 | train | INFO | Epoch 7 train batch 7/450: 112/7200 mean loss: 0.0016261270502582192 score: 1.0
2021-08-08 04:20:35,564 | train | INFO | Epoch 7 train batch 8/450: 128/7200 mean loss: 0.0014791033463552594 score: 1.0
2021-08-08 04:20:36,466 | train | INFO | Epoch 7 train batch 9/450: 144/7200 mean loss: 0.0017014405457302928 score: 1.0
2021-08-08 04:20:37,264 | train | INFO | Epoch 7 train batch 10/450: 160/7200 mean loss: 0.0016770216170698404 score: 1.0
2021-08-08 04:20:38,039 | train | INFO | Epoch 7 train batch 11/450: 176/7200 mean loss: 0.0016046141972765326 score: 1.0
2021-08-08 04:20:38,870 | train | INFO | Epoch 7 train batch 12/450: 192/7200 mean loss: 0.0015699852956458926 score: 1.0
2021-08-08 04:20:39,655 | train | INFO | Epoch 7 train batch 13/450: 208/7200 mean loss: 0.0014791330322623253 score: 1.0
2021-08-08 04:20:40,487 | train | INFO | Epoch 7 train batch 14/450: 224/7200 mean loss: 0.0013305360917001963 score: 1.0
2021-08-08 04:20:41,308 | train | INFO | Epoch 7 train batch 15/450: 240/7200 mean loss: 0.0015070168301463127 score: 1.0
2021-08-08 04:20:42,209 | train | INFO | Epoch 7 train batch 16/450: 256/7200 mean loss: 0.0015244511887431145 score: 1.0
2021-08-08 04:20:43,031 | train | INFO | Epoch 7 train batch 17/450: 272/7200 mean loss: 0.0015427495818585157 score: 1.0
2021-08-08 04:20:43,898 | train | INFO | Epoch 7 train batch 18/450: 288/7200 mean loss: 0.0013639673124998808 score: 0.9926470588235294
2021-08-08 04:20:44,671 | train | INFO | Epoch 7 train batch 19/450: 304/7200 mean loss: 0.0014611349906772375 score: 0.9889705882352942
2021-08-08 04:20:45,463 | train | INFO | Epoch 7 train batch 20/450: 320/7200 mean loss: 0.0016063256189227104 score: 1.0
2021-08-08 04:20:46,234 | train | INFO | Epoch 7 train batch 21/450: 336/7200 mean loss: 0.001504371641203761 score: 0.9889705882352942
2021-08-08 04:20:47,108 | train | INFO | Epoch 7 train batch 22/450: 352/7200 mean loss: 0.0016436852747574449 score: 1.0
2021-08-08 04:20:47,902 | train | INFO | Epoch 7 train batch 23/450: 368/7200 mean loss: 0.0016331665683537722 score: 1.0
2021-08-08 04:20:48,702 | train | INFO | Epoch 7 train batch 24/450: 384/7200 mean loss: 0.0015127378283068538 score: 1.0
2021-08-08 04:20:49,500 | train | INFO | Epoch 7 train batch 25/450: 400/7200 mean loss: 0.0016355771804228425 score: 1.0
2021-08-08 04:20:50,280 | train | INFO | Epoch 7 train batch 26/450: 416/7200 mean loss: 0.0013496994506567717 score: 1.0
2021-08-08 04:20:51,063 | train | INFO | Epoch 7 train batch 27/450: 432/7200 mean loss: 0.0016122952802106738 score: 1.0
2021-08-08 04:20:51,835 | train | INFO | Epoch 7 train batch 28/450: 448/7200 mean loss: 0.0014510999899357557 score: 1.0
2021-08-08 04:20:52,645 | train | INFO | Epoch 7 train batch 29/450: 464/7200 mean loss: 0.0015311577590182424 score: 1.0
2021-08-08 04:20:53,447 | train | INFO | Epoch 7 train batch 30/450: 480/7200 mean loss: 0.0015645368257537484 score: 0.9963235294117647
2021-08-08 04:20:54,245 | train | INFO | Epoch 7 train batch 31/450: 496/7200 mean loss: 0.0015664700185880065 score: 1.0
2021-08-08 04:20:55,014 | train | INFO | Epoch 7 train batch 32/450: 512/7200 mean loss: 0.001353802508674562 score: 1.0
2021-08-08 04:20:55,826 | train | INFO | Epoch 7 train batch 33/450: 528/7200 mean loss: 0.0016978938365355134 score: 1.0
2021-08-08 04:20:56,614 | train | INFO | Epoch 7 train batch 34/450: 544/7200 mean loss: 0.0015584506327286363 score: 1.0
2021-08-08 04:20:57,401 | train | INFO | Epoch 7 train batch 35/450: 560/7200 mean loss: 0.0018277140334248543 score: 1.0
2021-08-08 04:20:58,203 | train | INFO | Epoch 7 train batch 36/450: 576/7200 mean loss: 0.0014660777524113655 score: 0.9926470588235294
2021-08-08 04:20:58,969 | train | INFO | Epoch 7 train batch 37/450: 592/7200 mean loss: 0.0015142230549827218 score: 0.9816176470588235
2021-08-08 04:20:59,756 | train | INFO | Epoch 7 train batch 38/450: 608/7200 mean loss: 0.001468891859985888 score: 0.9695728291316525
2021-08-08 04:21:00,535 | train | INFO | Epoch 7 train batch 39/450: 624/7200 mean loss: 0.0014748231042176485 score: 1.0
2021-08-08 04:21:01,362 | train | INFO | Epoch 7 train batch 40/450: 640/7200 mean loss: 0.001564448932185769 score: 0.9963235294117647
2021-08-08 04:21:02,140 | train | INFO | Epoch 7 train batch 41/450: 656/7200 mean loss: 0.0014194130199030042 score: 0.9963235294117647
2021-08-08 04:21:02,919 | train | INFO | Epoch 7 train batch 42/450: 672/7200 mean loss: 0.0014114425284788013 score: 1.0
2021-08-08 04:21:03,717 | train | INFO | Epoch 7 train batch 43/450: 688/7200 mean loss: 0.0014779254561290145 score: 1.0
2021-08-08 04:21:04,496 | train | INFO | Epoch 7 train batch 44/450: 704/7200 mean loss: 0.001522920560091734 score: 1.0
2021-08-08 04:21:05,290 | train | INFO | Epoch 7 train batch 45/450: 720/7200 mean loss: 0.001513548195362091 score: 1.0
2021-08-08 04:21:06,065 | train | INFO | Epoch 7 train batch 46/450: 736/7200 mean loss: 0.0016586226411163807 score: 1.0
2021-08-08 04:21:06,860 | train | INFO | Epoch 7 train batch 47/450: 752/7200 mean loss: 0.0015966660575941205 score: 1.0
2021-08-08 04:21:07,666 | train | INFO | Epoch 7 train batch 48/450: 768/7200 mean loss: 0.001321229967288673 score: 1.0
2021-08-08 04:21:08,451 | train | INFO | Epoch 7 train batch 49/450: 784/7200 mean loss: 0.0015023216838017106 score: 1.0
2021-08-08 04:21:09,230 | train | INFO | Epoch 7 train batch 50/450: 800/7200 mean loss: 0.0012803501449525356 score: 1.0
2021-08-08 04:21:10,033 | train | INFO | Epoch 7 train batch 51/450: 816/7200 mean loss: 0.0015604962827637792 score: 1.0
2021-08-08 04:21:10,836 | train | INFO | Epoch 7 train batch 52/450: 832/7200 mean loss: 0.0013390752719715238 score: 1.0
2021-08-08 04:21:11,628 | train | INFO | Epoch 7 train batch 53/450: 848/7200 mean loss: 0.0014246526407077909 score: 1.0
2021-08-08 04:21:12,441 | train | INFO | Epoch 7 train batch 54/450: 864/7200 mean loss: 0.0014195116236805916 score: 0.8294117647058823
2021-08-08 04:21:13,240 | train | INFO | Epoch 7 train batch 55/450: 880/7200 mean loss: 0.00139270827639848 score: 1.0
2021-08-08 04:21:14,010 | train | INFO | Epoch 7 train batch 56/450: 896/7200 mean loss: 0.0014157661935314536 score: 1.0
2021-08-08 04:21:14,791 | train | INFO | Epoch 7 train batch 57/450: 912/7200 mean loss: 0.001384361064992845 score: 1.0
2021-08-08 04:21:15,564 | train | INFO | Epoch 7 train batch 58/450: 928/7200 mean loss: 0.0012348528252914548 score: 0.996078431372549
2021-08-08 04:21:16,341 | train | INFO | Epoch 7 train batch 59/450: 944/7200 mean loss: 0.0015180818736553192 score: 1.0
2021-08-08 04:21:17,180 | train | INFO | Epoch 7 train batch 60/450: 960/7200 mean loss: 0.0015838901745155454 score: 1.0
2021-08-08 04:21:18,024 | train | INFO | Epoch 7 train batch 61/450: 976/7200 mean loss: 0.0015915916301310062 score: 1.0
2021-08-08 04:21:18,822 | train | INFO | Epoch 7 train batch 62/450: 992/7200 mean loss: 0.0016105150571092963 score: 0.9963235294117647
2021-08-08 04:21:19,625 | train | INFO | Epoch 7 train batch 63/450: 1008/7200 mean loss: 0.0013862306950613856 score: 1.0
2021-08-08 04:21:20,438 | train | INFO | Epoch 7 train batch 64/450: 1024/7200 mean loss: 0.0016180492239072919 score: 1.0
2021-08-08 04:21:21,217 | train | INFO | Epoch 7 train batch 65/450: 1040/7200 mean loss: 0.0014502997510135174 score: 1.0
2021-08-08 04:21:22,014 | train | INFO | Epoch 7 train batch 66/450: 1056/7200 mean loss: 0.0014326089294627309 score: 0.9887254901960785
2021-08-08 04:21:22,789 | train | INFO | Epoch 7 train batch 67/450: 1072/7200 mean loss: 0.0013821275206282735 score: 1.0
2021-08-08 04:21:23,620 | train | INFO | Epoch 7 train batch 68/450: 1088/7200 mean loss: 0.0014866768615320325 score: 1.0
2021-08-08 04:21:24,426 | train | INFO | Epoch 7 train batch 69/450: 1104/7200 mean loss: 0.0015939309960231185 score: 0.9764705882352942
2021-08-08 04:21:25,253 | train | INFO | Epoch 7 train batch 70/450: 1120/7200 mean loss: 0.001631336403079331 score: 1.0
2021-08-08 04:21:26,090 | train | INFO | Epoch 7 train batch 71/450: 1136/7200 mean loss: 0.0015191800193861127 score: 1.0
2021-08-08 04:21:26,918 | train | INFO | Epoch 7 train batch 72/450: 1152/7200 mean loss: 0.001416300772689283 score: 0.8708333333333333
2021-08-08 04:21:27,751 | train | INFO | Epoch 7 train batch 73/450: 1168/7200 mean loss: 0.0012790696928277612 score: 1.0
2021-08-08 04:21:28,544 | train | INFO | Epoch 7 train batch 74/450: 1184/7200 mean loss: 0.0012706571724265814 score: 1.0
2021-08-08 04:21:29,332 | train | INFO | Epoch 7 train batch 75/450: 1200/7200 mean loss: 0.0015884925378486514 score: 1.0
2021-08-08 04:21:30,119 | train | INFO | Epoch 7 train batch 76/450: 1216/7200 mean loss: 0.0015114817069843411 score: 1.0
2021-08-08 04:21:30,948 | train | INFO | Epoch 7 train batch 77/450: 1232/7200 mean loss: 0.0014599647838622332 score: 1.0
2021-08-08 04:21:31,750 | train | INFO | Epoch 7 train batch 78/450: 1248/7200 mean loss: 0.001384380622766912 score: 1.0
2021-08-08 04:21:32,594 | train | INFO | Epoch 7 train batch 79/450: 1264/7200 mean loss: 0.0015644208760932088 score: 1.0
2021-08-08 04:21:33,475 | train | INFO | Epoch 7 train batch 80/450: 1280/7200 mean loss: 0.0014630501391366124 score: 1.0
2021-08-08 04:21:34,321 | train | INFO | Epoch 7 train batch 81/450: 1296/7200 mean loss: 0.0015540615422651172 score: 1.0
2021-08-08 04:21:35,099 | train | INFO | Epoch 7 train batch 82/450: 1312/7200 mean loss: 0.0012060271110385656 score: 1.0
2021-08-08 04:21:35,878 | train | INFO | Epoch 7 train batch 83/450: 1328/7200 mean loss: 0.0015046234475448728 score: 1.0
2021-08-08 04:21:36,663 | train | INFO | Epoch 7 train batch 84/450: 1344/7200 mean loss: 0.00123348378110677 score: 1.0
2021-08-08 04:21:37,460 | train | INFO | Epoch 7 train batch 85/450: 1360/7200 mean loss: 0.0016078035114333034 score: 1.0
2021-08-08 04:21:38,241 | train | INFO | Epoch 7 train batch 86/450: 1376/7200 mean loss: 0.0015426625031977892 score: 1.0
2021-08-08 04:21:39,012 | train | INFO | Epoch 7 train batch 87/450: 1392/7200 mean loss: 0.0014840220101177692 score: 0.9848039215686275
2021-08-08 04:21:39,780 | train | INFO | Epoch 7 train batch 88/450: 1408/7200 mean loss: 0.0014255947899073362 score: 1.0
2021-08-08 04:21:40,583 | train | INFO | Epoch 7 train batch 89/450: 1424/7200 mean loss: 0.0014056528452783823 score: 1.0
2021-08-08 04:21:41,380 | train | INFO | Epoch 7 train batch 90/450: 1440/7200 mean loss: 0.0015949486987665296 score: 0.9963235294117647
2021-08-08 04:21:42,160 | train | INFO | Epoch 7 train batch 91/450: 1456/7200 mean loss: 0.0015842517605051398 score: 0.996078431372549
2021-08-08 04:21:42,982 | train | INFO | Epoch 7 train batch 92/450: 1472/7200 mean loss: 0.0015120359603315592 score: 0.9740196078431372
2021-08-08 04:21:43,768 | train | INFO | Epoch 7 train batch 93/450: 1488/7200 mean loss: 0.0012631714344024658 score: 1.0
2021-08-08 04:21:44,544 | train | INFO | Epoch 7 train batch 94/450: 1504/7200 mean loss: 0.0016145569970831275 score: 1.0
2021-08-08 04:21:45,320 | train | INFO | Epoch 7 train batch 95/450: 1520/7200 mean loss: 0.0016202143160626292 score: 1.0
2021-08-08 04:21:46,108 | train | INFO | Epoch 7 train batch 96/450: 1536/7200 mean loss: 0.0014172533992677927 score: 0.9926470588235294
2021-08-08 04:21:46,912 | train | INFO | Epoch 7 train batch 97/450: 1552/7200 mean loss: 0.0017669450026005507 score: 1.0
2021-08-08 04:21:47,794 | train | INFO | Epoch 7 train batch 98/450: 1568/7200 mean loss: 0.0014298310270532966 score: 1.0
2021-08-08 04:21:48,592 | train | INFO | Epoch 7 train batch 99/450: 1584/7200 mean loss: 0.001617657719179988 score: 1.0
2021-08-08 04:21:49,376 | train | INFO | Epoch 7 train batch 100/450: 1600/7200 mean loss: 0.0013474981533363461 score: 1.0
2021-08-08 04:21:50,258 | train | INFO | Epoch 7 train batch 101/450: 1616/7200 mean loss: 0.0014781474601477385 score: 1.0
2021-08-08 04:21:51,065 | train | INFO | Epoch 7 train batch 102/450: 1632/7200 mean loss: 0.0014398994389921427 score: 1.0
2021-08-08 04:21:51,895 | train | INFO | Epoch 7 train batch 103/450: 1648/7200 mean loss: 0.0013969141291454434 score: 0.9879201680672269
2021-08-08 04:21:52,699 | train | INFO | Epoch 7 train batch 104/450: 1664/7200 mean loss: 0.001267022336833179 score: 0.9779411764705882
2021-08-08 04:21:53,507 | train | INFO | Epoch 7 train batch 105/450: 1680/7200 mean loss: 0.001407982548698783 score: 0.7541666666666667
2021-08-08 04:21:54,324 | train | INFO | Epoch 7 train batch 106/450: 1696/7200 mean loss: 0.0013934755697846413 score: 1.0
2021-08-08 04:21:55,105 | train | INFO | Epoch 7 train batch 107/450: 1712/7200 mean loss: 0.0014612145023420453 score: 1.0
2021-08-08 04:21:55,903 | train | INFO | Epoch 7 train batch 108/450: 1728/7200 mean loss: 0.0015729799633845687 score: 0.9963235294117647
2021-08-08 04:21:56,677 | train | INFO | Epoch 7 train batch 109/450: 1744/7200 mean loss: 0.001556760398671031 score: 1.0
2021-08-08 04:21:57,447 | train | INFO | Epoch 7 train batch 110/450: 1760/7200 mean loss: 0.001489617396146059 score: 0.9632352941176471
2021-08-08 04:21:58,265 | train | INFO | Epoch 7 train batch 111/450: 1776/7200 mean loss: 0.0016844859346747398 score: 1.0
2021-08-08 04:21:59,043 | train | INFO | Epoch 7 train batch 112/450: 1792/7200 mean loss: 0.0015789201715961099 score: 1.0
2021-08-08 04:21:59,817 | train | INFO | Epoch 7 train batch 113/450: 1808/7200 mean loss: 0.0014646700583398342 score: 1.0
2021-08-08 04:22:00,590 | train | INFO | Epoch 7 train batch 114/450: 1824/7200 mean loss: 0.0014361661160364747 score: 1.0
2021-08-08 04:22:01,427 | train | INFO | Epoch 7 train batch 115/450: 1840/7200 mean loss: 0.001483415369875729 score: 1.0
2021-08-08 04:22:02,206 | train | INFO | Epoch 7 train batch 116/450: 1856/7200 mean loss: 0.0012256961781531572 score: 0.98109243697479
2021-08-08 04:22:03,005 | train | INFO | Epoch 7 train batch 117/450: 1872/7200 mean loss: 0.0013454974396154284 score: 1.0
2021-08-08 04:22:03,830 | train | INFO | Epoch 7 train batch 118/450: 1888/7200 mean loss: 0.0015354239149019122 score: 1.0
2021-08-08 04:22:04,660 | train | INFO | Epoch 7 train batch 119/450: 1904/7200 mean loss: 0.0012886663898825645 score: 1.0
2021-08-08 04:22:05,494 | train | INFO | Epoch 7 train batch 120/450: 1920/7200 mean loss: 0.0015824484871700406 score: 1.0
2021-08-08 04:22:06,296 | train | INFO | Epoch 7 train batch 121/450: 1936/7200 mean loss: 0.0013937762705609202 score: 1.0
2021-08-08 04:22:07,075 | train | INFO | Epoch 7 train batch 122/450: 1952/7200 mean loss: 0.0015362895792350173 score: 0.9963235294117647
2021-08-08 04:22:07,899 | train | INFO | Epoch 7 train batch 123/450: 1968/7200 mean loss: 0.0014661584282293916 score: 1.0
2021-08-08 04:22:08,673 | train | INFO | Epoch 7 train batch 124/450: 1984/7200 mean loss: 0.0015479970024898648 score: 1.0
2021-08-08 04:22:09,470 | train | INFO | Epoch 7 train batch 125/450: 2000/7200 mean loss: 0.0016169610898941755 score: 1.0
2021-08-08 04:22:10,278 | train | INFO | Epoch 7 train batch 126/450: 2016/7200 mean loss: 0.0014868720900267363 score: 1.0
2021-08-08 04:22:11,042 | train | INFO | Epoch 7 train batch 127/450: 2032/7200 mean loss: 0.0015269613359123468 score: 1.0
2021-08-08 04:22:11,847 | train | INFO | Epoch 7 train batch 128/450: 2048/7200 mean loss: 0.001456401776522398 score: 1.0
2021-08-08 04:22:12,665 | train | INFO | Epoch 7 train batch 129/450: 2064/7200 mean loss: 0.0015124730998650193 score: 0.9963235294117647
2021-08-08 04:22:13,494 | train | INFO | Epoch 7 train batch 130/450: 2080/7200 mean loss: 0.0015273827593773603 score: 0.9889705882352942
2021-08-08 04:22:14,371 | train | INFO | Epoch 7 train batch 131/450: 2096/7200 mean loss: 0.001390300109051168 score: 1.0
2021-08-08 04:22:15,177 | train | INFO | Epoch 7 train batch 132/450: 2112/7200 mean loss: 0.0014713478740304708 score: 0.9963235294117647
2021-08-08 04:22:16,001 | train | INFO | Epoch 7 train batch 133/450: 2128/7200 mean loss: 0.0014390255091711879 score: 1.0
2021-08-08 04:22:16,827 | train | INFO | Epoch 7 train batch 134/450: 2144/7200 mean loss: 0.0013898331671953201 score: 1.0
2021-08-08 04:22:17,602 | train | INFO | Epoch 7 train batch 135/450: 2160/7200 mean loss: 0.0012874602107331157 score: 1.0
2021-08-08 04:22:18,389 | train | INFO | Epoch 7 train batch 136/450: 2176/7200 mean loss: 0.00161727424710989 score: 1.0
2021-08-08 04:22:19,188 | train | INFO | Epoch 7 train batch 137/450: 2192/7200 mean loss: 0.0016348764766007662 score: 1.0
2021-08-08 04:22:20,064 | train | INFO | Epoch 7 train batch 138/450: 2208/7200 mean loss: 0.0013044903753325343 score: 1.0
2021-08-08 04:22:20,855 | train | INFO | Epoch 7 train batch 139/450: 2224/7200 mean loss: 0.0014142460422590375 score: 0.9779411764705882
2021-08-08 04:22:21,653 | train | INFO | Epoch 7 train batch 140/450: 2240/7200 mean loss: 0.0014791317516937852 score: 1.0
2021-08-08 04:22:22,452 | train | INFO | Epoch 7 train batch 141/450: 2256/7200 mean loss: 0.0015068658394739032 score: 0.996078431372549
2021-08-08 04:22:23,270 | train | INFO | Epoch 7 train batch 142/450: 2272/7200 mean loss: 0.0014292134437710047 score: 1.0
2021-08-08 04:22:24,077 | train | INFO | Epoch 7 train batch 143/450: 2288/7200 mean loss: 0.001508994260802865 score: 1.0
2021-08-08 04:22:24,864 | train | INFO | Epoch 7 train batch 144/450: 2304/7200 mean loss: 0.001445808564312756 score: 1.0
2021-08-08 04:22:25,674 | train | INFO | Epoch 7 train batch 145/450: 2320/7200 mean loss: 0.0013507227413356304 score: 1.0
2021-08-08 04:22:26,444 | train | INFO | Epoch 7 train batch 146/450: 2336/7200 mean loss: 0.0015749781159684062 score: 1.0
2021-08-08 04:22:27,258 | train | INFO | Epoch 7 train batch 147/450: 2352/7200 mean loss: 0.0014210003428161144 score: 1.0
2021-08-08 04:22:28,036 | train | INFO | Epoch 7 train batch 148/450: 2368/7200 mean loss: 0.0013851580442860723 score: 1.0
2021-08-08 04:22:28,860 | train | INFO | Epoch 7 train batch 149/450: 2384/7200 mean loss: 0.0013741172151640058 score: 1.0
2021-08-08 04:22:29,636 | train | INFO | Epoch 7 train batch 150/450: 2400/7200 mean loss: 0.0015756222419440746 score: 1.0
2021-08-08 04:22:30,443 | train | INFO | Epoch 7 train batch 151/450: 2416/7200 mean loss: 0.0013859330210834742 score: 1.0
2021-08-08 04:22:31,214 | train | INFO | Epoch 7 train batch 152/450: 2432/7200 mean loss: 0.0015329826856032014 score: 0.9963235294117647
2021-08-08 04:22:31,988 | train | INFO | Epoch 7 train batch 153/450: 2448/7200 mean loss: 0.001432933029718697 score: 1.0
2021-08-08 04:22:32,875 | train | INFO | Epoch 7 train batch 154/450: 2464/7200 mean loss: 0.001527218846604228 score: 0.9632352941176471
2021-08-08 04:22:33,684 | train | INFO | Epoch 7 train batch 155/450: 2480/7200 mean loss: 0.0015699545620009303 score: 1.0
2021-08-08 04:22:34,464 | train | INFO | Epoch 7 train batch 156/450: 2496/7200 mean loss: 0.001661833026446402 score: 1.0
2021-08-08 04:22:35,290 | train | INFO | Epoch 7 train batch 157/450: 2512/7200 mean loss: 0.0016329759964719415 score: 1.0
2021-08-08 04:22:36,094 | train | INFO | Epoch 7 train batch 158/450: 2528/7200 mean loss: 0.0017736523877829313 score: 0.9887254901960785
2021-08-08 04:22:36,890 | train | INFO | Epoch 7 train batch 159/450: 2544/7200 mean loss: 0.0018380455439910293 score: 0.996078431372549
2021-08-08 04:22:37,694 | train | INFO | Epoch 7 train batch 160/450: 2560/7200 mean loss: 0.0015542488545179367 score: 1.0
2021-08-08 04:22:38,481 | train | INFO | Epoch 7 train batch 161/450: 2576/7200 mean loss: 0.0014988550683483481 score: 1.0
2021-08-08 04:22:39,264 | train | INFO | Epoch 7 train batch 162/450: 2592/7200 mean loss: 0.0015744129195809364 score: 1.0
2021-08-08 04:22:40,043 | train | INFO | Epoch 7 train batch 163/450: 2608/7200 mean loss: 0.0014888766454532743 score: 1.0
2021-08-08 04:22:40,866 | train | INFO | Epoch 7 train batch 164/450: 2624/7200 mean loss: 0.0016676932573318481 score: 0.9852941176470589
2021-08-08 04:22:41,646 | train | INFO | Epoch 7 train batch 165/450: 2640/7200 mean loss: 0.0016253135399892926 score: 1.0
2021-08-08 04:22:42,421 | train | INFO | Epoch 7 train batch 166/450: 2656/7200 mean loss: 0.0016084499657154083 score: 1.0
2021-08-08 04:22:43,193 | train | INFO | Epoch 7 train batch 167/450: 2672/7200 mean loss: 0.00146133650559932 score: 1.0
2021-08-08 04:22:43,976 | train | INFO | Epoch 7 train batch 168/450: 2688/7200 mean loss: 0.0013571421150118113 score: 1.0
2021-08-08 04:22:44,781 | train | INFO | Epoch 7 train batch 169/450: 2704/7200 mean loss: 0.001246819389052689 score: 1.0
2021-08-08 04:22:45,588 | train | INFO | Epoch 7 train batch 170/450: 2720/7200 mean loss: 0.0012105515925213695 score: 1.0
2021-08-08 04:22:46,368 | train | INFO | Epoch 7 train batch 171/450: 2736/7200 mean loss: 0.0015213985461741686 score: 0.9007352941176471
2021-08-08 04:22:47,165 | train | INFO | Epoch 7 train batch 172/450: 2752/7200 mean loss: 0.0012566203949972987 score: 1.0
2021-08-08 04:22:47,956 | train | INFO | Epoch 7 train batch 173/450: 2768/7200 mean loss: 0.001525438274256885 score: 1.0
2021-08-08 04:22:48,740 | train | INFO | Epoch 7 train batch 174/450: 2784/7200 mean loss: 0.001514214207418263 score: 1.0
2021-08-08 04:22:49,570 | train | INFO | Epoch 7 train batch 175/450: 2800/7200 mean loss: 0.0015825695591047406 score: 1.0
2021-08-08 04:22:50,380 | train | INFO | Epoch 7 train batch 176/450: 2816/7200 mean loss: 0.0016062394715845585 score: 0.996078431372549
2021-08-08 04:22:51,230 | train | INFO | Epoch 7 train batch 177/450: 2832/7200 mean loss: 0.0016170396702364087 score: 1.0
2021-08-08 04:22:52,063 | train | INFO | Epoch 7 train batch 178/450: 2848/7200 mean loss: 0.0015326980501413345 score: 1.0
2021-08-08 04:22:52,902 | train | INFO | Epoch 7 train batch 179/450: 2864/7200 mean loss: 0.001648360281251371 score: 1.0
2021-08-08 04:22:53,681 | train | INFO | Epoch 7 train batch 180/450: 2880/7200 mean loss: 0.001417695195414126 score: 0.9963235294117647
2021-08-08 04:22:54,457 | train | INFO | Epoch 7 train batch 181/450: 2896/7200 mean loss: 0.001428104704245925 score: 0.875
2021-08-08 04:22:55,274 | train | INFO | Epoch 7 train batch 182/450: 2912/7200 mean loss: 0.0015461287694051862 score: 1.0
2021-08-08 04:22:56,068 | train | INFO | Epoch 7 train batch 183/450: 2928/7200 mean loss: 0.0015095883281901479 score: 1.0
2021-08-08 04:22:56,884 | train | INFO | Epoch 7 train batch 184/450: 2944/7200 mean loss: 0.0014710272662341595 score: 0.9963235294117647
2021-08-08 04:22:57,660 | train | INFO | Epoch 7 train batch 185/450: 2960/7200 mean loss: 0.0014703919878229499 score: 1.0
2021-08-08 04:22:58,435 | train | INFO | Epoch 7 train batch 186/450: 2976/7200 mean loss: 0.001684002229012549 score: 0.9889705882352942
2021-08-08 04:22:59,217 | train | INFO | Epoch 7 train batch 187/450: 2992/7200 mean loss: 0.0015011439099907875 score: 1.0
2021-08-08 04:23:00,011 | train | INFO | Epoch 7 train batch 188/450: 3008/7200 mean loss: 0.0015787457814440131 score: 1.0
2021-08-08 04:23:00,941 | train | INFO | Epoch 7 train batch 189/450: 3024/7200 mean loss: 0.0017383289523422718 score: 1.0
2021-08-08 04:23:01,771 | train | INFO | Epoch 7 train batch 190/450: 3040/7200 mean loss: 0.0014108138857409358 score: 1.0
2021-08-08 04:23:02,658 | train | INFO | Epoch 7 train batch 191/450: 3056/7200 mean loss: 0.0015121292090043426 score: 0.9740196078431372
2021-08-08 04:23:03,497 | train | INFO | Epoch 7 train batch 192/450: 3072/7200 mean loss: 0.001548579428344965 score: 1.0
2021-08-08 04:23:04,292 | train | INFO | Epoch 7 train batch 193/450: 3088/7200 mean loss: 0.0012905594194307923 score: 1.0
2021-08-08 04:23:05,097 | train | INFO | Epoch 7 train batch 194/450: 3104/7200 mean loss: 0.0011261467589065433 score: 1.0
2021-08-08 04:23:05,903 | train | INFO | Epoch 7 train batch 195/450: 3120/7200 mean loss: 0.0016114593017846346 score: 1.0
2021-08-08 04:23:06,721 | train | INFO | Epoch 7 train batch 196/450: 3136/7200 mean loss: 0.0014816665789112449 score: 1.0
2021-08-08 04:23:07,499 | train | INFO | Epoch 7 train batch 197/450: 3152/7200 mean loss: 0.0014426723355427384 score: 1.0
2021-08-08 04:23:08,304 | train | INFO | Epoch 7 train batch 198/450: 3168/7200 mean loss: 0.00157638406381011 score: 0.9772058823529413
2021-08-08 04:23:09,075 | train | INFO | Epoch 7 train batch 199/450: 3184/7200 mean loss: 0.0015365808503702283 score: 1.0
2021-08-08 04:23:09,868 | train | INFO | Epoch 7 train batch 200/450: 3200/7200 mean loss: 0.0014941830886527896 score: 1.0
2021-08-08 04:23:10,667 | train | INFO | Epoch 7 train batch 201/450: 3216/7200 mean loss: 0.0015274399193003774 score: 1.0
2021-08-08 04:23:11,482 | train | INFO | Epoch 7 train batch 202/450: 3232/7200 mean loss: 0.0014678272418677807 score: 1.0
2021-08-08 04:23:12,305 | train | INFO | Epoch 7 train batch 203/450: 3248/7200 mean loss: 0.0015758414519950747 score: 1.0
2021-08-08 04:23:13,082 | train | INFO | Epoch 7 train batch 204/450: 3264/7200 mean loss: 0.001386761199682951 score: 1.0
2021-08-08 04:23:13,903 | train | INFO | Epoch 7 train batch 205/450: 3280/7200 mean loss: 0.0014646004419773817 score: 1.0
2021-08-08 04:23:14,698 | train | INFO | Epoch 7 train batch 206/450: 3296/7200 mean loss: 0.001516949851065874 score: 0.9963235294117647
2021-08-08 04:23:15,510 | train | INFO | Epoch 7 train batch 207/450: 3312/7200 mean loss: 0.0015034812968224287 score: 1.0
2021-08-08 04:23:16,296 | train | INFO | Epoch 7 train batch 208/450: 3328/7200 mean loss: 0.0013414255809038877 score: 0.9889705882352942
2021-08-08 04:23:17,175 | train | INFO | Epoch 7 train batch 209/450: 3344/7200 mean loss: 0.0013387321960180998 score: 1.0
2021-08-08 04:23:17,973 | train | INFO | Epoch 7 train batch 210/450: 3360/7200 mean loss: 0.0014622388407588005 score: 1.0
2021-08-08 04:23:18,746 | train | INFO | Epoch 7 train batch 211/450: 3376/7200 mean loss: 0.0015358597738668323 score: 1.0
2021-08-08 04:23:19,512 | train | INFO | Epoch 7 train batch 212/450: 3392/7200 mean loss: 0.0016210188623517752 score: 0.9843137254901961
2021-08-08 04:23:20,297 | train | INFO | Epoch 7 train batch 213/450: 3408/7200 mean loss: 0.0016297270776703954 score: 1.0
2021-08-08 04:23:21,083 | train | INFO | Epoch 7 train batch 214/450: 3424/7200 mean loss: 0.0015407680766656995 score: 1.0
2021-08-08 04:23:21,890 | train | INFO | Epoch 7 train batch 215/450: 3440/7200 mean loss: 0.0014896553475409746 score: 1.0
2021-08-08 04:23:22,706 | train | INFO | Epoch 7 train batch 216/450: 3456/7200 mean loss: 0.001625542645342648 score: 1.0
2021-08-08 04:23:23,528 | train | INFO | Epoch 7 train batch 217/450: 3472/7200 mean loss: 0.001494362368248403 score: 1.0
2021-08-08 04:23:24,373 | train | INFO | Epoch 7 train batch 218/450: 3488/7200 mean loss: 0.0016431912081316113 score: 1.0
2021-08-08 04:23:25,160 | train | INFO | Epoch 7 train batch 219/450: 3504/7200 mean loss: 0.0013841039035469294 score: 1.0
2021-08-08 04:23:25,960 | train | INFO | Epoch 7 train batch 220/450: 3520/7200 mean loss: 0.0015640021301805973 score: 1.0
2021-08-08 04:23:26,748 | train | INFO | Epoch 7 train batch 221/450: 3536/7200 mean loss: 0.0015026928158476949 score: 1.0
2021-08-08 04:23:27,563 | train | INFO | Epoch 7 train batch 222/450: 3552/7200 mean loss: 0.001438476494513452 score: 1.0
2021-08-08 04:23:28,374 | train | INFO | Epoch 7 train batch 223/450: 3568/7200 mean loss: 0.00142320292070508 score: 0.996078431372549
2021-08-08 04:23:29,158 | train | INFO | Epoch 7 train batch 224/450: 3584/7200 mean loss: 0.0014379722997546196 score: 0.996078431372549
2021-08-08 04:23:29,954 | train | INFO | Epoch 7 train batch 225/450: 3600/7200 mean loss: 0.0015936096897348762 score: 0.9448529411764706
2021-08-08 04:23:30,735 | train | INFO | Epoch 7 train batch 226/450: 3616/7200 mean loss: 0.001419028383679688 score: 1.0
2021-08-08 04:23:31,536 | train | INFO | Epoch 7 train batch 227/450: 3632/7200 mean loss: 0.0015243473462760448 score: 1.0
2021-08-08 04:23:32,338 | train | INFO | Epoch 7 train batch 228/450: 3648/7200 mean loss: 0.0015312974574044347 score: 0.9873949579831932
2021-08-08 04:23:33,147 | train | INFO | Epoch 7 train batch 229/450: 3664/7200 mean loss: 0.0016358108259737492 score: 1.0
2021-08-08 04:23:33,950 | train | INFO | Epoch 7 train batch 230/450: 3680/7200 mean loss: 0.0013016639277338982 score: 1.0
2021-08-08 04:23:34,723 | train | INFO | Epoch 7 train batch 231/450: 3696/7200 mean loss: 0.001540662837214768 score: 1.0
2021-08-08 04:23:35,548 | train | INFO | Epoch 7 train batch 232/450: 3712/7200 mean loss: 0.0014772379072383046 score: 0.6465874811463046
2021-08-08 04:23:36,377 | train | INFO | Epoch 7 train batch 233/450: 3728/7200 mean loss: 0.0014508716994896531 score: 0.9477941176470589
2021-08-08 04:23:37,153 | train | INFO | Epoch 7 train batch 234/450: 3744/7200 mean loss: 0.0013912292197346687 score: 1.0
2021-08-08 04:23:37,971 | train | INFO | Epoch 7 train batch 235/450: 3760/7200 mean loss: 0.0013379137963056564 score: 0.996078431372549
2021-08-08 04:23:38,747 | train | INFO | Epoch 7 train batch 236/450: 3776/7200 mean loss: 0.0014155048411339521 score: 1.0
2021-08-08 04:23:39,642 | train | INFO | Epoch 7 train batch 237/450: 3792/7200 mean loss: 0.0014462111284956336 score: 1.0
2021-08-08 04:23:40,416 | train | INFO | Epoch 7 train batch 238/450: 3808/7200 mean loss: 0.001429299940355122 score: 1.0
2021-08-08 04:23:41,195 | train | INFO | Epoch 7 train batch 239/450: 3824/7200 mean loss: 0.001511433976702392 score: 1.0
2021-08-08 04:23:42,007 | train | INFO | Epoch 7 train batch 240/450: 3840/7200 mean loss: 0.001619818271137774 score: 0.9924019607843138
2021-08-08 04:23:42,780 | train | INFO | Epoch 7 train batch 241/450: 3856/7200 mean loss: 0.0015357562806457281 score: 1.0
2021-08-08 04:23:43,577 | train | INFO | Epoch 7 train batch 242/450: 3872/7200 mean loss: 0.0014454696793109179 score: 0.995798319327731
2021-08-08 04:23:44,414 | train | INFO | Epoch 7 train batch 243/450: 3888/7200 mean loss: 0.0014121142448857427 score: 1.0
2021-08-08 04:23:45,184 | train | INFO | Epoch 7 train batch 244/450: 3904/7200 mean loss: 0.0015532152028754354 score: 1.0
2021-08-08 04:23:45,956 | train | INFO | Epoch 7 train batch 245/450: 3920/7200 mean loss: 0.0015829750336706638 score: 0.9963235294117647
2021-08-08 04:23:46,734 | train | INFO | Epoch 7 train batch 246/450: 3936/7200 mean loss: 0.00176797725725919 score: 1.0
2021-08-08 04:23:47,548 | train | INFO | Epoch 7 train batch 247/450: 3952/7200 mean loss: 0.0016179847298189998 score: 1.0
2021-08-08 04:23:48,325 | train | INFO | Epoch 7 train batch 248/450: 3968/7200 mean loss: 0.0014168040361255407 score: 1.0
2021-08-08 04:23:49,118 | train | INFO | Epoch 7 train batch 249/450: 3984/7200 mean loss: 0.0015699624782428145 score: 0.9835972850678734
2021-08-08 04:23:49,883 | train | INFO | Epoch 7 train batch 250/450: 4000/7200 mean loss: 0.0016904935473576188 score: 0.9926470588235294
2021-08-08 04:23:50,679 | train | INFO | Epoch 7 train batch 251/450: 4016/7200 mean loss: 0.0014570741914212704 score: 1.0
2021-08-08 04:23:51,498 | train | INFO | Epoch 7 train batch 252/450: 4032/7200 mean loss: 0.0013969817664474249 score: 1.0
2021-08-08 04:23:52,311 | train | INFO | Epoch 7 train batch 253/450: 4048/7200 mean loss: 0.0014277338050305843 score: 1.0
2021-08-08 04:23:53,087 | train | INFO | Epoch 7 train batch 254/450: 4064/7200 mean loss: 0.0016415361315011978 score: 1.0
2021-08-08 04:23:53,866 | train | INFO | Epoch 7 train batch 255/450: 4080/7200 mean loss: 0.0014380478532984853 score: 0.9963235294117647
2021-08-08 04:23:54,639 | train | INFO | Epoch 7 train batch 256/450: 4096/7200 mean loss: 0.0016044635558500886 score: 1.0
2021-08-08 04:23:55,454 | train | INFO | Epoch 7 train batch 257/450: 4112/7200 mean loss: 0.0015170971164479852 score: 0.9238795518207282
2021-08-08 04:23:56,234 | train | INFO | Epoch 7 train batch 258/450: 4128/7200 mean loss: 0.0014795964816585183 score: 1.0
2021-08-08 04:23:57,012 | train | INFO | Epoch 7 train batch 259/450: 4144/7200 mean loss: 0.0014039697125554085 score: 1.0
2021-08-08 04:23:57,826 | train | INFO | Epoch 7 train batch 260/450: 4160/7200 mean loss: 0.0016134354518726468 score: 0.9742647058823529
2021-08-08 04:23:58,602 | train | INFO | Epoch 7 train batch 261/450: 4176/7200 mean loss: 0.001461123232729733 score: 1.0
2021-08-08 04:23:59,390 | train | INFO | Epoch 7 train batch 262/450: 4192/7200 mean loss: 0.0014909313758835196 score: 0.9850490196078432
2021-08-08 04:24:00,244 | train | INFO | Epoch 7 train batch 263/450: 4208/7200 mean loss: 0.0014885705895721912 score: 1.0
2021-08-08 04:24:01,040 | train | INFO | Epoch 7 train batch 264/450: 4224/7200 mean loss: 0.0014853751054033637 score: 1.0
2021-08-08 04:24:01,894 | train | INFO | Epoch 7 train batch 265/450: 4240/7200 mean loss: 0.001396381645463407 score: 1.0
2021-08-08 04:24:02,714 | train | INFO | Epoch 7 train batch 266/450: 4256/7200 mean loss: 0.0013824355555698276 score: 1.0
2021-08-08 04:24:03,489 | train | INFO | Epoch 7 train batch 267/450: 4272/7200 mean loss: 0.0016376473940908909 score: 1.0
2021-08-08 04:24:04,303 | train | INFO | Epoch 7 train batch 268/450: 4288/7200 mean loss: 0.001427711802534759 score: 0.9154411764705882
2021-08-08 04:24:05,112 | train | INFO | Epoch 7 train batch 269/450: 4304/7200 mean loss: 0.0012602872448042035 score: 1.0
2021-08-08 04:24:05,897 | train | INFO | Epoch 7 train batch 270/450: 4320/7200 mean loss: 0.001740285544656217 score: 1.0
2021-08-08 04:24:06,691 | train | INFO | Epoch 7 train batch 271/450: 4336/7200 mean loss: 0.0015728872967883945 score: 1.0
2021-08-08 04:24:07,508 | train | INFO | Epoch 7 train batch 272/450: 4352/7200 mean loss: 0.0015679997159168124 score: 0.9732843137254903
2021-08-08 04:24:08,305 | train | INFO | Epoch 7 train batch 273/450: 4368/7200 mean loss: 0.0015995334833860397 score: 1.0
2021-08-08 04:24:09,188 | train | INFO | Epoch 7 train batch 274/450: 4384/7200 mean loss: 0.0015788475284352899 score: 1.0
2021-08-08 04:24:10,083 | train | INFO | Epoch 7 train batch 275/450: 4400/7200 mean loss: 0.001745733548887074 score: 0.9813725490196079
2021-08-08 04:24:10,910 | train | INFO | Epoch 7 train batch 276/450: 4416/7200 mean loss: 0.0013996869092807174 score: 1.0
2021-08-08 04:24:11,726 | train | INFO | Epoch 7 train batch 277/450: 4432/7200 mean loss: 0.0014514703070744872 score: 1.0
2021-08-08 04:24:12,531 | train | INFO | Epoch 7 train batch 278/450: 4448/7200 mean loss: 0.0014300972688943148 score: 1.0
2021-08-08 04:24:13,308 | train | INFO | Epoch 7 train batch 279/450: 4464/7200 mean loss: 0.0014569583581760526 score: 1.0
2021-08-08 04:24:14,087 | train | INFO | Epoch 7 train batch 280/450: 4480/7200 mean loss: 0.0014447227586060762 score: 1.0
2021-08-08 04:24:14,901 | train | INFO | Epoch 7 train batch 281/450: 4496/7200 mean loss: 0.0015165257500484586 score: 1.0
2021-08-08 04:24:15,679 | train | INFO | Epoch 7 train batch 282/450: 4512/7200 mean loss: 0.001429543481208384 score: 1.0
2021-08-08 04:24:16,480 | train | INFO | Epoch 7 train batch 283/450: 4528/7200 mean loss: 0.0015708704013377428 score: 0.9926470588235294
2021-08-08 04:24:17,294 | train | INFO | Epoch 7 train batch 284/450: 4544/7200 mean loss: 0.0014579009730368853 score: 1.0
2021-08-08 04:24:18,064 | train | INFO | Epoch 7 train batch 285/450: 4560/7200 mean loss: 0.001383558614179492 score: 1.0
2021-08-08 04:24:18,865 | train | INFO | Epoch 7 train batch 286/450: 4576/7200 mean loss: 0.0015667700208723545 score: 0.9963235294117647
2021-08-08 04:24:19,641 | train | INFO | Epoch 7 train batch 287/450: 4592/7200 mean loss: 0.0015178699977695942 score: 1.0
2021-08-08 04:24:20,439 | train | INFO | Epoch 7 train batch 288/450: 4608/7200 mean loss: 0.0015573679702356458 score: 0.996078431372549
2021-08-08 04:24:21,218 | train | INFO | Epoch 7 train batch 289/450: 4624/7200 mean loss: 0.001523080631159246 score: 0.9924019607843138
2021-08-08 04:24:22,025 | train | INFO | Epoch 7 train batch 290/450: 4640/7200 mean loss: 0.0017229830846190453 score: 1.0
2021-08-08 04:24:22,796 | train | INFO | Epoch 7 train batch 291/450: 4656/7200 mean loss: 0.0014653222169727087 score: 1.0
2021-08-08 04:24:23,577 | train | INFO | Epoch 7 train batch 292/450: 4672/7200 mean loss: 0.001482043880969286 score: 1.0
2021-08-08 04:24:24,358 | train | INFO | Epoch 7 train batch 293/450: 4688/7200 mean loss: 0.0013974284520372748 score: 0.9882352941176471
2021-08-08 04:24:25,132 | train | INFO | Epoch 7 train batch 294/450: 4704/7200 mean loss: 0.0014701338950544596 score: 1.0
2021-08-08 04:24:25,900 | train | INFO | Epoch 7 train batch 295/450: 4720/7200 mean loss: 0.0015999540919438004 score: 1.0
2021-08-08 04:24:26,702 | train | INFO | Epoch 7 train batch 296/450: 4736/7200 mean loss: 0.0013972646556794643 score: 0.9963235294117647
2021-08-08 04:24:27,519 | train | INFO | Epoch 7 train batch 297/450: 4752/7200 mean loss: 0.0014991072239354253 score: 0.9115196078431372
2021-08-08 04:24:28,382 | train | INFO | Epoch 7 train batch 298/450: 4768/7200 mean loss: 0.001257014460861683 score: 1.0
2021-08-08 04:24:29,218 | train | INFO | Epoch 7 train batch 299/450: 4784/7200 mean loss: 0.001554398681037128 score: 1.0
2021-08-08 04:24:30,052 | train | INFO | Epoch 7 train batch 300/450: 4800/7200 mean loss: 0.0014846429694443941 score: 1.0
2021-08-08 04:24:30,850 | train | INFO | Epoch 7 train batch 301/450: 4816/7200 mean loss: 0.0015196803724393249 score: 1.0
2021-08-08 04:24:31,652 | train | INFO | Epoch 7 train batch 302/450: 4832/7200 mean loss: 0.0014437250792980194 score: 1.0
2021-08-08 04:24:32,460 | train | INFO | Epoch 7 train batch 303/450: 4848/7200 mean loss: 0.0017637278651818633 score: 1.0
2021-08-08 04:24:33,242 | train | INFO | Epoch 7 train batch 304/450: 4864/7200 mean loss: 0.0012974879937246442 score: 1.0
2021-08-08 04:24:34,034 | train | INFO | Epoch 7 train batch 305/450: 4880/7200 mean loss: 0.0013508307747542858 score: 1.0
2021-08-08 04:24:34,845 | train | INFO | Epoch 7 train batch 306/450: 4896/7200 mean loss: 0.0014555093366652727 score: 0.9924019607843138
2021-08-08 04:24:35,627 | train | INFO | Epoch 7 train batch 307/450: 4912/7200 mean loss: 0.0016036248998716474 score: 1.0
2021-08-08 04:24:36,431 | train | INFO | Epoch 7 train batch 308/450: 4928/7200 mean loss: 0.0014874349581077695 score: 1.0
2021-08-08 04:24:37,220 | train | INFO | Epoch 7 train batch 309/450: 4944/7200 mean loss: 0.001394282910041511 score: 0.9926470588235294
2021-08-08 04:24:38,030 | train | INFO | Epoch 7 train batch 310/450: 4960/7200 mean loss: 0.0016679593827575445 score: 1.0
2021-08-08 04:24:38,830 | train | INFO | Epoch 7 train batch 311/450: 4976/7200 mean loss: 0.0016887880628928542 score: 1.0
2021-08-08 04:24:39,643 | train | INFO | Epoch 7 train batch 312/450: 4992/7200 mean loss: 0.0014246226055547595 score: 1.0
2021-08-08 04:24:40,439 | train | INFO | Epoch 7 train batch 313/450: 5008/7200 mean loss: 0.0012511061504483223 score: 1.0
2021-08-08 04:24:41,218 | train | INFO | Epoch 7 train batch 314/450: 5024/7200 mean loss: 0.0015680368524044752 score: 1.0
2021-08-08 04:24:42,046 | train | INFO | Epoch 7 train batch 315/450: 5040/7200 mean loss: 0.001565747195854783 score: 0.9477941176470589
2021-08-08 04:24:42,827 | train | INFO | Epoch 7 train batch 316/450: 5056/7200 mean loss: 0.001507094711996615 score: 0.9191176470588235
2021-08-08 04:24:43,600 | train | INFO | Epoch 7 train batch 317/450: 5072/7200 mean loss: 0.0013579352525994182 score: 1.0
2021-08-08 04:24:44,416 | train | INFO | Epoch 7 train batch 318/450: 5088/7200 mean loss: 0.0014696979196742177 score: 1.0
2021-08-08 04:24:45,193 | train | INFO | Epoch 7 train batch 319/450: 5104/7200 mean loss: 0.0017461165552958846 score: 1.0
2021-08-08 04:24:45,993 | train | INFO | Epoch 7 train batch 320/450: 5120/7200 mean loss: 0.0015552683034911752 score: 1.0
2021-08-08 04:24:46,773 | train | INFO | Epoch 7 train batch 321/450: 5136/7200 mean loss: 0.0015746427234262228 score: 1.0
2021-08-08 04:24:47,590 | train | INFO | Epoch 7 train batch 322/450: 5152/7200 mean loss: 0.0016610819147899747 score: 1.0
2021-08-08 04:24:48,371 | train | INFO | Epoch 7 train batch 323/450: 5168/7200 mean loss: 0.0017275112913921475 score: 0.995798319327731
2021-08-08 04:24:49,178 | train | INFO | Epoch 7 train batch 324/450: 5184/7200 mean loss: 0.0015773479826748371 score: 0.9921218487394957
2021-08-08 04:24:49,960 | train | INFO | Epoch 7 train batch 325/450: 5200/7200 mean loss: 0.0014375544851645827 score: 1.0
2021-08-08 04:24:50,735 | train | INFO | Epoch 7 train batch 326/450: 5216/7200 mean loss: 0.001547470921650529 score: 0.9963235294117647
2021-08-08 04:24:51,568 | train | INFO | Epoch 7 train batch 327/450: 5232/7200 mean loss: 0.0013516347389668226 score: 1.0
2021-08-08 04:24:52,396 | train | INFO | Epoch 7 train batch 328/450: 5248/7200 mean loss: 0.0014774537412449718 score: 1.0
2021-08-08 04:24:53,184 | train | INFO | Epoch 7 train batch 329/450: 5264/7200 mean loss: 0.001500563113950193 score: 1.0
2021-08-08 04:24:53,985 | train | INFO | Epoch 7 train batch 330/450: 5280/7200 mean loss: 0.0013091799337416887 score: 1.0
2021-08-08 04:24:54,773 | train | INFO | Epoch 7 train batch 331/450: 5296/7200 mean loss: 0.0014603794552385807 score: 0.9926470588235294
2021-08-08 04:24:55,552 | train | INFO | Epoch 7 train batch 332/450: 5312/7200 mean loss: 0.0014909835299476981 score: 1.0
2021-08-08 04:24:56,345 | train | INFO | Epoch 7 train batch 333/450: 5328/7200 mean loss: 0.0015479937428608537 score: 0.9963235294117647
2021-08-08 04:24:57,143 | train | INFO | Epoch 7 train batch 334/450: 5344/7200 mean loss: 0.0014058563392609358 score: 1.0
2021-08-08 04:24:57,928 | train | INFO | Epoch 7 train batch 335/450: 5360/7200 mean loss: 0.0013570507289841771 score: 1.0
2021-08-08 04:24:58,710 | train | INFO | Epoch 7 train batch 336/450: 5376/7200 mean loss: 0.0017258242005482316 score: 0.9963235294117647
2021-08-08 04:24:59,494 | train | INFO | Epoch 7 train batch 337/450: 5392/7200 mean loss: 0.0015177518362179399 score: 1.0
2021-08-08 04:25:00,277 | train | INFO | Epoch 7 train batch 338/450: 5408/7200 mean loss: 0.0015697358176112175 score: 0.9926470588235294
2021-08-08 04:25:01,091 | train | INFO | Epoch 7 train batch 339/450: 5424/7200 mean loss: 0.001460089348256588 score: 1.0
2021-08-08 04:25:01,876 | train | INFO | Epoch 7 train batch 340/450: 5440/7200 mean loss: 0.001310039428062737 score: 0.9926470588235294
2021-08-08 04:25:02,689 | train | INFO | Epoch 7 train batch 341/450: 5456/7200 mean loss: 0.0013495726743713021 score: 1.0
2021-08-08 04:25:03,478 | train | INFO | Epoch 7 train batch 342/450: 5472/7200 mean loss: 0.0013288661139085889 score: 0.996078431372549
2021-08-08 04:25:04,262 | train | INFO | Epoch 7 train batch 343/450: 5488/7200 mean loss: 0.0015777434455230832 score: 0.9889705882352942
2021-08-08 04:25:05,035 | train | INFO | Epoch 7 train batch 344/450: 5504/7200 mean loss: 0.001664069714024663 score: 1.0
2021-08-08 04:25:05,831 | train | INFO | Epoch 7 train batch 345/450: 5520/7200 mean loss: 0.001872802502475679 score: 1.0
2021-08-08 04:25:06,625 | train | INFO | Epoch 7 train batch 346/450: 5536/7200 mean loss: 0.0015296887140721083 score: 0.9884453781512604
2021-08-08 04:25:07,443 | train | INFO | Epoch 7 train batch 347/450: 5552/7200 mean loss: 0.0015827360330149531 score: 1.0
2021-08-08 04:25:08,227 | train | INFO | Epoch 7 train batch 348/450: 5568/7200 mean loss: 0.001523221260868013 score: 1.0
2021-08-08 04:25:09,053 | train | INFO | Epoch 7 train batch 349/450: 5584/7200 mean loss: 0.0013423548080027103 score: 1.0
2021-08-08 04:25:09,841 | train | INFO | Epoch 7 train batch 350/450: 5600/7200 mean loss: 0.0013737896224483848 score: 0.996078431372549
2021-08-08 04:25:10,620 | train | INFO | Epoch 7 train batch 351/450: 5616/7200 mean loss: 0.0013824977213516831 score: 1.0
2021-08-08 04:25:11,401 | train | INFO | Epoch 7 train batch 352/450: 5632/7200 mean loss: 0.0014066703151911497 score: 1.0
2021-08-08 04:25:12,233 | train | INFO | Epoch 7 train batch 353/450: 5648/7200 mean loss: 0.0016978336498141289 score: 1.0
2021-08-08 04:25:13,061 | train | INFO | Epoch 7 train batch 354/450: 5664/7200 mean loss: 0.0016318107955157757 score: 1.0
2021-08-08 04:25:13,840 | train | INFO | Epoch 7 train batch 355/450: 5680/7200 mean loss: 0.0016221827827394009 score: 0.9852941176470589
2021-08-08 04:25:14,624 | train | INFO | Epoch 7 train batch 356/450: 5696/7200 mean loss: 0.0014971113996580243 score: 0.9852941176470589
2021-08-08 04:25:15,417 | train | INFO | Epoch 7 train batch 357/450: 5712/7200 mean loss: 0.0016025687800720334 score: 1.0
2021-08-08 04:25:16,226 | train | INFO | Epoch 7 train batch 358/450: 5728/7200 mean loss: 0.0014489205786958337 score: 1.0
2021-08-08 04:25:17,007 | train | INFO | Epoch 7 train batch 359/450: 5744/7200 mean loss: 0.001426114933565259 score: 1.0
2021-08-08 04:25:17,782 | train | INFO | Epoch 7 train batch 360/450: 5760/7200 mean loss: 0.0015377355739474297 score: 1.0
2021-08-08 04:25:18,556 | train | INFO | Epoch 7 train batch 361/450: 5776/7200 mean loss: 0.0013224281137809157 score: 0.7095588235294118
2021-08-08 04:25:19,331 | train | INFO | Epoch 7 train batch 362/450: 5792/7200 mean loss: 0.001622189418412745 score: 1.0
2021-08-08 04:25:20,117 | train | INFO | Epoch 7 train batch 363/450: 5808/7200 mean loss: 0.001715544844046235 score: 0.9963235294117647
2021-08-08 04:25:20,918 | train | INFO | Epoch 7 train batch 364/450: 5824/7200 mean loss: 0.0014972102362662554 score: 1.0
2021-08-08 04:25:21,739 | train | INFO | Epoch 7 train batch 365/450: 5840/7200 mean loss: 0.0015200205380097032 score: 1.0
2021-08-08 04:25:22,558 | train | INFO | Epoch 7 train batch 366/450: 5856/7200 mean loss: 0.0015872698277235031 score: 1.0
2021-08-08 04:25:23,378 | train | INFO | Epoch 7 train batch 367/450: 5872/7200 mean loss: 0.0016045428346842527 score: 1.0
2021-08-08 04:25:24,152 | train | INFO | Epoch 7 train batch 368/450: 5888/7200 mean loss: 0.0017279313178732991 score: 1.0
2021-08-08 04:25:24,939 | train | INFO | Epoch 7 train batch 369/450: 5904/7200 mean loss: 0.0014809247804805636 score: 1.0
2021-08-08 04:25:25,706 | train | INFO | Epoch 7 train batch 370/450: 5920/7200 mean loss: 0.0014739434700459242 score: 1.0
2021-08-08 04:25:26,474 | train | INFO | Epoch 7 train batch 371/450: 5936/7200 mean loss: 0.0015586382942274213 score: 0.996078431372549
2021-08-08 04:25:27,257 | train | INFO | Epoch 7 train batch 372/450: 5952/7200 mean loss: 0.0015845284797251225 score: 1.0
2021-08-08 04:25:28,056 | train | INFO | Epoch 7 train batch 373/450: 5968/7200 mean loss: 0.0012497968273237348 score: 1.0
2021-08-08 04:25:28,852 | train | INFO | Epoch 7 train batch 374/450: 5984/7200 mean loss: 0.0014796566683799028 score: 1.0
2021-08-08 04:25:29,650 | train | INFO | Epoch 7 train batch 375/450: 6000/7200 mean loss: 0.001425115973688662 score: 1.0
2021-08-08 04:25:30,416 | train | INFO | Epoch 7 train batch 376/450: 6016/7200 mean loss: 0.0013196757063269615 score: 1.0
2021-08-08 04:25:31,182 | train | INFO | Epoch 7 train batch 377/450: 6032/7200 mean loss: 0.0015875125536695123 score: 1.0
2021-08-08 04:25:31,988 | train | INFO | Epoch 7 train batch 378/450: 6048/7200 mean loss: 0.00136001652572304 score: 1.0
2021-08-08 04:25:32,794 | train | INFO | Epoch 7 train batch 379/450: 6064/7200 mean loss: 0.0012992904521524906 score: 1.0
2021-08-08 04:25:33,685 | train | INFO | Epoch 7 train batch 380/450: 6080/7200 mean loss: 0.0015895303804427385 score: 1.0
2021-08-08 04:25:34,489 | train | INFO | Epoch 7 train batch 381/450: 6096/7200 mean loss: 0.0012863044394180179 score: 1.0
2021-08-08 04:25:35,260 | train | INFO | Epoch 7 train batch 382/450: 6112/7200 mean loss: 0.0014937331434339285 score: 1.0
2021-08-08 04:25:36,051 | train | INFO | Epoch 7 train batch 383/450: 6128/7200 mean loss: 0.0015529498923569918 score: 1.0
2021-08-08 04:25:36,909 | train | INFO | Epoch 7 train batch 384/450: 6144/7200 mean loss: 0.0016809379449114203 score: 1.0
2021-08-08 04:25:37,695 | train | INFO | Epoch 7 train batch 385/450: 6160/7200 mean loss: 0.0016780265141278505 score: 1.0
2021-08-08 04:25:38,504 | train | INFO | Epoch 7 train batch 386/450: 6176/7200 mean loss: 0.0017961520934477448 score: 1.0
2021-08-08 04:25:39,320 | train | INFO | Epoch 7 train batch 387/450: 6192/7200 mean loss: 0.0015839800471439958 score: 1.0
2021-08-08 04:25:40,108 | train | INFO | Epoch 7 train batch 388/450: 6208/7200 mean loss: 0.0016051927814260125 score: 1.0
2021-08-08 04:25:40,884 | train | INFO | Epoch 7 train batch 389/450: 6224/7200 mean loss: 0.0016007402446120977 score: 1.0
2021-08-08 04:25:41,663 | train | INFO | Epoch 7 train batch 390/450: 6240/7200 mean loss: 0.001423533190973103 score: 1.0
2021-08-08 04:25:42,433 | train | INFO | Epoch 7 train batch 391/450: 6256/7200 mean loss: 0.001248433836735785 score: 1.0
2021-08-08 04:25:43,208 | train | INFO | Epoch 7 train batch 392/450: 6272/7200 mean loss: 0.0014030715683475137 score: 1.0
2021-08-08 04:25:44,011 | train | INFO | Epoch 7 train batch 393/450: 6288/7200 mean loss: 0.0013759034918621182 score: 1.0
2021-08-08 04:25:44,787 | train | INFO | Epoch 7 train batch 394/450: 6304/7200 mean loss: 0.0015603549545630813 score: 0.99187675070028
2021-08-08 04:25:45,580 | train | INFO | Epoch 7 train batch 395/450: 6320/7200 mean loss: 0.0013144598342478275 score: 1.0
2021-08-08 04:25:46,376 | train | INFO | Epoch 7 train batch 396/450: 6336/7200 mean loss: 0.0015990526881068945 score: 0.9142156862745099
2021-08-08 04:25:47,161 | train | INFO | Epoch 7 train batch 397/450: 6352/7200 mean loss: 0.001525417435914278 score: 0.8848039215686274
2021-08-08 04:25:47,948 | train | INFO | Epoch 7 train batch 398/450: 6368/7200 mean loss: 0.0014860105002298951 score: 1.0
2021-08-08 04:25:48,768 | train | INFO | Epoch 7 train batch 399/450: 6384/7200 mean loss: 0.0015758329536765814 score: 1.0
2021-08-08 04:25:49,554 | train | INFO | Epoch 7 train batch 400/450: 6400/7200 mean loss: 0.0013146016281098127 score: 1.0
2021-08-08 04:25:50,342 | train | INFO | Epoch 7 train batch 401/450: 6416/7200 mean loss: 0.0015943204052746296 score: 1.0
2021-08-08 04:25:51,113 | train | INFO | Epoch 7 train batch 402/450: 6432/7200 mean loss: 0.0013682504650205374 score: 0.995798319327731
2021-08-08 04:25:51,879 | train | INFO | Epoch 7 train batch 403/450: 6448/7200 mean loss: 0.0015486169140785933 score: 1.0
2021-08-08 04:25:52,680 | train | INFO | Epoch 7 train batch 404/450: 6464/7200 mean loss: 0.0016738093690946698 score: 1.0
2021-08-08 04:25:53,498 | train | INFO | Epoch 7 train batch 405/450: 6480/7200 mean loss: 0.0013489369302988052 score: 1.0
2021-08-08 04:25:54,299 | train | INFO | Epoch 7 train batch 406/450: 6496/7200 mean loss: 0.0014102490385994315 score: 1.0
2021-08-08 04:25:55,078 | train | INFO | Epoch 7 train batch 407/450: 6512/7200 mean loss: 0.0015177467139437795 score: 1.0
2021-08-08 04:25:55,860 | train | INFO | Epoch 7 train batch 408/450: 6528/7200 mean loss: 0.001412233104929328 score: 1.0
2021-08-08 04:25:56,627 | train | INFO | Epoch 7 train batch 409/450: 6544/7200 mean loss: 0.0012643488589674234 score: 0.9963235294117647
2021-08-08 04:25:57,419 | train | INFO | Epoch 7 train batch 410/450: 6560/7200 mean loss: 0.0014078798703849316 score: 1.0
2021-08-08 04:25:58,219 | train | INFO | Epoch 7 train batch 411/450: 6576/7200 mean loss: 0.0014082371490076184 score: 0.996078431372549
2021-08-08 04:25:58,990 | train | INFO | Epoch 7 train batch 412/450: 6592/7200 mean loss: 0.0012844960438087583 score: 1.0
2021-08-08 04:25:59,771 | train | INFO | Epoch 7 train batch 413/450: 6608/7200 mean loss: 0.0014113917713984847 score: 1.0
2021-08-08 04:26:00,544 | train | INFO | Epoch 7 train batch 414/450: 6624/7200 mean loss: 0.0015708012506365776 score: 0.9625
2021-08-08 04:26:01,313 | train | INFO | Epoch 7 train batch 415/450: 6640/7200 mean loss: 0.0013369540683925152 score: 1.0
2021-08-08 04:26:02,110 | train | INFO | Epoch 7 train batch 416/450: 6656/7200 mean loss: 0.0013945272658020258 score: 1.0
2021-08-08 04:26:02,905 | train | INFO | Epoch 7 train batch 417/450: 6672/7200 mean loss: 0.0014799069613218307 score: 1.0
2021-08-08 04:26:03,691 | train | INFO | Epoch 7 train batch 418/450: 6688/7200 mean loss: 0.001531417714431882 score: 1.0
2021-08-08 04:26:04,474 | train | INFO | Epoch 7 train batch 419/450: 6704/7200 mean loss: 0.0017044760752469301 score: 1.0
2021-08-08 04:26:05,272 | train | INFO | Epoch 7 train batch 420/450: 6720/7200 mean loss: 0.001703097834251821 score: 1.0
2021-08-08 04:26:06,052 | train | INFO | Epoch 7 train batch 421/450: 6736/7200 mean loss: 0.0016204435378313065 score: 0.9495286576168928
2021-08-08 04:26:06,865 | train | INFO | Epoch 7 train batch 422/450: 6752/7200 mean loss: 0.001744968118146062 score: 1.0
2021-08-08 04:26:07,776 | train | INFO | Epoch 7 train batch 423/450: 6768/7200 mean loss: 0.0016877767629921436 score: 1.0
2021-08-08 04:26:08,602 | train | INFO | Epoch 7 train batch 424/450: 6784/7200 mean loss: 0.001415987964719534 score: 1.0
2021-08-08 04:26:09,405 | train | INFO | Epoch 7 train batch 425/450: 6800/7200 mean loss: 0.0016092665027827024 score: 0.995798319327731
2021-08-08 04:26:10,205 | train | INFO | Epoch 7 train batch 426/450: 6816/7200 mean loss: 0.001457312610000372 score: 0.9732843137254903
2021-08-08 04:26:11,088 | train | INFO | Epoch 7 train batch 427/450: 6832/7200 mean loss: 0.0015872688964009285 score: 1.0
2021-08-08 04:26:11,893 | train | INFO | Epoch 7 train batch 428/450: 6848/7200 mean loss: 0.001745019224472344 score: 1.0
2021-08-08 04:26:12,694 | train | INFO | Epoch 7 train batch 429/450: 6864/7200 mean loss: 0.0017388061387464404 score: 0.9816176470588235
2021-08-08 04:26:13,470 | train | INFO | Epoch 7 train batch 430/450: 6880/7200 mean loss: 0.001307739526964724 score: 1.0
2021-08-08 04:26:14,243 | train | INFO | Epoch 7 train batch 431/450: 6896/7200 mean loss: 0.0016963165253400803 score: 0.9926470588235294
2021-08-08 04:26:15,040 | train | INFO | Epoch 7 train batch 432/450: 6912/7200 mean loss: 0.0015553052071481943 score: 1.0
2021-08-08 04:26:15,820 | train | INFO | Epoch 7 train batch 433/450: 6928/7200 mean loss: 0.001677953521721065 score: 0.9845588235294118
2021-08-08 04:26:16,599 | train | INFO | Epoch 7 train batch 434/450: 6944/7200 mean loss: 0.001461762934923172 score: 1.0
2021-08-08 04:26:17,387 | train | INFO | Epoch 7 train batch 435/450: 6960/7200 mean loss: 0.0014858255162835121 score: 0.9924019607843138
2021-08-08 04:26:18,174 | train | INFO | Epoch 7 train batch 436/450: 6976/7200 mean loss: 0.0013733009109273553 score: 1.0
2021-08-08 04:26:18,951 | train | INFO | Epoch 7 train batch 437/450: 6992/7200 mean loss: 0.0014595711836591363 score: 1.0
2021-08-08 04:26:19,715 | train | INFO | Epoch 7 train batch 438/450: 7008/7200 mean loss: 0.0012996777659282088 score: 1.0
2021-08-08 04:26:20,478 | train | INFO | Epoch 7 train batch 439/450: 7024/7200 mean loss: 0.0017842409433797002 score: 0.9693627450980393
2021-08-08 04:26:21,241 | train | INFO | Epoch 7 train batch 440/450: 7040/7200 mean loss: 0.001529018278233707 score: 0.996078431372549
2021-08-08 04:26:22,003 | train | INFO | Epoch 7 train batch 441/450: 7056/7200 mean loss: 0.0015557613223791122 score: 1.0
2021-08-08 04:26:22,769 | train | INFO | Epoch 7 train batch 442/450: 7072/7200 mean loss: 0.0017752216663211584 score: 0.9625
2021-08-08 04:26:23,538 | train | INFO | Epoch 7 train batch 443/450: 7088/7200 mean loss: 0.0015176208689808846 score: 0.9963235294117647
2021-08-08 04:26:24,303 | train | INFO | Epoch 7 train batch 444/450: 7104/7200 mean loss: 0.001585071557201445 score: 0.9921568627450981
2021-08-08 04:26:25,073 | train | INFO | Epoch 7 train batch 445/450: 7120/7200 mean loss: 0.0014223054749891162 score: 0.9887254901960785
2021-08-08 04:26:25,839 | train | INFO | Epoch 7 train batch 446/450: 7136/7200 mean loss: 0.0014579234411939979 score: 1.0
2021-08-08 04:26:26,606 | train | INFO | Epoch 7 train batch 447/450: 7152/7200 mean loss: 0.0016996675403788686 score: 0.9963235294117647
2021-08-08 04:26:27,376 | train | INFO | Epoch 7 train batch 448/450: 7168/7200 mean loss: 0.0012730695307254791 score: 1.0
2021-08-08 04:26:28,175 | train | INFO | Epoch 7 train batch 449/450: 7184/7200 mean loss: 0.0014092429773882031 score: 1.0
2021-08-08 04:26:28,324 | train | INFO | Epoch 7, Train, Mean loss: 0.0239895250234339, Score: 0.9928314359932007
2021-08-08 04:26:29,752 | train | INFO | Epoch 7 validation batch 0/113: 0/1800 mean loss: 0.001013679662719369 score: 1.0
2021-08-08 04:26:29,987 | train | INFO | Epoch 7 validation batch 1/113: 16/1800 mean loss: 0.0010348380310460925 score: 0.9926470588235294
2021-08-08 04:26:30,232 | train | INFO | Epoch 7 validation batch 2/113: 32/1800 mean loss: 0.001325912307947874 score: 1.0
2021-08-08 04:26:30,475 | train | INFO | Epoch 7 validation batch 3/113: 48/1800 mean loss: 0.0011332324938848615 score: 1.0
2021-08-08 04:26:30,721 | train | INFO | Epoch 7 validation batch 4/113: 64/1800 mean loss: 0.00105070392601192 score: 1.0
2021-08-08 04:26:30,951 | train | INFO | Epoch 7 validation batch 5/113: 80/1800 mean loss: 0.0010492069413885474 score: 1.0
2021-08-08 04:26:31,194 | train | INFO | Epoch 7 validation batch 6/113: 96/1800 mean loss: 0.0009777270024642348 score: 1.0
2021-08-08 04:26:31,452 | train | INFO | Epoch 7 validation batch 7/113: 112/1800 mean loss: 0.0011534721124917269 score: 1.0
2021-08-08 04:26:31,702 | train | INFO | Epoch 7 validation batch 8/113: 128/1800 mean loss: 0.0010962043888866901 score: 1.0
2021-08-08 04:26:31,955 | train | INFO | Epoch 7 validation batch 9/113: 144/1800 mean loss: 0.0010797701543197036 score: 1.0
2021-08-08 04:26:32,223 | train | INFO | Epoch 7 validation batch 10/113: 160/1800 mean loss: 0.0011392488377168775 score: 0.9816176470588235
2021-08-08 04:26:32,454 | train | INFO | Epoch 7 validation batch 11/113: 176/1800 mean loss: 0.0011811883887276053 score: 0.9963235294117647
2021-08-08 04:26:32,688 | train | INFO | Epoch 7 validation batch 12/113: 192/1800 mean loss: 0.001068991725333035 score: 1.0
2021-08-08 04:26:32,920 | train | INFO | Epoch 7 validation batch 13/113: 208/1800 mean loss: 0.0010281585855409503 score: 1.0
2021-08-08 04:26:33,160 | train | INFO | Epoch 7 validation batch 14/113: 224/1800 mean loss: 0.0009207240073010325 score: 1.0
2021-08-08 04:26:33,438 | train | INFO | Epoch 7 validation batch 15/113: 240/1800 mean loss: 0.0010674409568309784 score: 1.0
2021-08-08 04:26:33,690 | train | INFO | Epoch 7 validation batch 16/113: 256/1800 mean loss: 0.001055059372447431 score: 1.0
2021-08-08 04:26:33,944 | train | INFO | Epoch 7 validation batch 17/113: 272/1800 mean loss: 0.0011951480992138386 score: 1.0
2021-08-08 04:26:34,181 | train | INFO | Epoch 7 validation batch 18/113: 288/1800 mean loss: 0.0008815832552500069 score: 1.0
2021-08-08 04:26:34,435 | train | INFO | Epoch 7 validation batch 19/113: 304/1800 mean loss: 0.0010351015953347087 score: 1.0
2021-08-08 04:26:34,714 | train | INFO | Epoch 7 validation batch 20/113: 320/1800 mean loss: 0.0011844523251056671 score: 0.9887254901960785
2021-08-08 04:26:34,967 | train | INFO | Epoch 7 validation batch 21/113: 336/1800 mean loss: 0.0010305937612429261 score: 1.0
2021-08-08 04:26:35,200 | train | INFO | Epoch 7 validation batch 22/113: 352/1800 mean loss: 0.0009976191213354468 score: 1.0
2021-08-08 04:26:35,448 | train | INFO | Epoch 7 validation batch 23/113: 368/1800 mean loss: 0.000995227019302547 score: 1.0
2021-08-08 04:26:35,679 | train | INFO | Epoch 7 validation batch 24/113: 384/1800 mean loss: 0.0010489766718819737 score: 1.0
2021-08-08 04:26:35,935 | train | INFO | Epoch 7 validation batch 25/113: 400/1800 mean loss: 0.0011532307835295796 score: 1.0
2021-08-08 04:26:36,180 | train | INFO | Epoch 7 validation batch 26/113: 416/1800 mean loss: 0.0009251214214600623 score: 1.0
2021-08-08 04:26:36,421 | train | INFO | Epoch 7 validation batch 27/113: 432/1800 mean loss: 0.0011647786013782024 score: 1.0
2021-08-08 04:26:36,666 | train | INFO | Epoch 7 validation batch 28/113: 448/1800 mean loss: 0.001071901642717421 score: 1.0
2021-08-08 04:26:36,917 | train | INFO | Epoch 7 validation batch 29/113: 464/1800 mean loss: 0.0010772583773359656 score: 1.0
2021-08-08 04:26:37,161 | train | INFO | Epoch 7 validation batch 30/113: 480/1800 mean loss: 0.0010681456187739968 score: 1.0
2021-08-08 04:26:37,406 | train | INFO | Epoch 7 validation batch 31/113: 496/1800 mean loss: 0.0010142273968085647 score: 1.0
2021-08-08 04:26:37,682 | train | INFO | Epoch 7 validation batch 32/113: 512/1800 mean loss: 0.0010554577456787229 score: 1.0
2021-08-08 04:26:37,916 | train | INFO | Epoch 7 validation batch 33/113: 528/1800 mean loss: 0.0009568585664965212 score: 1.0
2021-08-08 04:26:38,167 | train | INFO | Epoch 7 validation batch 34/113: 544/1800 mean loss: 0.0008136517717503011 score: 1.0
2021-08-08 04:26:38,418 | train | INFO | Epoch 7 validation batch 35/113: 560/1800 mean loss: 0.0011894641211256385 score: 1.0
2021-08-08 04:26:38,653 | train | INFO | Epoch 7 validation batch 36/113: 576/1800 mean loss: 0.0011750980047509074 score: 0.9183823529411765
2021-08-08 04:26:38,898 | train | INFO | Epoch 7 validation batch 37/113: 592/1800 mean loss: 0.0008871574536897242 score: 1.0
2021-08-08 04:26:39,130 | train | INFO | Epoch 7 validation batch 38/113: 608/1800 mean loss: 0.0011142200091853738 score: 1.0
2021-08-08 04:26:39,365 | train | INFO | Epoch 7 validation batch 39/113: 624/1800 mean loss: 0.001022201613523066 score: 1.0
2021-08-08 04:26:39,600 | train | INFO | Epoch 7 validation batch 40/113: 640/1800 mean loss: 0.0010908404365181923 score: 1.0
2021-08-08 04:26:39,841 | train | INFO | Epoch 7 validation batch 41/113: 656/1800 mean loss: 0.0009965982753783464 score: 1.0
2021-08-08 04:26:40,071 | train | INFO | Epoch 7 validation batch 42/113: 672/1800 mean loss: 0.0010222273413091898 score: 0.9963235294117647
2021-08-08 04:26:40,322 | train | INFO | Epoch 7 validation batch 43/113: 688/1800 mean loss: 0.0010224467841908336 score: 1.0
2021-08-08 04:26:40,570 | train | INFO | Epoch 7 validation batch 44/113: 704/1800 mean loss: 0.0013047620886936784 score: 0.9742647058823529
2021-08-08 04:26:40,801 | train | INFO | Epoch 7 validation batch 45/113: 720/1800 mean loss: 0.0010639235842972994 score: 1.0
2021-08-08 04:26:41,034 | train | INFO | Epoch 7 validation batch 46/113: 736/1800 mean loss: 0.0010895660379901528 score: 0.9926470588235294
2021-08-08 04:26:41,282 | train | INFO | Epoch 7 validation batch 47/113: 752/1800 mean loss: 0.0009627692634239793 score: 1.0
2021-08-08 04:26:41,512 | train | INFO | Epoch 7 validation batch 48/113: 768/1800 mean loss: 0.0010239437688142061 score: 1.0
2021-08-08 04:26:41,757 | train | INFO | Epoch 7 validation batch 49/113: 784/1800 mean loss: 0.0010705654276534915 score: 1.0
2021-08-08 04:26:42,000 | train | INFO | Epoch 7 validation batch 50/113: 800/1800 mean loss: 0.0009767926530912519 score: 1.0
2021-08-08 04:26:42,245 | train | INFO | Epoch 7 validation batch 51/113: 816/1800 mean loss: 0.0011078399838879704 score: 0.9889705882352942
2021-08-08 04:26:42,495 | train | INFO | Epoch 7 validation batch 52/113: 832/1800 mean loss: 0.001077580382116139 score: 1.0
2021-08-08 04:26:42,749 | train | INFO | Epoch 7 validation batch 53/113: 848/1800 mean loss: 0.0010366018395870924 score: 1.0
2021-08-08 04:26:43,004 | train | INFO | Epoch 7 validation batch 54/113: 864/1800 mean loss: 0.0010125377448275685 score: 1.0
2021-08-08 04:26:43,234 | train | INFO | Epoch 7 validation batch 55/113: 880/1800 mean loss: 0.001100944820791483 score: 1.0
2021-08-08 04:26:43,464 | train | INFO | Epoch 7 validation batch 56/113: 896/1800 mean loss: 0.0010335065890103579 score: 1.0
2021-08-08 04:26:43,695 | train | INFO | Epoch 7 validation batch 57/113: 912/1800 mean loss: 0.001123344525694847 score: 1.0
2021-08-08 04:26:43,929 | train | INFO | Epoch 7 validation batch 58/113: 928/1800 mean loss: 0.001131099765188992 score: 0.9852941176470589
2021-08-08 04:26:44,186 | train | INFO | Epoch 7 validation batch 59/113: 944/1800 mean loss: 0.0010069134877994657 score: 1.0
2021-08-08 04:26:44,423 | train | INFO | Epoch 7 validation batch 60/113: 960/1800 mean loss: 0.0008897730149328709 score: 1.0
2021-08-08 04:26:44,669 | train | INFO | Epoch 7 validation batch 61/113: 976/1800 mean loss: 0.000948397908359766 score: 1.0
2021-08-08 04:26:44,906 | train | INFO | Epoch 7 validation batch 62/113: 992/1800 mean loss: 0.0010221307165920734 score: 1.0
2021-08-08 04:26:45,137 | train | INFO | Epoch 7 validation batch 63/113: 1008/1800 mean loss: 0.0009865526808425784 score: 1.0
2021-08-08 04:26:45,391 | train | INFO | Epoch 7 validation batch 64/113: 1024/1800 mean loss: 0.0010732965311035514 score: 1.0
2021-08-08 04:26:45,643 | train | INFO | Epoch 7 validation batch 65/113: 1040/1800 mean loss: 0.0011051917681470513 score: 1.0
2021-08-08 04:26:45,874 | train | INFO | Epoch 7 validation batch 66/113: 1056/1800 mean loss: 0.0010693349177017808 score: 1.0
2021-08-08 04:26:46,105 | train | INFO | Epoch 7 validation batch 67/113: 1072/1800 mean loss: 0.0011336702154949307 score: 1.0
2021-08-08 04:26:46,343 | train | INFO | Epoch 7 validation batch 68/113: 1088/1800 mean loss: 0.0009059171425178647 score: 1.0
2021-08-08 04:26:46,591 | train | INFO | Epoch 7 validation batch 69/113: 1104/1800 mean loss: 0.0010134316980838776 score: 1.0
2021-08-08 04:26:46,838 | train | INFO | Epoch 7 validation batch 70/113: 1120/1800 mean loss: 0.0011777777690440416 score: 1.0
2021-08-08 04:26:47,082 | train | INFO | Epoch 7 validation batch 71/113: 1136/1800 mean loss: 0.0009851799113675952 score: 1.0
2021-08-08 04:26:47,312 | train | INFO | Epoch 7 validation batch 72/113: 1152/1800 mean loss: 0.0010058286134153605 score: 1.0
2021-08-08 04:26:47,549 | train | INFO | Epoch 7 validation batch 73/113: 1168/1800 mean loss: 0.001216589706018567 score: 1.0
2021-08-08 04:26:47,805 | train | INFO | Epoch 7 validation batch 74/113: 1184/1800 mean loss: 0.0011078821262344718 score: 1.0
2021-08-08 04:26:48,037 | train | INFO | Epoch 7 validation batch 75/113: 1200/1800 mean loss: 0.0010144694242626429 score: 1.0
2021-08-08 04:26:48,278 | train | INFO | Epoch 7 validation batch 76/113: 1216/1800 mean loss: 0.0009050149819813669 score: 1.0
2021-08-08 04:26:48,510 | train | INFO | Epoch 7 validation batch 77/113: 1232/1800 mean loss: 0.0009167235693894327 score: 1.0
2021-08-08 04:26:48,745 | train | INFO | Epoch 7 validation batch 78/113: 1248/1800 mean loss: 0.0010349310468882322 score: 0.9816176470588235
2021-08-08 04:26:48,975 | train | INFO | Epoch 7 validation batch 79/113: 1264/1800 mean loss: 0.0011482982663437724 score: 0.9921568627450981
2021-08-08 04:26:49,206 | train | INFO | Epoch 7 validation batch 80/113: 1280/1800 mean loss: 0.0012245230609551072 score: 1.0
2021-08-08 04:26:49,441 | train | INFO | Epoch 7 validation batch 81/113: 1296/1800 mean loss: 0.0010484481463208795 score: 1.0
2021-08-08 04:26:49,685 | train | INFO | Epoch 7 validation batch 82/113: 1312/1800 mean loss: 0.001001169322989881 score: 1.0
2021-08-08 04:26:49,943 | train | INFO | Epoch 7 validation batch 83/113: 1328/1800 mean loss: 0.0011659165611490607 score: 1.0
2021-08-08 04:26:50,220 | train | INFO | Epoch 7 validation batch 84/113: 1344/1800 mean loss: 0.0011872807517647743 score: 0.9889705882352942
2021-08-08 04:26:50,472 | train | INFO | Epoch 7 validation batch 85/113: 1360/1800 mean loss: 0.0011129501508548856 score: 1.0
2021-08-08 04:26:50,724 | train | INFO | Epoch 7 validation batch 86/113: 1376/1800 mean loss: 0.0012793057831004262 score: 1.0
2021-08-08 04:26:50,959 | train | INFO | Epoch 7 validation batch 87/113: 1392/1800 mean loss: 0.0011996070388704538 score: 1.0
2021-08-08 04:26:51,189 | train | INFO | Epoch 7 validation batch 88/113: 1408/1800 mean loss: 0.0010228516766801476 score: 1.0
2021-08-08 04:26:51,445 | train | INFO | Epoch 7 validation batch 89/113: 1424/1800 mean loss: 0.000919438898563385 score: 1.0
2021-08-08 04:26:51,705 | train | INFO | Epoch 7 validation batch 90/113: 1440/1800 mean loss: 0.0010140510275959969 score: 1.0
2021-08-08 04:26:51,944 | train | INFO | Epoch 7 validation batch 91/113: 1456/1800 mean loss: 0.00127013074234128 score: 1.0
2021-08-08 04:26:52,174 | train | INFO | Epoch 7 validation batch 92/113: 1472/1800 mean loss: 0.0010482862126082182 score: 1.0
2021-08-08 04:26:52,405 | train | INFO | Epoch 7 validation batch 93/113: 1488/1800 mean loss: 0.0010730043286457658 score: 1.0
2021-08-08 04:26:52,645 | train | INFO | Epoch 7 validation batch 94/113: 1504/1800 mean loss: 0.0010397579753771424 score: 1.0
2021-08-08 04:26:52,895 | train | INFO | Epoch 7 validation batch 95/113: 1520/1800 mean loss: 0.0010984858963638544 score: 1.0
2021-08-08 04:26:53,125 | train | INFO | Epoch 7 validation batch 96/113: 1536/1800 mean loss: 0.0011877208016812801 score: 0.9963235294117647
2021-08-08 04:26:53,372 | train | INFO | Epoch 7 validation batch 97/113: 1552/1800 mean loss: 0.0010718093253672123 score: 1.0
2021-08-08 04:26:53,604 | train | INFO | Epoch 7 validation batch 98/113: 1568/1800 mean loss: 0.0010597078362479806 score: 1.0
2021-08-08 04:26:53,855 | train | INFO | Epoch 7 validation batch 99/113: 1584/1800 mean loss: 0.0009919849690049887 score: 1.0
2021-08-08 04:26:54,113 | train | INFO | Epoch 7 validation batch 100/113: 1600/1800 mean loss: 0.0012111689429730177 score: 1.0
2021-08-08 04:26:54,345 | train | INFO | Epoch 7 validation batch 101/113: 1616/1800 mean loss: 0.0010385318892076612 score: 1.0
2021-08-08 04:26:54,576 | train | INFO | Epoch 7 validation batch 102/113: 1632/1800 mean loss: 0.0009797681123018265 score: 1.0
2021-08-08 04:26:54,807 | train | INFO | Epoch 7 validation batch 103/113: 1648/1800 mean loss: 0.000986790400929749 score: 1.0
2021-08-08 04:26:55,038 | train | INFO | Epoch 7 validation batch 104/113: 1664/1800 mean loss: 0.0011284868232905865 score: 1.0
2021-08-08 04:26:55,268 | train | INFO | Epoch 7 validation batch 105/113: 1680/1800 mean loss: 0.0010788647923618555 score: 1.0
2021-08-08 04:26:55,499 | train | INFO | Epoch 7 validation batch 106/113: 1696/1800 mean loss: 0.0010824098717421293 score: 1.0
2021-08-08 04:26:55,736 | train | INFO | Epoch 7 validation batch 107/113: 1712/1800 mean loss: 0.0013152080355212092 score: 1.0
2021-08-08 04:26:55,967 | train | INFO | Epoch 7 validation batch 108/113: 1728/1800 mean loss: 0.0012801290722563863 score: 1.0
2021-08-08 04:26:56,198 | train | INFO | Epoch 7 validation batch 109/113: 1744/1800 mean loss: 0.0011897067306563258 score: 1.0
2021-08-08 04:26:56,429 | train | INFO | Epoch 7 validation batch 110/113: 1760/1800 mean loss: 0.000974385067820549 score: 1.0
2021-08-08 04:26:56,660 | train | INFO | Epoch 7 validation batch 111/113: 1776/1800 mean loss: 0.001016481313854456 score: 1.0
2021-08-08 04:26:56,826 | train | INFO | Epoch 7 validation batch 112/113: 1792/1800 mean loss: 0.0009322913829237223 score: 1.0
2021-08-08 04:26:57,008 | train | INFO | Epoch 7, Validation, Mean loss: 0.01707311626523733, Score: 0.9980023425299324
2021-08-08 04:26:57,009 | train | INFO | Write row 7
2021-08-08 04:26:59,623 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:26:59,626 | train | INFO | Update best record row 8, checkpoints 0.017532147928676772 -> 0.01707311626523733
2021-08-08 04:27:01,533 | train | INFO | Epoch 8 train batch 0/450: 0/7200 mean loss: 0.001261094119399786 score: 1.0
2021-08-08 04:27:02,403 | train | INFO | Epoch 8 train batch 1/450: 16/7200 mean loss: 0.0014532931381836534 score: 1.0
2021-08-08 04:27:03,214 | train | INFO | Epoch 8 train batch 2/450: 32/7200 mean loss: 0.0014154744567349553 score: 1.0
2021-08-08 04:27:03,996 | train | INFO | Epoch 8 train batch 3/450: 48/7200 mean loss: 0.0014173244126141071 score: 0.9926470588235294
2021-08-08 04:27:04,802 | train | INFO | Epoch 8 train batch 4/450: 64/7200 mean loss: 0.00137668929528445 score: 1.0
2021-08-08 04:27:05,660 | train | INFO | Epoch 8 train batch 5/450: 80/7200 mean loss: 0.0011954210931435227 score: 1.0
2021-08-08 04:27:06,453 | train | INFO | Epoch 8 train batch 6/450: 96/7200 mean loss: 0.0015012110816314816 score: 0.995798319327731
2021-08-08 04:27:07,347 | train | INFO | Epoch 8 train batch 7/450: 112/7200 mean loss: 0.0015625021187588573 score: 1.0
2021-08-08 04:27:08,151 | train | INFO | Epoch 8 train batch 8/450: 128/7200 mean loss: 0.0015513199614360929 score: 1.0
2021-08-08 04:27:08,927 | train | INFO | Epoch 8 train batch 9/450: 144/7200 mean loss: 0.001536268973723054 score: 1.0
2021-08-08 04:27:09,704 | train | INFO | Epoch 8 train batch 10/450: 160/7200 mean loss: 0.0015554591082036495 score: 1.0
2021-08-08 04:27:10,496 | train | INFO | Epoch 8 train batch 11/450: 176/7200 mean loss: 0.0015701811062172055 score: 1.0
2021-08-08 04:27:11,278 | train | INFO | Epoch 8 train batch 12/450: 192/7200 mean loss: 0.001584329642355442 score: 1.0
2021-08-08 04:27:12,056 | train | INFO | Epoch 8 train batch 13/450: 208/7200 mean loss: 0.0015027773333713412 score: 1.0
2021-08-08 04:27:12,827 | train | INFO | Epoch 8 train batch 14/450: 224/7200 mean loss: 0.0016243635909631848 score: 1.0
2021-08-08 04:27:13,639 | train | INFO | Epoch 8 train batch 15/450: 240/7200 mean loss: 0.0015345871215686202 score: 1.0
2021-08-08 04:27:14,411 | train | INFO | Epoch 8 train batch 16/450: 256/7200 mean loss: 0.001466304063796997 score: 1.0
2021-08-08 04:27:15,189 | train | INFO | Epoch 8 train batch 17/450: 272/7200 mean loss: 0.0015615845331922174 score: 1.0
2021-08-08 04:27:15,956 | train | INFO | Epoch 8 train batch 18/450: 288/7200 mean loss: 0.0015429017366841435 score: 1.0
2021-08-08 04:27:16,754 | train | INFO | Epoch 8 train batch 19/450: 304/7200 mean loss: 0.0014804002130404115 score: 1.0
2021-08-08 04:27:17,521 | train | INFO | Epoch 8 train batch 20/450: 320/7200 mean loss: 0.0015037896810099483 score: 1.0
2021-08-08 04:27:18,318 | train | INFO | Epoch 8 train batch 21/450: 336/7200 mean loss: 0.001681733992882073 score: 1.0
2021-08-08 04:27:19,091 | train | INFO | Epoch 8 train batch 22/450: 352/7200 mean loss: 0.001624101190827787 score: 1.0
2021-08-08 04:27:19,872 | train | INFO | Epoch 8 train batch 23/450: 368/7200 mean loss: 0.001616617082618177 score: 0.9848039215686275
2021-08-08 04:27:20,652 | train | INFO | Epoch 8 train batch 24/450: 384/7200 mean loss: 0.001447063754312694 score: 1.0
2021-08-08 04:27:21,458 | train | INFO | Epoch 8 train batch 25/450: 400/7200 mean loss: 0.0016240670811384916 score: 1.0
2021-08-08 04:27:22,237 | train | INFO | Epoch 8 train batch 26/450: 416/7200 mean loss: 0.0013913331786170602 score: 1.0
2021-08-08 04:27:23,046 | train | INFO | Epoch 8 train batch 27/450: 432/7200 mean loss: 0.0015000621788203716 score: 1.0
2021-08-08 04:27:23,925 | train | INFO | Epoch 8 train batch 28/450: 448/7200 mean loss: 0.0015659746713936329 score: 1.0
2021-08-08 04:27:24,777 | train | INFO | Epoch 8 train batch 29/450: 464/7200 mean loss: 0.0016160724917426705 score: 0.9137254901960784
2021-08-08 04:27:25,604 | train | INFO | Epoch 8 train batch 30/450: 480/7200 mean loss: 0.0016440220642834902 score: 1.0
2021-08-08 04:27:26,429 | train | INFO | Epoch 8 train batch 31/450: 496/7200 mean loss: 0.0016111173899844289 score: 1.0
2021-08-08 04:27:27,219 | train | INFO | Epoch 8 train batch 32/450: 512/7200 mean loss: 0.0016633272171020508 score: 1.0
2021-08-08 04:27:28,086 | train | INFO | Epoch 8 train batch 33/450: 528/7200 mean loss: 0.0014408229617401958 score: 1.0
2021-08-08 04:27:28,955 | train | INFO | Epoch 8 train batch 34/450: 544/7200 mean loss: 0.0016521920915693045 score: 1.0
2021-08-08 04:27:29,757 | train | INFO | Epoch 8 train batch 35/450: 560/7200 mean loss: 0.001560773584060371 score: 1.0
2021-08-08 04:27:30,577 | train | INFO | Epoch 8 train batch 36/450: 576/7200 mean loss: 0.0015217651380226016 score: 1.0
2021-08-08 04:27:31,382 | train | INFO | Epoch 8 train batch 37/450: 592/7200 mean loss: 0.00153747305739671 score: 1.0
2021-08-08 04:27:32,187 | train | INFO | Epoch 8 train batch 38/450: 608/7200 mean loss: 0.001373065053485334 score: 1.0
2021-08-08 04:27:32,965 | train | INFO | Epoch 8 train batch 39/450: 624/7200 mean loss: 0.0015375694492831826 score: 1.0
2021-08-08 04:27:33,738 | train | INFO | Epoch 8 train batch 40/450: 640/7200 mean loss: 0.0013788080541417003 score: 1.0
2021-08-08 04:27:34,569 | train | INFO | Epoch 8 train batch 41/450: 656/7200 mean loss: 0.0015025894390419126 score: 1.0
2021-08-08 04:27:35,423 | train | INFO | Epoch 8 train batch 42/450: 672/7200 mean loss: 0.0013284462038427591 score: 1.0
2021-08-08 04:27:36,251 | train | INFO | Epoch 8 train batch 43/450: 688/7200 mean loss: 0.0015187609242275357 score: 0.9887254901960785
2021-08-08 04:27:37,026 | train | INFO | Epoch 8 train batch 44/450: 704/7200 mean loss: 0.001293921610340476 score: 1.0
2021-08-08 04:27:37,823 | train | INFO | Epoch 8 train batch 45/450: 720/7200 mean loss: 0.0014906430151313543 score: 1.0
2021-08-08 04:27:38,646 | train | INFO | Epoch 8 train batch 46/450: 736/7200 mean loss: 0.0016582782845944166 score: 1.0
2021-08-08 04:27:39,422 | train | INFO | Epoch 8 train batch 47/450: 752/7200 mean loss: 0.001338526257313788 score: 1.0
2021-08-08 04:27:40,195 | train | INFO | Epoch 8 train batch 48/450: 768/7200 mean loss: 0.0014070252655074 score: 1.0
2021-08-08 04:27:40,979 | train | INFO | Epoch 8 train batch 49/450: 784/7200 mean loss: 0.0014221741585060954 score: 0.9695728291316528
2021-08-08 04:27:41,753 | train | INFO | Epoch 8 train batch 50/450: 800/7200 mean loss: 0.0014374415623024106 score: 1.0
2021-08-08 04:27:42,542 | train | INFO | Epoch 8 train batch 51/450: 816/7200 mean loss: 0.0014856562484055758 score: 1.0
2021-08-08 04:27:43,361 | train | INFO | Epoch 8 train batch 52/450: 832/7200 mean loss: 0.0014281303156167269 score: 1.0
2021-08-08 04:27:44,170 | train | INFO | Epoch 8 train batch 53/450: 848/7200 mean loss: 0.001469151582568884 score: 1.0
2021-08-08 04:27:44,971 | train | INFO | Epoch 8 train batch 54/450: 864/7200 mean loss: 0.00150872312951833 score: 1.0
2021-08-08 04:27:45,775 | train | INFO | Epoch 8 train batch 55/450: 880/7200 mean loss: 0.0012036159168928862 score: 1.0
2021-08-08 04:27:46,543 | train | INFO | Epoch 8 train batch 56/450: 896/7200 mean loss: 0.0012914864346385002 score: 1.0
2021-08-08 04:27:47,349 | train | INFO | Epoch 8 train batch 57/450: 912/7200 mean loss: 0.0014769858680665493 score: 1.0
2021-08-08 04:27:48,153 | train | INFO | Epoch 8 train batch 58/450: 928/7200 mean loss: 0.0012286582496017218 score: 1.0
2021-08-08 04:27:48,940 | train | INFO | Epoch 8 train batch 59/450: 944/7200 mean loss: 0.0013834895798936486 score: 0.9963235294117647
2021-08-08 04:27:49,731 | train | INFO | Epoch 8 train batch 60/450: 960/7200 mean loss: 0.0015809587202966213 score: 1.0
2021-08-08 04:27:50,563 | train | INFO | Epoch 8 train batch 61/450: 976/7200 mean loss: 0.00163913588039577 score: 1.0
2021-08-08 04:27:51,358 | train | INFO | Epoch 8 train batch 62/450: 992/7200 mean loss: 0.0015614219009876251 score: 1.0
2021-08-08 04:27:52,162 | train | INFO | Epoch 8 train batch 63/450: 1008/7200 mean loss: 0.001590427360497415 score: 1.0
2021-08-08 04:27:52,944 | train | INFO | Epoch 8 train batch 64/450: 1024/7200 mean loss: 0.0014711803523823619 score: 0.9774159663865545
2021-08-08 04:27:53,715 | train | INFO | Epoch 8 train batch 65/450: 1040/7200 mean loss: 0.0016273530200123787 score: 0.996078431372549
2021-08-08 04:27:54,498 | train | INFO | Epoch 8 train batch 66/450: 1056/7200 mean loss: 0.0014109184266999364 score: 1.0
2021-08-08 04:27:55,309 | train | INFO | Epoch 8 train batch 67/450: 1072/7200 mean loss: 0.001562801655381918 score: 1.0
2021-08-08 04:27:56,094 | train | INFO | Epoch 8 train batch 68/450: 1088/7200 mean loss: 0.0015287355054169893 score: 1.0
2021-08-08 04:27:56,871 | train | INFO | Epoch 8 train batch 69/450: 1104/7200 mean loss: 0.0015382930869236588 score: 1.0
2021-08-08 04:27:57,659 | train | INFO | Epoch 8 train batch 70/450: 1120/7200 mean loss: 0.001460800296626985 score: 0.9926470588235294
2021-08-08 04:27:58,475 | train | INFO | Epoch 8 train batch 71/450: 1136/7200 mean loss: 0.0013081214856356382 score: 1.0
2021-08-08 04:27:59,250 | train | INFO | Epoch 8 train batch 72/450: 1152/7200 mean loss: 0.0013893096474930644 score: 1.0
2021-08-08 04:28:00,031 | train | INFO | Epoch 8 train batch 73/450: 1168/7200 mean loss: 0.001467013731598854 score: 0.9963235294117647
2021-08-08 04:28:00,845 | train | INFO | Epoch 8 train batch 74/450: 1184/7200 mean loss: 0.0014544026926159859 score: 1.0
2021-08-08 04:28:01,649 | train | INFO | Epoch 8 train batch 75/450: 1200/7200 mean loss: 0.0014475677162408829 score: 1.0
2021-08-08 04:28:02,429 | train | INFO | Epoch 8 train batch 76/450: 1216/7200 mean loss: 0.0015016560209915042 score: 1.0
2021-08-08 04:28:03,227 | train | INFO | Epoch 8 train batch 77/450: 1232/7200 mean loss: 0.0014728696551173925 score: 1.0
2021-08-08 04:28:03,995 | train | INFO | Epoch 8 train batch 78/450: 1248/7200 mean loss: 0.0013809835072606802 score: 1.0
2021-08-08 04:28:04,802 | train | INFO | Epoch 8 train batch 79/450: 1264/7200 mean loss: 0.0013322755694389343 score: 0.9926470588235294
2021-08-08 04:28:05,605 | train | INFO | Epoch 8 train batch 80/450: 1280/7200 mean loss: 0.001297069014981389 score: 0.9007352941176471
2021-08-08 04:28:06,378 | train | INFO | Epoch 8 train batch 81/450: 1296/7200 mean loss: 0.0013900077901780605 score: 1.0
2021-08-08 04:28:07,183 | train | INFO | Epoch 8 train batch 82/450: 1312/7200 mean loss: 0.0013939380878582597 score: 1.0
2021-08-08 04:28:07,989 | train | INFO | Epoch 8 train batch 83/450: 1328/7200 mean loss: 0.0014396655606105924 score: 1.0
2021-08-08 04:28:08,819 | train | INFO | Epoch 8 train batch 84/450: 1344/7200 mean loss: 0.001413905993103981 score: 1.0
2021-08-08 04:28:09,635 | train | INFO | Epoch 8 train batch 85/450: 1360/7200 mean loss: 0.001368895755149424 score: 1.0
2021-08-08 04:28:10,445 | train | INFO | Epoch 8 train batch 86/450: 1376/7200 mean loss: 0.0013068646658211946 score: 1.0
2021-08-08 04:28:11,255 | train | INFO | Epoch 8 train batch 87/450: 1392/7200 mean loss: 0.0015080517623573542 score: 0.9884803921568628
2021-08-08 04:28:12,034 | train | INFO | Epoch 8 train batch 88/450: 1408/7200 mean loss: 0.001473009935580194 score: 1.0
2021-08-08 04:28:12,823 | train | INFO | Epoch 8 train batch 89/450: 1424/7200 mean loss: 0.0015933823306113482 score: 1.0
2021-08-08 04:28:13,650 | train | INFO | Epoch 8 train batch 90/450: 1440/7200 mean loss: 0.0014064436545595527 score: 0.9963235294117647
2021-08-08 04:28:14,435 | train | INFO | Epoch 8 train batch 91/450: 1456/7200 mean loss: 0.0013585753040388227 score: 1.0
2021-08-08 04:28:15,239 | train | INFO | Epoch 8 train batch 92/450: 1472/7200 mean loss: 0.0015054696705192327 score: 1.0
2021-08-08 04:28:16,023 | train | INFO | Epoch 8 train batch 93/450: 1488/7200 mean loss: 0.0015247772680595517 score: 1.0
2021-08-08 04:28:16,827 | train | INFO | Epoch 8 train batch 94/450: 1504/7200 mean loss: 0.0014583808369934559 score: 1.0
2021-08-08 04:28:17,630 | train | INFO | Epoch 8 train batch 95/450: 1520/7200 mean loss: 0.0014185975305736065 score: 1.0
2021-08-08 04:28:18,417 | train | INFO | Epoch 8 train batch 96/450: 1536/7200 mean loss: 0.0013564613182097673 score: 1.0
2021-08-08 04:28:19,247 | train | INFO | Epoch 8 train batch 97/450: 1552/7200 mean loss: 0.0013906401582062244 score: 0.9887254901960785
2021-08-08 04:28:20,043 | train | INFO | Epoch 8 train batch 98/450: 1568/7200 mean loss: 0.0015149868559092283 score: 1.0
2021-08-08 04:28:20,860 | train | INFO | Epoch 8 train batch 99/450: 1584/7200 mean loss: 0.0014916284708306193 score: 1.0
2021-08-08 04:28:21,684 | train | INFO | Epoch 8 train batch 100/450: 1600/7200 mean loss: 0.001278359442949295 score: 1.0
2021-08-08 04:28:22,490 | train | INFO | Epoch 8 train batch 101/450: 1616/7200 mean loss: 0.0014285801444202662 score: 1.0
2021-08-08 04:28:23,287 | train | INFO | Epoch 8 train batch 102/450: 1632/7200 mean loss: 0.0013769712531939149 score: 1.0
2021-08-08 04:28:24,080 | train | INFO | Epoch 8 train batch 103/450: 1648/7200 mean loss: 0.001590199419297278 score: 1.0
2021-08-08 04:28:24,901 | train | INFO | Epoch 8 train batch 104/450: 1664/7200 mean loss: 0.0016327790217474103 score: 1.0
2021-08-08 04:28:25,720 | train | INFO | Epoch 8 train batch 105/450: 1680/7200 mean loss: 0.001363773480989039 score: 1.0
2021-08-08 04:28:26,524 | train | INFO | Epoch 8 train batch 106/450: 1696/7200 mean loss: 0.0012960827443748713 score: 1.0
2021-08-08 04:28:27,307 | train | INFO | Epoch 8 train batch 107/450: 1712/7200 mean loss: 0.0013275668025016785 score: 1.0
2021-08-08 04:28:28,132 | train | INFO | Epoch 8 train batch 108/450: 1728/7200 mean loss: 0.0015638194745406508 score: 1.0
2021-08-08 04:28:28,966 | train | INFO | Epoch 8 train batch 109/450: 1744/7200 mean loss: 0.0016368768410757184 score: 0.996078431372549
2021-08-08 04:28:29,760 | train | INFO | Epoch 8 train batch 110/450: 1760/7200 mean loss: 0.0016524166567251086 score: 1.0
2021-08-08 04:28:30,725 | train | INFO | Epoch 8 train batch 111/450: 1776/7200 mean loss: 0.001665732590481639 score: 1.0
2021-08-08 04:28:31,642 | train | INFO | Epoch 8 train batch 112/450: 1792/7200 mean loss: 0.0016573191387578845 score: 1.0
2021-08-08 04:28:32,516 | train | INFO | Epoch 8 train batch 113/450: 1808/7200 mean loss: 0.0016589938895776868 score: 0.995798319327731
2021-08-08 04:28:33,290 | train | INFO | Epoch 8 train batch 114/450: 1824/7200 mean loss: 0.0015481417067348957 score: 1.0
2021-08-08 04:28:34,066 | train | INFO | Epoch 8 train batch 115/450: 1840/7200 mean loss: 0.001424047164618969 score: 1.0
2021-08-08 04:28:34,874 | train | INFO | Epoch 8 train batch 116/450: 1856/7200 mean loss: 0.0016063048969954252 score: 1.0
2021-08-08 04:28:35,646 | train | INFO | Epoch 8 train batch 117/450: 1872/7200 mean loss: 0.0013883430510759354 score: 1.0
2021-08-08 04:28:36,461 | train | INFO | Epoch 8 train batch 118/450: 1888/7200 mean loss: 0.001224508392624557 score: 1.0
2021-08-08 04:28:37,242 | train | INFO | Epoch 8 train batch 119/450: 1904/7200 mean loss: 0.001487335772253573 score: 1.0
2021-08-08 04:28:38,042 | train | INFO | Epoch 8 train batch 120/450: 1920/7200 mean loss: 0.001509469118900597 score: 0.996078431372549
2021-08-08 04:28:38,837 | train | INFO | Epoch 8 train batch 121/450: 1936/7200 mean loss: 0.001446568756364286 score: 0.9558823529411765
2021-08-08 04:28:39,618 | train | INFO | Epoch 8 train batch 122/450: 1952/7200 mean loss: 0.001348302699625492 score: 1.0
2021-08-08 04:28:40,393 | train | INFO | Epoch 8 train batch 123/450: 1968/7200 mean loss: 0.0013566993875429034 score: 0.9813725490196079
2021-08-08 04:28:41,175 | train | INFO | Epoch 8 train batch 124/450: 1984/7200 mean loss: 0.001479530124925077 score: 0.9556372549019608
2021-08-08 04:28:41,991 | train | INFO | Epoch 8 train batch 125/450: 2000/7200 mean loss: 0.0014127939939498901 score: 1.0
2021-08-08 04:28:42,885 | train | INFO | Epoch 8 train batch 126/450: 2016/7200 mean loss: 0.0013644559076055884 score: 1.0
2021-08-08 04:28:43,659 | train | INFO | Epoch 8 train batch 127/450: 2032/7200 mean loss: 0.0014263398479670286 score: 1.0
2021-08-08 04:28:44,450 | train | INFO | Epoch 8 train batch 128/450: 2048/7200 mean loss: 0.001318935421295464 score: 1.0
2021-08-08 04:28:45,267 | train | INFO | Epoch 8 train batch 129/450: 2064/7200 mean loss: 0.0012914544204249978 score: 1.0
2021-08-08 04:28:46,076 | train | INFO | Epoch 8 train batch 130/450: 2080/7200 mean loss: 0.0015007135225459933 score: 1.0
2021-08-08 04:28:46,850 | train | INFO | Epoch 8 train batch 131/450: 2096/7200 mean loss: 0.0012979108141735196 score: 0.9845588235294118
2021-08-08 04:28:47,630 | train | INFO | Epoch 8 train batch 132/450: 2112/7200 mean loss: 0.0014705569483339787 score: 1.0
2021-08-08 04:28:48,456 | train | INFO | Epoch 8 train batch 133/450: 2128/7200 mean loss: 0.0013818707084283233 score: 1.0
2021-08-08 04:28:49,281 | train | INFO | Epoch 8 train batch 134/450: 2144/7200 mean loss: 0.0015112508554011583 score: 1.0
2021-08-08 04:28:50,102 | train | INFO | Epoch 8 train batch 135/450: 2160/7200 mean loss: 0.0013947831466794014 score: 1.0
2021-08-08 04:28:50,912 | train | INFO | Epoch 8 train batch 136/450: 2176/7200 mean loss: 0.0015509444056078792 score: 0.996078431372549
2021-08-08 04:28:51,686 | train | INFO | Epoch 8 train batch 137/450: 2192/7200 mean loss: 0.0014261355390772223 score: 1.0
2021-08-08 04:28:52,467 | train | INFO | Epoch 8 train batch 138/450: 2208/7200 mean loss: 0.0013058087788522243 score: 1.0
2021-08-08 04:28:53,285 | train | INFO | Epoch 8 train batch 139/450: 2224/7200 mean loss: 0.0016967703122645617 score: 0.9963235294117647
2021-08-08 04:28:54,052 | train | INFO | Epoch 8 train batch 140/450: 2240/7200 mean loss: 0.0013049007393419743 score: 1.0
2021-08-08 04:28:54,822 | train | INFO | Epoch 8 train batch 141/450: 2256/7200 mean loss: 0.0013756218831986189 score: 1.0
2021-08-08 04:28:55,716 | train | INFO | Epoch 8 train batch 142/450: 2272/7200 mean loss: 0.0012243560049682856 score: 1.0
2021-08-08 04:28:56,529 | train | INFO | Epoch 8 train batch 143/450: 2288/7200 mean loss: 0.0015040664002299309 score: 0.9963235294117647
2021-08-08 04:28:57,309 | train | INFO | Epoch 8 train batch 144/450: 2304/7200 mean loss: 0.001571993576362729 score: 1.0
2021-08-08 04:28:58,086 | train | INFO | Epoch 8 train batch 145/450: 2320/7200 mean loss: 0.0014956510858610272 score: 0.9811274509803922
2021-08-08 04:28:58,886 | train | INFO | Epoch 8 train batch 146/450: 2336/7200 mean loss: 0.0015155223663896322 score: 1.0
2021-08-08 04:28:59,695 | train | INFO | Epoch 8 train batch 147/450: 2352/7200 mean loss: 0.0013408242957666516 score: 0.9926470588235294
2021-08-08 04:29:00,467 | train | INFO | Epoch 8 train batch 148/450: 2368/7200 mean loss: 0.0015544715570285916 score: 1.0
2021-08-08 04:29:01,304 | train | INFO | Epoch 8 train batch 149/450: 2384/7200 mean loss: 0.0014136708341538906 score: 1.0
2021-08-08 04:29:02,080 | train | INFO | Epoch 8 train batch 150/450: 2400/7200 mean loss: 0.001646786229684949 score: 0.8227941176470589
2021-08-08 04:29:02,868 | train | INFO | Epoch 8 train batch 151/450: 2416/7200 mean loss: 0.001588578918017447 score: 1.0
2021-08-08 04:29:03,681 | train | INFO | Epoch 8 train batch 152/450: 2432/7200 mean loss: 0.0015169732505455613 score: 1.0
2021-08-08 04:29:04,479 | train | INFO | Epoch 8 train batch 153/450: 2448/7200 mean loss: 0.0016786581836640835 score: 1.0
2021-08-08 04:29:05,286 | train | INFO | Epoch 8 train batch 154/450: 2464/7200 mean loss: 0.0016792879905551672 score: 0.996078431372549
2021-08-08 04:29:06,083 | train | INFO | Epoch 8 train batch 155/450: 2480/7200 mean loss: 0.0014727750094607472 score: 0.996078431372549
2021-08-08 04:29:06,910 | train | INFO | Epoch 8 train batch 156/450: 2496/7200 mean loss: 0.001627504825592041 score: 0.9926470588235294
2021-08-08 04:29:07,696 | train | INFO | Epoch 8 train batch 157/450: 2512/7200 mean loss: 0.0015638017794117332 score: 0.9963235294117647
2021-08-08 04:29:08,481 | train | INFO | Epoch 8 train batch 158/450: 2528/7200 mean loss: 0.0016244027065113187 score: 1.0
2021-08-08 04:29:09,282 | train | INFO | Epoch 8 train batch 159/450: 2544/7200 mean loss: 0.0014085249276831746 score: 1.0
2021-08-08 04:29:10,055 | train | INFO | Epoch 8 train batch 160/450: 2560/7200 mean loss: 0.0016190999886021018 score: 1.0
2021-08-08 04:29:10,839 | train | INFO | Epoch 8 train batch 161/450: 2576/7200 mean loss: 0.0014797091716900468 score: 0.9924019607843138
2021-08-08 04:29:11,637 | train | INFO | Epoch 8 train batch 162/450: 2592/7200 mean loss: 0.0015000650892034173 score: 1.0
2021-08-08 04:29:12,411 | train | INFO | Epoch 8 train batch 163/450: 2608/7200 mean loss: 0.0016769045032560825 score: 1.0
2021-08-08 04:29:13,189 | train | INFO | Epoch 8 train batch 164/450: 2624/7200 mean loss: 0.0015224587405100465 score: 1.0
2021-08-08 04:29:14,000 | train | INFO | Epoch 8 train batch 165/450: 2640/7200 mean loss: 0.0014433242613449693 score: 1.0
2021-08-08 04:29:14,799 | train | INFO | Epoch 8 train batch 166/450: 2656/7200 mean loss: 0.0016091085271909833 score: 1.0
2021-08-08 04:29:15,609 | train | INFO | Epoch 8 train batch 167/450: 2672/7200 mean loss: 0.001545617007650435 score: 0.9963235294117647
2021-08-08 04:29:16,410 | train | INFO | Epoch 8 train batch 168/450: 2688/7200 mean loss: 0.0014504313003271818 score: 0.9963235294117647
2021-08-08 04:29:17,216 | train | INFO | Epoch 8 train batch 169/450: 2704/7200 mean loss: 0.0012865746393799782 score: 1.0
2021-08-08 04:29:17,998 | train | INFO | Epoch 8 train batch 170/450: 2720/7200 mean loss: 0.001695725368335843 score: 0.995798319327731
2021-08-08 04:29:18,801 | train | INFO | Epoch 8 train batch 171/450: 2736/7200 mean loss: 0.0015227263793349266 score: 1.0
2021-08-08 04:29:19,591 | train | INFO | Epoch 8 train batch 172/450: 2752/7200 mean loss: 0.0014847007114440203 score: 1.0
2021-08-08 04:29:20,393 | train | INFO | Epoch 8 train batch 173/450: 2768/7200 mean loss: 0.0014025464188307524 score: 1.0
2021-08-08 04:29:21,198 | train | INFO | Epoch 8 train batch 174/450: 2784/7200 mean loss: 0.001686100848019123 score: 1.0
2021-08-08 04:29:21,988 | train | INFO | Epoch 8 train batch 175/450: 2800/7200 mean loss: 0.0015305670676752925 score: 1.0
2021-08-08 04:29:22,851 | train | INFO | Epoch 8 train batch 176/450: 2816/7200 mean loss: 0.0015822368441149592 score: 1.0
2021-08-08 04:29:23,669 | train | INFO | Epoch 8 train batch 177/450: 2832/7200 mean loss: 0.0016417736187577248 score: 1.0
2021-08-08 04:29:24,446 | train | INFO | Epoch 8 train batch 178/450: 2848/7200 mean loss: 0.0014157729456201196 score: 1.0
2021-08-08 04:29:25,216 | train | INFO | Epoch 8 train batch 179/450: 2864/7200 mean loss: 0.00156212889123708 score: 0.9887254901960785
2021-08-08 04:29:25,999 | train | INFO | Epoch 8 train batch 180/450: 2880/7200 mean loss: 0.0017739523900672793 score: 0.5257352941176471
2021-08-08 04:29:26,773 | train | INFO | Epoch 8 train batch 181/450: 2896/7200 mean loss: 0.0012715482152998447 score: 1.0
2021-08-08 04:29:27,555 | train | INFO | Epoch 8 train batch 182/450: 2912/7200 mean loss: 0.0016065642703324556 score: 0.9963235294117647
2021-08-08 04:29:28,358 | train | INFO | Epoch 8 train batch 183/450: 2928/7200 mean loss: 0.001538070384413004 score: 1.0
2021-08-08 04:29:29,157 | train | INFO | Epoch 8 train batch 184/450: 2944/7200 mean loss: 0.0014606729382649064 score: 1.0
2021-08-08 04:29:30,001 | train | INFO | Epoch 8 train batch 185/450: 2960/7200 mean loss: 0.001368377241306007 score: 1.0
2021-08-08 04:29:30,797 | train | INFO | Epoch 8 train batch 186/450: 2976/7200 mean loss: 0.0017663496546447277 score: 1.0
2021-08-08 04:29:31,571 | train | INFO | Epoch 8 train batch 187/450: 2992/7200 mean loss: 0.0015897501725703478 score: 1.0
2021-08-08 04:29:32,391 | train | INFO | Epoch 8 train batch 188/450: 3008/7200 mean loss: 0.001590593485161662 score: 1.0
2021-08-08 04:29:33,200 | train | INFO | Epoch 8 train batch 189/450: 3024/7200 mean loss: 0.0015796000370755792 score: 1.0
2021-08-08 04:29:33,982 | train | INFO | Epoch 8 train batch 190/450: 3040/7200 mean loss: 0.001533112139441073 score: 1.0
2021-08-08 04:29:34,793 | train | INFO | Epoch 8 train batch 191/450: 3056/7200 mean loss: 0.001700143446214497 score: 0.996078431372549
2021-08-08 04:29:35,570 | train | INFO | Epoch 8 train batch 192/450: 3072/7200 mean loss: 0.001580273499712348 score: 0.9963235294117647
2021-08-08 04:29:36,343 | train | INFO | Epoch 8 train batch 193/450: 3088/7200 mean loss: 0.0013940383214503527 score: 1.0
2021-08-08 04:29:37,129 | train | INFO | Epoch 8 train batch 194/450: 3104/7200 mean loss: 0.0014773121802136302 score: 1.0
2021-08-08 04:29:37,901 | train | INFO | Epoch 8 train batch 195/450: 3120/7200 mean loss: 0.0014136595418676734 score: 0.8995098039215687
2021-08-08 04:29:38,713 | train | INFO | Epoch 8 train batch 196/450: 3136/7200 mean loss: 0.0014896137872710824 score: 0.9963235294117647
2021-08-08 04:29:39,521 | train | INFO | Epoch 8 train batch 197/450: 3152/7200 mean loss: 0.0013537821359932423 score: 0.9813725490196079
2021-08-08 04:29:40,330 | train | INFO | Epoch 8 train batch 198/450: 3168/7200 mean loss: 0.0014511293265968561 score: 1.0
2021-08-08 04:29:41,143 | train | INFO | Epoch 8 train batch 199/450: 3184/7200 mean loss: 0.0014050487661734223 score: 1.0
2021-08-08 04:29:41,939 | train | INFO | Epoch 8 train batch 200/450: 3200/7200 mean loss: 0.0015693455934524536 score: 0.9963235294117647
2021-08-08 04:29:42,713 | train | INFO | Epoch 8 train batch 201/450: 3216/7200 mean loss: 0.0015402243006974459 score: 1.0
2021-08-08 04:29:43,522 | train | INFO | Epoch 8 train batch 202/450: 3232/7200 mean loss: 0.0013898874167352915 score: 1.0
2021-08-08 04:29:44,296 | train | INFO | Epoch 8 train batch 203/450: 3248/7200 mean loss: 0.0014681173488497734 score: 1.0
2021-08-08 04:29:45,092 | train | INFO | Epoch 8 train batch 204/450: 3264/7200 mean loss: 0.0014266448561102152 score: 1.0
2021-08-08 04:29:45,901 | train | INFO | Epoch 8 train batch 205/450: 3280/7200 mean loss: 0.0014240926830098033 score: 1.0
2021-08-08 04:29:46,704 | train | INFO | Epoch 8 train batch 206/450: 3296/7200 mean loss: 0.0016466870438307524 score: 0.995798319327731
2021-08-08 04:29:47,495 | train | INFO | Epoch 8 train batch 207/450: 3312/7200 mean loss: 0.0013172171311452985 score: 1.0
2021-08-08 04:29:48,300 | train | INFO | Epoch 8 train batch 208/450: 3328/7200 mean loss: 0.001483634696342051 score: 0.9889705882352942
2021-08-08 04:29:49,115 | train | INFO | Epoch 8 train batch 209/450: 3344/7200 mean loss: 0.0014192895032465458 score: 1.0
2021-08-08 04:29:49,896 | train | INFO | Epoch 8 train batch 210/450: 3360/7200 mean loss: 0.0017465357668697834 score: 0.9926470588235294
2021-08-08 04:29:50,688 | train | INFO | Epoch 8 train batch 211/450: 3376/7200 mean loss: 0.0015095220878720284 score: 1.0
2021-08-08 04:29:51,543 | train | INFO | Epoch 8 train batch 212/450: 3392/7200 mean loss: 0.0016039591282606125 score: 1.0
2021-08-08 04:29:52,329 | train | INFO | Epoch 8 train batch 213/450: 3408/7200 mean loss: 0.00146327237598598 score: 1.0
2021-08-08 04:29:53,097 | train | INFO | Epoch 8 train batch 214/450: 3424/7200 mean loss: 0.0015117786824703217 score: 1.0
2021-08-08 04:29:53,907 | train | INFO | Epoch 8 train batch 215/450: 3440/7200 mean loss: 0.0015750521561130881 score: 1.0
2021-08-08 04:29:54,688 | train | INFO | Epoch 8 train batch 216/450: 3456/7200 mean loss: 0.0015885243192315102 score: 1.0
2021-08-08 04:29:55,468 | train | INFO | Epoch 8 train batch 217/450: 3472/7200 mean loss: 0.0015720099909231067 score: 0.9926470588235294
2021-08-08 04:29:56,276 | train | INFO | Epoch 8 train batch 218/450: 3488/7200 mean loss: 0.0016573024913668633 score: 1.0
2021-08-08 04:29:57,063 | train | INFO | Epoch 8 train batch 219/450: 3504/7200 mean loss: 0.001607979298569262 score: 1.0
2021-08-08 04:29:57,876 | train | INFO | Epoch 8 train batch 220/450: 3520/7200 mean loss: 0.0016340336296707392 score: 1.0
2021-08-08 04:29:58,652 | train | INFO | Epoch 8 train batch 221/450: 3536/7200 mean loss: 0.0015640273923054338 score: 0.7107843137254901
2021-08-08 04:29:59,443 | train | INFO | Epoch 8 train batch 222/450: 3552/7200 mean loss: 0.0014545678859576583 score: 0.9700630252100839
2021-08-08 04:30:00,269 | train | INFO | Epoch 8 train batch 223/450: 3568/7200 mean loss: 0.0016265774611383677 score: 1.0
2021-08-08 04:30:01,062 | train | INFO | Epoch 8 train batch 224/450: 3584/7200 mean loss: 0.001352981198579073 score: 0.9963235294117647
2021-08-08 04:30:01,834 | train | INFO | Epoch 8 train batch 225/450: 3600/7200 mean loss: 0.001622662995941937 score: 0.995798319327731
2021-08-08 04:30:02,622 | train | INFO | Epoch 8 train batch 226/450: 3616/7200 mean loss: 0.001315084402449429 score: 1.0
2021-08-08 04:30:03,413 | train | INFO | Epoch 8 train batch 227/450: 3632/7200 mean loss: 0.0014979755505919456 score: 1.0
2021-08-08 04:30:04,191 | train | INFO | Epoch 8 train batch 228/450: 3648/7200 mean loss: 0.0015513132093474269 score: 1.0
2021-08-08 04:30:05,025 | train | INFO | Epoch 8 train batch 229/450: 3664/7200 mean loss: 0.0013150464510545135 score: 1.0
2021-08-08 04:30:05,830 | train | INFO | Epoch 8 train batch 230/450: 3680/7200 mean loss: 0.0014541753334924579 score: 1.0
2021-08-08 04:30:06,599 | train | INFO | Epoch 8 train batch 231/450: 3696/7200 mean loss: 0.0014697241131216288 score: 0.996078431372549
2021-08-08 04:30:07,370 | train | INFO | Epoch 8 train batch 232/450: 3712/7200 mean loss: 0.0017361878417432308 score: 1.0
2021-08-08 04:30:08,185 | train | INFO | Epoch 8 train batch 233/450: 3728/7200 mean loss: 0.0013512909645214677 score: 1.0
2021-08-08 04:30:08,967 | train | INFO | Epoch 8 train batch 234/450: 3744/7200 mean loss: 0.001282031531445682 score: 1.0
2021-08-08 04:30:09,743 | train | INFO | Epoch 8 train batch 235/450: 3760/7200 mean loss: 0.0012494936818256974 score: 1.0
2021-08-08 04:30:10,541 | train | INFO | Epoch 8 train batch 236/450: 3776/7200 mean loss: 0.0014947764575481415 score: 1.0
2021-08-08 04:30:11,349 | train | INFO | Epoch 8 train batch 237/450: 3792/7200 mean loss: 0.0012424123706296086 score: 0.9887254901960785
2021-08-08 04:30:12,302 | train | INFO | Epoch 8 train batch 238/450: 3808/7200 mean loss: 0.001339595066383481 score: 1.0
2021-08-08 04:30:13,106 | train | INFO | Epoch 8 train batch 239/450: 3824/7200 mean loss: 0.0015289755538105965 score: 1.0
2021-08-08 04:30:13,911 | train | INFO | Epoch 8 train batch 240/450: 3840/7200 mean loss: 0.0016249497421085835 score: 0.9627450980392157
2021-08-08 04:30:14,731 | train | INFO | Epoch 8 train batch 241/450: 3856/7200 mean loss: 0.0013879321049898863 score: 1.0
2021-08-08 04:30:15,552 | train | INFO | Epoch 8 train batch 242/450: 3872/7200 mean loss: 0.0015880309510976076 score: 0.995798319327731
2021-08-08 04:30:16,331 | train | INFO | Epoch 8 train batch 243/450: 3888/7200 mean loss: 0.0015588866081088781 score: 1.0
2021-08-08 04:30:17,145 | train | INFO | Epoch 8 train batch 244/450: 3904/7200 mean loss: 0.001432726625353098 score: 0.9852941176470589
2021-08-08 04:30:17,975 | train | INFO | Epoch 8 train batch 245/450: 3920/7200 mean loss: 0.001305305166170001 score: 1.0
2021-08-08 04:30:18,789 | train | INFO | Epoch 8 train batch 246/450: 3936/7200 mean loss: 0.0013919195625931025 score: 0.9963235294117647
2021-08-08 04:30:19,630 | train | INFO | Epoch 8 train batch 247/450: 3952/7200 mean loss: 0.001328419428318739 score: 0.996078431372549
2021-08-08 04:30:20,408 | train | INFO | Epoch 8 train batch 248/450: 3968/7200 mean loss: 0.0015933053800836205 score: 0.9926470588235294
2021-08-08 04:30:21,223 | train | INFO | Epoch 8 train batch 249/450: 3984/7200 mean loss: 0.0016325117321684957 score: 1.0
2021-08-08 04:30:21,996 | train | INFO | Epoch 8 train batch 250/450: 4000/7200 mean loss: 0.0014778978656977415 score: 1.0
2021-08-08 04:30:22,843 | train | INFO | Epoch 8 train batch 251/450: 4016/7200 mean loss: 0.0013315345859155059 score: 0.9926470588235294
2021-08-08 04:30:23,625 | train | INFO | Epoch 8 train batch 252/450: 4032/7200 mean loss: 0.001411921577528119 score: 1.0
2021-08-08 04:30:24,438 | train | INFO | Epoch 8 train batch 253/450: 4048/7200 mean loss: 0.0016639359528198838 score: 1.0
2021-08-08 04:30:25,217 | train | INFO | Epoch 8 train batch 254/450: 4064/7200 mean loss: 0.0014860708033666015 score: 1.0
2021-08-08 04:30:26,027 | train | INFO | Epoch 8 train batch 255/450: 4080/7200 mean loss: 0.0016433160053566098 score: 1.0
2021-08-08 04:30:26,818 | train | INFO | Epoch 8 train batch 256/450: 4096/7200 mean loss: 0.0014688246883451939 score: 1.0
2021-08-08 04:30:27,611 | train | INFO | Epoch 8 train batch 257/450: 4112/7200 mean loss: 0.001642865128815174 score: 0.9924019607843138
2021-08-08 04:30:28,439 | train | INFO | Epoch 8 train batch 258/450: 4128/7200 mean loss: 0.0014047244330868125 score: 0.9963235294117647
2021-08-08 04:30:29,220 | train | INFO | Epoch 8 train batch 259/450: 4144/7200 mean loss: 0.0013966882834210992 score: 1.0
2021-08-08 04:30:30,034 | train | INFO | Epoch 8 train batch 260/450: 4160/7200 mean loss: 0.0012775465147569776 score: 1.0
2021-08-08 04:30:30,862 | train | INFO | Epoch 8 train batch 261/450: 4176/7200 mean loss: 0.0014332592254504561 score: 0.996078431372549
2021-08-08 04:30:31,642 | train | INFO | Epoch 8 train batch 262/450: 4192/7200 mean loss: 0.0015565539943054318 score: 0.9926470588235294
2021-08-08 04:30:32,415 | train | INFO | Epoch 8 train batch 263/450: 4208/7200 mean loss: 0.0012784433783963323 score: 1.0
2021-08-08 04:30:33,219 | train | INFO | Epoch 8 train batch 264/450: 4224/7200 mean loss: 0.0014244253979995847 score: 1.0
2021-08-08 04:30:33,989 | train | INFO | Epoch 8 train batch 265/450: 4240/7200 mean loss: 0.001522560603916645 score: 1.0
2021-08-08 04:30:34,763 | train | INFO | Epoch 8 train batch 266/450: 4256/7200 mean loss: 0.0016135515179485083 score: 1.0
2021-08-08 04:30:35,574 | train | INFO | Epoch 8 train batch 267/450: 4272/7200 mean loss: 0.0016169678419828415 score: 0.996078431372549
2021-08-08 04:30:36,358 | train | INFO | Epoch 8 train batch 268/450: 4288/7200 mean loss: 0.001353141968138516 score: 1.0
2021-08-08 04:30:37,219 | train | INFO | Epoch 8 train batch 269/450: 4304/7200 mean loss: 0.0014462724793702364 score: 0.9742647058823529
2021-08-08 04:30:37,993 | train | INFO | Epoch 8 train batch 270/450: 4320/7200 mean loss: 0.001735606463626027 score: 1.0
2021-08-08 04:30:38,773 | train | INFO | Epoch 8 train batch 271/450: 4336/7200 mean loss: 0.0014458231162279844 score: 1.0
2021-08-08 04:30:39,586 | train | INFO | Epoch 8 train batch 272/450: 4352/7200 mean loss: 0.0015606844099238515 score: 1.0
2021-08-08 04:30:40,422 | train | INFO | Epoch 8 train batch 273/450: 4368/7200 mean loss: 0.0016799068544059992 score: 1.0
2021-08-08 04:30:41,225 | train | INFO | Epoch 8 train batch 274/450: 4384/7200 mean loss: 0.0015471031656488776 score: 0.9475490196078432
2021-08-08 04:30:42,020 | train | INFO | Epoch 8 train batch 275/450: 4400/7200 mean loss: 0.0016034925356507301 score: 1.0
2021-08-08 04:30:42,794 | train | INFO | Epoch 8 train batch 276/450: 4416/7200 mean loss: 0.0014794492162764072 score: 1.0
2021-08-08 04:30:43,570 | train | INFO | Epoch 8 train batch 277/450: 4432/7200 mean loss: 0.0015705961268395185 score: 0.9926470588235294
2021-08-08 04:30:44,350 | train | INFO | Epoch 8 train batch 278/450: 4448/7200 mean loss: 0.001396543113514781 score: 0.9963235294117647
2021-08-08 04:30:45,127 | train | INFO | Epoch 8 train batch 279/450: 4464/7200 mean loss: 0.0014433637261390686 score: 1.0
2021-08-08 04:30:45,939 | train | INFO | Epoch 8 train batch 280/450: 4480/7200 mean loss: 0.001542635029181838 score: 0.9847689075630252
2021-08-08 04:30:46,729 | train | INFO | Epoch 8 train batch 281/450: 4496/7200 mean loss: 0.0014077028026804328 score: 1.0
2021-08-08 04:30:47,519 | train | INFO | Epoch 8 train batch 282/450: 4512/7200 mean loss: 0.0015367413870990276 score: 0.9963235294117647
2021-08-08 04:30:48,306 | train | INFO | Epoch 8 train batch 283/450: 4528/7200 mean loss: 0.0014574725646525621 score: 1.0
2021-08-08 04:30:49,094 | train | INFO | Epoch 8 train batch 284/450: 4544/7200 mean loss: 0.0015818447573110461 score: 1.0
2021-08-08 04:30:49,906 | train | INFO | Epoch 8 train batch 285/450: 4560/7200 mean loss: 0.0015408702893182635 score: 1.0
2021-08-08 04:30:50,683 | train | INFO | Epoch 8 train batch 286/450: 4576/7200 mean loss: 0.0014368563424795866 score: 1.0
2021-08-08 04:30:51,460 | train | INFO | Epoch 8 train batch 287/450: 4592/7200 mean loss: 0.001449188101105392 score: 1.0
2021-08-08 04:30:52,256 | train | INFO | Epoch 8 train batch 288/450: 4608/7200 mean loss: 0.0014113469514995813 score: 1.0
2021-08-08 04:30:53,102 | train | INFO | Epoch 8 train batch 289/450: 4624/7200 mean loss: 0.001491499599069357 score: 1.0
2021-08-08 04:30:53,906 | train | INFO | Epoch 8 train batch 290/450: 4640/7200 mean loss: 0.001600478426553309 score: 1.0
2021-08-08 04:30:54,677 | train | INFO | Epoch 8 train batch 291/450: 4656/7200 mean loss: 0.0015927118947729468 score: 1.0
2021-08-08 04:30:55,466 | train | INFO | Epoch 8 train batch 292/450: 4672/7200 mean loss: 0.0016663135029375553 score: 1.0
2021-08-08 04:30:56,256 | train | INFO | Epoch 8 train batch 293/450: 4688/7200 mean loss: 0.001562944264151156 score: 0.939950980392157
2021-08-08 04:30:57,060 | train | INFO | Epoch 8 train batch 294/450: 4704/7200 mean loss: 0.001370426150970161 score: 1.0
2021-08-08 04:30:57,871 | train | INFO | Epoch 8 train batch 295/450: 4720/7200 mean loss: 0.0015206277603283525 score: 0.9963235294117647
2021-08-08 04:30:58,656 | train | INFO | Epoch 8 train batch 296/450: 4736/7200 mean loss: 0.0015783763956278563 score: 1.0
2021-08-08 04:30:59,444 | train | INFO | Epoch 8 train batch 297/450: 4752/7200 mean loss: 0.0014309240505099297 score: 1.0
2021-08-08 04:31:00,229 | train | INFO | Epoch 8 train batch 298/450: 4768/7200 mean loss: 0.0013543226523324847 score: 1.0
2021-08-08 04:31:01,021 | train | INFO | Epoch 8 train batch 299/450: 4784/7200 mean loss: 0.0015739434165880084 score: 1.0
2021-08-08 04:31:01,922 | train | INFO | Epoch 8 train batch 300/450: 4800/7200 mean loss: 0.0014964985894039273 score: 1.0
2021-08-08 04:31:02,745 | train | INFO | Epoch 8 train batch 301/450: 4816/7200 mean loss: 0.0015575340948998928 score: 1.0
2021-08-08 04:31:03,524 | train | INFO | Epoch 8 train batch 302/450: 4832/7200 mean loss: 0.0015118857845664024 score: 1.0
2021-08-08 04:31:04,345 | train | INFO | Epoch 8 train batch 303/450: 4848/7200 mean loss: 0.001426482805982232 score: 1.0
2021-08-08 04:31:05,151 | train | INFO | Epoch 8 train batch 304/450: 4864/7200 mean loss: 0.0014132159994915128 score: 1.0
2021-08-08 04:31:05,966 | train | INFO | Epoch 8 train batch 305/450: 4880/7200 mean loss: 0.0015866054454818368 score: 1.0
2021-08-08 04:31:06,731 | train | INFO | Epoch 8 train batch 306/450: 4896/7200 mean loss: 0.0014353841543197632 score: 1.0
2021-08-08 04:31:07,505 | train | INFO | Epoch 8 train batch 307/450: 4912/7200 mean loss: 0.0014913888880982995 score: 1.0
2021-08-08 04:31:08,293 | train | INFO | Epoch 8 train batch 308/450: 4928/7200 mean loss: 0.0014921576948836446 score: 0.9924019607843138
2021-08-08 04:31:09,108 | train | INFO | Epoch 8 train batch 309/450: 4944/7200 mean loss: 0.0016446099616587162 score: 0.9740196078431372
2021-08-08 04:31:09,885 | train | INFO | Epoch 8 train batch 310/450: 4960/7200 mean loss: 0.001528409426100552 score: 1.0
2021-08-08 04:31:10,688 | train | INFO | Epoch 8 train batch 311/450: 4976/7200 mean loss: 0.0015575067372992635 score: 1.0
2021-08-08 04:31:11,500 | train | INFO | Epoch 8 train batch 312/450: 4992/7200 mean loss: 0.0012142527848482132 score: 1.0
2021-08-08 04:31:12,293 | train | INFO | Epoch 8 train batch 313/450: 5008/7200 mean loss: 0.001339650247246027 score: 1.0
2021-08-08 04:31:13,090 | train | INFO | Epoch 8 train batch 314/450: 5024/7200 mean loss: 0.0016521119978278875 score: 0.9889705882352942
2021-08-08 04:31:13,897 | train | INFO | Epoch 8 train batch 315/450: 5040/7200 mean loss: 0.0014163285959511995 score: 1.0
2021-08-08 04:31:14,675 | train | INFO | Epoch 8 train batch 316/450: 5056/7200 mean loss: 0.001467916532419622 score: 1.0
2021-08-08 04:31:15,543 | train | INFO | Epoch 8 train batch 317/450: 5072/7200 mean loss: 0.0014368488918989897 score: 1.0
2021-08-08 04:31:16,350 | train | INFO | Epoch 8 train batch 318/450: 5088/7200 mean loss: 0.0016811592504382133 score: 1.0
2021-08-08 04:31:17,150 | train | INFO | Epoch 8 train batch 319/450: 5104/7200 mean loss: 0.0015844132285565138 score: 1.0
2021-08-08 04:31:17,938 | train | INFO | Epoch 8 train batch 320/450: 5120/7200 mean loss: 0.0017211138037964702 score: 0.9330882352941177
2021-08-08 04:31:18,800 | train | INFO | Epoch 8 train batch 321/450: 5136/7200 mean loss: 0.00161017628852278 score: 1.0
2021-08-08 04:31:19,742 | train | INFO | Epoch 8 train batch 322/450: 5152/7200 mean loss: 0.001618802547454834 score: 0.5997899159663865
2021-08-08 04:31:20,532 | train | INFO | Epoch 8 train batch 323/450: 5168/7200 mean loss: 0.001648706616833806 score: 0.9737745098039216
2021-08-08 04:31:21,344 | train | INFO | Epoch 8 train batch 324/450: 5184/7200 mean loss: 0.0013881943887099624 score: 0.9926470588235294
2021-08-08 04:31:22,123 | train | INFO | Epoch 8 train batch 325/450: 5200/7200 mean loss: 0.0015281798550859094 score: 1.0
2021-08-08 04:31:22,937 | train | INFO | Epoch 8 train batch 326/450: 5216/7200 mean loss: 0.0016091665020212531 score: 1.0
2021-08-08 04:31:23,762 | train | INFO | Epoch 8 train batch 327/450: 5232/7200 mean loss: 0.0014429278671741486 score: 1.0
2021-08-08 04:31:24,584 | train | INFO | Epoch 8 train batch 328/450: 5248/7200 mean loss: 0.001268662279471755 score: 1.0
2021-08-08 04:31:25,392 | train | INFO | Epoch 8 train batch 329/450: 5264/7200 mean loss: 0.001588276238180697 score: 0.9813725490196079
2021-08-08 04:31:26,200 | train | INFO | Epoch 8 train batch 330/450: 5280/7200 mean loss: 0.0013976090122014284 score: 1.0
2021-08-08 04:31:26,971 | train | INFO | Epoch 8 train batch 331/450: 5296/7200 mean loss: 0.0014034718042239547 score: 1.0
2021-08-08 04:31:27,855 | train | INFO | Epoch 8 train batch 332/450: 5312/7200 mean loss: 0.001510151894763112 score: 0.9963235294117647
2021-08-08 04:31:28,674 | train | INFO | Epoch 8 train batch 333/450: 5328/7200 mean loss: 0.0013930121203884482 score: 1.0
2021-08-08 04:31:29,444 | train | INFO | Epoch 8 train batch 334/450: 5344/7200 mean loss: 0.00152481603436172 score: 0.996078431372549
2021-08-08 04:31:30,229 | train | INFO | Epoch 8 train batch 335/450: 5360/7200 mean loss: 0.0014941812260076404 score: 1.0
2021-08-08 04:31:31,044 | train | INFO | Epoch 8 train batch 336/450: 5376/7200 mean loss: 0.0015401275595650077 score: 1.0
2021-08-08 04:31:31,878 | train | INFO | Epoch 8 train batch 337/450: 5392/7200 mean loss: 0.0016149802831932902 score: 1.0
2021-08-08 04:31:32,692 | train | INFO | Epoch 8 train batch 338/450: 5408/7200 mean loss: 0.0018197867320850492 score: 1.0
2021-08-08 04:31:33,476 | train | INFO | Epoch 8 train batch 339/450: 5424/7200 mean loss: 0.001454041455872357 score: 1.0
2021-08-08 04:31:34,306 | train | INFO | Epoch 8 train batch 340/450: 5440/7200 mean loss: 0.0014661933528259397 score: 1.0
2021-08-08 04:31:35,089 | train | INFO | Epoch 8 train batch 341/450: 5456/7200 mean loss: 0.0013223910937085748 score: 0.9963235294117647
2021-08-08 04:31:35,898 | train | INFO | Epoch 8 train batch 342/450: 5472/7200 mean loss: 0.0015748660080134869 score: 0.7522058823529412
2021-08-08 04:31:36,694 | train | INFO | Epoch 8 train batch 343/450: 5488/7200 mean loss: 0.0016554497415199876 score: 0.9926470588235294
2021-08-08 04:31:37,487 | train | INFO | Epoch 8 train batch 344/450: 5504/7200 mean loss: 0.0015520306769758463 score: 0.9661764705882353
2021-08-08 04:31:38,275 | train | INFO | Epoch 8 train batch 345/450: 5520/7200 mean loss: 0.0016916004242375493 score: 1.0
2021-08-08 04:31:39,096 | train | INFO | Epoch 8 train batch 346/450: 5536/7200 mean loss: 0.0015360534889623523 score: 0.9117647058823529
2021-08-08 04:31:39,933 | train | INFO | Epoch 8 train batch 347/450: 5552/7200 mean loss: 0.0017079687677323818 score: 0.966421568627451
2021-08-08 04:31:40,744 | train | INFO | Epoch 8 train batch 348/450: 5568/7200 mean loss: 0.0014705478679388762 score: 1.0
2021-08-08 04:31:41,543 | train | INFO | Epoch 8 train batch 349/450: 5584/7200 mean loss: 0.0015001334249973297 score: 0.9963235294117647
2021-08-08 04:31:42,318 | train | INFO | Epoch 8 train batch 350/450: 5600/7200 mean loss: 0.0016063711373135448 score: 0.8975490196078432
2021-08-08 04:31:43,092 | train | INFO | Epoch 8 train batch 351/450: 5616/7200 mean loss: 0.0015260173240676522 score: 1.0
2021-08-08 04:31:43,863 | train | INFO | Epoch 8 train batch 352/450: 5632/7200 mean loss: 0.0014364207163453102 score: 0.9622549019607843
2021-08-08 04:31:44,695 | train | INFO | Epoch 8 train batch 353/450: 5648/7200 mean loss: 0.0014626391930505633 score: 0.9338235294117647
2021-08-08 04:31:45,517 | train | INFO | Epoch 8 train batch 354/450: 5664/7200 mean loss: 0.0015058523276820779 score: 0.9963235294117647
2021-08-08 04:31:46,329 | train | INFO | Epoch 8 train batch 355/450: 5680/7200 mean loss: 0.0015088970540091395 score: 1.0
2021-08-08 04:31:47,111 | train | INFO | Epoch 8 train batch 356/450: 5696/7200 mean loss: 0.0014089633477851748 score: 1.0
2021-08-08 04:31:47,893 | train | INFO | Epoch 8 train batch 357/450: 5712/7200 mean loss: 0.001403085538186133 score: 0.996078431372549
2021-08-08 04:31:48,725 | train | INFO | Epoch 8 train batch 358/450: 5728/7200 mean loss: 0.001439332845620811 score: 0.808718487394958
2021-08-08 04:31:49,510 | train | INFO | Epoch 8 train batch 359/450: 5744/7200 mean loss: 0.0013851862167939544 score: 1.0
2021-08-08 04:31:50,289 | train | INFO | Epoch 8 train batch 360/450: 5760/7200 mean loss: 0.0014782887883484364 score: 1.0
2021-08-08 04:31:51,071 | train | INFO | Epoch 8 train batch 361/450: 5776/7200 mean loss: 0.0016412349650636315 score: 1.0
2021-08-08 04:31:51,846 | train | INFO | Epoch 8 train batch 362/450: 5792/7200 mean loss: 0.0015672448789700866 score: 1.0
2021-08-08 04:31:52,670 | train | INFO | Epoch 8 train batch 363/450: 5808/7200 mean loss: 0.0015101702883839607 score: 1.0
2021-08-08 04:31:53,499 | train | INFO | Epoch 8 train batch 364/450: 5824/7200 mean loss: 0.0014816001057624817 score: 1.0
2021-08-08 04:31:54,288 | train | INFO | Epoch 8 train batch 365/450: 5840/7200 mean loss: 0.001449090545065701 score: 1.0
2021-08-08 04:31:55,056 | train | INFO | Epoch 8 train batch 366/450: 5856/7200 mean loss: 0.0014342578360810876 score: 1.0
2021-08-08 04:31:55,822 | train | INFO | Epoch 8 train batch 367/450: 5872/7200 mean loss: 0.0016413636039942503 score: 1.0
2021-08-08 04:31:56,648 | train | INFO | Epoch 8 train batch 368/450: 5888/7200 mean loss: 0.001493883435614407 score: 0.9963235294117647
2021-08-08 04:31:57,422 | train | INFO | Epoch 8 train batch 369/450: 5904/7200 mean loss: 0.0014473750488832593 score: 1.0
2021-08-08 04:31:58,207 | train | INFO | Epoch 8 train batch 370/450: 5920/7200 mean loss: 0.0015825808513909578 score: 1.0
2021-08-08 04:31:58,984 | train | INFO | Epoch 8 train batch 371/450: 5936/7200 mean loss: 0.0013940926874056458 score: 1.0
2021-08-08 04:31:59,812 | train | INFO | Epoch 8 train batch 372/450: 5952/7200 mean loss: 0.0015025197062641382 score: 1.0
2021-08-08 04:32:00,640 | train | INFO | Epoch 8 train batch 373/450: 5968/7200 mean loss: 0.00152078946121037 score: 0.78789592760181
2021-08-08 04:32:01,440 | train | INFO | Epoch 8 train batch 374/450: 5984/7200 mean loss: 0.0015421613352373242 score: 1.0
2021-08-08 04:32:02,271 | train | INFO | Epoch 8 train batch 375/450: 6000/7200 mean loss: 0.0014951396733522415 score: 1.0
2021-08-08 04:32:03,050 | train | INFO | Epoch 8 train batch 376/450: 6016/7200 mean loss: 0.0016513523878529668 score: 0.9887254901960785
2021-08-08 04:32:03,829 | train | INFO | Epoch 8 train batch 377/450: 6032/7200 mean loss: 0.0014482915867120028 score: 1.0
2021-08-08 04:32:04,610 | train | INFO | Epoch 8 train batch 378/450: 6048/7200 mean loss: 0.0014908509328961372 score: 1.0
2021-08-08 04:32:05,395 | train | INFO | Epoch 8 train batch 379/450: 6064/7200 mean loss: 0.0013767778873443604 score: 1.0
2021-08-08 04:32:06,179 | train | INFO | Epoch 8 train batch 380/450: 6080/7200 mean loss: 0.0013147321296855807 score: 0.9522058823529411
2021-08-08 04:32:06,975 | train | INFO | Epoch 8 train batch 381/450: 6096/7200 mean loss: 0.0014027678407728672 score: 1.0
2021-08-08 04:32:07,760 | train | INFO | Epoch 8 train batch 382/450: 6112/7200 mean loss: 0.0015608061803504825 score: 0.9963235294117647
2021-08-08 04:32:08,536 | train | INFO | Epoch 8 train batch 383/450: 6128/7200 mean loss: 0.0014541777782142162 score: 1.0
2021-08-08 04:32:09,341 | train | INFO | Epoch 8 train batch 384/450: 6144/7200 mean loss: 0.0016987104900181293 score: 0.9963235294117647
2021-08-08 04:32:10,123 | train | INFO | Epoch 8 train batch 385/450: 6160/7200 mean loss: 0.0017855606274679303 score: 0.8986344537815125
2021-08-08 04:32:10,970 | train | INFO | Epoch 8 train batch 386/450: 6176/7200 mean loss: 0.0016338394489139318 score: 1.0
2021-08-08 04:32:11,738 | train | INFO | Epoch 8 train batch 387/450: 6192/7200 mean loss: 0.0017327857203781605 score: 1.0
2021-08-08 04:32:12,510 | train | INFO | Epoch 8 train batch 388/450: 6208/7200 mean loss: 0.001649737823754549 score: 1.0
2021-08-08 04:32:13,299 | train | INFO | Epoch 8 train batch 389/450: 6224/7200 mean loss: 0.0017095095245167613 score: 0.9963235294117647
2021-08-08 04:32:14,101 | train | INFO | Epoch 8 train batch 390/450: 6240/7200 mean loss: 0.0013860565377399325 score: 1.0
2021-08-08 04:32:14,927 | train | INFO | Epoch 8 train batch 391/450: 6256/7200 mean loss: 0.001252276124432683 score: 1.0
2021-08-08 04:32:15,726 | train | INFO | Epoch 8 train batch 392/450: 6272/7200 mean loss: 0.0012296002823859453 score: 1.0
2021-08-08 04:32:16,527 | train | INFO | Epoch 8 train batch 393/450: 6288/7200 mean loss: 0.0014865017728880048 score: 1.0
2021-08-08 04:32:17,303 | train | INFO | Epoch 8 train batch 394/450: 6304/7200 mean loss: 0.0014401369262486696 score: 1.0
2021-08-08 04:32:18,175 | train | INFO | Epoch 8 train batch 395/450: 6320/7200 mean loss: 0.0012750093592330813 score: 1.0
2021-08-08 04:32:18,994 | train | INFO | Epoch 8 train batch 396/450: 6336/7200 mean loss: 0.0016480687772855163 score: 0.9776960784313725
2021-08-08 04:32:19,785 | train | INFO | Epoch 8 train batch 397/450: 6352/7200 mean loss: 0.0015076221898198128 score: 1.0
2021-08-08 04:32:20,574 | train | INFO | Epoch 8 train batch 398/450: 6368/7200 mean loss: 0.001366897253319621 score: 1.0
2021-08-08 04:32:21,399 | train | INFO | Epoch 8 train batch 399/450: 6384/7200 mean loss: 0.0014515455113723874 score: 1.0
2021-08-08 04:32:22,208 | train | INFO | Epoch 8 train batch 400/450: 6400/7200 mean loss: 0.001322904136031866 score: 0.9889705882352942
2021-08-08 04:32:23,023 | train | INFO | Epoch 8 train batch 401/450: 6416/7200 mean loss: 0.0015838061226531863 score: 1.0
2021-08-08 04:32:23,799 | train | INFO | Epoch 8 train batch 402/450: 6432/7200 mean loss: 0.0014876113273203373 score: 0.983998599439776
2021-08-08 04:32:24,570 | train | INFO | Epoch 8 train batch 403/450: 6448/7200 mean loss: 0.0015499184373766184 score: 1.0
2021-08-08 04:32:25,448 | train | INFO | Epoch 8 train batch 404/450: 6464/7200 mean loss: 0.0014083206187933683 score: 0.9808823529411765
2021-08-08 04:32:26,229 | train | INFO | Epoch 8 train batch 405/450: 6480/7200 mean loss: 0.0014628448989242315 score: 1.0
2021-08-08 04:32:27,003 | train | INFO | Epoch 8 train batch 406/450: 6496/7200 mean loss: 0.0014558011898770928 score: 0.9774509803921569
2021-08-08 04:32:27,806 | train | INFO | Epoch 8 train batch 407/450: 6512/7200 mean loss: 0.0013685921439900994 score: 1.0
2021-08-08 04:32:28,604 | train | INFO | Epoch 8 train batch 408/450: 6528/7200 mean loss: 0.0014857281930744648 score: 1.0
2021-08-08 04:32:29,384 | train | INFO | Epoch 8 train batch 409/450: 6544/7200 mean loss: 0.0011872207978740335 score: 1.0
2021-08-08 04:32:30,189 | train | INFO | Epoch 8 train batch 410/450: 6560/7200 mean loss: 0.0017013135366141796 score: 1.0
2021-08-08 04:32:31,049 | train | INFO | Epoch 8 train batch 411/450: 6576/7200 mean loss: 0.0014066554140299559 score: 1.0
2021-08-08 04:32:31,842 | train | INFO | Epoch 8 train batch 412/450: 6592/7200 mean loss: 0.0014943606220185757 score: 1.0
2021-08-08 04:32:32,620 | train | INFO | Epoch 8 train batch 413/450: 6608/7200 mean loss: 0.0013763860333710909 score: 0.996078431372549
2021-08-08 04:32:33,399 | train | INFO | Epoch 8 train batch 414/450: 6624/7200 mean loss: 0.001347426907159388 score: 1.0
2021-08-08 04:32:34,202 | train | INFO | Epoch 8 train batch 415/450: 6640/7200 mean loss: 0.0014016871573403478 score: 1.0
2021-08-08 04:32:35,013 | train | INFO | Epoch 8 train batch 416/450: 6656/7200 mean loss: 0.0013494305312633514 score: 1.0
2021-08-08 04:32:35,823 | train | INFO | Epoch 8 train batch 417/450: 6672/7200 mean loss: 0.0013477811589837074 score: 0.9921218487394957
2021-08-08 04:32:36,631 | train | INFO | Epoch 8 train batch 418/450: 6688/7200 mean loss: 0.0014699064195156097 score: 0.996078431372549
2021-08-08 04:32:37,458 | train | INFO | Epoch 8 train batch 419/450: 6704/7200 mean loss: 0.0014676999999210238 score: 1.0
2021-08-08 04:32:38,245 | train | INFO | Epoch 8 train batch 420/450: 6720/7200 mean loss: 0.001756593119353056 score: 0.9595588235294118
2021-08-08 04:32:39,068 | train | INFO | Epoch 8 train batch 421/450: 6736/7200 mean loss: 0.0016014473512768745 score: 1.0
2021-08-08 04:32:39,844 | train | INFO | Epoch 8 train batch 422/450: 6752/7200 mean loss: 0.0013325741747394204 score: 1.0
2021-08-08 04:32:40,624 | train | INFO | Epoch 8 train batch 423/450: 6768/7200 mean loss: 0.0016804358456283808 score: 1.0
2021-08-08 04:32:41,499 | train | INFO | Epoch 8 train batch 424/450: 6784/7200 mean loss: 0.0015746040735393763 score: 1.0
2021-08-08 04:32:42,282 | train | INFO | Epoch 8 train batch 425/450: 6800/7200 mean loss: 0.0015974005218595266 score: 1.0
2021-08-08 04:32:43,058 | train | INFO | Epoch 8 train batch 426/450: 6816/7200 mean loss: 0.001543971593491733 score: 1.0
2021-08-08 04:32:43,830 | train | INFO | Epoch 8 train batch 427/450: 6832/7200 mean loss: 0.001341937924735248 score: 1.0
2021-08-08 04:32:44,620 | train | INFO | Epoch 8 train batch 428/450: 6848/7200 mean loss: 0.0015156121226027608 score: 1.0
2021-08-08 04:32:45,404 | train | INFO | Epoch 8 train batch 429/450: 6864/7200 mean loss: 0.0015442431904375553 score: 1.0
2021-08-08 04:32:46,192 | train | INFO | Epoch 8 train batch 430/450: 6880/7200 mean loss: 0.0016152303433045745 score: 1.0
2021-08-08 04:32:46,974 | train | INFO | Epoch 8 train batch 431/450: 6896/7200 mean loss: 0.001445760135538876 score: 1.0
2021-08-08 04:32:47,761 | train | INFO | Epoch 8 train batch 432/450: 6912/7200 mean loss: 0.001624255208298564 score: 0.9963235294117647
2021-08-08 04:32:48,550 | train | INFO | Epoch 8 train batch 433/450: 6928/7200 mean loss: 0.0015757656656205654 score: 1.0
2021-08-08 04:32:49,335 | train | INFO | Epoch 8 train batch 434/450: 6944/7200 mean loss: 0.0014922559494152665 score: 0.9963235294117647
2021-08-08 04:32:50,140 | train | INFO | Epoch 8 train batch 435/450: 6960/7200 mean loss: 0.0016559769865125418 score: 1.0
2021-08-08 04:32:50,918 | train | INFO | Epoch 8 train batch 436/450: 6976/7200 mean loss: 0.001324929529801011 score: 1.0
2021-08-08 04:32:51,705 | train | INFO | Epoch 8 train batch 437/450: 6992/7200 mean loss: 0.0015365972649306059 score: 1.0
2021-08-08 04:32:52,474 | train | INFO | Epoch 8 train batch 438/450: 7008/7200 mean loss: 0.0017279532039538026 score: 1.0
2021-08-08 04:32:53,244 | train | INFO | Epoch 8 train batch 439/450: 7024/7200 mean loss: 0.001653677667491138 score: 0.9551470588235295
2021-08-08 04:32:54,014 | train | INFO | Epoch 8 train batch 440/450: 7040/7200 mean loss: 0.0016053656581789255 score: 1.0
2021-08-08 04:32:54,783 | train | INFO | Epoch 8 train batch 441/450: 7056/7200 mean loss: 0.001427392940968275 score: 1.0
2021-08-08 04:32:55,552 | train | INFO | Epoch 8 train batch 442/450: 7072/7200 mean loss: 0.0015732301399111748 score: 0.9500000000000002
2021-08-08 04:32:56,325 | train | INFO | Epoch 8 train batch 443/450: 7088/7200 mean loss: 0.001477189245633781 score: 1.0
2021-08-08 04:32:57,095 | train | INFO | Epoch 8 train batch 444/450: 7104/7200 mean loss: 0.0013166303979232907 score: 1.0
2021-08-08 04:32:57,864 | train | INFO | Epoch 8 train batch 445/450: 7120/7200 mean loss: 0.0014361344510689378 score: 0.9924019607843138
2021-08-08 04:32:58,632 | train | INFO | Epoch 8 train batch 446/450: 7136/7200 mean loss: 0.0013570659793913364 score: 1.0
2021-08-08 04:32:59,403 | train | INFO | Epoch 8 train batch 447/450: 7152/7200 mean loss: 0.0013804981717839837 score: 1.0
2021-08-08 04:33:00,172 | train | INFO | Epoch 8 train batch 448/450: 7168/7200 mean loss: 0.0012351407203823328 score: 1.0
2021-08-08 04:33:00,940 | train | INFO | Epoch 8 train batch 449/450: 7184/7200 mean loss: 0.0013769447105005383 score: 1.0
2021-08-08 04:33:01,110 | train | INFO | Epoch 8, Train, Mean loss: 0.02386067779941691, Score: 0.9910495104024516
2021-08-08 04:33:02,614 | train | INFO | Epoch 8 validation batch 0/113: 0/1800 mean loss: 0.0009948344668373466 score: 1.0
2021-08-08 04:33:02,870 | train | INFO | Epoch 8 validation batch 1/113: 16/1800 mean loss: 0.001033761422149837 score: 0.9926470588235294
2021-08-08 04:33:03,134 | train | INFO | Epoch 8 validation batch 2/113: 32/1800 mean loss: 0.0013105991529300809 score: 1.0
2021-08-08 04:33:03,404 | train | INFO | Epoch 8 validation batch 3/113: 48/1800 mean loss: 0.001150845317170024 score: 1.0
2021-08-08 04:33:03,682 | train | INFO | Epoch 8 validation batch 4/113: 64/1800 mean loss: 0.0010422463528811932 score: 1.0
2021-08-08 04:33:03,920 | train | INFO | Epoch 8 validation batch 5/113: 80/1800 mean loss: 0.0010198443196713924 score: 1.0
2021-08-08 04:33:04,165 | train | INFO | Epoch 8 validation batch 6/113: 96/1800 mean loss: 0.0009820256382226944 score: 1.0
2021-08-08 04:33:04,400 | train | INFO | Epoch 8 validation batch 7/113: 112/1800 mean loss: 0.001136237639002502 score: 1.0
2021-08-08 04:33:04,632 | train | INFO | Epoch 8 validation batch 8/113: 128/1800 mean loss: 0.0011060043470934033 score: 1.0
2021-08-08 04:33:04,863 | train | INFO | Epoch 8 validation batch 9/113: 144/1800 mean loss: 0.0010764083126559854 score: 1.0
2021-08-08 04:33:05,094 | train | INFO | Epoch 8 validation batch 10/113: 160/1800 mean loss: 0.0011366322869434953 score: 0.9816176470588235
2021-08-08 04:33:05,325 | train | INFO | Epoch 8 validation batch 11/113: 176/1800 mean loss: 0.0011661554453894496 score: 1.0
2021-08-08 04:33:05,555 | train | INFO | Epoch 8 validation batch 12/113: 192/1800 mean loss: 0.001075952430255711 score: 1.0
2021-08-08 04:33:05,806 | train | INFO | Epoch 8 validation batch 13/113: 208/1800 mean loss: 0.0009959678864106536 score: 1.0
2021-08-08 04:33:06,041 | train | INFO | Epoch 8 validation batch 14/113: 224/1800 mean loss: 0.0009250033763237298 score: 1.0
2021-08-08 04:33:06,274 | train | INFO | Epoch 8 validation batch 15/113: 240/1800 mean loss: 0.0010591407772153616 score: 1.0
2021-08-08 04:33:06,526 | train | INFO | Epoch 8 validation batch 16/113: 256/1800 mean loss: 0.0010310272919014096 score: 1.0
2021-08-08 04:33:06,766 | train | INFO | Epoch 8 validation batch 17/113: 272/1800 mean loss: 0.001178136095404625 score: 1.0
2021-08-08 04:33:06,998 | train | INFO | Epoch 8 validation batch 18/113: 288/1800 mean loss: 0.0008548526675440371 score: 1.0
2021-08-08 04:33:07,258 | train | INFO | Epoch 8 validation batch 19/113: 304/1800 mean loss: 0.0010550349252298474 score: 1.0
2021-08-08 04:33:07,491 | train | INFO | Epoch 8 validation batch 20/113: 320/1800 mean loss: 0.0011679818853735924 score: 0.9926470588235294
2021-08-08 04:33:07,746 | train | INFO | Epoch 8 validation batch 21/113: 336/1800 mean loss: 0.0010188145097345114 score: 1.0
2021-08-08 04:33:07,978 | train | INFO | Epoch 8 validation batch 22/113: 352/1800 mean loss: 0.0010157293872907758 score: 1.0
2021-08-08 04:33:08,211 | train | INFO | Epoch 8 validation batch 23/113: 368/1800 mean loss: 0.0009822864085435867 score: 1.0
2021-08-08 04:33:08,469 | train | INFO | Epoch 8 validation batch 24/113: 384/1800 mean loss: 0.0010409258538857102 score: 1.0
2021-08-08 04:33:08,701 | train | INFO | Epoch 8 validation batch 25/113: 400/1800 mean loss: 0.001147746224887669 score: 1.0
2021-08-08 04:33:08,960 | train | INFO | Epoch 8 validation batch 26/113: 416/1800 mean loss: 0.0009262011735700071 score: 1.0
2021-08-08 04:33:09,195 | train | INFO | Epoch 8 validation batch 27/113: 432/1800 mean loss: 0.0011392064625397325 score: 1.0
2021-08-08 04:33:09,428 | train | INFO | Epoch 8 validation batch 28/113: 448/1800 mean loss: 0.0010498544434085488 score: 1.0
2021-08-08 04:33:09,660 | train | INFO | Epoch 8 validation batch 29/113: 464/1800 mean loss: 0.0010576967615634203 score: 1.0
2021-08-08 04:33:09,893 | train | INFO | Epoch 8 validation batch 30/113: 480/1800 mean loss: 0.0010342716705054045 score: 1.0
2021-08-08 04:33:10,138 | train | INFO | Epoch 8 validation batch 31/113: 496/1800 mean loss: 0.0010233658831566572 score: 1.0
2021-08-08 04:33:10,368 | train | INFO | Epoch 8 validation batch 32/113: 512/1800 mean loss: 0.0010735414689406753 score: 1.0
2021-08-08 04:33:10,617 | train | INFO | Epoch 8 validation batch 33/113: 528/1800 mean loss: 0.0009448046330362558 score: 1.0
2021-08-08 04:33:10,861 | train | INFO | Epoch 8 validation batch 34/113: 544/1800 mean loss: 0.0008013048791326582 score: 1.0
2021-08-08 04:33:11,112 | train | INFO | Epoch 8 validation batch 35/113: 560/1800 mean loss: 0.001211587805300951 score: 1.0
2021-08-08 04:33:11,359 | train | INFO | Epoch 8 validation batch 36/113: 576/1800 mean loss: 0.0011642848839983344 score: 0.9220588235294118
2021-08-08 04:33:11,590 | train | INFO | Epoch 8 validation batch 37/113: 592/1800 mean loss: 0.0008749659755267203 score: 1.0
2021-08-08 04:33:11,822 | train | INFO | Epoch 8 validation batch 38/113: 608/1800 mean loss: 0.0011030049063265324 score: 1.0
2021-08-08 04:33:12,057 | train | INFO | Epoch 8 validation batch 39/113: 624/1800 mean loss: 0.0010204676073044538 score: 1.0
2021-08-08 04:33:12,325 | train | INFO | Epoch 8 validation batch 40/113: 640/1800 mean loss: 0.0010671508498489857 score: 1.0
2021-08-08 04:33:12,558 | train | INFO | Epoch 8 validation batch 41/113: 656/1800 mean loss: 0.0009967745281755924 score: 1.0
2021-08-08 04:33:12,805 | train | INFO | Epoch 8 validation batch 42/113: 672/1800 mean loss: 0.0010222989367321134 score: 1.0
2021-08-08 04:33:13,063 | train | INFO | Epoch 8 validation batch 43/113: 688/1800 mean loss: 0.001016063615679741 score: 1.0
2021-08-08 04:33:13,320 | train | INFO | Epoch 8 validation batch 44/113: 704/1800 mean loss: 0.0012676501646637917 score: 0.9742647058823529
2021-08-08 04:33:13,576 | train | INFO | Epoch 8 validation batch 45/113: 720/1800 mean loss: 0.001080545480363071 score: 1.0
2021-08-08 04:33:13,823 | train | INFO | Epoch 8 validation batch 46/113: 736/1800 mean loss: 0.0010813745902851224 score: 0.9926470588235294
2021-08-08 04:33:14,099 | train | INFO | Epoch 8 validation batch 47/113: 752/1800 mean loss: 0.0009526311187073588 score: 1.0
2021-08-08 04:33:14,359 | train | INFO | Epoch 8 validation batch 48/113: 768/1800 mean loss: 0.0010039204498752952 score: 1.0
2021-08-08 04:33:14,590 | train | INFO | Epoch 8 validation batch 49/113: 784/1800 mean loss: 0.0010566518176347017 score: 1.0
2021-08-08 04:33:14,820 | train | INFO | Epoch 8 validation batch 50/113: 800/1800 mean loss: 0.0009680528310127556 score: 1.0
2021-08-08 04:33:15,075 | train | INFO | Epoch 8 validation batch 51/113: 816/1800 mean loss: 0.001117464154958725 score: 0.9852941176470589
2021-08-08 04:33:15,329 | train | INFO | Epoch 8 validation batch 52/113: 832/1800 mean loss: 0.001068581361323595 score: 1.0
2021-08-08 04:33:15,570 | train | INFO | Epoch 8 validation batch 53/113: 848/1800 mean loss: 0.0010174212511628866 score: 1.0
2021-08-08 04:33:15,806 | train | INFO | Epoch 8 validation batch 54/113: 864/1800 mean loss: 0.0010137270437553525 score: 1.0
2021-08-08 04:33:16,037 | train | INFO | Epoch 8 validation batch 55/113: 880/1800 mean loss: 0.0011010809103026986 score: 1.0
2021-08-08 04:33:16,272 | train | INFO | Epoch 8 validation batch 56/113: 896/1800 mean loss: 0.0010471222922205925 score: 1.0
2021-08-08 04:33:16,519 | train | INFO | Epoch 8 validation batch 57/113: 912/1800 mean loss: 0.0011125161545351148 score: 1.0
2021-08-08 04:33:16,752 | train | INFO | Epoch 8 validation batch 58/113: 928/1800 mean loss: 0.0011322522768750787 score: 0.9779411764705882
2021-08-08 04:33:17,002 | train | INFO | Epoch 8 validation batch 59/113: 944/1800 mean loss: 0.0010150136658921838 score: 1.0
2021-08-08 04:33:17,234 | train | INFO | Epoch 8 validation batch 60/113: 960/1800 mean loss: 0.0008915466023609042 score: 1.0
2021-08-08 04:33:17,464 | train | INFO | Epoch 8 validation batch 61/113: 976/1800 mean loss: 0.0009493653778918087 score: 1.0
2021-08-08 04:33:17,715 | train | INFO | Epoch 8 validation batch 62/113: 992/1800 mean loss: 0.0010191452456638217 score: 1.0
2021-08-08 04:33:17,960 | train | INFO | Epoch 8 validation batch 63/113: 1008/1800 mean loss: 0.0009676648769527674 score: 1.0
2021-08-08 04:33:18,215 | train | INFO | Epoch 8 validation batch 64/113: 1024/1800 mean loss: 0.001046990044414997 score: 1.0
2021-08-08 04:33:18,467 | train | INFO | Epoch 8 validation batch 65/113: 1040/1800 mean loss: 0.0010819877497851849 score: 1.0
2021-08-08 04:33:18,761 | train | INFO | Epoch 8 validation batch 66/113: 1056/1800 mean loss: 0.001065193791873753 score: 1.0
2021-08-08 04:33:18,999 | train | INFO | Epoch 8 validation batch 67/113: 1072/1800 mean loss: 0.0011177579872310162 score: 1.0
2021-08-08 04:33:19,235 | train | INFO | Epoch 8 validation batch 68/113: 1088/1800 mean loss: 0.0008998157572932541 score: 1.0
2021-08-08 04:33:19,469 | train | INFO | Epoch 8 validation batch 69/113: 1104/1800 mean loss: 0.0010019486071541905 score: 1.0
2021-08-08 04:33:19,714 | train | INFO | Epoch 8 validation batch 70/113: 1120/1800 mean loss: 0.0011598221026360989 score: 0.9963235294117647
2021-08-08 04:33:19,965 | train | INFO | Epoch 8 validation batch 71/113: 1136/1800 mean loss: 0.0009772233897820115 score: 1.0
2021-08-08 04:33:20,213 | train | INFO | Epoch 8 validation batch 72/113: 1152/1800 mean loss: 0.0009731341269798577 score: 1.0
2021-08-08 04:33:20,455 | train | INFO | Epoch 8 validation batch 73/113: 1168/1800 mean loss: 0.0012055031256750226 score: 1.0
2021-08-08 04:33:20,695 | train | INFO | Epoch 8 validation batch 74/113: 1184/1800 mean loss: 0.0010887087555602193 score: 1.0
2021-08-08 04:33:20,937 | train | INFO | Epoch 8 validation batch 75/113: 1200/1800 mean loss: 0.0009917925344780087 score: 1.0
2021-08-08 04:33:21,171 | train | INFO | Epoch 8 validation batch 76/113: 1216/1800 mean loss: 0.0009125806973315775 score: 1.0
2021-08-08 04:33:21,410 | train | INFO | Epoch 8 validation batch 77/113: 1232/1800 mean loss: 0.000909043475985527 score: 1.0
2021-08-08 04:33:21,654 | train | INFO | Epoch 8 validation batch 78/113: 1248/1800 mean loss: 0.0010139646474272013 score: 0.9852941176470589
2021-08-08 04:33:21,903 | train | INFO | Epoch 8 validation batch 79/113: 1264/1800 mean loss: 0.001146160066127777 score: 0.9921568627450981
2021-08-08 04:33:22,148 | train | INFO | Epoch 8 validation batch 80/113: 1280/1800 mean loss: 0.0012139567406848073 score: 1.0
2021-08-08 04:33:22,388 | train | INFO | Epoch 8 validation batch 81/113: 1296/1800 mean loss: 0.0010220512049272656 score: 1.0
2021-08-08 04:33:22,637 | train | INFO | Epoch 8 validation batch 82/113: 1312/1800 mean loss: 0.0010303346207365394 score: 1.0
2021-08-08 04:33:22,893 | train | INFO | Epoch 8 validation batch 83/113: 1328/1800 mean loss: 0.0011623300379142165 score: 1.0
2021-08-08 04:33:23,137 | train | INFO | Epoch 8 validation batch 84/113: 1344/1800 mean loss: 0.0011898571392521262 score: 0.9889705882352942
2021-08-08 04:33:23,368 | train | INFO | Epoch 8 validation batch 85/113: 1360/1800 mean loss: 0.001111471327021718 score: 1.0
2021-08-08 04:33:23,653 | train | INFO | Epoch 8 validation batch 86/113: 1376/1800 mean loss: 0.0012703347019851208 score: 1.0
2021-08-08 04:33:23,903 | train | INFO | Epoch 8 validation batch 87/113: 1392/1800 mean loss: 0.001197226345539093 score: 1.0
2021-08-08 04:33:24,133 | train | INFO | Epoch 8 validation batch 88/113: 1408/1800 mean loss: 0.0010261677671223879 score: 1.0
2021-08-08 04:33:24,409 | train | INFO | Epoch 8 validation batch 89/113: 1424/1800 mean loss: 0.0008926246082410216 score: 1.0
2021-08-08 04:33:24,639 | train | INFO | Epoch 8 validation batch 90/113: 1440/1800 mean loss: 0.0009921129094436765 score: 1.0
2021-08-08 04:33:24,892 | train | INFO | Epoch 8 validation batch 91/113: 1456/1800 mean loss: 0.0012622929643839598 score: 1.0
2021-08-08 04:33:25,172 | train | INFO | Epoch 8 validation batch 92/113: 1472/1800 mean loss: 0.001016207505017519 score: 1.0
2021-08-08 04:33:25,420 | train | INFO | Epoch 8 validation batch 93/113: 1488/1800 mean loss: 0.0010436668526381254 score: 1.0
2021-08-08 04:33:25,653 | train | INFO | Epoch 8 validation batch 94/113: 1504/1800 mean loss: 0.001042611082084477 score: 1.0
2021-08-08 04:33:25,897 | train | INFO | Epoch 8 validation batch 95/113: 1520/1800 mean loss: 0.0010769297368824482 score: 1.0
2021-08-08 04:33:26,168 | train | INFO | Epoch 8 validation batch 96/113: 1536/1800 mean loss: 0.0011575978714972734 score: 0.9963235294117647
2021-08-08 04:33:26,400 | train | INFO | Epoch 8 validation batch 97/113: 1552/1800 mean loss: 0.001072887796908617 score: 1.0
2021-08-08 04:33:26,643 | train | INFO | Epoch 8 validation batch 98/113: 1568/1800 mean loss: 0.0010539783397689462 score: 1.0
2021-08-08 04:33:26,901 | train | INFO | Epoch 8 validation batch 99/113: 1584/1800 mean loss: 0.0010131949093192816 score: 1.0
2021-08-08 04:33:27,151 | train | INFO | Epoch 8 validation batch 100/113: 1600/1800 mean loss: 0.0012005274184048176 score: 1.0
2021-08-08 04:33:27,382 | train | INFO | Epoch 8 validation batch 101/113: 1616/1800 mean loss: 0.0010249284096062183 score: 1.0
2021-08-08 04:33:27,615 | train | INFO | Epoch 8 validation batch 102/113: 1632/1800 mean loss: 0.000944383442401886 score: 1.0
2021-08-08 04:33:27,848 | train | INFO | Epoch 8 validation batch 103/113: 1648/1800 mean loss: 0.0009833249496296048 score: 1.0
2021-08-08 04:33:28,079 | train | INFO | Epoch 8 validation batch 104/113: 1664/1800 mean loss: 0.0011276280274614692 score: 1.0
2021-08-08 04:33:28,310 | train | INFO | Epoch 8 validation batch 105/113: 1680/1800 mean loss: 0.0010701888240873814 score: 1.0
2021-08-08 04:33:28,541 | train | INFO | Epoch 8 validation batch 106/113: 1696/1800 mean loss: 0.0010612386977300048 score: 1.0
2021-08-08 04:33:28,771 | train | INFO | Epoch 8 validation batch 107/113: 1712/1800 mean loss: 0.001314923050813377 score: 1.0
2021-08-08 04:33:29,002 | train | INFO | Epoch 8 validation batch 108/113: 1728/1800 mean loss: 0.001271490240469575 score: 1.0
2021-08-08 04:33:29,232 | train | INFO | Epoch 8 validation batch 109/113: 1744/1800 mean loss: 0.0011766726383939385 score: 1.0
2021-08-08 04:33:29,462 | train | INFO | Epoch 8 validation batch 110/113: 1760/1800 mean loss: 0.0009506705100648105 score: 1.0
2021-08-08 04:33:29,693 | train | INFO | Epoch 8 validation batch 111/113: 1776/1800 mean loss: 0.00100218434818089 score: 1.0
2021-08-08 04:33:29,857 | train | INFO | Epoch 8 validation batch 112/113: 1792/1800 mean loss: 0.0009235065663233399 score: 1.0
2021-08-08 04:33:30,020 | train | INFO | Epoch 8, Validation, Mean loss: 0.016932516391759952, Score: 0.9980370466770779
2021-08-08 04:33:30,020 | train | INFO | Write row 8
2021-08-08 04:33:32,577 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:33:32,580 | train | INFO | Update best record row 9, checkpoints 0.01707311626523733 -> 0.016932516391759952
2021-08-08 04:33:34,642 | train | INFO | Epoch 9 train batch 0/450: 0/7200 mean loss: 0.0014821594813838601 score: 1.0
2021-08-08 04:33:35,442 | train | INFO | Epoch 9 train batch 1/450: 16/7200 mean loss: 0.0013277215184643865 score: 0.9816176470588235
2021-08-08 04:33:36,221 | train | INFO | Epoch 9 train batch 2/450: 32/7200 mean loss: 0.00127870321739465 score: 1.0
2021-08-08 04:33:37,005 | train | INFO | Epoch 9 train batch 3/450: 48/7200 mean loss: 0.0013282998697832227 score: 1.0
2021-08-08 04:33:37,822 | train | INFO | Epoch 9 train batch 4/450: 64/7200 mean loss: 0.0013899991754442453 score: 1.0
2021-08-08 04:33:38,622 | train | INFO | Epoch 9 train batch 5/450: 80/7200 mean loss: 0.0013710645725950599 score: 0.9889705882352942
2021-08-08 04:33:39,407 | train | INFO | Epoch 9 train batch 6/450: 96/7200 mean loss: 0.001499093254096806 score: 1.0
2021-08-08 04:33:40,186 | train | INFO | Epoch 9 train batch 7/450: 112/7200 mean loss: 0.0015765010612085462 score: 1.0
2021-08-08 04:33:40,975 | train | INFO | Epoch 9 train batch 8/450: 128/7200 mean loss: 0.0016589368460699916 score: 1.0
2021-08-08 04:33:41,762 | train | INFO | Epoch 9 train batch 9/450: 144/7200 mean loss: 0.00149982247967273 score: 0.9963235294117647
2021-08-08 04:33:42,569 | train | INFO | Epoch 9 train batch 10/450: 160/7200 mean loss: 0.0014252744149416685 score: 1.0
2021-08-08 04:33:43,379 | train | INFO | Epoch 9 train batch 11/450: 176/7200 mean loss: 0.0013987377751618624 score: 0.9556372549019608
2021-08-08 04:33:44,173 | train | INFO | Epoch 9 train batch 12/450: 192/7200 mean loss: 0.0013184049166738987 score: 1.0
2021-08-08 04:33:44,995 | train | INFO | Epoch 9 train batch 13/450: 208/7200 mean loss: 0.0015122622717171907 score: 1.0
2021-08-08 04:33:45,815 | train | INFO | Epoch 9 train batch 14/450: 224/7200 mean loss: 0.0015261613298207521 score: 1.0
2021-08-08 04:33:46,743 | train | INFO | Epoch 9 train batch 15/450: 240/7200 mean loss: 0.0014544103760272264 score: 1.0
2021-08-08 04:33:47,573 | train | INFO | Epoch 9 train batch 16/450: 256/7200 mean loss: 0.0014297586167231202 score: 1.0
2021-08-08 04:33:48,394 | train | INFO | Epoch 9 train batch 17/450: 272/7200 mean loss: 0.0015657098265364766 score: 1.0
2021-08-08 04:33:49,205 | train | INFO | Epoch 9 train batch 18/450: 288/7200 mean loss: 0.001387865049764514 score: 1.0
2021-08-08 04:33:49,983 | train | INFO | Epoch 9 train batch 19/450: 304/7200 mean loss: 0.001636136439628899 score: 0.9737745098039216
2021-08-08 04:33:50,759 | train | INFO | Epoch 9 train batch 20/450: 320/7200 mean loss: 0.0015159781323745847 score: 1.0
2021-08-08 04:33:51,637 | train | INFO | Epoch 9 train batch 21/450: 336/7200 mean loss: 0.0016776063712313771 score: 1.0
2021-08-08 04:33:52,440 | train | INFO | Epoch 9 train batch 22/450: 352/7200 mean loss: 0.0014012848259881139 score: 0.9926470588235294
2021-08-08 04:33:53,213 | train | INFO | Epoch 9 train batch 23/450: 368/7200 mean loss: 0.001516348565928638 score: 1.0
2021-08-08 04:33:53,985 | train | INFO | Epoch 9 train batch 24/450: 384/7200 mean loss: 0.0015657810727134347 score: 1.0
2021-08-08 04:33:54,762 | train | INFO | Epoch 9 train batch 25/450: 400/7200 mean loss: 0.0013261109124869108 score: 1.0
2021-08-08 04:33:55,575 | train | INFO | Epoch 9 train batch 26/450: 416/7200 mean loss: 0.0017362487269565463 score: 1.0
2021-08-08 04:33:56,370 | train | INFO | Epoch 9 train batch 27/450: 432/7200 mean loss: 0.0013775816187262535 score: 1.0
2021-08-08 04:33:57,176 | train | INFO | Epoch 9 train batch 28/450: 448/7200 mean loss: 0.0013874804135411978 score: 1.0
2021-08-08 04:33:58,000 | train | INFO | Epoch 9 train batch 29/450: 464/7200 mean loss: 0.0013756054686382413 score: 1.0
2021-08-08 04:33:58,780 | train | INFO | Epoch 9 train batch 30/450: 480/7200 mean loss: 0.0016064525116235018 score: 1.0
2021-08-08 04:33:59,558 | train | INFO | Epoch 9 train batch 31/450: 496/7200 mean loss: 0.0017414056928828359 score: 0.996078431372549
2021-08-08 04:34:00,333 | train | INFO | Epoch 9 train batch 32/450: 512/7200 mean loss: 0.0015196832828223705 score: 1.0
2021-08-08 04:34:01,109 | train | INFO | Epoch 9 train batch 33/450: 528/7200 mean loss: 0.0014663668116554618 score: 1.0
2021-08-08 04:34:01,929 | train | INFO | Epoch 9 train batch 34/450: 544/7200 mean loss: 0.0013056379975751042 score: 1.0
2021-08-08 04:34:02,715 | train | INFO | Epoch 9 train batch 35/450: 560/7200 mean loss: 0.0014899986563250422 score: 1.0
2021-08-08 04:34:03,483 | train | INFO | Epoch 9 train batch 36/450: 576/7200 mean loss: 0.0014033152256160975 score: 1.0
2021-08-08 04:34:04,255 | train | INFO | Epoch 9 train batch 37/450: 592/7200 mean loss: 0.0012239118805155158 score: 1.0
2021-08-08 04:34:05,068 | train | INFO | Epoch 9 train batch 38/450: 608/7200 mean loss: 0.0015406415332108736 score: 1.0
2021-08-08 04:34:05,847 | train | INFO | Epoch 9 train batch 39/450: 624/7200 mean loss: 0.0014304023934528232 score: 1.0
2021-08-08 04:34:06,660 | train | INFO | Epoch 9 train batch 40/450: 640/7200 mean loss: 0.0013862189371138811 score: 1.0
2021-08-08 04:34:07,459 | train | INFO | Epoch 9 train batch 41/450: 656/7200 mean loss: 0.0014329745899885893 score: 1.0
2021-08-08 04:34:08,263 | train | INFO | Epoch 9 train batch 42/450: 672/7200 mean loss: 0.0014515912625938654 score: 1.0
2021-08-08 04:34:09,031 | train | INFO | Epoch 9 train batch 43/450: 688/7200 mean loss: 0.0015159816248342395 score: 1.0
2021-08-08 04:34:09,834 | train | INFO | Epoch 9 train batch 44/450: 704/7200 mean loss: 0.0013217125087976456 score: 1.0
2021-08-08 04:34:10,638 | train | INFO | Epoch 9 train batch 45/450: 720/7200 mean loss: 0.0013402891345322132 score: 1.0
2021-08-08 04:34:11,448 | train | INFO | Epoch 9 train batch 46/450: 736/7200 mean loss: 0.0013841773616150022 score: 0.9926470588235294
2021-08-08 04:34:12,362 | train | INFO | Epoch 9 train batch 47/450: 752/7200 mean loss: 0.0014596737455576658 score: 1.0
2021-08-08 04:34:13,141 | train | INFO | Epoch 9 train batch 48/450: 768/7200 mean loss: 0.0013323173625394702 score: 1.0
2021-08-08 04:34:13,965 | train | INFO | Epoch 9 train batch 49/450: 784/7200 mean loss: 0.001534267095848918 score: 1.0
2021-08-08 04:34:14,731 | train | INFO | Epoch 9 train batch 50/450: 800/7200 mean loss: 0.0016282029682770371 score: 1.0
2021-08-08 04:34:15,497 | train | INFO | Epoch 9 train batch 51/450: 816/7200 mean loss: 0.001348597346805036 score: 1.0
2021-08-08 04:34:16,271 | train | INFO | Epoch 9 train batch 52/450: 832/7200 mean loss: 0.001492723822593689 score: 0.9889705882352942
2021-08-08 04:34:17,085 | train | INFO | Epoch 9 train batch 53/450: 848/7200 mean loss: 0.0014308744575828314 score: 1.0
2021-08-08 04:34:17,885 | train | INFO | Epoch 9 train batch 54/450: 864/7200 mean loss: 0.0013204744318500161 score: 1.0
2021-08-08 04:34:18,673 | train | INFO | Epoch 9 train batch 55/450: 880/7200 mean loss: 0.001398018328472972 score: 1.0
2021-08-08 04:34:19,458 | train | INFO | Epoch 9 train batch 56/450: 896/7200 mean loss: 0.0014815633185207844 score: 1.0
2021-08-08 04:34:20,271 | train | INFO | Epoch 9 train batch 57/450: 912/7200 mean loss: 0.0013935250462964177 score: 1.0
2021-08-08 04:34:21,075 | train | INFO | Epoch 9 train batch 58/450: 928/7200 mean loss: 0.0011502119014039636 score: 1.0
2021-08-08 04:34:21,887 | train | INFO | Epoch 9 train batch 59/450: 944/7200 mean loss: 0.0013864850625395775 score: 0.9852941176470589
2021-08-08 04:34:22,745 | train | INFO | Epoch 9 train batch 60/450: 960/7200 mean loss: 0.0015906745102256536 score: 1.0
2021-08-08 04:34:23,519 | train | INFO | Epoch 9 train batch 61/450: 976/7200 mean loss: 0.0014689728850498796 score: 1.0
2021-08-08 04:34:24,305 | train | INFO | Epoch 9 train batch 62/450: 992/7200 mean loss: 0.0016218622913584113 score: 1.0
2021-08-08 04:34:25,082 | train | INFO | Epoch 9 train batch 63/450: 1008/7200 mean loss: 0.001735414145514369 score: 1.0
2021-08-08 04:34:25,886 | train | INFO | Epoch 9 train batch 64/450: 1024/7200 mean loss: 0.0014486787840723991 score: 0.9926470588235294
2021-08-08 04:34:26,670 | train | INFO | Epoch 9 train batch 65/450: 1040/7200 mean loss: 0.001545491861179471 score: 1.0
2021-08-08 04:34:27,443 | train | INFO | Epoch 9 train batch 66/450: 1056/7200 mean loss: 0.001466310117393732 score: 0.9509803921568628
2021-08-08 04:34:28,227 | train | INFO | Epoch 9 train batch 67/450: 1072/7200 mean loss: 0.001343489857390523 score: 0.9044117647058824
2021-08-08 04:34:29,000 | train | INFO | Epoch 9 train batch 68/450: 1088/7200 mean loss: 0.0014529434265568852 score: 1.0
2021-08-08 04:34:29,770 | train | INFO | Epoch 9 train batch 69/450: 1104/7200 mean loss: 0.0013132775202393532 score: 1.0
2021-08-08 04:34:30,570 | train | INFO | Epoch 9 train batch 70/450: 1120/7200 mean loss: 0.0014109729090705514 score: 0.9946524064171124
2021-08-08 04:34:31,352 | train | INFO | Epoch 9 train batch 71/450: 1136/7200 mean loss: 0.0015945404302328825 score: 0.9963235294117647
2021-08-08 04:34:32,140 | train | INFO | Epoch 9 train batch 72/450: 1152/7200 mean loss: 0.0015177467139437795 score: 1.0
2021-08-08 04:34:32,966 | train | INFO | Epoch 9 train batch 73/450: 1168/7200 mean loss: 0.0015350825851783156 score: 0.9963235294117647
2021-08-08 04:34:33,753 | train | INFO | Epoch 9 train batch 74/450: 1184/7200 mean loss: 0.0012376779923215508 score: 1.0
2021-08-08 04:34:34,569 | train | INFO | Epoch 9 train batch 75/450: 1200/7200 mean loss: 0.0012959596933797002 score: 1.0
2021-08-08 04:34:35,362 | train | INFO | Epoch 9 train batch 76/450: 1216/7200 mean loss: 0.0014138779370114207 score: 1.0
2021-08-08 04:34:36,169 | train | INFO | Epoch 9 train batch 77/450: 1232/7200 mean loss: 0.00130201387219131 score: 1.0
2021-08-08 04:34:36,949 | train | INFO | Epoch 9 train batch 78/450: 1248/7200 mean loss: 0.0013770838268101215 score: 1.0
2021-08-08 04:34:37,720 | train | INFO | Epoch 9 train batch 79/450: 1264/7200 mean loss: 0.0013260417617857456 score: 1.0
2021-08-08 04:34:38,498 | train | INFO | Epoch 9 train batch 80/450: 1280/7200 mean loss: 0.0013218480162322521 score: 1.0
2021-08-08 04:34:39,280 | train | INFO | Epoch 9 train batch 81/450: 1296/7200 mean loss: 0.0015164775541052222 score: 1.0
2021-08-08 04:34:40,091 | train | INFO | Epoch 9 train batch 82/450: 1312/7200 mean loss: 0.0013117565540596843 score: 0.9926470588235294
2021-08-08 04:34:40,888 | train | INFO | Epoch 9 train batch 83/450: 1328/7200 mean loss: 0.0013481035130098462 score: 1.0
2021-08-08 04:34:41,669 | train | INFO | Epoch 9 train batch 84/450: 1344/7200 mean loss: 0.0014314197469502687 score: 1.0
2021-08-08 04:34:42,447 | train | INFO | Epoch 9 train batch 85/450: 1360/7200 mean loss: 0.0013477109605446458 score: 1.0
2021-08-08 04:34:43,274 | train | INFO | Epoch 9 train batch 86/450: 1376/7200 mean loss: 0.0013021115446463227 score: 1.0
2021-08-08 04:34:44,064 | train | INFO | Epoch 9 train batch 87/450: 1392/7200 mean loss: 0.0014883314725011587 score: 1.0
2021-08-08 04:34:44,839 | train | INFO | Epoch 9 train batch 88/450: 1408/7200 mean loss: 0.0013489428674802184 score: 0.9963235294117647
2021-08-08 04:34:45,714 | train | INFO | Epoch 9 train batch 89/450: 1424/7200 mean loss: 0.0015411595813930035 score: 1.0
2021-08-08 04:34:46,499 | train | INFO | Epoch 9 train batch 90/450: 1440/7200 mean loss: 0.001693067024461925 score: 0.9811274509803922
2021-08-08 04:34:47,320 | train | INFO | Epoch 9 train batch 91/450: 1456/7200 mean loss: 0.0014766305685043335 score: 1.0
2021-08-08 04:34:48,089 | train | INFO | Epoch 9 train batch 92/450: 1472/7200 mean loss: 0.0014943850692361593 score: 1.0
2021-08-08 04:34:48,859 | train | INFO | Epoch 9 train batch 93/450: 1488/7200 mean loss: 0.0016082144575193524 score: 1.0
2021-08-08 04:34:49,631 | train | INFO | Epoch 9 train batch 94/450: 1504/7200 mean loss: 0.0013401301112025976 score: 1.0
2021-08-08 04:34:50,401 | train | INFO | Epoch 9 train batch 95/450: 1520/7200 mean loss: 0.001488403999246657 score: 1.0
2021-08-08 04:34:51,169 | train | INFO | Epoch 9 train batch 96/450: 1536/7200 mean loss: 0.0016299211420118809 score: 1.0
2021-08-08 04:34:51,940 | train | INFO | Epoch 9 train batch 97/450: 1552/7200 mean loss: 0.001423782086931169 score: 1.0
2021-08-08 04:34:52,714 | train | INFO | Epoch 9 train batch 98/450: 1568/7200 mean loss: 0.0012679517967626452 score: 0.9963235294117647
2021-08-08 04:34:53,481 | train | INFO | Epoch 9 train batch 99/450: 1584/7200 mean loss: 0.0014057859079912305 score: 1.0
2021-08-08 04:34:54,251 | train | INFO | Epoch 9 train batch 100/450: 1600/7200 mean loss: 0.0015255153411999345 score: 0.9924019607843138
2021-08-08 04:34:55,086 | train | INFO | Epoch 9 train batch 101/450: 1616/7200 mean loss: 0.0014055371284484863 score: 1.0
2021-08-08 04:34:55,889 | train | INFO | Epoch 9 train batch 102/450: 1632/7200 mean loss: 0.001432283315807581 score: 1.0
2021-08-08 04:34:56,697 | train | INFO | Epoch 9 train batch 103/450: 1648/7200 mean loss: 0.0016017697053030133 score: 1.0
2021-08-08 04:34:57,510 | train | INFO | Epoch 9 train batch 104/450: 1664/7200 mean loss: 0.0014754331205040216 score: 1.0
2021-08-08 04:34:58,297 | train | INFO | Epoch 9 train batch 105/450: 1680/7200 mean loss: 0.0013216353254392743 score: 0.9926470588235294
2021-08-08 04:34:59,129 | train | INFO | Epoch 9 train batch 106/450: 1696/7200 mean loss: 0.0014463677071034908 score: 1.0
2021-08-08 04:34:59,919 | train | INFO | Epoch 9 train batch 107/450: 1712/7200 mean loss: 0.0012865883763879538 score: 1.0
2021-08-08 04:35:00,728 | train | INFO | Epoch 9 train batch 108/450: 1728/7200 mean loss: 0.001488755806349218 score: 1.0
2021-08-08 04:35:01,541 | train | INFO | Epoch 9 train batch 109/450: 1744/7200 mean loss: 0.0017062834231182933 score: 1.0
2021-08-08 04:35:02,359 | train | INFO | Epoch 9 train batch 110/450: 1760/7200 mean loss: 0.0015389450127258897 score: 1.0
2021-08-08 04:35:03,171 | train | INFO | Epoch 9 train batch 111/450: 1776/7200 mean loss: 0.001545861130580306 score: 1.0
2021-08-08 04:35:03,972 | train | INFO | Epoch 9 train batch 112/450: 1792/7200 mean loss: 0.0017171228537335992 score: 1.0
2021-08-08 04:35:04,822 | train | INFO | Epoch 9 train batch 113/450: 1808/7200 mean loss: 0.0016368140932172537 score: 1.0
2021-08-08 04:35:05,618 | train | INFO | Epoch 9 train batch 114/450: 1824/7200 mean loss: 0.0011816576588898897 score: 1.0
2021-08-08 04:35:06,419 | train | INFO | Epoch 9 train batch 115/450: 1840/7200 mean loss: 0.0013290670467540622 score: 1.0
2021-08-08 04:35:07,230 | train | INFO | Epoch 9 train batch 116/450: 1856/7200 mean loss: 0.001493899617344141 score: 1.0
2021-08-08 04:35:08,048 | train | INFO | Epoch 9 train batch 117/450: 1872/7200 mean loss: 0.001361373346298933 score: 1.0
2021-08-08 04:35:08,861 | train | INFO | Epoch 9 train batch 118/450: 1888/7200 mean loss: 0.0014076509978622198 score: 1.0
2021-08-08 04:35:09,627 | train | INFO | Epoch 9 train batch 119/450: 1904/7200 mean loss: 0.0014390788273885846 score: 0.9301470588235294
2021-08-08 04:35:10,416 | train | INFO | Epoch 9 train batch 120/450: 1920/7200 mean loss: 0.0014371592551469803 score: 1.0
2021-08-08 04:35:11,191 | train | INFO | Epoch 9 train batch 121/450: 1936/7200 mean loss: 0.0012845303863286972 score: 1.0
2021-08-08 04:35:11,978 | train | INFO | Epoch 9 train batch 122/450: 1952/7200 mean loss: 0.0015143788186833262 score: 1.0
2021-08-08 04:35:12,772 | train | INFO | Epoch 9 train batch 123/450: 1968/7200 mean loss: 0.0013950171414762735 score: 1.0
2021-08-08 04:35:13,582 | train | INFO | Epoch 9 train batch 124/450: 1984/7200 mean loss: 0.0015074535040184855 score: 1.0
2021-08-08 04:35:14,379 | train | INFO | Epoch 9 train batch 125/450: 2000/7200 mean loss: 0.0016340685542672873 score: 0.9963235294117647
2021-08-08 04:35:15,159 | train | INFO | Epoch 9 train batch 126/450: 2016/7200 mean loss: 0.0015326527645811439 score: 1.0
2021-08-08 04:35:15,981 | train | INFO | Epoch 9 train batch 127/450: 2032/7200 mean loss: 0.001421252149157226 score: 0.9963235294117647
2021-08-08 04:35:16,760 | train | INFO | Epoch 9 train batch 128/450: 2048/7200 mean loss: 0.0014870059676468372 score: 1.0
2021-08-08 04:35:17,543 | train | INFO | Epoch 9 train batch 129/450: 2064/7200 mean loss: 0.0015237738844007254 score: 1.0
2021-08-08 04:35:18,418 | train | INFO | Epoch 9 train batch 130/450: 2080/7200 mean loss: 0.0014898127410560846 score: 1.0
2021-08-08 04:35:19,245 | train | INFO | Epoch 9 train batch 131/450: 2096/7200 mean loss: 0.0014929119497537613 score: 1.0
2021-08-08 04:35:20,073 | train | INFO | Epoch 9 train batch 132/450: 2112/7200 mean loss: 0.0013220293913036585 score: 1.0
2021-08-08 04:35:20,862 | train | INFO | Epoch 9 train batch 133/450: 2128/7200 mean loss: 0.001458023558370769 score: 1.0
2021-08-08 04:35:21,659 | train | INFO | Epoch 9 train batch 134/450: 2144/7200 mean loss: 0.0014813067391514778 score: 1.0
2021-08-08 04:35:22,476 | train | INFO | Epoch 9 train batch 135/450: 2160/7200 mean loss: 0.0015083715552464128 score: 0.9963235294117647
2021-08-08 04:35:23,264 | train | INFO | Epoch 9 train batch 136/450: 2176/7200 mean loss: 0.0015993203269317746 score: 1.0
2021-08-08 04:35:24,069 | train | INFO | Epoch 9 train batch 137/450: 2192/7200 mean loss: 0.0013413750566542149 score: 1.0
2021-08-08 04:35:24,842 | train | INFO | Epoch 9 train batch 138/450: 2208/7200 mean loss: 0.001423180801793933 score: 0.9779411764705882
2021-08-08 04:35:25,623 | train | INFO | Epoch 9 train batch 139/450: 2224/7200 mean loss: 0.0013072793371975422 score: 1.0
2021-08-08 04:35:26,442 | train | INFO | Epoch 9 train batch 140/450: 2240/7200 mean loss: 0.0013899285113438964 score: 1.0
2021-08-08 04:35:27,238 | train | INFO | Epoch 9 train batch 141/450: 2256/7200 mean loss: 0.0014360476052388549 score: 1.0
2021-08-08 04:35:28,024 | train | INFO | Epoch 9 train batch 142/450: 2272/7200 mean loss: 0.0014449767768383026 score: 1.0
2021-08-08 04:35:28,803 | train | INFO | Epoch 9 train batch 143/450: 2288/7200 mean loss: 0.0013886692468076944 score: 1.0
2021-08-08 04:35:29,612 | train | INFO | Epoch 9 train batch 144/450: 2304/7200 mean loss: 0.001340112998150289 score: 1.0
2021-08-08 04:35:30,427 | train | INFO | Epoch 9 train batch 145/450: 2320/7200 mean loss: 0.001232940354384482 score: 0.9926470588235294
2021-08-08 04:35:31,228 | train | INFO | Epoch 9 train batch 146/450: 2336/7200 mean loss: 0.0013009672984480858 score: 1.0
2021-08-08 04:35:32,000 | train | INFO | Epoch 9 train batch 147/450: 2352/7200 mean loss: 0.0012936517596244812 score: 0.9776960784313725
2021-08-08 04:35:32,784 | train | INFO | Epoch 9 train batch 148/450: 2368/7200 mean loss: 0.0014705198118463159 score: 0.9850490196078432
2021-08-08 04:35:33,560 | train | INFO | Epoch 9 train batch 149/450: 2384/7200 mean loss: 0.0013867308152839541 score: 0.996078431372549
2021-08-08 04:35:34,347 | train | INFO | Epoch 9 train batch 150/450: 2400/7200 mean loss: 0.0017312843119725585 score: 1.0
2021-08-08 04:35:35,129 | train | INFO | Epoch 9 train batch 151/450: 2416/7200 mean loss: 0.001608075574040413 score: 0.9774159663865547
2021-08-08 04:35:35,943 | train | INFO | Epoch 9 train batch 152/450: 2432/7200 mean loss: 0.0015919790603220463 score: 1.0
2021-08-08 04:35:36,749 | train | INFO | Epoch 9 train batch 153/450: 2448/7200 mean loss: 0.00166278425604105 score: 0.9734943977591035
2021-08-08 04:35:37,549 | train | INFO | Epoch 9 train batch 154/450: 2464/7200 mean loss: 0.0014780047349631786 score: 1.0
2021-08-08 04:35:38,366 | train | INFO | Epoch 9 train batch 155/450: 2480/7200 mean loss: 0.001738202408887446 score: 1.0
2021-08-08 04:35:39,206 | train | INFO | Epoch 9 train batch 156/450: 2496/7200 mean loss: 0.0016244110884144902 score: 1.0
2021-08-08 04:35:39,971 | train | INFO | Epoch 9 train batch 157/450: 2512/7200 mean loss: 0.0013331995578482747 score: 0.996078431372549
2021-08-08 04:35:40,782 | train | INFO | Epoch 9 train batch 158/450: 2528/7200 mean loss: 0.001457719481550157 score: 1.0
2021-08-08 04:35:41,576 | train | INFO | Epoch 9 train batch 159/450: 2544/7200 mean loss: 0.0016080582281574607 score: 1.0
2021-08-08 04:35:42,403 | train | INFO | Epoch 9 train batch 160/450: 2560/7200 mean loss: 0.0015897882403805852 score: 1.0
2021-08-08 04:35:43,212 | train | INFO | Epoch 9 train batch 161/450: 2576/7200 mean loss: 0.001619823044165969 score: 1.0
2021-08-08 04:35:43,997 | train | INFO | Epoch 9 train batch 162/450: 2592/7200 mean loss: 0.0015584479551762342 score: 1.0
2021-08-08 04:35:44,826 | train | INFO | Epoch 9 train batch 163/450: 2608/7200 mean loss: 0.0016331004444509745 score: 1.0
2021-08-08 04:35:45,637 | train | INFO | Epoch 9 train batch 164/450: 2624/7200 mean loss: 0.0016267431201413274 score: 1.0
2021-08-08 04:35:46,459 | train | INFO | Epoch 9 train batch 165/450: 2640/7200 mean loss: 0.0016439898172393441 score: 1.0
2021-08-08 04:35:47,306 | train | INFO | Epoch 9 train batch 166/450: 2656/7200 mean loss: 0.0015186445089057088 score: 1.0
2021-08-08 04:35:48,115 | train | INFO | Epoch 9 train batch 167/450: 2672/7200 mean loss: 0.0015292218886315823 score: 1.0
2021-08-08 04:35:48,915 | train | INFO | Epoch 9 train batch 168/450: 2688/7200 mean loss: 0.0014416857156902552 score: 0.996078431372549
2021-08-08 04:35:49,708 | train | INFO | Epoch 9 train batch 169/450: 2704/7200 mean loss: 0.0015147742815315723 score: 0.996078431372549
2021-08-08 04:35:50,534 | train | INFO | Epoch 9 train batch 170/450: 2720/7200 mean loss: 0.0013297952245920897 score: 0.9926470588235294
2021-08-08 04:35:51,333 | train | INFO | Epoch 9 train batch 171/450: 2736/7200 mean loss: 0.0011933185160160065 score: 1.0
2021-08-08 04:35:52,180 | train | INFO | Epoch 9 train batch 172/450: 2752/7200 mean loss: 0.0014784794766455889 score: 1.0
2021-08-08 04:35:52,983 | train | INFO | Epoch 9 train batch 173/450: 2768/7200 mean loss: 0.0013200907269492745 score: 1.0
2021-08-08 04:35:53,783 | train | INFO | Epoch 9 train batch 174/450: 2784/7200 mean loss: 0.0013995362678542733 score: 1.0
2021-08-08 04:35:54,590 | train | INFO | Epoch 9 train batch 175/450: 2800/7200 mean loss: 0.0017509139142930508 score: 0.9963235294117647
2021-08-08 04:35:55,392 | train | INFO | Epoch 9 train batch 176/450: 2816/7200 mean loss: 0.0015652916627004743 score: 0.9963235294117647
2021-08-08 04:35:56,169 | train | INFO | Epoch 9 train batch 177/450: 2832/7200 mean loss: 0.0015210033161565661 score: 1.0
2021-08-08 04:35:56,970 | train | INFO | Epoch 9 train batch 178/450: 2848/7200 mean loss: 0.0014686178183183074 score: 1.0
2021-08-08 04:35:57,749 | train | INFO | Epoch 9 train batch 179/450: 2864/7200 mean loss: 0.0016938663320615888 score: 1.0
2021-08-08 04:35:58,559 | train | INFO | Epoch 9 train batch 180/450: 2880/7200 mean loss: 0.0015604612417519093 score: 1.0
2021-08-08 04:35:59,341 | train | INFO | Epoch 9 train batch 181/450: 2896/7200 mean loss: 0.0014083270216360688 score: 0.9963235294117647
2021-08-08 04:36:00,137 | train | INFO | Epoch 9 train batch 182/450: 2912/7200 mean loss: 0.001448869938030839 score: 1.0
2021-08-08 04:36:00,948 | train | INFO | Epoch 9 train batch 183/450: 2928/7200 mean loss: 0.0014768814435228705 score: 1.0
2021-08-08 04:36:01,755 | train | INFO | Epoch 9 train batch 184/450: 2944/7200 mean loss: 0.0015393885551020503 score: 1.0
2021-08-08 04:36:02,560 | train | INFO | Epoch 9 train batch 185/450: 2960/7200 mean loss: 0.0013166192220523953 score: 1.0
2021-08-08 04:36:03,350 | train | INFO | Epoch 9 train batch 186/450: 2976/7200 mean loss: 0.0015058572171255946 score: 0.9794306184012067
2021-08-08 04:36:04,166 | train | INFO | Epoch 9 train batch 187/450: 2992/7200 mean loss: 0.0014103584690019488 score: 0.9924019607843138
2021-08-08 04:36:04,931 | train | INFO | Epoch 9 train batch 188/450: 3008/7200 mean loss: 0.0016206249129027128 score: 1.0
2021-08-08 04:36:05,733 | train | INFO | Epoch 9 train batch 189/450: 3024/7200 mean loss: 0.0015541871543973684 score: 0.987028657616893
2021-08-08 04:36:06,551 | train | INFO | Epoch 9 train batch 190/450: 3040/7200 mean loss: 0.0016477856552228332 score: 1.0
2021-08-08 04:36:07,384 | train | INFO | Epoch 9 train batch 191/450: 3056/7200 mean loss: 0.0016570509178563952 score: 1.0
2021-08-08 04:36:08,207 | train | INFO | Epoch 9 train batch 192/450: 3072/7200 mean loss: 0.00148690992500633 score: 0.9963235294117647
2021-08-08 04:36:09,011 | train | INFO | Epoch 9 train batch 193/450: 3088/7200 mean loss: 0.001377602806314826 score: 0.996078431372549
2021-08-08 04:36:09,784 | train | INFO | Epoch 9 train batch 194/450: 3104/7200 mean loss: 0.0013020007172599435 score: 1.0
2021-08-08 04:36:10,576 | train | INFO | Epoch 9 train batch 195/450: 3120/7200 mean loss: 0.001231109956279397 score: 0.996078431372549
2021-08-08 04:36:11,376 | train | INFO | Epoch 9 train batch 196/450: 3136/7200 mean loss: 0.001555160852149129 score: 1.0
2021-08-08 04:36:12,193 | train | INFO | Epoch 9 train batch 197/450: 3152/7200 mean loss: 0.001405550865456462 score: 1.0
2021-08-08 04:36:13,025 | train | INFO | Epoch 9 train batch 198/450: 3168/7200 mean loss: 0.0014624996110796928 score: 1.0
2021-08-08 04:36:13,806 | train | INFO | Epoch 9 train batch 199/450: 3184/7200 mean loss: 0.0016257845563814044 score: 1.0
2021-08-08 04:36:14,613 | train | INFO | Epoch 9 train batch 200/450: 3200/7200 mean loss: 0.0014926723670214415 score: 0.9889705882352942
2021-08-08 04:36:15,414 | train | INFO | Epoch 9 train batch 201/450: 3216/7200 mean loss: 0.0016168702859431505 score: 1.0
2021-08-08 04:36:16,190 | train | INFO | Epoch 9 train batch 202/450: 3232/7200 mean loss: 0.0013768246863037348 score: 1.0
2021-08-08 04:36:16,981 | train | INFO | Epoch 9 train batch 203/450: 3248/7200 mean loss: 0.0014308351092040539 score: 1.0
2021-08-08 04:36:17,759 | train | INFO | Epoch 9 train batch 204/450: 3264/7200 mean loss: 0.001385678886435926 score: 1.0
2021-08-08 04:36:18,566 | train | INFO | Epoch 9 train batch 205/450: 3280/7200 mean loss: 0.001514064846560359 score: 1.0
2021-08-08 04:36:19,346 | train | INFO | Epoch 9 train batch 206/450: 3296/7200 mean loss: 0.0015853048535063863 score: 1.0
2021-08-08 04:36:20,175 | train | INFO | Epoch 9 train batch 207/450: 3312/7200 mean loss: 0.0016073038568720222 score: 1.0
2021-08-08 04:36:20,977 | train | INFO | Epoch 9 train batch 208/450: 3328/7200 mean loss: 0.0015300301602110267 score: 1.0
2021-08-08 04:36:21,752 | train | INFO | Epoch 9 train batch 209/450: 3344/7200 mean loss: 0.0014227894134819508 score: 1.0
2021-08-08 04:36:22,551 | train | INFO | Epoch 9 train batch 210/450: 3360/7200 mean loss: 0.0014481788966804743 score: 1.0
2021-08-08 04:36:23,370 | train | INFO | Epoch 9 train batch 211/450: 3376/7200 mean loss: 0.0017742824275046587 score: 1.0
2021-08-08 04:36:24,162 | train | INFO | Epoch 9 train batch 212/450: 3392/7200 mean loss: 0.0015447858022525907 score: 1.0
2021-08-08 04:36:24,940 | train | INFO | Epoch 9 train batch 213/450: 3408/7200 mean loss: 0.001483136205933988 score: 1.0
2021-08-08 04:36:25,783 | train | INFO | Epoch 9 train batch 214/450: 3424/7200 mean loss: 0.0013173609040677547 score: 1.0
2021-08-08 04:36:26,659 | train | INFO | Epoch 9 train batch 215/450: 3440/7200 mean loss: 0.00148748978972435 score: 1.0
2021-08-08 04:36:27,454 | train | INFO | Epoch 9 train batch 216/450: 3456/7200 mean loss: 0.0014072058256715536 score: 0.9669117647058824
2021-08-08 04:36:28,243 | train | INFO | Epoch 9 train batch 217/450: 3472/7200 mean loss: 0.0015328052686527371 score: 0.9963235294117647
2021-08-08 04:36:29,047 | train | INFO | Epoch 9 train batch 218/450: 3488/7200 mean loss: 0.001537590753287077 score: 1.0
2021-08-08 04:36:29,829 | train | INFO | Epoch 9 train batch 219/450: 3504/7200 mean loss: 0.0015233884332701564 score: 1.0
2021-08-08 04:36:30,637 | train | INFO | Epoch 9 train batch 220/450: 3520/7200 mean loss: 0.0017662991303950548 score: 1.0
2021-08-08 04:36:31,418 | train | INFO | Epoch 9 train batch 221/450: 3536/7200 mean loss: 0.00166885438375175 score: 0.996078431372549
2021-08-08 04:36:32,230 | train | INFO | Epoch 9 train batch 222/450: 3552/7200 mean loss: 0.0015173244755715132 score: 1.0
2021-08-08 04:36:33,056 | train | INFO | Epoch 9 train batch 223/450: 3568/7200 mean loss: 0.001179616549052298 score: 1.0
2021-08-08 04:36:33,849 | train | INFO | Epoch 9 train batch 224/450: 3584/7200 mean loss: 0.0014189640060067177 score: 1.0
2021-08-08 04:36:34,683 | train | INFO | Epoch 9 train batch 225/450: 3600/7200 mean loss: 0.001458692830055952 score: 1.0
2021-08-08 04:36:35,460 | train | INFO | Epoch 9 train batch 226/450: 3616/7200 mean loss: 0.0016736022662371397 score: 1.0
2021-08-08 04:36:36,239 | train | INFO | Epoch 9 train batch 227/450: 3632/7200 mean loss: 0.0012720823287963867 score: 0.9889705882352942
2021-08-08 04:36:37,070 | train | INFO | Epoch 9 train batch 228/450: 3648/7200 mean loss: 0.001673643128015101 score: 1.0
2021-08-08 04:36:37,897 | train | INFO | Epoch 9 train batch 229/450: 3664/7200 mean loss: 0.0013856012374162674 score: 0.996078431372549
2021-08-08 04:36:38,715 | train | INFO | Epoch 9 train batch 230/450: 3680/7200 mean loss: 0.0015292089665308595 score: 0.9433823529411766
2021-08-08 04:36:39,484 | train | INFO | Epoch 9 train batch 231/450: 3696/7200 mean loss: 0.0014332311693578959 score: 1.0
2021-08-08 04:36:40,259 | train | INFO | Epoch 9 train batch 232/450: 3712/7200 mean loss: 0.0016199734527617693 score: 1.0
2021-08-08 04:36:41,071 | train | INFO | Epoch 9 train batch 233/450: 3728/7200 mean loss: 0.001389291137456894 score: 0.996078431372549
2021-08-08 04:36:41,907 | train | INFO | Epoch 9 train batch 234/450: 3744/7200 mean loss: 0.0015581176849082112 score: 0.996078431372549
2021-08-08 04:36:42,706 | train | INFO | Epoch 9 train batch 235/450: 3760/7200 mean loss: 0.0014127434697002172 score: 1.0
2021-08-08 04:36:43,505 | train | INFO | Epoch 9 train batch 236/450: 3776/7200 mean loss: 0.0015141671756282449 score: 0.995475113122172
2021-08-08 04:36:44,300 | train | INFO | Epoch 9 train batch 237/450: 3792/7200 mean loss: 0.0014317816821858287 score: 1.0
2021-08-08 04:36:45,126 | train | INFO | Epoch 9 train batch 238/450: 3808/7200 mean loss: 0.0014901323011144996 score: 1.0
2021-08-08 04:36:45,931 | train | INFO | Epoch 9 train batch 239/450: 3824/7200 mean loss: 0.0012861279537901282 score: 0.9963235294117647
2021-08-08 04:36:46,716 | train | INFO | Epoch 9 train batch 240/450: 3840/7200 mean loss: 0.0013856638688594103 score: 1.0
2021-08-08 04:36:47,511 | train | INFO | Epoch 9 train batch 241/450: 3856/7200 mean loss: 0.0014296001754701138 score: 0.9926470588235294
2021-08-08 04:36:48,284 | train | INFO | Epoch 9 train batch 242/450: 3872/7200 mean loss: 0.0015128063969314098 score: 1.0
2021-08-08 04:36:49,053 | train | INFO | Epoch 9 train batch 243/450: 3888/7200 mean loss: 0.0014483528211712837 score: 1.0
2021-08-08 04:36:49,860 | train | INFO | Epoch 9 train batch 244/450: 3904/7200 mean loss: 0.0015636984026059508 score: 0.9924019607843138
2021-08-08 04:36:50,640 | train | INFO | Epoch 9 train batch 245/450: 3920/7200 mean loss: 0.0014671181561425328 score: 1.0
2021-08-08 04:36:51,429 | train | INFO | Epoch 9 train batch 246/450: 3936/7200 mean loss: 0.0013930099084973335 score: 1.0
2021-08-08 04:36:52,203 | train | INFO | Epoch 9 train batch 247/450: 3952/7200 mean loss: 0.001510603935457766 score: 0.9963235294117647
2021-08-08 04:36:53,014 | train | INFO | Epoch 9 train batch 248/450: 3968/7200 mean loss: 0.0014372662408277392 score: 1.0
2021-08-08 04:36:53,796 | train | INFO | Epoch 9 train batch 249/450: 3984/7200 mean loss: 0.0012835606466978788 score: 0.996078431372549
2021-08-08 04:36:54,584 | train | INFO | Epoch 9 train batch 250/450: 4000/7200 mean loss: 0.0014859341317787766 score: 1.0
2021-08-08 04:36:55,355 | train | INFO | Epoch 9 train batch 251/450: 4016/7200 mean loss: 0.0015071071684360504 score: 1.0
2021-08-08 04:36:56,172 | train | INFO | Epoch 9 train batch 252/450: 4032/7200 mean loss: 0.0014841391239315271 score: 1.0
2021-08-08 04:36:56,973 | train | INFO | Epoch 9 train batch 253/450: 4048/7200 mean loss: 0.001578332157805562 score: 1.0
2021-08-08 04:36:57,779 | train | INFO | Epoch 9 train batch 254/450: 4064/7200 mean loss: 0.0015535358106717467 score: 1.0
2021-08-08 04:36:58,562 | train | INFO | Epoch 9 train batch 255/450: 4080/7200 mean loss: 0.0015382727142423391 score: 1.0
2021-08-08 04:36:59,382 | train | INFO | Epoch 9 train batch 256/450: 4096/7200 mean loss: 0.001593917142599821 score: 1.0
2021-08-08 04:37:00,188 | train | INFO | Epoch 9 train batch 257/450: 4112/7200 mean loss: 0.00147730833850801 score: 0.9963235294117647
2021-08-08 04:37:00,972 | train | INFO | Epoch 9 train batch 258/450: 4128/7200 mean loss: 0.0013611539034172893 score: 1.0
2021-08-08 04:37:01,744 | train | INFO | Epoch 9 train batch 259/450: 4144/7200 mean loss: 0.0015054240357130766 score: 1.0
2021-08-08 04:37:02,542 | train | INFO | Epoch 9 train batch 260/450: 4160/7200 mean loss: 0.0014791704015806317 score: 0.9963235294117647
2021-08-08 04:37:03,334 | train | INFO | Epoch 9 train batch 261/450: 4176/7200 mean loss: 0.0013717737747356296 score: 1.0
2021-08-08 04:37:04,140 | train | INFO | Epoch 9 train batch 262/450: 4192/7200 mean loss: 0.0013709986815229058 score: 0.9227941176470589
2021-08-08 04:37:04,946 | train | INFO | Epoch 9 train batch 263/450: 4208/7200 mean loss: 0.0014586234465241432 score: 1.0
2021-08-08 04:37:05,733 | train | INFO | Epoch 9 train batch 264/450: 4224/7200 mean loss: 0.0013659964315593243 score: 0.9669117647058824
2021-08-08 04:37:06,502 | train | INFO | Epoch 9 train batch 265/450: 4240/7200 mean loss: 0.0015122570330277085 score: 0.9963235294117647
2021-08-08 04:37:07,289 | train | INFO | Epoch 9 train batch 266/450: 4256/7200 mean loss: 0.001372592058032751 score: 1.0
2021-08-08 04:37:08,078 | train | INFO | Epoch 9 train batch 267/450: 4272/7200 mean loss: 0.0013147895224392414 score: 1.0
2021-08-08 04:37:08,899 | train | INFO | Epoch 9 train batch 268/450: 4288/7200 mean loss: 0.0013611490139737725 score: 1.0
2021-08-08 04:37:09,714 | train | INFO | Epoch 9 train batch 269/450: 4304/7200 mean loss: 0.0014639848377555609 score: 1.0
2021-08-08 04:37:10,495 | train | INFO | Epoch 9 train batch 270/450: 4320/7200 mean loss: 0.001691022189334035 score: 1.0
2021-08-08 04:37:11,351 | train | INFO | Epoch 9 train batch 271/450: 4336/7200 mean loss: 0.0017601350555196404 score: 1.0
2021-08-08 04:37:12,179 | train | INFO | Epoch 9 train batch 272/450: 4352/7200 mean loss: 0.0017494966741651297 score: 1.0
2021-08-08 04:37:12,964 | train | INFO | Epoch 9 train batch 273/450: 4368/7200 mean loss: 0.0016549775609746575 score: 0.9924019607843138
2021-08-08 04:37:13,752 | train | INFO | Epoch 9 train batch 274/450: 4384/7200 mean loss: 0.0017252537654712796 score: 1.0
2021-08-08 04:37:14,540 | train | INFO | Epoch 9 train batch 275/450: 4400/7200 mean loss: 0.0015712941531091928 score: 1.0
2021-08-08 04:37:15,314 | train | INFO | Epoch 9 train batch 276/450: 4416/7200 mean loss: 0.0013793202815577388 score: 0.9963235294117647
2021-08-08 04:37:16,090 | train | INFO | Epoch 9 train batch 277/450: 4432/7200 mean loss: 0.0014014869229868054 score: 0.9924019607843138
2021-08-08 04:37:16,889 | train | INFO | Epoch 9 train batch 278/450: 4448/7200 mean loss: 0.0013720294227823615 score: 0.9926470588235294
2021-08-08 04:37:17,700 | train | INFO | Epoch 9 train batch 279/450: 4464/7200 mean loss: 0.0014388255076482892 score: 0.9963235294117647
2021-08-08 04:37:18,473 | train | INFO | Epoch 9 train batch 280/450: 4480/7200 mean loss: 0.0013435373548418283 score: 1.0
2021-08-08 04:37:19,259 | train | INFO | Epoch 9 train batch 281/450: 4496/7200 mean loss: 0.0014282085467129946 score: 0.996078431372549
2021-08-08 04:37:20,035 | train | INFO | Epoch 9 train batch 282/450: 4512/7200 mean loss: 0.0015147693920880556 score: 0.9924019607843138
2021-08-08 04:37:20,836 | train | INFO | Epoch 9 train batch 283/450: 4528/7200 mean loss: 0.0014049798483029008 score: 0.9852941176470589
2021-08-08 04:37:21,647 | train | INFO | Epoch 9 train batch 284/450: 4544/7200 mean loss: 0.001445856411010027 score: 0.9963235294117647
2021-08-08 04:37:22,436 | train | INFO | Epoch 9 train batch 285/450: 4560/7200 mean loss: 0.0016300725983455777 score: 1.0
2021-08-08 04:37:23,235 | train | INFO | Epoch 9 train batch 286/450: 4576/7200 mean loss: 0.0013809642987325788 score: 1.0
2021-08-08 04:37:24,012 | train | INFO | Epoch 9 train batch 287/450: 4592/7200 mean loss: 0.0014258174924179912 score: 1.0
2021-08-08 04:37:24,795 | train | INFO | Epoch 9 train batch 288/450: 4608/7200 mean loss: 0.0013612399343401194 score: 1.0
2021-08-08 04:37:25,592 | train | INFO | Epoch 9 train batch 289/450: 4624/7200 mean loss: 0.0014966082526370883 score: 0.9889705882352942
2021-08-08 04:37:26,400 | train | INFO | Epoch 9 train batch 290/450: 4640/7200 mean loss: 0.0013926151441410184 score: 1.0
2021-08-08 04:37:27,178 | train | INFO | Epoch 9 train batch 291/450: 4656/7200 mean loss: 0.001630144426599145 score: 1.0
2021-08-08 04:37:27,965 | train | INFO | Epoch 9 train batch 292/450: 4672/7200 mean loss: 0.00163696997333318 score: 1.0
2021-08-08 04:37:28,776 | train | INFO | Epoch 9 train batch 293/450: 4688/7200 mean loss: 0.0013663116842508316 score: 1.0
2021-08-08 04:37:29,596 | train | INFO | Epoch 9 train batch 294/450: 4704/7200 mean loss: 0.0013971546432003379 score: 1.0
2021-08-08 04:37:30,401 | train | INFO | Epoch 9 train batch 295/450: 4720/7200 mean loss: 0.0014570072526112199 score: 1.0
2021-08-08 04:37:31,185 | train | INFO | Epoch 9 train batch 296/450: 4736/7200 mean loss: 0.001612004591152072 score: 0.9963235294117647
2021-08-08 04:37:31,971 | train | INFO | Epoch 9 train batch 297/450: 4752/7200 mean loss: 0.0013568861177191138 score: 1.0
2021-08-08 04:37:32,751 | train | INFO | Epoch 9 train batch 298/450: 4768/7200 mean loss: 0.0015129807870835066 score: 1.0
2021-08-08 04:37:33,554 | train | INFO | Epoch 9 train batch 299/450: 4784/7200 mean loss: 0.0015385010046884418 score: 1.0
2021-08-08 04:37:34,358 | train | INFO | Epoch 9 train batch 300/450: 4800/7200 mean loss: 0.001569579471834004 score: 0.9774509803921569
2021-08-08 04:37:35,148 | train | INFO | Epoch 9 train batch 301/450: 4816/7200 mean loss: 0.0014021580573171377 score: 1.0
2021-08-08 04:37:35,928 | train | INFO | Epoch 9 train batch 302/450: 4832/7200 mean loss: 0.0013602281687781215 score: 1.0
2021-08-08 04:37:36,741 | train | INFO | Epoch 9 train batch 303/450: 4848/7200 mean loss: 0.0013780323788523674 score: 1.0
2021-08-08 04:37:37,539 | train | INFO | Epoch 9 train batch 304/450: 4864/7200 mean loss: 0.0013897473691031337 score: 1.0
2021-08-08 04:37:38,355 | train | INFO | Epoch 9 train batch 305/450: 4880/7200 mean loss: 0.0014141566352918744 score: 0.996078431372549
2021-08-08 04:37:39,151 | train | INFO | Epoch 9 train batch 306/450: 4896/7200 mean loss: 0.0014226962812244892 score: 0.996078431372549
2021-08-08 04:37:39,955 | train | INFO | Epoch 9 train batch 307/450: 4912/7200 mean loss: 0.0014562982833012938 score: 1.0
2021-08-08 04:37:40,753 | train | INFO | Epoch 9 train batch 308/450: 4928/7200 mean loss: 0.0014853847678750753 score: 1.0
2021-08-08 04:37:41,559 | train | INFO | Epoch 9 train batch 309/450: 4944/7200 mean loss: 0.001659400062635541 score: 1.0
2021-08-08 04:37:42,357 | train | INFO | Epoch 9 train batch 310/450: 4960/7200 mean loss: 0.0017335062148049474 score: 1.0
2021-08-08 04:37:43,156 | train | INFO | Epoch 9 train batch 311/450: 4976/7200 mean loss: 0.0014199799625203013 score: 1.0
2021-08-08 04:37:43,920 | train | INFO | Epoch 9 train batch 312/450: 4992/7200 mean loss: 0.0014522999990731478 score: 1.0
2021-08-08 04:37:44,692 | train | INFO | Epoch 9 train batch 313/450: 5008/7200 mean loss: 0.001366529962979257 score: 0.996078431372549
2021-08-08 04:37:45,498 | train | INFO | Epoch 9 train batch 314/450: 5024/7200 mean loss: 0.0013530092546716332 score: 0.9963235294117647
2021-08-08 04:37:46,282 | train | INFO | Epoch 9 train batch 315/450: 5040/7200 mean loss: 0.0013944670790806413 score: 0.9887254901960785
2021-08-08 04:37:47,102 | train | INFO | Epoch 9 train batch 316/450: 5056/7200 mean loss: 0.0013338183052837849 score: 1.0
2021-08-08 04:37:47,910 | train | INFO | Epoch 9 train batch 317/450: 5072/7200 mean loss: 0.0014274234417825937 score: 1.0
2021-08-08 04:37:48,719 | train | INFO | Epoch 9 train batch 318/450: 5088/7200 mean loss: 0.001748387818224728 score: 1.0
2021-08-08 04:37:49,623 | train | INFO | Epoch 9 train batch 319/450: 5104/7200 mean loss: 0.001691513229161501 score: 1.0
2021-08-08 04:37:50,446 | train | INFO | Epoch 9 train batch 320/450: 5120/7200 mean loss: 0.001799719757400453 score: 1.0
2021-08-08 04:37:51,259 | train | INFO | Epoch 9 train batch 321/450: 5136/7200 mean loss: 0.0016120040090754628 score: 0.9889705882352942
2021-08-08 04:37:52,077 | train | INFO | Epoch 9 train batch 322/450: 5152/7200 mean loss: 0.001668401644565165 score: 1.0
2021-08-08 04:37:52,858 | train | INFO | Epoch 9 train batch 323/450: 5168/7200 mean loss: 0.0017493938794359565 score: 1.0
2021-08-08 04:37:53,636 | train | INFO | Epoch 9 train batch 324/450: 5184/7200 mean loss: 0.0015695960028097034 score: 1.0
2021-08-08 04:37:54,448 | train | INFO | Epoch 9 train batch 325/450: 5200/7200 mean loss: 0.0014628767967224121 score: 1.0
2021-08-08 04:37:55,226 | train | INFO | Epoch 9 train batch 326/450: 5216/7200 mean loss: 0.0013061115751042962 score: 1.0
2021-08-08 04:37:56,057 | train | INFO | Epoch 9 train batch 327/450: 5232/7200 mean loss: 0.0013253289507701993 score: 1.0
2021-08-08 04:37:56,857 | train | INFO | Epoch 9 train batch 328/450: 5248/7200 mean loss: 0.0014118097024038434 score: 1.0
2021-08-08 04:37:57,642 | train | INFO | Epoch 9 train batch 329/450: 5264/7200 mean loss: 0.001214645686559379 score: 1.0
2021-08-08 04:37:58,416 | train | INFO | Epoch 9 train batch 330/450: 5280/7200 mean loss: 0.001438037259504199 score: 0.9963235294117647
2021-08-08 04:37:59,239 | train | INFO | Epoch 9 train batch 331/450: 5296/7200 mean loss: 0.0013629078166559339 score: 1.0
2021-08-08 04:38:00,015 | train | INFO | Epoch 9 train batch 332/450: 5312/7200 mean loss: 0.001313746557570994 score: 1.0
2021-08-08 04:38:00,793 | train | INFO | Epoch 9 train batch 333/450: 5328/7200 mean loss: 0.0013715820387005806 score: 0.9963235294117647
2021-08-08 04:38:01,573 | train | INFO | Epoch 9 train batch 334/450: 5344/7200 mean loss: 0.0012211119756102562 score: 1.0
2021-08-08 04:38:02,378 | train | INFO | Epoch 9 train batch 335/450: 5360/7200 mean loss: 0.0014166501350700855 score: 1.0
2021-08-08 04:38:03,160 | train | INFO | Epoch 9 train batch 336/450: 5376/7200 mean loss: 0.0013139636721462011 score: 1.0
2021-08-08 04:38:03,978 | train | INFO | Epoch 9 train batch 337/450: 5392/7200 mean loss: 0.001546160550788045 score: 0.9963235294117647
2021-08-08 04:38:04,782 | train | INFO | Epoch 9 train batch 338/450: 5408/7200 mean loss: 0.001683885115198791 score: 0.9848039215686275
2021-08-08 04:38:05,558 | train | INFO | Epoch 9 train batch 339/450: 5424/7200 mean loss: 0.0015091063687577844 score: 0.996078431372549
2021-08-08 04:38:06,346 | train | INFO | Epoch 9 train batch 340/450: 5440/7200 mean loss: 0.0014816588955000043 score: 1.0
2021-08-08 04:38:07,123 | train | INFO | Epoch 9 train batch 341/450: 5456/7200 mean loss: 0.0015683913370594382 score: 0.9963235294117647
2021-08-08 04:38:07,930 | train | INFO | Epoch 9 train batch 342/450: 5472/7200 mean loss: 0.0015363632701337337 score: 0.9921568627450981
2021-08-08 04:38:08,741 | train | INFO | Epoch 9 train batch 343/450: 5488/7200 mean loss: 0.001604866934940219 score: 1.0
2021-08-08 04:38:09,523 | train | INFO | Epoch 9 train batch 344/450: 5504/7200 mean loss: 0.001689284574240446 score: 1.0
2021-08-08 04:38:10,321 | train | INFO | Epoch 9 train batch 345/450: 5520/7200 mean loss: 0.0014231051318347454 score: 1.0
2021-08-08 04:38:11,105 | train | INFO | Epoch 9 train batch 346/450: 5536/7200 mean loss: 0.001578044961206615 score: 0.9963235294117647
2021-08-08 04:38:11,893 | train | INFO | Epoch 9 train batch 347/450: 5552/7200 mean loss: 0.001661089831031859 score: 0.8894607843137255
2021-08-08 04:38:12,663 | train | INFO | Epoch 9 train batch 348/450: 5568/7200 mean loss: 0.0013476043241098523 score: 1.0
2021-08-08 04:38:13,473 | train | INFO | Epoch 9 train batch 349/450: 5584/7200 mean loss: 0.0013174292398616672 score: 1.0
2021-08-08 04:38:14,298 | train | INFO | Epoch 9 train batch 350/450: 5600/7200 mean loss: 0.0016285906312987208 score: 1.0
2021-08-08 04:38:15,131 | train | INFO | Epoch 9 train batch 351/450: 5616/7200 mean loss: 0.0015622928040102124 score: 1.0
2021-08-08 04:38:15,914 | train | INFO | Epoch 9 train batch 352/450: 5632/7200 mean loss: 0.0013220704859122634 score: 1.0
2021-08-08 04:38:16,695 | train | INFO | Epoch 9 train batch 353/450: 5648/7200 mean loss: 0.0014397823251783848 score: 1.0
2021-08-08 04:38:17,521 | train | INFO | Epoch 9 train batch 354/450: 5664/7200 mean loss: 0.0013779097935184836 score: 1.0
2021-08-08 04:38:18,322 | train | INFO | Epoch 9 train batch 355/450: 5680/7200 mean loss: 0.0014104675501585007 score: 1.0
2021-08-08 04:38:19,112 | train | INFO | Epoch 9 train batch 356/450: 5696/7200 mean loss: 0.0016533567104488611 score: 1.0
2021-08-08 04:38:19,976 | train | INFO | Epoch 9 train batch 357/450: 5712/7200 mean loss: 0.0015135589055716991 score: 1.0
2021-08-08 04:38:20,774 | train | INFO | Epoch 9 train batch 358/450: 5728/7200 mean loss: 0.0013170248130336404 score: 1.0
2021-08-08 04:38:21,573 | train | INFO | Epoch 9 train batch 359/450: 5744/7200 mean loss: 0.0014464023988693953 score: 1.0
2021-08-08 04:38:22,395 | train | INFO | Epoch 9 train batch 360/450: 5760/7200 mean loss: 0.001483230385929346 score: 1.0
2021-08-08 04:38:23,162 | train | INFO | Epoch 9 train batch 361/450: 5776/7200 mean loss: 0.001450844923965633 score: 1.0
2021-08-08 04:38:23,945 | train | INFO | Epoch 9 train batch 362/450: 5792/7200 mean loss: 0.0015377175295725465 score: 1.0
2021-08-08 04:38:24,815 | train | INFO | Epoch 9 train batch 363/450: 5808/7200 mean loss: 0.0012673892779275775 score: 0.9813725490196079
2021-08-08 04:38:25,617 | train | INFO | Epoch 9 train batch 364/450: 5824/7200 mean loss: 0.0015013591619208455 score: 1.0
2021-08-08 04:38:26,394 | train | INFO | Epoch 9 train batch 365/450: 5840/7200 mean loss: 0.0014272269327193499 score: 1.0
2021-08-08 04:38:27,206 | train | INFO | Epoch 9 train batch 366/450: 5856/7200 mean loss: 0.00159177475143224 score: 0.9889705882352942
2021-08-08 04:38:27,991 | train | INFO | Epoch 9 train batch 367/450: 5872/7200 mean loss: 0.0015057752607390285 score: 0.7941176470588235
2021-08-08 04:38:28,778 | train | INFO | Epoch 9 train batch 368/450: 5888/7200 mean loss: 0.001391394529491663 score: 1.0
2021-08-08 04:38:29,590 | train | INFO | Epoch 9 train batch 369/450: 5904/7200 mean loss: 0.001434304635040462 score: 1.0
2021-08-08 04:38:30,396 | train | INFO | Epoch 9 train batch 370/450: 5920/7200 mean loss: 0.0014706297079101205 score: 1.0
2021-08-08 04:38:31,179 | train | INFO | Epoch 9 train batch 371/450: 5936/7200 mean loss: 0.0015124029014259577 score: 0.9926470588235294
2021-08-08 04:38:31,965 | train | INFO | Epoch 9 train batch 372/450: 5952/7200 mean loss: 0.001324886572547257 score: 1.0
2021-08-08 04:38:32,750 | train | INFO | Epoch 9 train batch 373/450: 5968/7200 mean loss: 0.0016163962427526712 score: 1.0
2021-08-08 04:38:33,522 | train | INFO | Epoch 9 train batch 374/450: 5984/7200 mean loss: 0.001206562272273004 score: 0.9926470588235294
2021-08-08 04:38:34,322 | train | INFO | Epoch 9 train batch 375/450: 6000/7200 mean loss: 0.0015027648769319057 score: 0.8629578754578755
2021-08-08 04:38:35,103 | train | INFO | Epoch 9 train batch 376/450: 6016/7200 mean loss: 0.0014619966968894005 score: 1.0
2021-08-08 04:38:35,890 | train | INFO | Epoch 9 train batch 377/450: 6032/7200 mean loss: 0.001494243391789496 score: 0.9887254901960785
2021-08-08 04:38:36,664 | train | INFO | Epoch 9 train batch 378/450: 6048/7200 mean loss: 0.0013944976963102818 score: 1.0
2021-08-08 04:38:37,470 | train | INFO | Epoch 9 train batch 379/450: 6064/7200 mean loss: 0.0014746191445738077 score: 1.0
2021-08-08 04:38:38,305 | train | INFO | Epoch 9 train batch 380/450: 6080/7200 mean loss: 0.0014109632465988398 score: 1.0
2021-08-08 04:38:39,131 | train | INFO | Epoch 9 train batch 381/450: 6096/7200 mean loss: 0.0015294228214770555 score: 1.0
2021-08-08 04:38:39,912 | train | INFO | Epoch 9 train batch 382/450: 6112/7200 mean loss: 0.00137968803755939 score: 0.9887254901960785
2021-08-08 04:38:40,692 | train | INFO | Epoch 9 train batch 383/450: 6128/7200 mean loss: 0.0014089527539908886 score: 0.9889705882352942
2021-08-08 04:38:41,494 | train | INFO | Epoch 9 train batch 384/450: 6144/7200 mean loss: 0.001631001359783113 score: 1.0
2021-08-08 04:38:42,297 | train | INFO | Epoch 9 train batch 385/450: 6160/7200 mean loss: 0.0015381588600575924 score: 1.0
2021-08-08 04:38:43,096 | train | INFO | Epoch 9 train batch 386/450: 6176/7200 mean loss: 0.001626831479370594 score: 0.996078431372549
2021-08-08 04:38:43,908 | train | INFO | Epoch 9 train batch 387/450: 6192/7200 mean loss: 0.0017183746676892042 score: 1.0
2021-08-08 04:38:44,736 | train | INFO | Epoch 9 train batch 388/450: 6208/7200 mean loss: 0.00144584896042943 score: 1.0
2021-08-08 04:38:45,591 | train | INFO | Epoch 9 train batch 389/450: 6224/7200 mean loss: 0.0015654995804652572 score: 1.0
2021-08-08 04:38:46,498 | train | INFO | Epoch 9 train batch 390/450: 6240/7200 mean loss: 0.0012951201060786843 score: 1.0
2021-08-08 04:38:47,293 | train | INFO | Epoch 9 train batch 391/450: 6256/7200 mean loss: 0.0013612700859084725 score: 1.0
2021-08-08 04:38:48,094 | train | INFO | Epoch 9 train batch 392/450: 6272/7200 mean loss: 0.0012647091643884778 score: 0.996078431372549
2021-08-08 04:38:48,882 | train | INFO | Epoch 9 train batch 393/450: 6288/7200 mean loss: 0.001173084252513945 score: 1.0
2021-08-08 04:38:49,683 | train | INFO | Epoch 9 train batch 394/450: 6304/7200 mean loss: 0.0013472113059833646 score: 1.0
2021-08-08 04:38:50,457 | train | INFO | Epoch 9 train batch 395/450: 6320/7200 mean loss: 0.001451107207685709 score: 0.9850490196078432
2021-08-08 04:38:51,227 | train | INFO | Epoch 9 train batch 396/450: 6336/7200 mean loss: 0.0013302365550771356 score: 1.0
2021-08-08 04:38:51,991 | train | INFO | Epoch 9 train batch 397/450: 6352/7200 mean loss: 0.0015771138714626431 score: 1.0
2021-08-08 04:38:52,758 | train | INFO | Epoch 9 train batch 398/450: 6368/7200 mean loss: 0.001570700784213841 score: 1.0
2021-08-08 04:38:53,564 | train | INFO | Epoch 9 train batch 399/450: 6384/7200 mean loss: 0.0015702324453741312 score: 0.9924019607843138
2021-08-08 04:38:54,339 | train | INFO | Epoch 9 train batch 400/450: 6400/7200 mean loss: 0.0015804461436346173 score: 0.9963235294117647
2021-08-08 04:38:55,112 | train | INFO | Epoch 9 train batch 401/450: 6416/7200 mean loss: 0.001427098410204053 score: 1.0
2021-08-08 04:38:55,892 | train | INFO | Epoch 9 train batch 402/450: 6432/7200 mean loss: 0.0015595975564792752 score: 1.0
2021-08-08 04:38:56,672 | train | INFO | Epoch 9 train batch 403/450: 6448/7200 mean loss: 0.001581165473908186 score: 1.0
2021-08-08 04:38:57,443 | train | INFO | Epoch 9 train batch 404/450: 6464/7200 mean loss: 0.0016322120791301131 score: 1.0
2021-08-08 04:38:58,206 | train | INFO | Epoch 9 train batch 405/450: 6480/7200 mean loss: 0.0013581785606220365 score: 1.0
2021-08-08 04:38:59,017 | train | INFO | Epoch 9 train batch 406/450: 6496/7200 mean loss: 0.0015580739127472043 score: 1.0
2021-08-08 04:38:59,841 | train | INFO | Epoch 9 train batch 407/450: 6512/7200 mean loss: 0.0013948315754532814 score: 1.0
2021-08-08 04:39:00,607 | train | INFO | Epoch 9 train batch 408/450: 6528/7200 mean loss: 0.0014909282326698303 score: 0.9884803921568628
2021-08-08 04:39:01,422 | train | INFO | Epoch 9 train batch 409/450: 6544/7200 mean loss: 0.0014325763331726193 score: 1.0
2021-08-08 04:39:02,215 | train | INFO | Epoch 9 train batch 410/450: 6560/7200 mean loss: 0.0014121356653049588 score: 0.9411764705882353
2021-08-08 04:39:03,031 | train | INFO | Epoch 9 train batch 411/450: 6576/7200 mean loss: 0.0014583697775378823 score: 0.9769257703081232
2021-08-08 04:39:03,857 | train | INFO | Epoch 9 train batch 412/450: 6592/7200 mean loss: 0.0012492176610976458 score: 1.0
2021-08-08 04:39:04,667 | train | INFO | Epoch 9 train batch 413/450: 6608/7200 mean loss: 0.0014648651704192162 score: 1.0
2021-08-08 04:39:05,444 | train | INFO | Epoch 9 train batch 414/450: 6624/7200 mean loss: 0.001381299109198153 score: 1.0
2021-08-08 04:39:06,224 | train | INFO | Epoch 9 train batch 415/450: 6640/7200 mean loss: 0.0014915214851498604 score: 1.0
2021-08-08 04:39:06,994 | train | INFO | Epoch 9 train batch 416/450: 6656/7200 mean loss: 0.0014982460997998714 score: 1.0
2021-08-08 04:39:07,805 | train | INFO | Epoch 9 train batch 417/450: 6672/7200 mean loss: 0.0014471847098320723 score: 1.0
2021-08-08 04:39:08,629 | train | INFO | Epoch 9 train batch 418/450: 6688/7200 mean loss: 0.0016797418938949704 score: 0.9921568627450981
2021-08-08 04:39:09,413 | train | INFO | Epoch 9 train batch 419/450: 6704/7200 mean loss: 0.0013555176556110382 score: 0.9950980392156863
2021-08-08 04:39:10,187 | train | INFO | Epoch 9 train batch 420/450: 6720/7200 mean loss: 0.0015999575844034553 score: 1.0
2021-08-08 04:39:10,963 | train | INFO | Epoch 9 train batch 421/450: 6736/7200 mean loss: 0.0015815615188330412 score: 1.0
2021-08-08 04:39:11,747 | train | INFO | Epoch 9 train batch 422/450: 6752/7200 mean loss: 0.0015567998634651303 score: 1.0
2021-08-08 04:39:12,534 | train | INFO | Epoch 9 train batch 423/450: 6768/7200 mean loss: 0.0015470514772459865 score: 1.0
2021-08-08 04:39:13,318 | train | INFO | Epoch 9 train batch 424/450: 6784/7200 mean loss: 0.0014343478251248598 score: 1.0
2021-08-08 04:39:14,092 | train | INFO | Epoch 9 train batch 425/450: 6800/7200 mean loss: 0.001485089655034244 score: 1.0
2021-08-08 04:39:14,870 | train | INFO | Epoch 9 train batch 426/450: 6816/7200 mean loss: 0.0016278484836220741 score: 1.0
2021-08-08 04:39:15,661 | train | INFO | Epoch 9 train batch 427/450: 6832/7200 mean loss: 0.0014380166539922357 score: 1.0
2021-08-08 04:39:16,476 | train | INFO | Epoch 9 train batch 428/450: 6848/7200 mean loss: 0.0016445149667561054 score: 1.0
2021-08-08 04:39:17,256 | train | INFO | Epoch 9 train batch 429/450: 6864/7200 mean loss: 0.0016597697976976633 score: 1.0
2021-08-08 04:39:18,042 | train | INFO | Epoch 9 train batch 430/450: 6880/7200 mean loss: 0.0014689663657918572 score: 0.6458333333333333
2021-08-08 04:39:18,811 | train | INFO | Epoch 9 train batch 431/450: 6896/7200 mean loss: 0.0015928163193166256 score: 1.0
2021-08-08 04:39:19,591 | train | INFO | Epoch 9 train batch 432/450: 6912/7200 mean loss: 0.001577169168740511 score: 1.0
2021-08-08 04:39:20,541 | train | INFO | Epoch 9 train batch 433/450: 6928/7200 mean loss: 0.0017131109489127994 score: 1.0
2021-08-08 04:39:21,441 | train | INFO | Epoch 9 train batch 434/450: 6944/7200 mean loss: 0.0016323927557095885 score: 1.0
2021-08-08 04:39:22,258 | train | INFO | Epoch 9 train batch 435/450: 6960/7200 mean loss: 0.001350550795905292 score: 0.9847689075630254
2021-08-08 04:39:23,103 | train | INFO | Epoch 9 train batch 436/450: 6976/7200 mean loss: 0.00129218609072268 score: 0.996078431372549
2021-08-08 04:39:23,878 | train | INFO | Epoch 9 train batch 437/450: 6992/7200 mean loss: 0.0015595621662214398 score: 0.9963235294117647
2021-08-08 04:39:24,648 | train | INFO | Epoch 9 train batch 438/450: 7008/7200 mean loss: 0.0015153746353462338 score: 1.0
2021-08-08 04:39:25,417 | train | INFO | Epoch 9 train batch 439/450: 7024/7200 mean loss: 0.001639254973269999 score: 1.0
2021-08-08 04:39:26,184 | train | INFO | Epoch 9 train batch 440/450: 7040/7200 mean loss: 0.0017194094834849238 score: 1.0
2021-08-08 04:39:26,949 | train | INFO | Epoch 9 train batch 441/450: 7056/7200 mean loss: 0.0016596131026744843 score: 1.0
2021-08-08 04:39:27,721 | train | INFO | Epoch 9 train batch 442/450: 7072/7200 mean loss: 0.0015427892794832587 score: 0.9926470588235294
2021-08-08 04:39:28,495 | train | INFO | Epoch 9 train batch 443/450: 7088/7200 mean loss: 0.0016261644195765257 score: 1.0
2021-08-08 04:39:29,266 | train | INFO | Epoch 9 train batch 444/450: 7104/7200 mean loss: 0.0013692412758246064 score: 1.0
2021-08-08 04:39:30,045 | train | INFO | Epoch 9 train batch 445/450: 7120/7200 mean loss: 0.0013582707615569234 score: 1.0
2021-08-08 04:39:30,818 | train | INFO | Epoch 9 train batch 446/450: 7136/7200 mean loss: 0.0012688738061115146 score: 1.0
2021-08-08 04:39:31,585 | train | INFO | Epoch 9 train batch 447/450: 7152/7200 mean loss: 0.0013886785600334406 score: 1.0
2021-08-08 04:39:32,348 | train | INFO | Epoch 9 train batch 448/450: 7168/7200 mean loss: 0.0014542678836733103 score: 1.0
2021-08-08 04:39:33,112 | train | INFO | Epoch 9 train batch 449/450: 7184/7200 mean loss: 0.0014772453578189015 score: 1.0
2021-08-08 04:39:33,264 | train | INFO | Epoch 9, Train, Mean loss: 0.023578212538527116, Score: 0.9951912695147989
2021-08-08 04:39:34,683 | train | INFO | Epoch 9 validation batch 0/113: 0/1800 mean loss: 0.0010077067418023944 score: 1.0
2021-08-08 04:39:34,922 | train | INFO | Epoch 9 validation batch 1/113: 16/1800 mean loss: 0.0009941254975274205 score: 0.9963235294117647
2021-08-08 04:39:35,156 | train | INFO | Epoch 9 validation batch 2/113: 32/1800 mean loss: 0.0013057803735136986 score: 1.0
2021-08-08 04:39:35,400 | train | INFO | Epoch 9 validation batch 3/113: 48/1800 mean loss: 0.0011390066938474774 score: 1.0
2021-08-08 04:39:35,629 | train | INFO | Epoch 9 validation batch 4/113: 64/1800 mean loss: 0.0010224231518805027 score: 1.0
2021-08-08 04:39:35,860 | train | INFO | Epoch 9 validation batch 5/113: 80/1800 mean loss: 0.0010223713470622897 score: 1.0
2021-08-08 04:39:36,111 | train | INFO | Epoch 9 validation batch 6/113: 96/1800 mean loss: 0.0009523049229755998 score: 1.0
2021-08-08 04:39:36,342 | train | INFO | Epoch 9 validation batch 7/113: 112/1800 mean loss: 0.0011161655420437455 score: 1.0
2021-08-08 04:39:36,607 | train | INFO | Epoch 9 validation batch 8/113: 128/1800 mean loss: 0.0010895513696596026 score: 1.0
2021-08-08 04:39:36,858 | train | INFO | Epoch 9 validation batch 9/113: 144/1800 mean loss: 0.0010497434996068478 score: 1.0
2021-08-08 04:39:37,089 | train | INFO | Epoch 9 validation batch 10/113: 160/1800 mean loss: 0.0010801758617162704 score: 0.9816176470588235
2021-08-08 04:39:37,319 | train | INFO | Epoch 9 validation batch 11/113: 176/1800 mean loss: 0.0011150339851155877 score: 1.0
2021-08-08 04:39:37,552 | train | INFO | Epoch 9 validation batch 12/113: 192/1800 mean loss: 0.0010498937917873263 score: 1.0
2021-08-08 04:39:37,799 | train | INFO | Epoch 9 validation batch 13/113: 208/1800 mean loss: 0.0009870013454928994 score: 1.0
2021-08-08 04:39:38,061 | train | INFO | Epoch 9 validation batch 14/113: 224/1800 mean loss: 0.000911296927370131 score: 1.0
2021-08-08 04:39:38,325 | train | INFO | Epoch 9 validation batch 15/113: 240/1800 mean loss: 0.0010398718295618892 score: 1.0
2021-08-08 04:39:38,560 | train | INFO | Epoch 9 validation batch 16/113: 256/1800 mean loss: 0.0010227952152490616 score: 1.0
2021-08-08 04:39:38,813 | train | INFO | Epoch 9 validation batch 17/113: 272/1800 mean loss: 0.001153690624050796 score: 1.0
2021-08-08 04:39:39,043 | train | INFO | Epoch 9 validation batch 18/113: 288/1800 mean loss: 0.0008332720608450472 score: 1.0
2021-08-08 04:39:39,293 | train | INFO | Epoch 9 validation batch 19/113: 304/1800 mean loss: 0.0010251423809677362 score: 1.0
2021-08-08 04:39:39,533 | train | INFO | Epoch 9 validation batch 20/113: 320/1800 mean loss: 0.0011587523622438312 score: 0.9926470588235294
2021-08-08 04:39:39,783 | train | INFO | Epoch 9 validation batch 21/113: 336/1800 mean loss: 0.0009933203691616654 score: 1.0
2021-08-08 04:39:40,019 | train | INFO | Epoch 9 validation batch 22/113: 352/1800 mean loss: 0.0009973634732887149 score: 1.0
2021-08-08 04:39:40,293 | train | INFO | Epoch 9 validation batch 23/113: 368/1800 mean loss: 0.0009755437495186925 score: 1.0
2021-08-08 04:39:40,559 | train | INFO | Epoch 9 validation batch 24/113: 384/1800 mean loss: 0.0010453736176714301 score: 1.0
2021-08-08 04:39:40,790 | train | INFO | Epoch 9 validation batch 25/113: 400/1800 mean loss: 0.0011558901751413941 score: 1.0
2021-08-08 04:39:41,036 | train | INFO | Epoch 9 validation batch 26/113: 416/1800 mean loss: 0.0009053208632394671 score: 1.0
2021-08-08 04:39:41,287 | train | INFO | Epoch 9 validation batch 27/113: 432/1800 mean loss: 0.0011399505892768502 score: 1.0
2021-08-08 04:39:41,562 | train | INFO | Epoch 9 validation batch 28/113: 448/1800 mean loss: 0.0010533732129260898 score: 1.0
2021-08-08 04:39:41,808 | train | INFO | Epoch 9 validation batch 29/113: 464/1800 mean loss: 0.0010492708534002304 score: 1.0
2021-08-08 04:39:42,050 | train | INFO | Epoch 9 validation batch 30/113: 480/1800 mean loss: 0.0010249289916828275 score: 1.0
2021-08-08 04:39:42,284 | train | INFO | Epoch 9 validation batch 31/113: 496/1800 mean loss: 0.000976837007328868 score: 1.0
2021-08-08 04:39:42,515 | train | INFO | Epoch 9 validation batch 32/113: 512/1800 mean loss: 0.0010765311308205128 score: 1.0
2021-08-08 04:39:42,747 | train | INFO | Epoch 9 validation batch 33/113: 528/1800 mean loss: 0.0009369835024699569 score: 1.0
2021-08-08 04:39:42,999 | train | INFO | Epoch 9 validation batch 34/113: 544/1800 mean loss: 0.0007881600176915526 score: 1.0
2021-08-08 04:39:43,251 | train | INFO | Epoch 9 validation batch 35/113: 560/1800 mean loss: 0.0012013060040771961 score: 1.0
2021-08-08 04:39:43,483 | train | INFO | Epoch 9 validation batch 36/113: 576/1800 mean loss: 0.0011563586303964257 score: 0.9147058823529413
2021-08-08 04:39:43,729 | train | INFO | Epoch 9 validation batch 37/113: 592/1800 mean loss: 0.0008490710752084851 score: 1.0
2021-08-08 04:39:43,980 | train | INFO | Epoch 9 validation batch 38/113: 608/1800 mean loss: 0.0010757296113297343 score: 1.0
2021-08-08 04:39:44,211 | train | INFO | Epoch 9 validation batch 39/113: 624/1800 mean loss: 0.0009927013888955116 score: 1.0
2021-08-08 04:39:44,469 | train | INFO | Epoch 9 validation batch 40/113: 640/1800 mean loss: 0.0010498047340661287 score: 1.0
2021-08-08 04:39:44,701 | train | INFO | Epoch 9 validation batch 41/113: 656/1800 mean loss: 0.0009687861893326044 score: 1.0
2021-08-08 04:39:44,960 | train | INFO | Epoch 9 validation batch 42/113: 672/1800 mean loss: 0.0010046318639069796 score: 1.0
2021-08-08 04:39:45,191 | train | INFO | Epoch 9 validation batch 43/113: 688/1800 mean loss: 0.0010050027631223202 score: 1.0
2021-08-08 04:39:45,423 | train | INFO | Epoch 9 validation batch 44/113: 704/1800 mean loss: 0.001244971645064652 score: 0.9705882352941176
2021-08-08 04:39:45,653 | train | INFO | Epoch 9 validation batch 45/113: 720/1800 mean loss: 0.0010424585780128837 score: 1.0
2021-08-08 04:39:45,902 | train | INFO | Epoch 9 validation batch 46/113: 736/1800 mean loss: 0.0010416221339255571 score: 0.9926470588235294
2021-08-08 04:39:46,139 | train | INFO | Epoch 9 validation batch 47/113: 752/1800 mean loss: 0.0009597918833605945 score: 1.0
2021-08-08 04:39:46,383 | train | INFO | Epoch 9 validation batch 48/113: 768/1800 mean loss: 0.0009768983582034707 score: 1.0
2021-08-08 04:39:46,616 | train | INFO | Epoch 9 validation batch 49/113: 784/1800 mean loss: 0.0010561009403318167 score: 1.0
2021-08-08 04:39:46,870 | train | INFO | Epoch 9 validation batch 50/113: 800/1800 mean loss: 0.0009485206101089716 score: 1.0
2021-08-08 04:39:47,115 | train | INFO | Epoch 9 validation batch 51/113: 816/1800 mean loss: 0.001098140375688672 score: 0.9889705882352942
2021-08-08 04:39:47,358 | train | INFO | Epoch 9 validation batch 52/113: 832/1800 mean loss: 0.001059919479303062 score: 1.0
2021-08-08 04:39:47,601 | train | INFO | Epoch 9 validation batch 53/113: 848/1800 mean loss: 0.0009894934482872486 score: 1.0
2021-08-08 04:39:47,840 | train | INFO | Epoch 9 validation batch 54/113: 864/1800 mean loss: 0.000993278925307095 score: 1.0
2021-08-08 04:39:48,077 | train | INFO | Epoch 9 validation batch 55/113: 880/1800 mean loss: 0.0011017352808266878 score: 1.0
2021-08-08 04:39:48,331 | train | INFO | Epoch 9 validation batch 56/113: 896/1800 mean loss: 0.0010415820870548487 score: 1.0
2021-08-08 04:39:48,561 | train | INFO | Epoch 9 validation batch 57/113: 912/1800 mean loss: 0.0011158540146425366 score: 1.0
2021-08-08 04:39:48,793 | train | INFO | Epoch 9 validation batch 58/113: 928/1800 mean loss: 0.0011088434839621186 score: 0.9852941176470589
2021-08-08 04:39:49,052 | train | INFO | Epoch 9 validation batch 59/113: 944/1800 mean loss: 0.0009999537141993642 score: 1.0
2021-08-08 04:39:49,292 | train | INFO | Epoch 9 validation batch 60/113: 960/1800 mean loss: 0.0008775457972660661 score: 1.0
2021-08-08 04:39:49,522 | train | INFO | Epoch 9 validation batch 61/113: 976/1800 mean loss: 0.000955964729655534 score: 1.0
2021-08-08 04:39:49,752 | train | INFO | Epoch 9 validation batch 62/113: 992/1800 mean loss: 0.0009973922278732061 score: 1.0
2021-08-08 04:39:49,983 | train | INFO | Epoch 9 validation batch 63/113: 1008/1800 mean loss: 0.0009490242809988558 score: 1.0
2021-08-08 04:39:50,213 | train | INFO | Epoch 9 validation batch 64/113: 1024/1800 mean loss: 0.0010218824027106166 score: 1.0
2021-08-08 04:39:50,463 | train | INFO | Epoch 9 validation batch 65/113: 1040/1800 mean loss: 0.0010785675840452313 score: 1.0
2021-08-08 04:39:50,704 | train | INFO | Epoch 9 validation batch 66/113: 1056/1800 mean loss: 0.0010586866410449147 score: 1.0
2021-08-08 04:39:50,936 | train | INFO | Epoch 9 validation batch 67/113: 1072/1800 mean loss: 0.0011036075884476304 score: 1.0
2021-08-08 04:39:51,189 | train | INFO | Epoch 9 validation batch 68/113: 1088/1800 mean loss: 0.0008913314086385071 score: 1.0
2021-08-08 04:39:51,424 | train | INFO | Epoch 9 validation batch 69/113: 1104/1800 mean loss: 0.000977243180386722 score: 1.0
2021-08-08 04:39:51,673 | train | INFO | Epoch 9 validation batch 70/113: 1120/1800 mean loss: 0.0011928407475352287 score: 0.9963235294117647
2021-08-08 04:39:51,906 | train | INFO | Epoch 9 validation batch 71/113: 1136/1800 mean loss: 0.0009535348508507013 score: 1.0
2021-08-08 04:39:52,151 | train | INFO | Epoch 9 validation batch 72/113: 1152/1800 mean loss: 0.0009753100457601249 score: 1.0
2021-08-08 04:39:52,386 | train | INFO | Epoch 9 validation batch 73/113: 1168/1800 mean loss: 0.0012035903055220842 score: 1.0
2021-08-08 04:39:52,639 | train | INFO | Epoch 9 validation batch 74/113: 1184/1800 mean loss: 0.0011030624154955149 score: 1.0
2021-08-08 04:39:52,885 | train | INFO | Epoch 9 validation batch 75/113: 1200/1800 mean loss: 0.0009829687187448144 score: 1.0
2021-08-08 04:39:53,130 | train | INFO | Epoch 9 validation batch 76/113: 1216/1800 mean loss: 0.000893937423825264 score: 1.0
2021-08-08 04:39:53,397 | train | INFO | Epoch 9 validation batch 77/113: 1232/1800 mean loss: 0.0008969293558038771 score: 1.0
2021-08-08 04:39:53,628 | train | INFO | Epoch 9 validation batch 78/113: 1248/1800 mean loss: 0.000987604958936572 score: 0.9852941176470589
2021-08-08 04:39:53,867 | train | INFO | Epoch 9 validation batch 79/113: 1264/1800 mean loss: 0.0011505516013130546 score: 0.996078431372549
2021-08-08 04:39:54,108 | train | INFO | Epoch 9 validation batch 80/113: 1280/1800 mean loss: 0.0012018439592793584 score: 1.0
2021-08-08 04:39:54,364 | train | INFO | Epoch 9 validation batch 81/113: 1296/1800 mean loss: 0.0010103798704221845 score: 1.0
2021-08-08 04:39:54,612 | train | INFO | Epoch 9 validation batch 82/113: 1312/1800 mean loss: 0.0010121682425960898 score: 1.0
2021-08-08 04:39:54,880 | train | INFO | Epoch 9 validation batch 83/113: 1328/1800 mean loss: 0.0011644094483926892 score: 1.0
2021-08-08 04:39:55,160 | train | INFO | Epoch 9 validation batch 84/113: 1344/1800 mean loss: 0.0011519445106387138 score: 0.9889705882352942
2021-08-08 04:39:55,438 | train | INFO | Epoch 9 validation batch 85/113: 1360/1800 mean loss: 0.0010757050476968288 score: 1.0
2021-08-08 04:39:55,712 | train | INFO | Epoch 9 validation batch 86/113: 1376/1800 mean loss: 0.0012652021832764149 score: 1.0
2021-08-08 04:39:55,959 | train | INFO | Epoch 9 validation batch 87/113: 1392/1800 mean loss: 0.0011981816496700048 score: 1.0
2021-08-08 04:39:56,191 | train | INFO | Epoch 9 validation batch 88/113: 1408/1800 mean loss: 0.000999760115519166 score: 1.0
2021-08-08 04:39:56,430 | train | INFO | Epoch 9 validation batch 89/113: 1424/1800 mean loss: 0.0008713269489817321 score: 1.0
2021-08-08 04:39:56,699 | train | INFO | Epoch 9 validation batch 90/113: 1440/1800 mean loss: 0.0009725959389470518 score: 1.0
2021-08-08 04:39:56,969 | train | INFO | Epoch 9 validation batch 91/113: 1456/1800 mean loss: 0.0012593803694471717 score: 1.0
2021-08-08 04:39:57,233 | train | INFO | Epoch 9 validation batch 92/113: 1472/1800 mean loss: 0.0010127717396244407 score: 1.0
2021-08-08 04:39:57,474 | train | INFO | Epoch 9 validation batch 93/113: 1488/1800 mean loss: 0.001036842935718596 score: 1.0
2021-08-08 04:39:57,715 | train | INFO | Epoch 9 validation batch 94/113: 1504/1800 mean loss: 0.001009359024465084 score: 1.0
2021-08-08 04:39:57,966 | train | INFO | Epoch 9 validation batch 95/113: 1520/1800 mean loss: 0.0010896621970459819 score: 1.0
2021-08-08 04:39:58,198 | train | INFO | Epoch 9 validation batch 96/113: 1536/1800 mean loss: 0.0011138111585751176 score: 0.9963235294117647
2021-08-08 04:39:58,450 | train | INFO | Epoch 9 validation batch 97/113: 1552/1800 mean loss: 0.0010545672848820686 score: 1.0
2021-08-08 04:39:58,681 | train | INFO | Epoch 9 validation batch 98/113: 1568/1800 mean loss: 0.001037308480590582 score: 1.0
2021-08-08 04:39:58,929 | train | INFO | Epoch 9 validation batch 99/113: 1584/1800 mean loss: 0.000986294588074088 score: 1.0
2021-08-08 04:39:59,164 | train | INFO | Epoch 9 validation batch 100/113: 1600/1800 mean loss: 0.0012108237715438008 score: 1.0
2021-08-08 04:39:59,394 | train | INFO | Epoch 9 validation batch 101/113: 1616/1800 mean loss: 0.0010025643277913332 score: 1.0
2021-08-08 04:39:59,626 | train | INFO | Epoch 9 validation batch 102/113: 1632/1800 mean loss: 0.0009533996344543993 score: 1.0
2021-08-08 04:39:59,860 | train | INFO | Epoch 9 validation batch 103/113: 1648/1800 mean loss: 0.0009689598227851093 score: 1.0
2021-08-08 04:40:00,092 | train | INFO | Epoch 9 validation batch 104/113: 1664/1800 mean loss: 0.0011142549337819219 score: 1.0
2021-08-08 04:40:00,324 | train | INFO | Epoch 9 validation batch 105/113: 1680/1800 mean loss: 0.001072562881745398 score: 1.0
2021-08-08 04:40:00,557 | train | INFO | Epoch 9 validation batch 106/113: 1696/1800 mean loss: 0.0010711040813475847 score: 1.0
2021-08-08 04:40:00,789 | train | INFO | Epoch 9 validation batch 107/113: 1712/1800 mean loss: 0.0012858811533078551 score: 1.0
2021-08-08 04:40:01,021 | train | INFO | Epoch 9 validation batch 108/113: 1728/1800 mean loss: 0.0012591471895575523 score: 1.0
2021-08-08 04:40:01,252 | train | INFO | Epoch 9 validation batch 109/113: 1744/1800 mean loss: 0.0011520240223035216 score: 1.0
2021-08-08 04:40:01,485 | train | INFO | Epoch 9 validation batch 110/113: 1760/1800 mean loss: 0.0009630352142266929 score: 1.0
2021-08-08 04:40:01,716 | train | INFO | Epoch 9 validation batch 111/113: 1776/1800 mean loss: 0.0009972067782655358 score: 1.0
2021-08-08 04:40:01,880 | train | INFO | Epoch 9 validation batch 112/113: 1792/1800 mean loss: 0.0009263479732908309 score: 1.0
2021-08-08 04:40:02,049 | train | INFO | Epoch 9, Validation, Mean loss: 0.016712200218003934, Score: 0.9981042859621725
2021-08-08 04:40:02,049 | train | INFO | Write row 9
2021-08-08 04:40:04,723 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:40:04,727 | train | INFO | Update best record row 10, checkpoints 0.016932516391759952 -> 0.016712200218003934
2021-08-08 04:40:06,800 | train | INFO | Epoch 10 train batch 0/450: 0/7200 mean loss: 0.0014875689521431923 score: 1.0
2021-08-08 04:40:07,577 | train | INFO | Epoch 10 train batch 1/450: 16/7200 mean loss: 0.001509730122052133 score: 1.0
2021-08-08 04:40:08,348 | train | INFO | Epoch 10 train batch 2/450: 32/7200 mean loss: 0.0013356772251427174 score: 1.0
2021-08-08 04:40:09,187 | train | INFO | Epoch 10 train batch 3/450: 48/7200 mean loss: 0.0014600693248212337 score: 1.0
2021-08-08 04:40:09,983 | train | INFO | Epoch 10 train batch 4/450: 64/7200 mean loss: 0.0014641191810369492 score: 0.9921568627450981
2021-08-08 04:40:10,818 | train | INFO | Epoch 10 train batch 5/450: 80/7200 mean loss: 0.0013269997434690595 score: 1.0
2021-08-08 04:40:11,602 | train | INFO | Epoch 10 train batch 6/450: 96/7200 mean loss: 0.0014799967175349593 score: 1.0
2021-08-08 04:40:12,392 | train | INFO | Epoch 10 train batch 7/450: 112/7200 mean loss: 0.0014784603845328093 score: 0.7779411764705882
2021-08-08 04:40:13,184 | train | INFO | Epoch 10 train batch 8/450: 128/7200 mean loss: 0.0016526359831914306 score: 0.9963235294117647
2021-08-08 04:40:13,971 | train | INFO | Epoch 10 train batch 9/450: 144/7200 mean loss: 0.0014570682542398572 score: 1.0
2021-08-08 04:40:14,772 | train | INFO | Epoch 10 train batch 10/450: 160/7200 mean loss: 0.0016008574748411775 score: 1.0
2021-08-08 04:40:15,611 | train | INFO | Epoch 10 train batch 11/450: 176/7200 mean loss: 0.001431728946045041 score: 1.0
2021-08-08 04:40:16,395 | train | INFO | Epoch 10 train batch 12/450: 192/7200 mean loss: 0.0017219445435330272 score: 1.0
2021-08-08 04:40:17,182 | train | INFO | Epoch 10 train batch 13/450: 208/7200 mean loss: 0.001561258570291102 score: 1.0
2021-08-08 04:40:17,981 | train | INFO | Epoch 10 train batch 14/450: 224/7200 mean loss: 0.001313242595642805 score: 1.0
2021-08-08 04:40:18,753 | train | INFO | Epoch 10 train batch 15/450: 240/7200 mean loss: 0.0014269534731283784 score: 1.0
2021-08-08 04:40:19,575 | train | INFO | Epoch 10 train batch 16/450: 256/7200 mean loss: 0.0013719083508476615 score: 1.0
2021-08-08 04:40:20,372 | train | INFO | Epoch 10 train batch 17/450: 272/7200 mean loss: 0.0015667470870539546 score: 1.0
2021-08-08 04:40:21,152 | train | INFO | Epoch 10 train batch 18/450: 288/7200 mean loss: 0.0014597672270610929 score: 0.9411764705882353
2021-08-08 04:40:21,955 | train | INFO | Epoch 10 train batch 19/450: 304/7200 mean loss: 0.0014519470278173685 score: 0.996078431372549
2021-08-08 04:40:22,737 | train | INFO | Epoch 10 train batch 20/450: 320/7200 mean loss: 0.0015491633675992489 score: 1.0
2021-08-08 04:40:23,533 | train | INFO | Epoch 10 train batch 21/450: 336/7200 mean loss: 0.0016250709304586053 score: 1.0
2021-08-08 04:40:24,330 | train | INFO | Epoch 10 train batch 22/450: 352/7200 mean loss: 0.0016518435440957546 score: 1.0
2021-08-08 04:40:25,118 | train | INFO | Epoch 10 train batch 23/450: 368/7200 mean loss: 0.0014628785429522395 score: 1.0
2021-08-08 04:40:25,894 | train | INFO | Epoch 10 train batch 24/450: 384/7200 mean loss: 0.0016084741801023483 score: 1.0
2021-08-08 04:40:26,752 | train | INFO | Epoch 10 train batch 25/450: 400/7200 mean loss: 0.0015138613525778055 score: 1.0
2021-08-08 04:40:27,550 | train | INFO | Epoch 10 train batch 26/450: 416/7200 mean loss: 0.0013875035801902413 score: 1.0
2021-08-08 04:40:28,328 | train | INFO | Epoch 10 train batch 27/450: 432/7200 mean loss: 0.001606191974133253 score: 1.0
2021-08-08 04:40:29,151 | train | INFO | Epoch 10 train batch 28/450: 448/7200 mean loss: 0.001575462520122528 score: 0.9963235294117647
2021-08-08 04:40:29,956 | train | INFO | Epoch 10 train batch 29/450: 464/7200 mean loss: 0.0013300786959007382 score: 1.0
2021-08-08 04:40:30,754 | train | INFO | Epoch 10 train batch 30/450: 480/7200 mean loss: 0.0015035128453746438 score: 0.9963235294117647
2021-08-08 04:40:31,570 | train | INFO | Epoch 10 train batch 31/450: 496/7200 mean loss: 0.001338635920546949 score: 1.0
2021-08-08 04:40:32,349 | train | INFO | Epoch 10 train batch 32/450: 512/7200 mean loss: 0.0015771223697811365 score: 0.9963235294117647
2021-08-08 04:40:33,169 | train | INFO | Epoch 10 train batch 33/450: 528/7200 mean loss: 0.0013672503409907222 score: 1.0
2021-08-08 04:40:33,966 | train | INFO | Epoch 10 train batch 34/450: 544/7200 mean loss: 0.0014157296391204 score: 1.0
2021-08-08 04:40:34,800 | train | INFO | Epoch 10 train batch 35/450: 560/7200 mean loss: 0.0015305732376873493 score: 1.0
2021-08-08 04:40:35,571 | train | INFO | Epoch 10 train batch 36/450: 576/7200 mean loss: 0.0013427542289718986 score: 1.0
2021-08-08 04:40:36,343 | train | INFO | Epoch 10 train batch 37/450: 592/7200 mean loss: 0.0014808335108682513 score: 0.9963235294117647
2021-08-08 04:40:37,122 | train | INFO | Epoch 10 train batch 38/450: 608/7200 mean loss: 0.0015740750823169947 score: 1.0
2021-08-08 04:40:37,929 | train | INFO | Epoch 10 train batch 39/450: 624/7200 mean loss: 0.0015708304708823562 score: 1.0
2021-08-08 04:40:38,698 | train | INFO | Epoch 10 train batch 40/450: 640/7200 mean loss: 0.001368328114040196 score: 1.0
2021-08-08 04:40:39,502 | train | INFO | Epoch 10 train batch 41/450: 656/7200 mean loss: 0.0013265875168144703 score: 1.0
2021-08-08 04:40:40,296 | train | INFO | Epoch 10 train batch 42/450: 672/7200 mean loss: 0.0012716110795736313 score: 1.0
2021-08-08 04:40:41,091 | train | INFO | Epoch 10 train batch 43/450: 688/7200 mean loss: 0.001285948441363871 score: 1.0
2021-08-08 04:40:41,896 | train | INFO | Epoch 10 train batch 44/450: 704/7200 mean loss: 0.0015526296338066459 score: 1.0
2021-08-08 04:40:42,672 | train | INFO | Epoch 10 train batch 45/450: 720/7200 mean loss: 0.0016648204764351249 score: 1.0
2021-08-08 04:40:43,447 | train | INFO | Epoch 10 train batch 46/450: 736/7200 mean loss: 0.0014233083929866552 score: 0.9889705882352942
2021-08-08 04:40:44,231 | train | INFO | Epoch 10 train batch 47/450: 752/7200 mean loss: 0.001482269843108952 score: 1.0
2021-08-08 04:40:45,021 | train | INFO | Epoch 10 train batch 48/450: 768/7200 mean loss: 0.0014522573910653591 score: 1.0
2021-08-08 04:40:45,814 | train | INFO | Epoch 10 train batch 49/450: 784/7200 mean loss: 0.0013071926077827811 score: 1.0
2021-08-08 04:40:46,688 | train | INFO | Epoch 10 train batch 50/450: 800/7200 mean loss: 0.0012994008138775826 score: 1.0
2021-08-08 04:40:47,510 | train | INFO | Epoch 10 train batch 51/450: 816/7200 mean loss: 0.0013493304140865803 score: 1.0
2021-08-08 04:40:48,325 | train | INFO | Epoch 10 train batch 52/450: 832/7200 mean loss: 0.0014992938376963139 score: 1.0
2021-08-08 04:40:49,096 | train | INFO | Epoch 10 train batch 53/450: 848/7200 mean loss: 0.0013165383134037256 score: 0.996078431372549
2021-08-08 04:40:49,869 | train | INFO | Epoch 10 train batch 54/450: 864/7200 mean loss: 0.001455276389606297 score: 0.9845588235294118
2021-08-08 04:40:50,640 | train | INFO | Epoch 10 train batch 55/450: 880/7200 mean loss: 0.0012746984139084816 score: 0.9926470588235294
2021-08-08 04:40:51,427 | train | INFO | Epoch 10 train batch 56/450: 896/7200 mean loss: 0.001586082624271512 score: 0.9774509803921569
2021-08-08 04:40:52,233 | train | INFO | Epoch 10 train batch 57/450: 912/7200 mean loss: 0.0014536171220242977 score: 0.996078431372549
2021-08-08 04:40:53,013 | train | INFO | Epoch 10 train batch 58/450: 928/7200 mean loss: 0.0014482922852039337 score: 1.0
2021-08-08 04:40:53,791 | train | INFO | Epoch 10 train batch 59/450: 944/7200 mean loss: 0.001174239325337112 score: 1.0
2021-08-08 04:40:54,562 | train | INFO | Epoch 10 train batch 60/450: 960/7200 mean loss: 0.0015902313170954585 score: 1.0
2021-08-08 04:40:55,335 | train | INFO | Epoch 10 train batch 61/450: 976/7200 mean loss: 0.0013193960767239332 score: 1.0
2021-08-08 04:40:56,132 | train | INFO | Epoch 10 train batch 62/450: 992/7200 mean loss: 0.0016375156119465828 score: 0.9921568627450981
2021-08-08 04:40:56,904 | train | INFO | Epoch 10 train batch 63/450: 1008/7200 mean loss: 0.0013029597466811538 score: 1.0
2021-08-08 04:40:57,686 | train | INFO | Epoch 10 train batch 64/450: 1024/7200 mean loss: 0.0015518533764407039 score: 1.0
2021-08-08 04:40:58,489 | train | INFO | Epoch 10 train batch 65/450: 1040/7200 mean loss: 0.0015248536365106702 score: 1.0
2021-08-08 04:40:59,256 | train | INFO | Epoch 10 train batch 66/450: 1056/7200 mean loss: 0.0014721794286742806 score: 1.0
2021-08-08 04:41:00,075 | train | INFO | Epoch 10 train batch 67/450: 1072/7200 mean loss: 0.0015496390406042337 score: 1.0
2021-08-08 04:41:00,888 | train | INFO | Epoch 10 train batch 68/450: 1088/7200 mean loss: 0.0012957117287442088 score: 1.0
2021-08-08 04:41:01,664 | train | INFO | Epoch 10 train batch 69/450: 1104/7200 mean loss: 0.0014354989398270845 score: 1.0
2021-08-08 04:41:02,443 | train | INFO | Epoch 10 train batch 70/450: 1120/7200 mean loss: 0.0013590602902695537 score: 1.0
2021-08-08 04:41:03,361 | train | INFO | Epoch 10 train batch 71/450: 1136/7200 mean loss: 0.0014319774927571416 score: 0.996078431372549
2021-08-08 04:41:04,134 | train | INFO | Epoch 10 train batch 72/450: 1152/7200 mean loss: 0.001546306419186294 score: 0.9926470588235294
2021-08-08 04:41:04,911 | train | INFO | Epoch 10 train batch 73/450: 1168/7200 mean loss: 0.0014560127165168524 score: 1.0
2021-08-08 04:41:05,719 | train | INFO | Epoch 10 train batch 74/450: 1184/7200 mean loss: 0.0014575781533494592 score: 0.9889705882352942
2021-08-08 04:41:06,525 | train | INFO | Epoch 10 train batch 75/450: 1200/7200 mean loss: 0.0014643429312855005 score: 0.9924019607843138
2021-08-08 04:41:07,327 | train | INFO | Epoch 10 train batch 76/450: 1216/7200 mean loss: 0.0013953166780993342 score: 1.0
2021-08-08 04:41:08,121 | train | INFO | Epoch 10 train batch 77/450: 1232/7200 mean loss: 0.0013453150168061256 score: 1.0
2021-08-08 04:41:08,913 | train | INFO | Epoch 10 train batch 78/450: 1248/7200 mean loss: 0.001428385148756206 score: 1.0
2021-08-08 04:41:09,715 | train | INFO | Epoch 10 train batch 79/450: 1264/7200 mean loss: 0.001520439749583602 score: 1.0
2021-08-08 04:41:10,480 | train | INFO | Epoch 10 train batch 80/450: 1280/7200 mean loss: 0.001428308431059122 score: 1.0
2021-08-08 04:41:11,284 | train | INFO | Epoch 10 train batch 81/450: 1296/7200 mean loss: 0.0013628742890432477 score: 1.0
2021-08-08 04:41:12,073 | train | INFO | Epoch 10 train batch 82/450: 1312/7200 mean loss: 0.0012772759655490518 score: 1.0
2021-08-08 04:41:12,882 | train | INFO | Epoch 10 train batch 83/450: 1328/7200 mean loss: 0.0013083863304927945 score: 1.0
2021-08-08 04:41:13,711 | train | INFO | Epoch 10 train batch 84/450: 1344/7200 mean loss: 0.001271741115488112 score: 1.0
2021-08-08 04:41:14,504 | train | INFO | Epoch 10 train batch 85/450: 1360/7200 mean loss: 0.001244035898707807 score: 1.0
2021-08-08 04:41:15,313 | train | INFO | Epoch 10 train batch 86/450: 1376/7200 mean loss: 0.0013103379169479012 score: 1.0
2021-08-08 04:41:16,093 | train | INFO | Epoch 10 train batch 87/450: 1392/7200 mean loss: 0.001624758937396109 score: 1.0
2021-08-08 04:41:16,893 | train | INFO | Epoch 10 train batch 88/450: 1408/7200 mean loss: 0.0014159225393086672 score: 0.9963235294117647
2021-08-08 04:41:17,668 | train | INFO | Epoch 10 train batch 89/450: 1424/7200 mean loss: 0.0011161857983097434 score: 1.0
2021-08-08 04:41:18,475 | train | INFO | Epoch 10 train batch 90/450: 1440/7200 mean loss: 0.0016120485961437225 score: 0.9921568627450981
2021-08-08 04:41:19,251 | train | INFO | Epoch 10 train batch 91/450: 1456/7200 mean loss: 0.001607366488315165 score: 0.9963235294117647
2021-08-08 04:41:20,074 | train | INFO | Epoch 10 train batch 92/450: 1472/7200 mean loss: 0.0015917333075776696 score: 1.0
2021-08-08 04:41:20,899 | train | INFO | Epoch 10 train batch 93/450: 1488/7200 mean loss: 0.0014521043049171567 score: 1.0
2021-08-08 04:41:21,711 | train | INFO | Epoch 10 train batch 94/450: 1504/7200 mean loss: 0.0015420630807057023 score: 0.9666666666666667
2021-08-08 04:41:22,511 | train | INFO | Epoch 10 train batch 95/450: 1520/7200 mean loss: 0.0012712610187008977 score: 1.0
2021-08-08 04:41:23,330 | train | INFO | Epoch 10 train batch 96/450: 1536/7200 mean loss: 0.0015163300558924675 score: 1.0
2021-08-08 04:41:24,157 | train | INFO | Epoch 10 train batch 97/450: 1552/7200 mean loss: 0.0016353612300008535 score: 1.0
2021-08-08 04:41:24,972 | train | INFO | Epoch 10 train batch 98/450: 1568/7200 mean loss: 0.0012908591888844967 score: 0.898529411764706
2021-08-08 04:41:25,790 | train | INFO | Epoch 10 train batch 99/450: 1584/7200 mean loss: 0.0014002937823534012 score: 1.0
2021-08-08 04:41:26,608 | train | INFO | Epoch 10 train batch 100/450: 1600/7200 mean loss: 0.0014428659342229366 score: 1.0
2021-08-08 04:41:27,425 | train | INFO | Epoch 10 train batch 101/450: 1616/7200 mean loss: 0.001703648711554706 score: 0.9926470588235294
2021-08-08 04:41:28,286 | train | INFO | Epoch 10 train batch 102/450: 1632/7200 mean loss: 0.0015874606324359775 score: 1.0
2021-08-08 04:41:29,074 | train | INFO | Epoch 10 train batch 103/450: 1648/7200 mean loss: 0.0014250248204916716 score: 1.0
2021-08-08 04:41:29,885 | train | INFO | Epoch 10 train batch 104/450: 1664/7200 mean loss: 0.0014138935366645455 score: 1.0
2021-08-08 04:41:30,692 | train | INFO | Epoch 10 train batch 105/450: 1680/7200 mean loss: 0.0012240044306963682 score: 1.0
2021-08-08 04:41:31,461 | train | INFO | Epoch 10 train batch 106/450: 1696/7200 mean loss: 0.0013447471428662539 score: 0.9926470588235294
2021-08-08 04:41:32,226 | train | INFO | Epoch 10 train batch 107/450: 1712/7200 mean loss: 0.0013252767967060208 score: 1.0
2021-08-08 04:41:32,999 | train | INFO | Epoch 10 train batch 108/450: 1728/7200 mean loss: 0.0015650878194719553 score: 0.996078431372549
2021-08-08 04:41:33,775 | train | INFO | Epoch 10 train batch 109/450: 1744/7200 mean loss: 0.0015219689812511206 score: 1.0
2021-08-08 04:41:34,586 | train | INFO | Epoch 10 train batch 110/450: 1760/7200 mean loss: 0.0016588354483246803 score: 0.995798319327731
2021-08-08 04:41:35,373 | train | INFO | Epoch 10 train batch 111/450: 1776/7200 mean loss: 0.001682213624008 score: 1.0
2021-08-08 04:41:36,148 | train | INFO | Epoch 10 train batch 112/450: 1792/7200 mean loss: 0.0017990225460380316 score: 1.0
2021-08-08 04:41:36,929 | train | INFO | Epoch 10 train batch 113/450: 1808/7200 mean loss: 0.0016934084706008434 score: 1.0
2021-08-08 04:41:37,712 | train | INFO | Epoch 10 train batch 114/450: 1824/7200 mean loss: 0.0012924127513542771 score: 1.0
2021-08-08 04:41:38,491 | train | INFO | Epoch 10 train batch 115/450: 1840/7200 mean loss: 0.0013675165828317404 score: 1.0
2021-08-08 04:41:39,287 | train | INFO | Epoch 10 train batch 116/450: 1856/7200 mean loss: 0.0013086982071399689 score: 1.0
2021-08-08 04:41:40,143 | train | INFO | Epoch 10 train batch 117/450: 1872/7200 mean loss: 0.0015115278074517846 score: 1.0
2021-08-08 04:41:40,920 | train | INFO | Epoch 10 train batch 118/450: 1888/7200 mean loss: 0.0012962586479261518 score: 1.0
2021-08-08 04:41:41,702 | train | INFO | Epoch 10 train batch 119/450: 1904/7200 mean loss: 0.0013717609690502286 score: 1.0
2021-08-08 04:41:42,474 | train | INFO | Epoch 10 train batch 120/450: 1920/7200 mean loss: 0.0015700451331213117 score: 0.9117647058823529
2021-08-08 04:41:43,253 | train | INFO | Epoch 10 train batch 121/450: 1936/7200 mean loss: 0.0013877638848498464 score: 1.0
2021-08-08 04:41:44,052 | train | INFO | Epoch 10 train batch 122/450: 1952/7200 mean loss: 0.0014749127440154552 score: 0.9963235294117647
2021-08-08 04:41:44,858 | train | INFO | Epoch 10 train batch 123/450: 1968/7200 mean loss: 0.001326109399087727 score: 1.0
2021-08-08 04:41:45,672 | train | INFO | Epoch 10 train batch 124/450: 1984/7200 mean loss: 0.001531458692625165 score: 1.0
2021-08-08 04:41:46,516 | train | INFO | Epoch 10 train batch 125/450: 2000/7200 mean loss: 0.0016069591511040926 score: 1.0
2021-08-08 04:41:47,312 | train | INFO | Epoch 10 train batch 126/450: 2016/7200 mean loss: 0.0014301040209829807 score: 0.9926470588235294
2021-08-08 04:41:48,129 | train | INFO | Epoch 10 train batch 127/450: 2032/7200 mean loss: 0.001549405395053327 score: 1.0
2021-08-08 04:41:48,932 | train | INFO | Epoch 10 train batch 128/450: 2048/7200 mean loss: 0.0015117184957489371 score: 1.0
2021-08-08 04:41:49,728 | train | INFO | Epoch 10 train batch 129/450: 2064/7200 mean loss: 0.001380917732603848 score: 0.9850490196078432
2021-08-08 04:41:50,527 | train | INFO | Epoch 10 train batch 130/450: 2080/7200 mean loss: 0.001379308640025556 score: 1.0
2021-08-08 04:41:51,341 | train | INFO | Epoch 10 train batch 131/450: 2096/7200 mean loss: 0.0014116265811026096 score: 1.0
2021-08-08 04:41:52,131 | train | INFO | Epoch 10 train batch 132/450: 2112/7200 mean loss: 0.0013250232441350818 score: 1.0
2021-08-08 04:41:52,962 | train | INFO | Epoch 10 train batch 133/450: 2128/7200 mean loss: 0.0015780021203681827 score: 0.9963235294117647
2021-08-08 04:41:53,774 | train | INFO | Epoch 10 train batch 134/450: 2144/7200 mean loss: 0.0014705080538988113 score: 1.0
2021-08-08 04:41:54,559 | train | INFO | Epoch 10 train batch 135/450: 2160/7200 mean loss: 0.0016144895926117897 score: 1.0
2021-08-08 04:41:55,332 | train | INFO | Epoch 10 train batch 136/450: 2176/7200 mean loss: 0.0014391241129487753 score: 1.0
2021-08-08 04:41:56,129 | train | INFO | Epoch 10 train batch 137/450: 2192/7200 mean loss: 0.001442993525415659 score: 1.0
2021-08-08 04:41:56,895 | train | INFO | Epoch 10 train batch 138/450: 2208/7200 mean loss: 0.0013034611474722624 score: 0.9963235294117647
2021-08-08 04:41:57,707 | train | INFO | Epoch 10 train batch 139/450: 2224/7200 mean loss: 0.0015442554140463471 score: 1.0
2021-08-08 04:41:58,486 | train | INFO | Epoch 10 train batch 140/450: 2240/7200 mean loss: 0.0014979478437453508 score: 1.0
2021-08-08 04:41:59,319 | train | INFO | Epoch 10 train batch 141/450: 2256/7200 mean loss: 0.0014207633212208748 score: 1.0
2021-08-08 04:42:00,109 | train | INFO | Epoch 10 train batch 142/450: 2272/7200 mean loss: 0.0013774334220215678 score: 1.0
2021-08-08 04:42:00,921 | train | INFO | Epoch 10 train batch 143/450: 2288/7200 mean loss: 0.001367758959531784 score: 1.0
2021-08-08 04:42:01,727 | train | INFO | Epoch 10 train batch 144/450: 2304/7200 mean loss: 0.0014398113125935197 score: 0.996078431372549
2021-08-08 04:42:02,533 | train | INFO | Epoch 10 train batch 145/450: 2320/7200 mean loss: 0.0014773915754631162 score: 1.0
2021-08-08 04:42:03,354 | train | INFO | Epoch 10 train batch 146/450: 2336/7200 mean loss: 0.0014188999775797129 score: 1.0
2021-08-08 04:42:04,130 | train | INFO | Epoch 10 train batch 147/450: 2352/7200 mean loss: 0.0012558038579300046 score: 1.0
2021-08-08 04:42:04,934 | train | INFO | Epoch 10 train batch 148/450: 2368/7200 mean loss: 0.0013033854775130749 score: 1.0
2021-08-08 04:42:05,711 | train | INFO | Epoch 10 train batch 149/450: 2384/7200 mean loss: 0.0013275510864332318 score: 1.0
2021-08-08 04:42:06,515 | train | INFO | Epoch 10 train batch 150/450: 2400/7200 mean loss: 0.0014911460457369685 score: 1.0
2021-08-08 04:42:07,328 | train | INFO | Epoch 10 train batch 151/450: 2416/7200 mean loss: 0.0015435845125466585 score: 1.0
2021-08-08 04:42:08,124 | train | INFO | Epoch 10 train batch 152/450: 2432/7200 mean loss: 0.0016296617686748505 score: 0.9963235294117647
2021-08-08 04:42:08,928 | train | INFO | Epoch 10 train batch 153/450: 2448/7200 mean loss: 0.0015241371002048254 score: 0.996078431372549
2021-08-08 04:42:09,754 | train | INFO | Epoch 10 train batch 154/450: 2464/7200 mean loss: 0.0014621689915657043 score: 1.0
2021-08-08 04:42:10,532 | train | INFO | Epoch 10 train batch 155/450: 2480/7200 mean loss: 0.0015646462561562657 score: 1.0
2021-08-08 04:42:11,312 | train | INFO | Epoch 10 train batch 156/450: 2496/7200 mean loss: 0.001340206479653716 score: 1.0
2021-08-08 04:42:12,121 | train | INFO | Epoch 10 train batch 157/450: 2512/7200 mean loss: 0.0014499021926894784 score: 1.0
2021-08-08 04:42:12,932 | train | INFO | Epoch 10 train batch 158/450: 2528/7200 mean loss: 0.0013773294631391764 score: 1.0
2021-08-08 04:42:13,737 | train | INFO | Epoch 10 train batch 159/450: 2544/7200 mean loss: 0.0016011581756174564 score: 1.0
2021-08-08 04:42:14,517 | train | INFO | Epoch 10 train batch 160/450: 2560/7200 mean loss: 0.001609433558769524 score: 0.9889705882352942
2021-08-08 04:42:15,288 | train | INFO | Epoch 10 train batch 161/450: 2576/7200 mean loss: 0.0015795581275597215 score: 0.9963235294117647
2021-08-08 04:42:16,152 | train | INFO | Epoch 10 train batch 162/450: 2592/7200 mean loss: 0.0016454587457701564 score: 1.0
2021-08-08 04:42:16,987 | train | INFO | Epoch 10 train batch 163/450: 2608/7200 mean loss: 0.0016998990904539824 score: 1.0
2021-08-08 04:42:17,787 | train | INFO | Epoch 10 train batch 164/450: 2624/7200 mean loss: 0.0016108930576592684 score: 0.9963235294117647
2021-08-08 04:42:18,606 | train | INFO | Epoch 10 train batch 165/450: 2640/7200 mean loss: 0.0015233183512464166 score: 1.0
2021-08-08 04:42:19,436 | train | INFO | Epoch 10 train batch 166/450: 2656/7200 mean loss: 0.001423397334292531 score: 0.9963235294117647
2021-08-08 04:42:20,291 | train | INFO | Epoch 10 train batch 167/450: 2672/7200 mean loss: 0.00162084202747792 score: 1.0
2021-08-08 04:42:21,076 | train | INFO | Epoch 10 train batch 168/450: 2688/7200 mean loss: 0.001387168187648058 score: 1.0
2021-08-08 04:42:21,875 | train | INFO | Epoch 10 train batch 169/450: 2704/7200 mean loss: 0.0015298090875148773 score: 0.9963235294117647
2021-08-08 04:42:22,665 | train | INFO | Epoch 10 train batch 170/450: 2720/7200 mean loss: 0.001583239994943142 score: 1.0
2021-08-08 04:42:23,471 | train | INFO | Epoch 10 train batch 171/450: 2736/7200 mean loss: 0.0014485244173556566 score: 1.0
2021-08-08 04:42:24,275 | train | INFO | Epoch 10 train batch 172/450: 2752/7200 mean loss: 0.0014892182080075145 score: 1.0
2021-08-08 04:42:25,049 | train | INFO | Epoch 10 train batch 173/450: 2768/7200 mean loss: 0.001544235972687602 score: 1.0
2021-08-08 04:42:25,823 | train | INFO | Epoch 10 train batch 174/450: 2784/7200 mean loss: 0.0013217120431363583 score: 0.9742647058823529
2021-08-08 04:42:26,606 | train | INFO | Epoch 10 train batch 175/450: 2800/7200 mean loss: 0.0016035034786909819 score: 0.9705882352941176
2021-08-08 04:42:27,396 | train | INFO | Epoch 10 train batch 176/450: 2816/7200 mean loss: 0.0014521651901304722 score: 0.9884803921568628
2021-08-08 04:42:28,190 | train | INFO | Epoch 10 train batch 177/450: 2832/7200 mean loss: 0.0013091585133224726 score: 0.9852941176470589
2021-08-08 04:42:28,970 | train | INFO | Epoch 10 train batch 178/450: 2848/7200 mean loss: 0.001450145267881453 score: 1.0
2021-08-08 04:42:29,745 | train | INFO | Epoch 10 train batch 179/450: 2864/7200 mean loss: 0.0016682421555742621 score: 1.0
2021-08-08 04:42:30,570 | train | INFO | Epoch 10 train batch 180/450: 2880/7200 mean loss: 0.0013859700411558151 score: 1.0
2021-08-08 04:42:31,371 | train | INFO | Epoch 10 train batch 181/450: 2896/7200 mean loss: 0.0015576458536088467 score: 1.0
2021-08-08 04:42:32,184 | train | INFO | Epoch 10 train batch 182/450: 2912/7200 mean loss: 0.0015778241213411093 score: 1.0
2021-08-08 04:42:32,997 | train | INFO | Epoch 10 train batch 183/450: 2928/7200 mean loss: 0.001366843469440937 score: 1.0
2021-08-08 04:42:33,809 | train | INFO | Epoch 10 train batch 184/450: 2944/7200 mean loss: 0.0015847699251025915 score: 1.0
2021-08-08 04:42:34,618 | train | INFO | Epoch 10 train batch 185/450: 2960/7200 mean loss: 0.0013689359184354544 score: 1.0
2021-08-08 04:42:35,396 | train | INFO | Epoch 10 train batch 186/450: 2976/7200 mean loss: 0.0015341335674747825 score: 0.9485294117647058
2021-08-08 04:42:36,175 | train | INFO | Epoch 10 train batch 187/450: 2992/7200 mean loss: 0.001432465622201562 score: 0.9779411764705882
2021-08-08 04:42:36,973 | train | INFO | Epoch 10 train batch 188/450: 3008/7200 mean loss: 0.0015639838529750705 score: 1.0
2021-08-08 04:42:37,838 | train | INFO | Epoch 10 train batch 189/450: 3024/7200 mean loss: 0.0015845411689952016 score: 0.9921218487394957
2021-08-08 04:42:38,647 | train | INFO | Epoch 10 train batch 190/450: 3040/7200 mean loss: 0.001534964656457305 score: 1.0
2021-08-08 04:42:39,425 | train | INFO | Epoch 10 train batch 191/450: 3056/7200 mean loss: 0.001638150541111827 score: 0.970343137254902
2021-08-08 04:42:40,204 | train | INFO | Epoch 10 train batch 192/450: 3072/7200 mean loss: 0.0013413194101303816 score: 1.0
2021-08-08 04:42:40,973 | train | INFO | Epoch 10 train batch 193/450: 3088/7200 mean loss: 0.0012780824908986688 score: 0.9926470588235294
2021-08-08 04:42:41,777 | train | INFO | Epoch 10 train batch 194/450: 3104/7200 mean loss: 0.001355787506327033 score: 1.0
2021-08-08 04:42:42,561 | train | INFO | Epoch 10 train batch 195/450: 3120/7200 mean loss: 0.0013501300709322095 score: 1.0
2021-08-08 04:42:43,369 | train | INFO | Epoch 10 train batch 196/450: 3136/7200 mean loss: 0.001184233813546598 score: 1.0
2021-08-08 04:42:44,214 | train | INFO | Epoch 10 train batch 197/450: 3152/7200 mean loss: 0.0013402652693912387 score: 0.9963235294117647
2021-08-08 04:42:45,032 | train | INFO | Epoch 10 train batch 198/450: 3168/7200 mean loss: 0.001501040649600327 score: 1.0
2021-08-08 04:42:45,801 | train | INFO | Epoch 10 train batch 199/450: 3184/7200 mean loss: 0.0012820283882319927 score: 1.0
2021-08-08 04:42:46,606 | train | INFO | Epoch 10 train batch 200/450: 3200/7200 mean loss: 0.0014626095071434975 score: 1.0
2021-08-08 04:42:47,398 | train | INFO | Epoch 10 train batch 201/450: 3216/7200 mean loss: 0.001548226224258542 score: 1.0
2021-08-08 04:42:48,193 | train | INFO | Epoch 10 train batch 202/450: 3232/7200 mean loss: 0.0014191536465659738 score: 1.0
2021-08-08 04:42:48,967 | train | INFO | Epoch 10 train batch 203/450: 3248/7200 mean loss: 0.0016314599197357893 score: 1.0
2021-08-08 04:42:49,863 | train | INFO | Epoch 10 train batch 204/450: 3264/7200 mean loss: 0.0012566900113597512 score: 1.0
2021-08-08 04:42:50,723 | train | INFO | Epoch 10 train batch 205/450: 3280/7200 mean loss: 0.0016487255925312638 score: 1.0
2021-08-08 04:42:51,537 | train | INFO | Epoch 10 train batch 206/450: 3296/7200 mean loss: 0.001426729024387896 score: 1.0
2021-08-08 04:42:52,338 | train | INFO | Epoch 10 train batch 207/450: 3312/7200 mean loss: 0.0015791883924975991 score: 1.0
2021-08-08 04:42:53,107 | train | INFO | Epoch 10 train batch 208/450: 3328/7200 mean loss: 0.0015524476766586304 score: 0.7847015729368669
2021-08-08 04:42:53,918 | train | INFO | Epoch 10 train batch 209/450: 3344/7200 mean loss: 0.001486254041083157 score: 1.0
2021-08-08 04:42:54,722 | train | INFO | Epoch 10 train batch 210/450: 3360/7200 mean loss: 0.0015332164475694299 score: 0.9879551820728291
2021-08-08 04:42:55,549 | train | INFO | Epoch 10 train batch 211/450: 3376/7200 mean loss: 0.001695177867077291 score: 0.9848039215686275
2021-08-08 04:42:56,347 | train | INFO | Epoch 10 train batch 212/450: 3392/7200 mean loss: 0.0014904806157574058 score: 1.0
2021-08-08 04:42:57,168 | train | INFO | Epoch 10 train batch 213/450: 3408/7200 mean loss: 0.001412572804838419 score: 0.9921568627450981
2021-08-08 04:42:57,973 | train | INFO | Epoch 10 train batch 214/450: 3424/7200 mean loss: 0.0014135058736428618 score: 1.0
2021-08-08 04:42:58,781 | train | INFO | Epoch 10 train batch 215/450: 3440/7200 mean loss: 0.0014606054173782468 score: 1.0
2021-08-08 04:42:59,574 | train | INFO | Epoch 10 train batch 216/450: 3456/7200 mean loss: 0.0015399298863485456 score: 0.9963235294117647
2021-08-08 04:43:00,364 | train | INFO | Epoch 10 train batch 217/450: 3472/7200 mean loss: 0.001644989475607872 score: 0.9924019607843138
2021-08-08 04:43:01,158 | train | INFO | Epoch 10 train batch 218/450: 3488/7200 mean loss: 0.0013997785281389952 score: 1.0
2021-08-08 04:43:01,938 | train | INFO | Epoch 10 train batch 219/450: 3504/7200 mean loss: 0.0014356764731928706 score: 0.9963235294117647
2021-08-08 04:43:02,713 | train | INFO | Epoch 10 train batch 220/450: 3520/7200 mean loss: 0.0015774028142914176 score: 1.0
2021-08-08 04:43:03,579 | train | INFO | Epoch 10 train batch 221/450: 3536/7200 mean loss: 0.0016015496803447604 score: 1.0
2021-08-08 04:43:04,388 | train | INFO | Epoch 10 train batch 222/450: 3552/7200 mean loss: 0.0015318520599976182 score: 1.0
2021-08-08 04:43:05,206 | train | INFO | Epoch 10 train batch 223/450: 3568/7200 mean loss: 0.0016017395537346601 score: 1.0
2021-08-08 04:43:05,992 | train | INFO | Epoch 10 train batch 224/450: 3584/7200 mean loss: 0.0014430066803470254 score: 1.0
2021-08-08 04:43:06,765 | train | INFO | Epoch 10 train batch 225/450: 3600/7200 mean loss: 0.0012332677142694592 score: 0.9813725490196079
2021-08-08 04:43:07,548 | train | INFO | Epoch 10 train batch 226/450: 3616/7200 mean loss: 0.0014823373639956117 score: 1.0
2021-08-08 04:43:08,319 | train | INFO | Epoch 10 train batch 227/450: 3632/7200 mean loss: 0.0016019463073462248 score: 1.0
2021-08-08 04:43:09,097 | train | INFO | Epoch 10 train batch 228/450: 3648/7200 mean loss: 0.0014013885520398617 score: 0.9926470588235294
2021-08-08 04:43:09,883 | train | INFO | Epoch 10 train batch 229/450: 3664/7200 mean loss: 0.0014248230727389455 score: 1.0
2021-08-08 04:43:10,690 | train | INFO | Epoch 10 train batch 230/450: 3680/7200 mean loss: 0.00148850551340729 score: 1.0
2021-08-08 04:43:11,586 | train | INFO | Epoch 10 train batch 231/450: 3696/7200 mean loss: 0.00151313585229218 score: 1.0
2021-08-08 04:43:12,366 | train | INFO | Epoch 10 train batch 232/450: 3712/7200 mean loss: 0.0016346395714208484 score: 0.9448529411764706
2021-08-08 04:43:13,136 | train | INFO | Epoch 10 train batch 233/450: 3728/7200 mean loss: 0.0013479767367243767 score: 0.995798319327731
2021-08-08 04:43:13,919 | train | INFO | Epoch 10 train batch 234/450: 3744/7200 mean loss: 0.0013343023601919413 score: 0.9558823529411765
2021-08-08 04:43:14,685 | train | INFO | Epoch 10 train batch 235/450: 3760/7200 mean loss: 0.0013828488299623132 score: 1.0
2021-08-08 04:43:15,487 | train | INFO | Epoch 10 train batch 236/450: 3776/7200 mean loss: 0.0013541184598580003 score: 1.0
2021-08-08 04:43:16,276 | train | INFO | Epoch 10 train batch 237/450: 3792/7200 mean loss: 0.0013883638894185424 score: 1.0
2021-08-08 04:43:17,063 | train | INFO | Epoch 10 train batch 238/450: 3808/7200 mean loss: 0.001222386141307652 score: 1.0
2021-08-08 04:43:17,838 | train | INFO | Epoch 10 train batch 239/450: 3824/7200 mean loss: 0.0012054276885464787 score: 0.9957983193277312
2021-08-08 04:43:18,643 | train | INFO | Epoch 10 train batch 240/450: 3840/7200 mean loss: 0.0015465904725715518 score: 1.0
2021-08-08 04:43:19,453 | train | INFO | Epoch 10 train batch 241/450: 3856/7200 mean loss: 0.0013615192146971822 score: 1.0
2021-08-08 04:43:20,241 | train | INFO | Epoch 10 train batch 242/450: 3872/7200 mean loss: 0.00158733781427145 score: 1.0
2021-08-08 04:43:21,019 | train | INFO | Epoch 10 train batch 243/450: 3888/7200 mean loss: 0.0016167621361091733 score: 1.0
2021-08-08 04:43:21,851 | train | INFO | Epoch 10 train batch 244/450: 3904/7200 mean loss: 0.0015840993728488684 score: 0.9926470588235294
2021-08-08 04:43:22,643 | train | INFO | Epoch 10 train batch 245/450: 3920/7200 mean loss: 0.0014675687998533249 score: 0.9852941176470589
2021-08-08 04:43:23,409 | train | INFO | Epoch 10 train batch 246/450: 3936/7200 mean loss: 0.0014097659150138497 score: 0.996078431372549
2021-08-08 04:43:24,227 | train | INFO | Epoch 10 train batch 247/450: 3952/7200 mean loss: 0.0014627125347033143 score: 1.0
2021-08-08 04:43:25,057 | train | INFO | Epoch 10 train batch 248/450: 3968/7200 mean loss: 0.0014792829751968384 score: 0.9848039215686275
2021-08-08 04:43:25,834 | train | INFO | Epoch 10 train batch 249/450: 3984/7200 mean loss: 0.0017833990277722478 score: 1.0
2021-08-08 04:43:26,654 | train | INFO | Epoch 10 train batch 250/450: 4000/7200 mean loss: 0.0013123179087415338 score: 1.0
2021-08-08 04:43:27,467 | train | INFO | Epoch 10 train batch 251/450: 4016/7200 mean loss: 0.0014680182794108987 score: 1.0
2021-08-08 04:43:28,260 | train | INFO | Epoch 10 train batch 252/450: 4032/7200 mean loss: 0.0016287352191284299 score: 1.0
2021-08-08 04:43:29,043 | train | INFO | Epoch 10 train batch 253/450: 4048/7200 mean loss: 0.0015391630586236715 score: 1.0
2021-08-08 04:43:29,842 | train | INFO | Epoch 10 train batch 254/450: 4064/7200 mean loss: 0.0014560858253389597 score: 1.0
2021-08-08 04:43:30,668 | train | INFO | Epoch 10 train batch 255/450: 4080/7200 mean loss: 0.0012740864185616374 score: 1.0
2021-08-08 04:43:31,476 | train | INFO | Epoch 10 train batch 256/450: 4096/7200 mean loss: 0.001502646366134286 score: 0.9485294117647058
2021-08-08 04:43:32,277 | train | INFO | Epoch 10 train batch 257/450: 4112/7200 mean loss: 0.0015352239133790135 score: 1.0
2021-08-08 04:43:33,053 | train | INFO | Epoch 10 train batch 258/450: 4128/7200 mean loss: 0.0015108813531696796 score: 0.9926470588235294
2021-08-08 04:43:33,851 | train | INFO | Epoch 10 train batch 259/450: 4144/7200 mean loss: 0.0013813866535201669 score: 1.0
2021-08-08 04:43:34,642 | train | INFO | Epoch 10 train batch 260/450: 4160/7200 mean loss: 0.0014114158693701029 score: 1.0
2021-08-08 04:43:35,422 | train | INFO | Epoch 10 train batch 261/450: 4176/7200 mean loss: 0.0016712306533008814 score: 1.0
2021-08-08 04:43:36,203 | train | INFO | Epoch 10 train batch 262/450: 4192/7200 mean loss: 0.0013658665120601654 score: 1.0
2021-08-08 04:43:36,979 | train | INFO | Epoch 10 train batch 263/450: 4208/7200 mean loss: 0.001388681004755199 score: 1.0
2021-08-08 04:43:37,755 | train | INFO | Epoch 10 train batch 264/450: 4224/7200 mean loss: 0.001347587094642222 score: 1.0
2021-08-08 04:43:38,544 | train | INFO | Epoch 10 train batch 265/450: 4240/7200 mean loss: 0.0013461331836879253 score: 1.0
2021-08-08 04:43:39,344 | train | INFO | Epoch 10 train batch 266/450: 4256/7200 mean loss: 0.0012259718496352434 score: 0.9884803921568628
2021-08-08 04:43:40,143 | train | INFO | Epoch 10 train batch 267/450: 4272/7200 mean loss: 0.0014222526224330068 score: 0.9963235294117647
2021-08-08 04:43:41,003 | train | INFO | Epoch 10 train batch 268/450: 4288/7200 mean loss: 0.0013849755050614476 score: 1.0
2021-08-08 04:43:41,818 | train | INFO | Epoch 10 train batch 269/450: 4304/7200 mean loss: 0.0013931868597865105 score: 1.0
2021-08-08 04:43:42,625 | train | INFO | Epoch 10 train batch 270/450: 4320/7200 mean loss: 0.0017188838683068752 score: 0.9558823529411765
2021-08-08 04:43:43,434 | train | INFO | Epoch 10 train batch 271/450: 4336/7200 mean loss: 0.001451952033676207 score: 1.0
2021-08-08 04:43:44,215 | train | INFO | Epoch 10 train batch 272/450: 4352/7200 mean loss: 0.001600965391844511 score: 0.995475113122172
2021-08-08 04:43:45,080 | train | INFO | Epoch 10 train batch 273/450: 4368/7200 mean loss: 0.0016298602567985654 score: 0.9742647058823529
2021-08-08 04:43:45,870 | train | INFO | Epoch 10 train batch 274/450: 4384/7200 mean loss: 0.0014582675648853183 score: 1.0
2021-08-08 04:43:46,651 | train | INFO | Epoch 10 train batch 275/450: 4400/7200 mean loss: 0.0017603086307644844 score: 0.9963235294117647
2021-08-08 04:43:47,493 | train | INFO | Epoch 10 train batch 276/450: 4416/7200 mean loss: 0.0013911728747189045 score: 1.0
2021-08-08 04:43:48,286 | train | INFO | Epoch 10 train batch 277/450: 4432/7200 mean loss: 0.0014254509005695581 score: 1.0
2021-08-08 04:43:49,064 | train | INFO | Epoch 10 train batch 278/450: 4448/7200 mean loss: 0.0012435115640982985 score: 0.9963235294117647
2021-08-08 04:43:49,880 | train | INFO | Epoch 10 train batch 279/450: 4464/7200 mean loss: 0.001428144401870668 score: 1.0
2021-08-08 04:43:50,695 | train | INFO | Epoch 10 train batch 280/450: 4480/7200 mean loss: 0.0016720856074243784 score: 0.9816176470588235
2021-08-08 04:43:51,550 | train | INFO | Epoch 10 train batch 281/450: 4496/7200 mean loss: 0.00154412304982543 score: 0.9963235294117647
2021-08-08 04:43:52,328 | train | INFO | Epoch 10 train batch 282/450: 4512/7200 mean loss: 0.0014523460995405912 score: 0.996078431372549
2021-08-08 04:43:53,136 | train | INFO | Epoch 10 train batch 283/450: 4528/7200 mean loss: 0.0015735493507236242 score: 1.0
2021-08-08 04:43:53,947 | train | INFO | Epoch 10 train batch 284/450: 4544/7200 mean loss: 0.0015199956251308322 score: 1.0
2021-08-08 04:43:54,751 | train | INFO | Epoch 10 train batch 285/450: 4560/7200 mean loss: 0.0014398423954844475 score: 1.0
2021-08-08 04:43:55,620 | train | INFO | Epoch 10 train batch 286/450: 4576/7200 mean loss: 0.0015864766901358962 score: 1.0
2021-08-08 04:43:56,508 | train | INFO | Epoch 10 train batch 287/450: 4592/7200 mean loss: 0.0017505930736660957 score: 1.0
2021-08-08 04:43:57,294 | train | INFO | Epoch 10 train batch 288/450: 4608/7200 mean loss: 0.001588783343322575 score: 1.0
2021-08-08 04:43:58,123 | train | INFO | Epoch 10 train batch 289/450: 4624/7200 mean loss: 0.0016337737906724215 score: 1.0
2021-08-08 04:43:58,897 | train | INFO | Epoch 10 train batch 290/450: 4640/7200 mean loss: 0.001400150591507554 score: 1.0
2021-08-08 04:43:59,688 | train | INFO | Epoch 10 train batch 291/450: 4656/7200 mean loss: 0.0014936273219063878 score: 1.0
2021-08-08 04:44:00,470 | train | INFO | Epoch 10 train batch 292/450: 4672/7200 mean loss: 0.0016135427867993712 score: 1.0
2021-08-08 04:44:01,254 | train | INFO | Epoch 10 train batch 293/450: 4688/7200 mean loss: 0.0013198191300034523 score: 1.0
2021-08-08 04:44:02,062 | train | INFO | Epoch 10 train batch 294/450: 4704/7200 mean loss: 0.001260742312297225 score: 0.9889705882352942
2021-08-08 04:44:02,884 | train | INFO | Epoch 10 train batch 295/450: 4720/7200 mean loss: 0.0012789963511750102 score: 1.0
2021-08-08 04:44:03,706 | train | INFO | Epoch 10 train batch 296/450: 4736/7200 mean loss: 0.0014543301658704877 score: 1.0
2021-08-08 04:44:04,485 | train | INFO | Epoch 10 train batch 297/450: 4752/7200 mean loss: 0.00135282042901963 score: 1.0
2021-08-08 04:44:05,300 | train | INFO | Epoch 10 train batch 298/450: 4768/7200 mean loss: 0.001343361334875226 score: 0.9684873949579833
2021-08-08 04:44:06,120 | train | INFO | Epoch 10 train batch 299/450: 4784/7200 mean loss: 0.001361584523692727 score: 0.996078431372549
2021-08-08 04:44:06,920 | train | INFO | Epoch 10 train batch 300/450: 4800/7200 mean loss: 0.0014167445478960872 score: 1.0
2021-08-08 04:44:07,697 | train | INFO | Epoch 10 train batch 301/450: 4816/7200 mean loss: 0.0014476666692644358 score: 1.0
2021-08-08 04:44:08,475 | train | INFO | Epoch 10 train batch 302/450: 4832/7200 mean loss: 0.0013700092677026987 score: 1.0
2021-08-08 04:44:09,257 | train | INFO | Epoch 10 train batch 303/450: 4848/7200 mean loss: 0.0014455453492701054 score: 0.9963235294117647
2021-08-08 04:44:10,031 | train | INFO | Epoch 10 train batch 304/450: 4864/7200 mean loss: 0.0012233692687004805 score: 1.0
2021-08-08 04:44:10,800 | train | INFO | Epoch 10 train batch 305/450: 4880/7200 mean loss: 0.0015749019803479314 score: 0.9776960784313725
2021-08-08 04:44:11,569 | train | INFO | Epoch 10 train batch 306/450: 4896/7200 mean loss: 0.0015900462167337537 score: 0.9963235294117647
2021-08-08 04:44:12,348 | train | INFO | Epoch 10 train batch 307/450: 4912/7200 mean loss: 0.0013542810920625925 score: 1.0
2021-08-08 04:44:13,121 | train | INFO | Epoch 10 train batch 308/450: 4928/7200 mean loss: 0.0015167633537203074 score: 1.0
2021-08-08 04:44:13,940 | train | INFO | Epoch 10 train batch 309/450: 4944/7200 mean loss: 0.001454677083529532 score: 1.0
2021-08-08 04:44:14,757 | train | INFO | Epoch 10 train batch 310/450: 4960/7200 mean loss: 0.0015613773139193654 score: 1.0
2021-08-08 04:44:15,567 | train | INFO | Epoch 10 train batch 311/450: 4976/7200 mean loss: 0.0016443399945273995 score: 1.0
2021-08-08 04:44:16,379 | train | INFO | Epoch 10 train batch 312/450: 4992/7200 mean loss: 0.0016653150087222457 score: 0.9889705882352942
2021-08-08 04:44:17,161 | train | INFO | Epoch 10 train batch 313/450: 5008/7200 mean loss: 0.0015506348572671413 score: 0.9963235294117647
2021-08-08 04:44:17,958 | train | INFO | Epoch 10 train batch 314/450: 5024/7200 mean loss: 0.0012199648190289736 score: 0.9845238095238095
2021-08-08 04:44:18,744 | train | INFO | Epoch 10 train batch 315/450: 5040/7200 mean loss: 0.001390462159179151 score: 1.0
2021-08-08 04:44:19,558 | train | INFO | Epoch 10 train batch 316/450: 5056/7200 mean loss: 0.0013802872272208333 score: 1.0
2021-08-08 04:44:20,336 | train | INFO | Epoch 10 train batch 317/450: 5072/7200 mean loss: 0.001512186019681394 score: 0.9730392156862746
2021-08-08 04:44:21,170 | train | INFO | Epoch 10 train batch 318/450: 5088/7200 mean loss: 0.001778294681571424 score: 1.0
2021-08-08 04:44:21,960 | train | INFO | Epoch 10 train batch 319/450: 5104/7200 mean loss: 0.0015707237180322409 score: 1.0
2021-08-08 04:44:22,764 | train | INFO | Epoch 10 train batch 320/450: 5120/7200 mean loss: 0.001775928889401257 score: 1.0
2021-08-08 04:44:23,573 | train | INFO | Epoch 10 train batch 321/450: 5136/7200 mean loss: 0.0016484869411215186 score: 1.0
2021-08-08 04:44:24,353 | train | INFO | Epoch 10 train batch 322/450: 5152/7200 mean loss: 0.001715368707664311 score: 1.0
2021-08-08 04:44:25,126 | train | INFO | Epoch 10 train batch 323/450: 5168/7200 mean loss: 0.0016990097938105464 score: 1.0
2021-08-08 04:44:25,906 | train | INFO | Epoch 10 train batch 324/450: 5184/7200 mean loss: 0.001232094713486731 score: 1.0
2021-08-08 04:44:26,670 | train | INFO | Epoch 10 train batch 325/450: 5200/7200 mean loss: 0.001473275013267994 score: 1.0
2021-08-08 04:44:27,445 | train | INFO | Epoch 10 train batch 326/450: 5216/7200 mean loss: 0.001389057724736631 score: 1.0
2021-08-08 04:44:28,220 | train | INFO | Epoch 10 train batch 327/450: 5232/7200 mean loss: 0.0013589180307462811 score: 1.0
2021-08-08 04:44:28,987 | train | INFO | Epoch 10 train batch 328/450: 5248/7200 mean loss: 0.001475919154472649 score: 0.9921218487394957
2021-08-08 04:44:29,770 | train | INFO | Epoch 10 train batch 329/450: 5264/7200 mean loss: 0.0013797322753816843 score: 1.0
2021-08-08 04:44:30,560 | train | INFO | Epoch 10 train batch 330/450: 5280/7200 mean loss: 0.0013989333529025316 score: 1.0
2021-08-08 04:44:31,362 | train | INFO | Epoch 10 train batch 331/450: 5296/7200 mean loss: 0.0015222762012854218 score: 1.0
2021-08-08 04:44:32,142 | train | INFO | Epoch 10 train batch 332/450: 5312/7200 mean loss: 0.0013774593826383352 score: 1.0
2021-08-08 04:44:32,963 | train | INFO | Epoch 10 train batch 333/450: 5328/7200 mean loss: 0.0012747037690132856 score: 1.0
2021-08-08 04:44:33,772 | train | INFO | Epoch 10 train batch 334/450: 5344/7200 mean loss: 0.0013168782461434603 score: 0.9768907563025211
2021-08-08 04:44:34,581 | train | INFO | Epoch 10 train batch 335/450: 5360/7200 mean loss: 0.0013083351077511907 score: 1.0
2021-08-08 04:44:35,365 | train | INFO | Epoch 10 train batch 336/450: 5376/7200 mean loss: 0.0013781058369204402 score: 1.0
2021-08-08 04:44:36,156 | train | INFO | Epoch 10 train batch 337/450: 5392/7200 mean loss: 0.001648356905207038 score: 1.0
2021-08-08 04:44:36,934 | train | INFO | Epoch 10 train batch 338/450: 5408/7200 mean loss: 0.001459808205254376 score: 0.996078431372549
2021-08-08 04:44:37,733 | train | INFO | Epoch 10 train batch 339/450: 5424/7200 mean loss: 0.0015738019719719887 score: 0.9889705882352942
2021-08-08 04:44:38,518 | train | INFO | Epoch 10 train batch 340/450: 5440/7200 mean loss: 0.0015956503339111805 score: 0.9850490196078432
2021-08-08 04:44:39,300 | train | INFO | Epoch 10 train batch 341/450: 5456/7200 mean loss: 0.0014424558030441403 score: 1.0
2021-08-08 04:44:40,101 | train | INFO | Epoch 10 train batch 342/450: 5472/7200 mean loss: 0.001572179957292974 score: 1.0
2021-08-08 04:44:40,883 | train | INFO | Epoch 10 train batch 343/450: 5488/7200 mean loss: 0.0016381300520151854 score: 1.0
2021-08-08 04:44:41,664 | train | INFO | Epoch 10 train batch 344/450: 5504/7200 mean loss: 0.001571442699059844 score: 0.9926470588235294
2021-08-08 04:44:42,455 | train | INFO | Epoch 10 train batch 345/450: 5520/7200 mean loss: 0.001444437657482922 score: 0.995798319327731
2021-08-08 04:44:43,259 | train | INFO | Epoch 10 train batch 346/450: 5536/7200 mean loss: 0.0015683042583987117 score: 1.0
2021-08-08 04:44:44,073 | train | INFO | Epoch 10 train batch 347/450: 5552/7200 mean loss: 0.0015702444361522794 score: 0.9889705882352942
2021-08-08 04:44:44,852 | train | INFO | Epoch 10 train batch 348/450: 5568/7200 mean loss: 0.0013086932012811303 score: 0.9887254901960785
2021-08-08 04:44:45,658 | train | INFO | Epoch 10 train batch 349/450: 5584/7200 mean loss: 0.00130160350818187 score: 1.0
2021-08-08 04:44:46,434 | train | INFO | Epoch 10 train batch 350/450: 5600/7200 mean loss: 0.0014660400338470936 score: 0.9915966386554622
2021-08-08 04:44:47,254 | train | INFO | Epoch 10 train batch 351/450: 5616/7200 mean loss: 0.0013558041537180543 score: 1.0
2021-08-08 04:44:48,069 | train | INFO | Epoch 10 train batch 352/450: 5632/7200 mean loss: 0.0015602175844833255 score: 1.0
2021-08-08 04:44:48,892 | train | INFO | Epoch 10 train batch 353/450: 5648/7200 mean loss: 0.0012798351235687733 score: 1.0
2021-08-08 04:44:49,692 | train | INFO | Epoch 10 train batch 354/450: 5664/7200 mean loss: 0.0013335986295714974 score: 0.9963235294117647
2021-08-08 04:44:50,478 | train | INFO | Epoch 10 train batch 355/450: 5680/7200 mean loss: 0.0014432556927204132 score: 1.0
2021-08-08 04:44:51,246 | train | INFO | Epoch 10 train batch 356/450: 5696/7200 mean loss: 0.0014156722463667393 score: 0.6857843137254902
2021-08-08 04:44:52,017 | train | INFO | Epoch 10 train batch 357/450: 5712/7200 mean loss: 0.001468708156608045 score: 1.0
2021-08-08 04:44:52,799 | train | INFO | Epoch 10 train batch 358/450: 5728/7200 mean loss: 0.001406172988936305 score: 1.0
2021-08-08 04:44:53,569 | train | INFO | Epoch 10 train batch 359/450: 5744/7200 mean loss: 0.0015967274084687233 score: 1.0
2021-08-08 04:44:54,344 | train | INFO | Epoch 10 train batch 360/450: 5760/7200 mean loss: 0.0014879093505442142 score: 0.9742647058823529
2021-08-08 04:44:55,170 | train | INFO | Epoch 10 train batch 361/450: 5776/7200 mean loss: 0.001452954369597137 score: 1.0
2021-08-08 04:44:55,948 | train | INFO | Epoch 10 train batch 362/450: 5792/7200 mean loss: 0.0014903723495081067 score: 1.0
2021-08-08 04:44:56,745 | train | INFO | Epoch 10 train batch 363/450: 5808/7200 mean loss: 0.0015050439396873116 score: 1.0
2021-08-08 04:44:57,557 | train | INFO | Epoch 10 train batch 364/450: 5824/7200 mean loss: 0.0016081954818218946 score: 1.0
2021-08-08 04:44:58,339 | train | INFO | Epoch 10 train batch 365/450: 5840/7200 mean loss: 0.001429963274858892 score: 0.9963235294117647
2021-08-08 04:44:59,137 | train | INFO | Epoch 10 train batch 366/450: 5856/7200 mean loss: 0.001725750626064837 score: 0.9889705882352942
2021-08-08 04:44:59,922 | train | INFO | Epoch 10 train batch 367/450: 5872/7200 mean loss: 0.0013921213103458285 score: 1.0
2021-08-08 04:45:00,744 | train | INFO | Epoch 10 train batch 368/450: 5888/7200 mean loss: 0.001554494141601026 score: 1.0
2021-08-08 04:45:01,622 | train | INFO | Epoch 10 train batch 369/450: 5904/7200 mean loss: 0.001491060946136713 score: 1.0
2021-08-08 04:45:02,440 | train | INFO | Epoch 10 train batch 370/450: 5920/7200 mean loss: 0.001399765838868916 score: 1.0
2021-08-08 04:45:03,214 | train | INFO | Epoch 10 train batch 371/450: 5936/7200 mean loss: 0.001571453525684774 score: 1.0
2021-08-08 04:45:04,034 | train | INFO | Epoch 10 train batch 372/450: 5952/7200 mean loss: 0.001462060259655118 score: 0.9963235294117647
2021-08-08 04:45:04,858 | train | INFO | Epoch 10 train batch 373/450: 5968/7200 mean loss: 0.0014101372798904777 score: 1.0
2021-08-08 04:45:05,658 | train | INFO | Epoch 10 train batch 374/450: 5984/7200 mean loss: 0.0016040682094171643 score: 1.0
2021-08-08 04:45:06,442 | train | INFO | Epoch 10 train batch 375/450: 6000/7200 mean loss: 0.0013358099386096 score: 1.0
2021-08-08 04:45:07,238 | train | INFO | Epoch 10 train batch 376/450: 6016/7200 mean loss: 0.0015283499378710985 score: 1.0
2021-08-08 04:45:08,017 | train | INFO | Epoch 10 train batch 377/450: 6032/7200 mean loss: 0.0015292800962924957 score: 1.0
2021-08-08 04:45:08,797 | train | INFO | Epoch 10 train batch 378/450: 6048/7200 mean loss: 0.0014508487656712532 score: 1.0
2021-08-08 04:45:09,575 | train | INFO | Epoch 10 train batch 379/450: 6064/7200 mean loss: 0.0016360345762223005 score: 1.0
2021-08-08 04:45:10,381 | train | INFO | Epoch 10 train batch 380/450: 6080/7200 mean loss: 0.0013448507525026798 score: 1.0
2021-08-08 04:45:11,156 | train | INFO | Epoch 10 train batch 381/450: 6096/7200 mean loss: 0.0013242776039987803 score: 1.0
2021-08-08 04:45:11,936 | train | INFO | Epoch 10 train batch 382/450: 6112/7200 mean loss: 0.0015540679451078176 score: 1.0
2021-08-08 04:45:12,729 | train | INFO | Epoch 10 train batch 383/450: 6128/7200 mean loss: 0.0015461387811228633 score: 0.9737745098039216
2021-08-08 04:45:13,497 | train | INFO | Epoch 10 train batch 384/450: 6144/7200 mean loss: 0.0014943289570510387 score: 1.0
2021-08-08 04:45:14,303 | train | INFO | Epoch 10 train batch 385/450: 6160/7200 mean loss: 0.0015430898638442159 score: 1.0
2021-08-08 04:45:15,076 | train | INFO | Epoch 10 train batch 386/450: 6176/7200 mean loss: 0.0016389257507398725 score: 1.0
2021-08-08 04:45:15,865 | train | INFO | Epoch 10 train batch 387/450: 6192/7200 mean loss: 0.001515381969511509 score: 0.9963235294117647
2021-08-08 04:45:16,647 | train | INFO | Epoch 10 train batch 388/450: 6208/7200 mean loss: 0.0015531147364526987 score: 0.9963235294117647
2021-08-08 04:45:17,429 | train | INFO | Epoch 10 train batch 389/450: 6224/7200 mean loss: 0.0016480280319228768 score: 0.9887254901960785
2021-08-08 04:45:18,207 | train | INFO | Epoch 10 train batch 390/450: 6240/7200 mean loss: 0.0011450243182480335 score: 1.0
2021-08-08 04:45:19,044 | train | INFO | Epoch 10 train batch 391/450: 6256/7200 mean loss: 0.0014451578026637435 score: 1.0
2021-08-08 04:45:19,840 | train | INFO | Epoch 10 train batch 392/450: 6272/7200 mean loss: 0.0012339430395513773 score: 1.0
2021-08-08 04:45:20,618 | train | INFO | Epoch 10 train batch 393/450: 6288/7200 mean loss: 0.0013102173106744885 score: 1.0
2021-08-08 04:45:21,409 | train | INFO | Epoch 10 train batch 394/450: 6304/7200 mean loss: 0.0011399752693250775 score: 1.0
2021-08-08 04:45:22,194 | train | INFO | Epoch 10 train batch 395/450: 6320/7200 mean loss: 0.0014100297121331096 score: 1.0
2021-08-08 04:45:22,992 | train | INFO | Epoch 10 train batch 396/450: 6336/7200 mean loss: 0.0015032208757475019 score: 1.0
2021-08-08 04:45:23,769 | train | INFO | Epoch 10 train batch 397/450: 6352/7200 mean loss: 0.0014119632542133331 score: 1.0
2021-08-08 04:45:24,574 | train | INFO | Epoch 10 train batch 398/450: 6368/7200 mean loss: 0.001654003164730966 score: 1.0
2021-08-08 04:45:25,354 | train | INFO | Epoch 10 train batch 399/450: 6384/7200 mean loss: 0.0013717489782720804 score: 1.0
2021-08-08 04:45:26,182 | train | INFO | Epoch 10 train batch 400/450: 6400/7200 mean loss: 0.0014907373115420341 score: 1.0
2021-08-08 04:45:26,956 | train | INFO | Epoch 10 train batch 401/450: 6416/7200 mean loss: 0.001647982164286077 score: 1.0
2021-08-08 04:45:27,743 | train | INFO | Epoch 10 train batch 402/450: 6432/7200 mean loss: 0.001390716410242021 score: 1.0
2021-08-08 04:45:28,544 | train | INFO | Epoch 10 train batch 403/450: 6448/7200 mean loss: 0.0014361978974193335 score: 0.9852941176470589
2021-08-08 04:45:29,391 | train | INFO | Epoch 10 train batch 404/450: 6464/7200 mean loss: 0.0014185522450134158 score: 1.0
2021-08-08 04:45:30,233 | train | INFO | Epoch 10 train batch 405/450: 6480/7200 mean loss: 0.0014512758934870362 score: 1.0
2021-08-08 04:45:31,144 | train | INFO | Epoch 10 train batch 406/450: 6496/7200 mean loss: 0.0012566319201141596 score: 0.9921218487394957
2021-08-08 04:45:31,947 | train | INFO | Epoch 10 train batch 407/450: 6512/7200 mean loss: 0.0012901976006105542 score: 1.0
2021-08-08 04:45:32,745 | train | INFO | Epoch 10 train batch 408/450: 6528/7200 mean loss: 0.0013134075561538339 score: 1.0
2021-08-08 04:45:33,565 | train | INFO | Epoch 10 train batch 409/450: 6544/7200 mean loss: 0.001380326459184289 score: 1.0
2021-08-08 04:45:34,341 | train | INFO | Epoch 10 train batch 410/450: 6560/7200 mean loss: 0.0015020347200334072 score: 1.0
2021-08-08 04:45:35,110 | train | INFO | Epoch 10 train batch 411/450: 6576/7200 mean loss: 0.0013314440147951245 score: 1.0
2021-08-08 04:45:35,890 | train | INFO | Epoch 10 train batch 412/450: 6592/7200 mean loss: 0.0014246877981349826 score: 1.0
2021-08-08 04:45:36,664 | train | INFO | Epoch 10 train batch 413/450: 6608/7200 mean loss: 0.0013334633549675345 score: 0.9926470588235294
2021-08-08 04:45:37,481 | train | INFO | Epoch 10 train batch 414/450: 6624/7200 mean loss: 0.0013555720215663314 score: 1.0
2021-08-08 04:45:38,266 | train | INFO | Epoch 10 train batch 415/450: 6640/7200 mean loss: 0.0015555766876786947 score: 0.9808473389355742
2021-08-08 04:45:39,041 | train | INFO | Epoch 10 train batch 416/450: 6656/7200 mean loss: 0.0015907868510112166 score: 1.0
2021-08-08 04:45:39,813 | train | INFO | Epoch 10 train batch 417/450: 6672/7200 mean loss: 0.0012163484934717417 score: 1.0
2021-08-08 04:45:40,589 | train | INFO | Epoch 10 train batch 418/450: 6688/7200 mean loss: 0.0014725425280630589 score: 1.0
2021-08-08 04:45:41,359 | train | INFO | Epoch 10 train batch 419/450: 6704/7200 mean loss: 0.0014286667574197054 score: 0.9963235294117647
2021-08-08 04:45:42,140 | train | INFO | Epoch 10 train batch 420/450: 6720/7200 mean loss: 0.001455383957363665 score: 1.0
2021-08-08 04:45:42,920 | train | INFO | Epoch 10 train batch 421/450: 6736/7200 mean loss: 0.0013769236393272877 score: 1.0
2021-08-08 04:45:43,696 | train | INFO | Epoch 10 train batch 422/450: 6752/7200 mean loss: 0.0014294731663540006 score: 1.0
2021-08-08 04:45:44,467 | train | INFO | Epoch 10 train batch 423/450: 6768/7200 mean loss: 0.0016687808092683554 score: 0.9882002801120447
2021-08-08 04:45:45,236 | train | INFO | Epoch 10 train batch 424/450: 6784/7200 mean loss: 0.0015704750549048185 score: 0.9963235294117647
2021-08-08 04:45:46,071 | train | INFO | Epoch 10 train batch 425/450: 6800/7200 mean loss: 0.001610659877769649 score: 1.0
2021-08-08 04:45:46,875 | train | INFO | Epoch 10 train batch 426/450: 6816/7200 mean loss: 0.0015487365890294313 score: 0.8524159663865546
2021-08-08 04:45:47,653 | train | INFO | Epoch 10 train batch 427/450: 6832/7200 mean loss: 0.001584331039339304 score: 0.9556749622926094
2021-08-08 04:45:48,446 | train | INFO | Epoch 10 train batch 428/450: 6848/7200 mean loss: 0.0015263560926541686 score: 0.7649509803921568
2021-08-08 04:45:49,242 | train | INFO | Epoch 10 train batch 429/450: 6864/7200 mean loss: 0.0014228575164452195 score: 0.9926470588235294
2021-08-08 04:45:50,027 | train | INFO | Epoch 10 train batch 430/450: 6880/7200 mean loss: 0.0017364862142130733 score: 1.0
2021-08-08 04:45:50,809 | train | INFO | Epoch 10 train batch 431/450: 6896/7200 mean loss: 0.0015007923357188702 score: 1.0
2021-08-08 04:45:51,642 | train | INFO | Epoch 10 train batch 432/450: 6912/7200 mean loss: 0.0015284959226846695 score: 1.0
2021-08-08 04:45:52,442 | train | INFO | Epoch 10 train batch 433/450: 6928/7200 mean loss: 0.0014731920091435313 score: 1.0
2021-08-08 04:45:53,226 | train | INFO | Epoch 10 train batch 434/450: 6944/7200 mean loss: 0.0014431242598220706 score: 0.9666666666666667
2021-08-08 04:45:54,000 | train | INFO | Epoch 10 train batch 435/450: 6960/7200 mean loss: 0.0015225739916786551 score: 1.0
2021-08-08 04:45:54,792 | train | INFO | Epoch 10 train batch 436/450: 6976/7200 mean loss: 0.001560137839987874 score: 1.0
2021-08-08 04:45:55,567 | train | INFO | Epoch 10 train batch 437/450: 6992/7200 mean loss: 0.0014326066011562943 score: 0.9887254901960785
2021-08-08 04:45:56,340 | train | INFO | Epoch 10 train batch 438/450: 7008/7200 mean loss: 0.0016388255171477795 score: 0.996078431372549
2021-08-08 04:45:57,115 | train | INFO | Epoch 10 train batch 439/450: 7024/7200 mean loss: 0.0016878843307495117 score: 1.0
2021-08-08 04:45:57,883 | train | INFO | Epoch 10 train batch 440/450: 7040/7200 mean loss: 0.0014546951279044151 score: 1.0
2021-08-08 04:45:58,659 | train | INFO | Epoch 10 train batch 441/450: 7056/7200 mean loss: 0.0016014600405469537 score: 0.9926470588235294
2021-08-08 04:45:59,434 | train | INFO | Epoch 10 train batch 442/450: 7072/7200 mean loss: 0.0017107721650972962 score: 0.9924019607843138
2021-08-08 04:46:00,208 | train | INFO | Epoch 10 train batch 443/450: 7088/7200 mean loss: 0.0014467175351455808 score: 1.0
2021-08-08 04:46:00,973 | train | INFO | Epoch 10 train batch 444/450: 7104/7200 mean loss: 0.0013497020117938519 score: 1.0
2021-08-08 04:46:01,741 | train | INFO | Epoch 10 train batch 445/450: 7120/7200 mean loss: 0.0013757634442299604 score: 1.0
2021-08-08 04:46:02,518 | train | INFO | Epoch 10 train batch 446/450: 7136/7200 mean loss: 0.0014962840359658003 score: 0.9669117647058824
2021-08-08 04:46:03,301 | train | INFO | Epoch 10 train batch 447/450: 7152/7200 mean loss: 0.0014547950122505426 score: 1.0
2021-08-08 04:46:04,064 | train | INFO | Epoch 10 train batch 448/450: 7168/7200 mean loss: 0.001474828808568418 score: 0.9924019607843138
2021-08-08 04:46:04,826 | train | INFO | Epoch 10 train batch 449/450: 7184/7200 mean loss: 0.001566113904118538 score: 1.0
2021-08-08 04:46:04,976 | train | INFO | Epoch 10, Train, Mean loss: 0.023484400250017645, Score: 0.9937333429098135
2021-08-08 04:46:06,394 | train | INFO | Epoch 10 validation batch 0/113: 0/1800 mean loss: 0.0009876831900328398 score: 1.0
2021-08-08 04:46:06,637 | train | INFO | Epoch 10 validation batch 1/113: 16/1800 mean loss: 0.001018053269945085 score: 0.9963235294117647
2021-08-08 04:46:06,870 | train | INFO | Epoch 10 validation batch 2/113: 32/1800 mean loss: 0.0012979349121451378 score: 1.0
2021-08-08 04:46:07,115 | train | INFO | Epoch 10 validation batch 3/113: 48/1800 mean loss: 0.0011118201073259115 score: 1.0
2021-08-08 04:46:07,350 | train | INFO | Epoch 10 validation batch 4/113: 64/1800 mean loss: 0.001016511581838131 score: 1.0
2021-08-08 04:46:07,580 | train | INFO | Epoch 10 validation batch 5/113: 80/1800 mean loss: 0.0010081478394567966 score: 1.0
2021-08-08 04:46:07,812 | train | INFO | Epoch 10 validation batch 6/113: 96/1800 mean loss: 0.0009471081430092454 score: 1.0
2021-08-08 04:46:08,042 | train | INFO | Epoch 10 validation batch 7/113: 112/1800 mean loss: 0.0011053323978558183 score: 1.0
2021-08-08 04:46:08,272 | train | INFO | Epoch 10 validation batch 8/113: 128/1800 mean loss: 0.00106556317768991 score: 1.0
2021-08-08 04:46:08,506 | train | INFO | Epoch 10 validation batch 9/113: 144/1800 mean loss: 0.0010507620172575116 score: 1.0
2021-08-08 04:46:08,738 | train | INFO | Epoch 10 validation batch 10/113: 160/1800 mean loss: 0.0011227737413719296 score: 0.9816176470588235
2021-08-08 04:46:08,970 | train | INFO | Epoch 10 validation batch 11/113: 176/1800 mean loss: 0.0011067577870562673 score: 0.9963235294117647
2021-08-08 04:46:09,229 | train | INFO | Epoch 10 validation batch 12/113: 192/1800 mean loss: 0.00103752629365772 score: 1.0
2021-08-08 04:46:09,476 | train | INFO | Epoch 10 validation batch 13/113: 208/1800 mean loss: 0.0009763358975760639 score: 1.0
2021-08-08 04:46:09,708 | train | INFO | Epoch 10 validation batch 14/113: 224/1800 mean loss: 0.0009019669960252941 score: 1.0
2021-08-08 04:46:09,958 | train | INFO | Epoch 10 validation batch 15/113: 240/1800 mean loss: 0.0010345433838665485 score: 1.0
2021-08-08 04:46:10,214 | train | INFO | Epoch 10 validation batch 16/113: 256/1800 mean loss: 0.0010232278145849705 score: 1.0
2021-08-08 04:46:10,446 | train | INFO | Epoch 10 validation batch 17/113: 272/1800 mean loss: 0.0011356307659298182 score: 1.0
2021-08-08 04:46:10,701 | train | INFO | Epoch 10 validation batch 18/113: 288/1800 mean loss: 0.0008288875105790794 score: 1.0
2021-08-08 04:46:10,932 | train | INFO | Epoch 10 validation batch 19/113: 304/1800 mean loss: 0.0010271962964907289 score: 1.0
2021-08-08 04:46:11,198 | train | INFO | Epoch 10 validation batch 20/113: 320/1800 mean loss: 0.001130150631070137 score: 0.9887254901960785
2021-08-08 04:46:11,459 | train | INFO | Epoch 10 validation batch 21/113: 336/1800 mean loss: 0.0009900230215862393 score: 1.0
2021-08-08 04:46:11,712 | train | INFO | Epoch 10 validation batch 22/113: 352/1800 mean loss: 0.0009889000793918967 score: 1.0
2021-08-08 04:46:11,946 | train | INFO | Epoch 10 validation batch 23/113: 368/1800 mean loss: 0.0009673318709246814 score: 1.0
2021-08-08 04:46:12,180 | train | INFO | Epoch 10 validation batch 24/113: 384/1800 mean loss: 0.0010425527580082417 score: 1.0
2021-08-08 04:46:12,413 | train | INFO | Epoch 10 validation batch 25/113: 400/1800 mean loss: 0.0011398573406040668 score: 1.0
2021-08-08 04:46:12,645 | train | INFO | Epoch 10 validation batch 26/113: 416/1800 mean loss: 0.00089077785378322 score: 1.0
2021-08-08 04:46:12,907 | train | INFO | Epoch 10 validation batch 27/113: 432/1800 mean loss: 0.0011250259121879935 score: 1.0
2021-08-08 04:46:13,161 | train | INFO | Epoch 10 validation batch 28/113: 448/1800 mean loss: 0.0010372158139944077 score: 1.0
2021-08-08 04:46:13,419 | train | INFO | Epoch 10 validation batch 29/113: 464/1800 mean loss: 0.0010319885332137346 score: 1.0
2021-08-08 04:46:13,682 | train | INFO | Epoch 10 validation batch 30/113: 480/1800 mean loss: 0.0010149626759812236 score: 1.0
2021-08-08 04:46:13,915 | train | INFO | Epoch 10 validation batch 31/113: 496/1800 mean loss: 0.0009754013153724372 score: 1.0
2021-08-08 04:46:14,147 | train | INFO | Epoch 10 validation batch 32/113: 512/1800 mean loss: 0.0010584561387076974 score: 1.0
2021-08-08 04:46:14,383 | train | INFO | Epoch 10 validation batch 33/113: 528/1800 mean loss: 0.0009174513397738338 score: 1.0
2021-08-08 04:46:14,615 | train | INFO | Epoch 10 validation batch 34/113: 544/1800 mean loss: 0.0007910570711828768 score: 1.0
2021-08-08 04:46:14,857 | train | INFO | Epoch 10 validation batch 35/113: 560/1800 mean loss: 0.0011860218364745378 score: 1.0
2021-08-08 04:46:15,105 | train | INFO | Epoch 10 validation batch 36/113: 576/1800 mean loss: 0.0011679987655952573 score: 0.9330882352941177
2021-08-08 04:46:15,359 | train | INFO | Epoch 10 validation batch 37/113: 592/1800 mean loss: 0.0008547953912056983 score: 1.0
2021-08-08 04:46:15,609 | train | INFO | Epoch 10 validation batch 38/113: 608/1800 mean loss: 0.0010640352265909314 score: 1.0
2021-08-08 04:46:15,851 | train | INFO | Epoch 10 validation batch 39/113: 624/1800 mean loss: 0.000995180569589138 score: 1.0
2021-08-08 04:46:16,097 | train | INFO | Epoch 10 validation batch 40/113: 640/1800 mean loss: 0.0010472972644492984 score: 1.0
2021-08-08 04:46:16,327 | train | INFO | Epoch 10 validation batch 41/113: 656/1800 mean loss: 0.0009620979544706643 score: 1.0
2021-08-08 04:46:16,559 | train | INFO | Epoch 10 validation batch 42/113: 672/1800 mean loss: 0.0009856304386630654 score: 1.0
2021-08-08 04:46:16,790 | train | INFO | Epoch 10 validation batch 43/113: 688/1800 mean loss: 0.000991173554211855 score: 1.0
2021-08-08 04:46:17,022 | train | INFO | Epoch 10 validation batch 44/113: 704/1800 mean loss: 0.0012650109129026532 score: 0.9742647058823529
2021-08-08 04:46:17,253 | train | INFO | Epoch 10 validation batch 45/113: 720/1800 mean loss: 0.0010533208260312676 score: 1.0
2021-08-08 04:46:17,486 | train | INFO | Epoch 10 validation batch 46/113: 736/1800 mean loss: 0.0010487142717465758 score: 0.9926470588235294
2021-08-08 04:46:17,721 | train | INFO | Epoch 10 validation batch 47/113: 752/1800 mean loss: 0.0009494316764175892 score: 1.0
2021-08-08 04:46:17,967 | train | INFO | Epoch 10 validation batch 48/113: 768/1800 mean loss: 0.0009704450494609773 score: 1.0
2021-08-08 04:46:18,201 | train | INFO | Epoch 10 validation batch 49/113: 784/1800 mean loss: 0.00106098095420748 score: 1.0
2021-08-08 04:46:18,439 | train | INFO | Epoch 10 validation batch 50/113: 800/1800 mean loss: 0.0009445302421227098 score: 1.0
2021-08-08 04:46:18,708 | train | INFO | Epoch 10 validation batch 51/113: 816/1800 mean loss: 0.0010910227429121733 score: 0.9889705882352942
2021-08-08 04:46:18,941 | train | INFO | Epoch 10 validation batch 52/113: 832/1800 mean loss: 0.0010214332723990083 score: 1.0
2021-08-08 04:46:19,172 | train | INFO | Epoch 10 validation batch 53/113: 848/1800 mean loss: 0.0009638455812819302 score: 1.0
2021-08-08 04:46:19,418 | train | INFO | Epoch 10 validation batch 54/113: 864/1800 mean loss: 0.0009727036231197417 score: 1.0
2021-08-08 04:46:19,649 | train | INFO | Epoch 10 validation batch 55/113: 880/1800 mean loss: 0.001082576927728951 score: 1.0
2021-08-08 04:46:19,944 | train | INFO | Epoch 10 validation batch 56/113: 896/1800 mean loss: 0.0010449020192027092 score: 1.0
2021-08-08 04:46:20,176 | train | INFO | Epoch 10 validation batch 57/113: 912/1800 mean loss: 0.0010842803167179227 score: 1.0
2021-08-08 04:46:20,452 | train | INFO | Epoch 10 validation batch 58/113: 928/1800 mean loss: 0.0011052807094529271 score: 0.9779411764705882
2021-08-08 04:46:20,686 | train | INFO | Epoch 10 validation batch 59/113: 944/1800 mean loss: 0.0009916932322084904 score: 1.0
2021-08-08 04:46:20,931 | train | INFO | Epoch 10 validation batch 60/113: 960/1800 mean loss: 0.0008657710277475417 score: 1.0
2021-08-08 04:46:21,171 | train | INFO | Epoch 10 validation batch 61/113: 976/1800 mean loss: 0.0009349836618639529 score: 1.0
2021-08-08 04:46:21,420 | train | INFO | Epoch 10 validation batch 62/113: 992/1800 mean loss: 0.000986639759503305 score: 1.0
2021-08-08 04:46:21,651 | train | INFO | Epoch 10 validation batch 63/113: 1008/1800 mean loss: 0.000944974017329514 score: 1.0
2021-08-08 04:46:21,913 | train | INFO | Epoch 10 validation batch 64/113: 1024/1800 mean loss: 0.0010150957386940718 score: 1.0
2021-08-08 04:46:22,164 | train | INFO | Epoch 10 validation batch 65/113: 1040/1800 mean loss: 0.0010698474943637848 score: 1.0
2021-08-08 04:46:22,462 | train | INFO | Epoch 10 validation batch 66/113: 1056/1800 mean loss: 0.0010362931061536074 score: 1.0
2021-08-08 04:46:22,731 | train | INFO | Epoch 10 validation batch 67/113: 1072/1800 mean loss: 0.0010910476557910442 score: 1.0
2021-08-08 04:46:23,004 | train | INFO | Epoch 10 validation batch 68/113: 1088/1800 mean loss: 0.0008786876569502056 score: 1.0
2021-08-08 04:46:23,236 | train | INFO | Epoch 10 validation batch 69/113: 1104/1800 mean loss: 0.000981479766778648 score: 1.0
2021-08-08 04:46:23,495 | train | INFO | Epoch 10 validation batch 70/113: 1120/1800 mean loss: 0.0011542970314621925 score: 0.9963235294117647
2021-08-08 04:46:23,727 | train | INFO | Epoch 10 validation batch 71/113: 1136/1800 mean loss: 0.0009582066559232771 score: 1.0
2021-08-08 04:46:23,969 | train | INFO | Epoch 10 validation batch 72/113: 1152/1800 mean loss: 0.0009749666787683964 score: 1.0
2021-08-08 04:46:24,199 | train | INFO | Epoch 10 validation batch 73/113: 1168/1800 mean loss: 0.0011844129767268896 score: 1.0
2021-08-08 04:46:24,459 | train | INFO | Epoch 10 validation batch 74/113: 1184/1800 mean loss: 0.0010933118173852563 score: 1.0
2021-08-08 04:46:24,718 | train | INFO | Epoch 10 validation batch 75/113: 1200/1800 mean loss: 0.0009739219094626606 score: 1.0
2021-08-08 04:46:24,950 | train | INFO | Epoch 10 validation batch 76/113: 1216/1800 mean loss: 0.0008652660762891173 score: 1.0
2021-08-08 04:46:25,198 | train | INFO | Epoch 10 validation batch 77/113: 1232/1800 mean loss: 0.0008764294325374067 score: 1.0
2021-08-08 04:46:25,442 | train | INFO | Epoch 10 validation batch 78/113: 1248/1800 mean loss: 0.000989138730801642 score: 0.9889705882352942
2021-08-08 04:46:25,672 | train | INFO | Epoch 10 validation batch 79/113: 1264/1800 mean loss: 0.0011355853639543056 score: 0.9921568627450981
2021-08-08 04:46:25,907 | train | INFO | Epoch 10 validation batch 80/113: 1280/1800 mean loss: 0.0011763947550207376 score: 1.0
2021-08-08 04:46:26,145 | train | INFO | Epoch 10 validation batch 81/113: 1296/1800 mean loss: 0.0010064966045320034 score: 1.0
2021-08-08 04:46:26,386 | train | INFO | Epoch 10 validation batch 82/113: 1312/1800 mean loss: 0.0010136646451428533 score: 1.0
2021-08-08 04:46:26,620 | train | INFO | Epoch 10 validation batch 83/113: 1328/1800 mean loss: 0.001148414914496243 score: 1.0
2021-08-08 04:46:26,868 | train | INFO | Epoch 10 validation batch 84/113: 1344/1800 mean loss: 0.0011513237841427326 score: 0.9889705882352942
2021-08-08 04:46:27,103 | train | INFO | Epoch 10 validation batch 85/113: 1360/1800 mean loss: 0.0010833819396793842 score: 1.0
2021-08-08 04:46:27,339 | train | INFO | Epoch 10 validation batch 86/113: 1376/1800 mean loss: 0.0012631098506972194 score: 1.0
2021-08-08 04:46:27,590 | train | INFO | Epoch 10 validation batch 87/113: 1392/1800 mean loss: 0.0012008451158180833 score: 1.0
2021-08-08 04:46:27,831 | train | INFO | Epoch 10 validation batch 88/113: 1408/1800 mean loss: 0.001002964680083096 score: 1.0
2021-08-08 04:46:28,062 | train | INFO | Epoch 10 validation batch 89/113: 1424/1800 mean loss: 0.0008746599778532982 score: 1.0
2021-08-08 04:46:28,310 | train | INFO | Epoch 10 validation batch 90/113: 1440/1800 mean loss: 0.0009721167152747512 score: 1.0
2021-08-08 04:46:28,544 | train | INFO | Epoch 10 validation batch 91/113: 1456/1800 mean loss: 0.0012642608489841223 score: 1.0
2021-08-08 04:46:28,779 | train | INFO | Epoch 10 validation batch 92/113: 1472/1800 mean loss: 0.0009983805939555168 score: 1.0
2021-08-08 04:46:29,016 | train | INFO | Epoch 10 validation batch 93/113: 1488/1800 mean loss: 0.001036577159538865 score: 1.0
2021-08-08 04:46:29,254 | train | INFO | Epoch 10 validation batch 94/113: 1504/1800 mean loss: 0.00099970493465662 score: 1.0
2021-08-08 04:46:29,518 | train | INFO | Epoch 10 validation batch 95/113: 1520/1800 mean loss: 0.001080371905118227 score: 1.0
2021-08-08 04:46:29,774 | train | INFO | Epoch 10 validation batch 96/113: 1536/1800 mean loss: 0.0011407334823161364 score: 1.0
2021-08-08 04:46:30,009 | train | INFO | Epoch 10 validation batch 97/113: 1552/1800 mean loss: 0.0010489389533177018 score: 1.0
2021-08-08 04:46:30,268 | train | INFO | Epoch 10 validation batch 98/113: 1568/1800 mean loss: 0.0010306475451216102 score: 1.0
2021-08-08 04:46:30,520 | train | INFO | Epoch 10 validation batch 99/113: 1584/1800 mean loss: 0.0009778932435438037 score: 1.0
2021-08-08 04:46:30,757 | train | INFO | Epoch 10 validation batch 100/113: 1600/1800 mean loss: 0.0011962506687268615 score: 1.0
2021-08-08 04:46:30,987 | train | INFO | Epoch 10 validation batch 101/113: 1616/1800 mean loss: 0.0010117234196513891 score: 1.0
2021-08-08 04:46:31,218 | train | INFO | Epoch 10 validation batch 102/113: 1632/1800 mean loss: 0.000935508287511766 score: 1.0
2021-08-08 04:46:31,448 | train | INFO | Epoch 10 validation batch 103/113: 1648/1800 mean loss: 0.0009812673088163137 score: 1.0
2021-08-08 04:46:31,678 | train | INFO | Epoch 10 validation batch 104/113: 1664/1800 mean loss: 0.001102048554457724 score: 1.0
2021-08-08 04:46:31,908 | train | INFO | Epoch 10 validation batch 105/113: 1680/1800 mean loss: 0.001041649142280221 score: 1.0
2021-08-08 04:46:32,138 | train | INFO | Epoch 10 validation batch 106/113: 1696/1800 mean loss: 0.00107766839209944 score: 1.0
2021-08-08 04:46:32,368 | train | INFO | Epoch 10 validation batch 107/113: 1712/1800 mean loss: 0.001286864746361971 score: 1.0
2021-08-08 04:46:32,598 | train | INFO | Epoch 10 validation batch 108/113: 1728/1800 mean loss: 0.0012639666674658656 score: 1.0
2021-08-08 04:46:32,829 | train | INFO | Epoch 10 validation batch 109/113: 1744/1800 mean loss: 0.0011460178066045046 score: 1.0
2021-08-08 04:46:33,065 | train | INFO | Epoch 10 validation batch 110/113: 1760/1800 mean loss: 0.000946219137404114 score: 1.0
2021-08-08 04:46:33,295 | train | INFO | Epoch 10 validation batch 111/113: 1776/1800 mean loss: 0.000980455195531249 score: 1.0
2021-08-08 04:46:33,458 | train | INFO | Epoch 10 validation batch 112/113: 1792/1800 mean loss: 0.0009366545709781349 score: 1.0
2021-08-08 04:46:33,637 | train | INFO | Epoch 10, Validation, Mean loss: 0.01659424438149528, Score: 0.9981975533576262
2021-08-08 04:46:33,638 | train | INFO | Write row 10
2021-08-08 04:46:36,186 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:46:36,190 | train | INFO | Update best record row 11, checkpoints 0.016712200218003934 -> 0.01659424438149528
2021-08-08 04:46:38,211 | train | INFO | Epoch 11 train batch 0/450: 0/7200 mean loss: 0.0012421068968251348 score: 1.0
2021-08-08 04:46:39,005 | train | INFO | Epoch 11 train batch 1/450: 16/7200 mean loss: 0.0014799541095271707 score: 1.0
2021-08-08 04:46:39,774 | train | INFO | Epoch 11 train batch 2/450: 32/7200 mean loss: 0.001377753564156592 score: 1.0
2021-08-08 04:46:40,547 | train | INFO | Epoch 11 train batch 3/450: 48/7200 mean loss: 0.0014521837001666427 score: 0.9889705882352942
2021-08-08 04:46:41,344 | train | INFO | Epoch 11 train batch 4/450: 64/7200 mean loss: 0.0014696347061544657 score: 1.0
2021-08-08 04:46:42,158 | train | INFO | Epoch 11 train batch 5/450: 80/7200 mean loss: 0.001532832975499332 score: 0.9963235294117647
2021-08-08 04:46:42,965 | train | INFO | Epoch 11 train batch 6/450: 96/7200 mean loss: 0.0015387696912512183 score: 1.0
2021-08-08 04:46:43,772 | train | INFO | Epoch 11 train batch 7/450: 112/7200 mean loss: 0.0014131340431049466 score: 1.0
2021-08-08 04:46:44,551 | train | INFO | Epoch 11 train batch 8/450: 128/7200 mean loss: 0.0015111691318452358 score: 1.0
2021-08-08 04:46:45,325 | train | INFO | Epoch 11 train batch 9/450: 144/7200 mean loss: 0.0014627511845901608 score: 1.0
2021-08-08 04:46:46,124 | train | INFO | Epoch 11 train batch 10/450: 160/7200 mean loss: 0.0016209156019613147 score: 1.0
2021-08-08 04:46:46,897 | train | INFO | Epoch 11 train batch 11/450: 176/7200 mean loss: 0.0014114679070189595 score: 1.0
2021-08-08 04:46:47,697 | train | INFO | Epoch 11 train batch 12/450: 192/7200 mean loss: 0.0013681820128113031 score: 1.0
2021-08-08 04:46:48,474 | train | INFO | Epoch 11 train batch 13/450: 208/7200 mean loss: 0.0016074415761977434 score: 1.0
2021-08-08 04:46:49,256 | train | INFO | Epoch 11 train batch 14/450: 224/7200 mean loss: 0.0014558687107637525 score: 0.9889705882352942
2021-08-08 04:46:50,073 | train | INFO | Epoch 11 train batch 15/450: 240/7200 mean loss: 0.0014051051111891866 score: 1.0
2021-08-08 04:46:50,845 | train | INFO | Epoch 11 train batch 16/450: 256/7200 mean loss: 0.001644484931603074 score: 0.8566176470588235
2021-08-08 04:46:51,618 | train | INFO | Epoch 11 train batch 17/450: 272/7200 mean loss: 0.0015428827609866858 score: 1.0
2021-08-08 04:46:52,447 | train | INFO | Epoch 11 train batch 18/450: 288/7200 mean loss: 0.0015073174145072699 score: 1.0
2021-08-08 04:46:53,249 | train | INFO | Epoch 11 train batch 19/450: 304/7200 mean loss: 0.00165649875998497 score: 1.0
2021-08-08 04:46:54,032 | train | INFO | Epoch 11 train batch 20/450: 320/7200 mean loss: 0.0015534756239503622 score: 1.0
2021-08-08 04:46:54,809 | train | INFO | Epoch 11 train batch 21/450: 336/7200 mean loss: 0.0015899048885330558 score: 1.0
2021-08-08 04:46:55,582 | train | INFO | Epoch 11 train batch 22/450: 352/7200 mean loss: 0.0015910111833363771 score: 1.0
2021-08-08 04:46:56,365 | train | INFO | Epoch 11 train batch 23/450: 368/7200 mean loss: 0.0016249449690803885 score: 0.995798319327731
2021-08-08 04:46:57,190 | train | INFO | Epoch 11 train batch 24/450: 384/7200 mean loss: 0.001384160714223981 score: 1.0
2021-08-08 04:46:57,956 | train | INFO | Epoch 11 train batch 25/450: 400/7200 mean loss: 0.0014541330747306347 score: 1.0
2021-08-08 04:46:58,729 | train | INFO | Epoch 11 train batch 26/450: 416/7200 mean loss: 0.001443812856450677 score: 1.0
2021-08-08 04:46:59,523 | train | INFO | Epoch 11 train batch 27/450: 432/7200 mean loss: 0.001384145114570856 score: 1.0
2021-08-08 04:47:00,304 | train | INFO | Epoch 11 train batch 28/450: 448/7200 mean loss: 0.0013633824419230223 score: 1.0
2021-08-08 04:47:01,102 | train | INFO | Epoch 11 train batch 29/450: 464/7200 mean loss: 0.001638336107134819 score: 1.0
2021-08-08 04:47:01,878 | train | INFO | Epoch 11 train batch 30/450: 480/7200 mean loss: 0.0014691755641251802 score: 0.9887254901960785
2021-08-08 04:47:02,659 | train | INFO | Epoch 11 train batch 31/450: 496/7200 mean loss: 0.0013258635299280286 score: 1.0
2021-08-08 04:47:03,442 | train | INFO | Epoch 11 train batch 32/450: 512/7200 mean loss: 0.0014784936793148518 score: 0.9963235294117647
2021-08-08 04:47:04,225 | train | INFO | Epoch 11 train batch 33/450: 528/7200 mean loss: 0.0015505432384088635 score: 0.9963235294117647
2021-08-08 04:47:04,995 | train | INFO | Epoch 11 train batch 34/450: 544/7200 mean loss: 0.0015853624790906906 score: 0.8686274509803922
2021-08-08 04:47:05,798 | train | INFO | Epoch 11 train batch 35/450: 560/7200 mean loss: 0.0013700224226340652 score: 1.0
2021-08-08 04:47:06,569 | train | INFO | Epoch 11 train batch 36/450: 576/7200 mean loss: 0.0014597674598917365 score: 1.0
2021-08-08 04:47:07,347 | train | INFO | Epoch 11 train batch 37/450: 592/7200 mean loss: 0.0014214618131518364 score: 1.0
2021-08-08 04:47:08,120 | train | INFO | Epoch 11 train batch 38/450: 608/7200 mean loss: 0.0016685250448063016 score: 1.0
2021-08-08 04:47:08,917 | train | INFO | Epoch 11 train batch 39/450: 624/7200 mean loss: 0.0012956095160916448 score: 0.9889705882352942
2021-08-08 04:47:09,710 | train | INFO | Epoch 11 train batch 40/450: 640/7200 mean loss: 0.0014386017573997378 score: 0.9963235294117647
2021-08-08 04:47:10,519 | train | INFO | Epoch 11 train batch 41/450: 656/7200 mean loss: 0.001554188784211874 score: 0.8857843137254902
2021-08-08 04:47:11,310 | train | INFO | Epoch 11 train batch 42/450: 672/7200 mean loss: 0.0012689294526353478 score: 0.996078431372549
2021-08-08 04:47:12,106 | train | INFO | Epoch 11 train batch 43/450: 688/7200 mean loss: 0.001561198034323752 score: 1.0
2021-08-08 04:47:12,889 | train | INFO | Epoch 11 train batch 44/450: 704/7200 mean loss: 0.0015282595995813608 score: 0.9963235294117647
2021-08-08 04:47:13,670 | train | INFO | Epoch 11 train batch 45/450: 720/7200 mean loss: 0.0016421159962192178 score: 0.9889705882352942
2021-08-08 04:47:14,477 | train | INFO | Epoch 11 train batch 46/450: 736/7200 mean loss: 0.0013024109648540616 score: 1.0
2021-08-08 04:47:15,270 | train | INFO | Epoch 11 train batch 47/450: 752/7200 mean loss: 0.0012528012739494443 score: 1.0
2021-08-08 04:47:16,076 | train | INFO | Epoch 11 train batch 48/450: 768/7200 mean loss: 0.0012779918033629656 score: 1.0
2021-08-08 04:47:16,859 | train | INFO | Epoch 11 train batch 49/450: 784/7200 mean loss: 0.0014463311526924372 score: 0.9963235294117647
2021-08-08 04:47:17,630 | train | INFO | Epoch 11 train batch 50/450: 800/7200 mean loss: 0.0016293994849547744 score: 1.0
2021-08-08 04:47:18,445 | train | INFO | Epoch 11 train batch 51/450: 816/7200 mean loss: 0.0014623772585764527 score: 0.996078431372549
2021-08-08 04:47:19,233 | train | INFO | Epoch 11 train batch 52/450: 832/7200 mean loss: 0.001369564444757998 score: 0.9698529411764706
2021-08-08 04:47:20,003 | train | INFO | Epoch 11 train batch 53/450: 848/7200 mean loss: 0.001332748681306839 score: 1.0
2021-08-08 04:47:20,767 | train | INFO | Epoch 11 train batch 54/450: 864/7200 mean loss: 0.0014272303087636828 score: 1.0
2021-08-08 04:47:21,534 | train | INFO | Epoch 11 train batch 55/450: 880/7200 mean loss: 0.0013532331213355064 score: 1.0
2021-08-08 04:47:22,330 | train | INFO | Epoch 11 train batch 56/450: 896/7200 mean loss: 0.0012306392891332507 score: 1.0
2021-08-08 04:47:23,112 | train | INFO | Epoch 11 train batch 57/450: 912/7200 mean loss: 0.0015020323917269707 score: 1.0
2021-08-08 04:47:23,902 | train | INFO | Epoch 11 train batch 58/450: 928/7200 mean loss: 0.001319504459388554 score: 1.0
2021-08-08 04:47:24,681 | train | INFO | Epoch 11 train batch 59/450: 944/7200 mean loss: 0.0015637988690286875 score: 1.0
2021-08-08 04:47:25,496 | train | INFO | Epoch 11 train batch 60/450: 960/7200 mean loss: 0.0015771443722769618 score: 1.0
2021-08-08 04:47:26,349 | train | INFO | Epoch 11 train batch 61/450: 976/7200 mean loss: 0.0015061943558976054 score: 0.9847689075630254
2021-08-08 04:47:27,151 | train | INFO | Epoch 11 train batch 62/450: 992/7200 mean loss: 0.0014834568137302995 score: 1.0
2021-08-08 04:47:27,940 | train | INFO | Epoch 11 train batch 63/450: 1008/7200 mean loss: 0.0013995793415233493 score: 1.0
2021-08-08 04:47:28,745 | train | INFO | Epoch 11 train batch 64/450: 1024/7200 mean loss: 0.001520097372122109 score: 1.0
2021-08-08 04:47:29,628 | train | INFO | Epoch 11 train batch 65/450: 1040/7200 mean loss: 0.0016187524888664484 score: 1.0
2021-08-08 04:47:30,405 | train | INFO | Epoch 11 train batch 66/450: 1056/7200 mean loss: 0.0016545848920941353 score: 1.0
2021-08-08 04:47:31,208 | train | INFO | Epoch 11 train batch 67/450: 1072/7200 mean loss: 0.0013795248232781887 score: 1.0
2021-08-08 04:47:31,978 | train | INFO | Epoch 11 train batch 68/450: 1088/7200 mean loss: 0.0016138508217409253 score: 0.9852941176470589
2021-08-08 04:47:32,752 | train | INFO | Epoch 11 train batch 69/450: 1104/7200 mean loss: 0.001329649705439806 score: 0.996078431372549
2021-08-08 04:47:33,536 | train | INFO | Epoch 11 train batch 70/450: 1120/7200 mean loss: 0.0012624777154996991 score: 1.0
2021-08-08 04:47:34,312 | train | INFO | Epoch 11 train batch 71/450: 1136/7200 mean loss: 0.0014528997708112001 score: 1.0
2021-08-08 04:47:35,124 | train | INFO | Epoch 11 train batch 72/450: 1152/7200 mean loss: 0.0017017024802044034 score: 1.0
2021-08-08 04:47:35,934 | train | INFO | Epoch 11 train batch 73/450: 1168/7200 mean loss: 0.0014466760912910104 score: 1.0
2021-08-08 04:47:36,739 | train | INFO | Epoch 11 train batch 74/450: 1184/7200 mean loss: 0.0014207095373421907 score: 1.0
2021-08-08 04:47:37,520 | train | INFO | Epoch 11 train batch 75/450: 1200/7200 mean loss: 0.0014360294444486499 score: 1.0
2021-08-08 04:47:38,379 | train | INFO | Epoch 11 train batch 76/450: 1216/7200 mean loss: 0.0012462561717256904 score: 1.0
2021-08-08 04:47:39,271 | train | INFO | Epoch 11 train batch 77/450: 1232/7200 mean loss: 0.0013850930845364928 score: 1.0
2021-08-08 04:47:40,062 | train | INFO | Epoch 11 train batch 78/450: 1248/7200 mean loss: 0.0013693843502551317 score: 1.0
2021-08-08 04:47:40,833 | train | INFO | Epoch 11 train batch 79/450: 1264/7200 mean loss: 0.0013765627518296242 score: 1.0
2021-08-08 04:47:41,617 | train | INFO | Epoch 11 train batch 80/450: 1280/7200 mean loss: 0.0012440768769010901 score: 1.0
2021-08-08 04:47:42,387 | train | INFO | Epoch 11 train batch 81/450: 1296/7200 mean loss: 0.0013195847859606147 score: 1.0
2021-08-08 04:47:43,170 | train | INFO | Epoch 11 train batch 82/450: 1312/7200 mean loss: 0.001360438298434019 score: 0.9850490196078432
2021-08-08 04:47:43,968 | train | INFO | Epoch 11 train batch 83/450: 1328/7200 mean loss: 0.001404348062351346 score: 0.9963235294117647
2021-08-08 04:47:44,762 | train | INFO | Epoch 11 train batch 84/450: 1344/7200 mean loss: 0.0014250752283260226 score: 1.0
2021-08-08 04:47:45,558 | train | INFO | Epoch 11 train batch 85/450: 1360/7200 mean loss: 0.0015100750606507063 score: 1.0
2021-08-08 04:47:46,352 | train | INFO | Epoch 11 train batch 86/450: 1376/7200 mean loss: 0.0012943277833983302 score: 1.0
2021-08-08 04:47:47,133 | train | INFO | Epoch 11 train batch 87/450: 1392/7200 mean loss: 0.0013549216091632843 score: 1.0
2021-08-08 04:47:47,911 | train | INFO | Epoch 11 train batch 88/450: 1408/7200 mean loss: 0.0014759119367226958 score: 1.0
2021-08-08 04:47:48,683 | train | INFO | Epoch 11 train batch 89/450: 1424/7200 mean loss: 0.0014843472745269537 score: 0.9921568627450981
2021-08-08 04:47:49,488 | train | INFO | Epoch 11 train batch 90/450: 1440/7200 mean loss: 0.0014418265782296658 score: 1.0
2021-08-08 04:47:50,250 | train | INFO | Epoch 11 train batch 91/450: 1456/7200 mean loss: 0.0015340994577854872 score: 0.9926470588235294
2021-08-08 04:47:51,147 | train | INFO | Epoch 11 train batch 92/450: 1472/7200 mean loss: 0.001429670606739819 score: 0.9926470588235294
2021-08-08 04:47:51,956 | train | INFO | Epoch 11 train batch 93/450: 1488/7200 mean loss: 0.0014308278914541006 score: 1.0
2021-08-08 04:47:52,741 | train | INFO | Epoch 11 train batch 94/450: 1504/7200 mean loss: 0.0015110909007489681 score: 1.0
2021-08-08 04:47:53,570 | train | INFO | Epoch 11 train batch 95/450: 1520/7200 mean loss: 0.0013412929838523269 score: 1.0
2021-08-08 04:47:54,346 | train | INFO | Epoch 11 train batch 96/450: 1536/7200 mean loss: 0.00162255740724504 score: 1.0
2021-08-08 04:47:55,241 | train | INFO | Epoch 11 train batch 97/450: 1552/7200 mean loss: 0.0014833702007308602 score: 0.996078431372549
2021-08-08 04:47:56,036 | train | INFO | Epoch 11 train batch 98/450: 1568/7200 mean loss: 0.0015431124484166503 score: 0.996078431372549
2021-08-08 04:47:56,835 | train | INFO | Epoch 11 train batch 99/450: 1584/7200 mean loss: 0.0014192125527188182 score: 1.0
2021-08-08 04:47:57,750 | train | INFO | Epoch 11 train batch 100/450: 1600/7200 mean loss: 0.0014463829575106502 score: 1.0
2021-08-08 04:47:58,553 | train | INFO | Epoch 11 train batch 101/450: 1616/7200 mean loss: 0.0013394353445619345 score: 1.0
2021-08-08 04:47:59,357 | train | INFO | Epoch 11 train batch 102/450: 1632/7200 mean loss: 0.001290394109673798 score: 1.0
2021-08-08 04:48:00,158 | train | INFO | Epoch 11 train batch 103/450: 1648/7200 mean loss: 0.0015133866108953953 score: 1.0
2021-08-08 04:48:00,962 | train | INFO | Epoch 11 train batch 104/450: 1664/7200 mean loss: 0.0014383795205503702 score: 1.0
2021-08-08 04:48:01,744 | train | INFO | Epoch 11 train batch 105/450: 1680/7200 mean loss: 0.0014068919699639082 score: 0.9926470588235294
2021-08-08 04:48:02,557 | train | INFO | Epoch 11 train batch 106/450: 1696/7200 mean loss: 0.0013626556610688567 score: 1.0
2021-08-08 04:48:03,347 | train | INFO | Epoch 11 train batch 107/450: 1712/7200 mean loss: 0.001288565923459828 score: 1.0
2021-08-08 04:48:04,189 | train | INFO | Epoch 11 train batch 108/450: 1728/7200 mean loss: 0.001446054200641811 score: 1.0
2021-08-08 04:48:05,007 | train | INFO | Epoch 11 train batch 109/450: 1744/7200 mean loss: 0.001811342895962298 score: 0.9737745098039216
2021-08-08 04:48:05,824 | train | INFO | Epoch 11 train batch 110/450: 1760/7200 mean loss: 0.0015853652730584145 score: 1.0
2021-08-08 04:48:06,601 | train | INFO | Epoch 11 train batch 111/450: 1776/7200 mean loss: 0.0015853114891797304 score: 1.0
2021-08-08 04:48:07,428 | train | INFO | Epoch 11 train batch 112/450: 1792/7200 mean loss: 0.0014939112588763237 score: 1.0
2021-08-08 04:48:08,209 | train | INFO | Epoch 11 train batch 113/450: 1808/7200 mean loss: 0.0016856837319210172 score: 1.0
2021-08-08 04:48:08,993 | train | INFO | Epoch 11 train batch 114/450: 1824/7200 mean loss: 0.0014962238492444158 score: 1.0
2021-08-08 04:48:09,769 | train | INFO | Epoch 11 train batch 115/450: 1840/7200 mean loss: 0.0012860422721132636 score: 1.0
2021-08-08 04:48:10,558 | train | INFO | Epoch 11 train batch 116/450: 1856/7200 mean loss: 0.0014555352972820401 score: 1.0
2021-08-08 04:48:11,351 | train | INFO | Epoch 11 train batch 117/450: 1872/7200 mean loss: 0.0010690049966797233 score: 1.0
2021-08-08 04:48:12,158 | train | INFO | Epoch 11 train batch 118/450: 1888/7200 mean loss: 0.0013243344146758318 score: 1.0
2021-08-08 04:48:12,962 | train | INFO | Epoch 11 train batch 119/450: 1904/7200 mean loss: 0.0014962921850383282 score: 1.0
2021-08-08 04:48:13,743 | train | INFO | Epoch 11 train batch 120/450: 1920/7200 mean loss: 0.001558127929456532 score: 1.0
2021-08-08 04:48:14,530 | train | INFO | Epoch 11 train batch 121/450: 1936/7200 mean loss: 0.0016748205525800586 score: 0.9852941176470589
2021-08-08 04:48:15,303 | train | INFO | Epoch 11 train batch 122/450: 1952/7200 mean loss: 0.0013657218078151345 score: 1.0
2021-08-08 04:48:16,113 | train | INFO | Epoch 11 train batch 123/450: 1968/7200 mean loss: 0.001352515653707087 score: 0.996078431372549
2021-08-08 04:48:16,903 | train | INFO | Epoch 11 train batch 124/450: 1984/7200 mean loss: 0.0014849756844341755 score: 1.0
2021-08-08 04:48:17,703 | train | INFO | Epoch 11 train batch 125/450: 2000/7200 mean loss: 0.0013997883070260286 score: 1.0
2021-08-08 04:48:18,485 | train | INFO | Epoch 11 train batch 126/450: 2016/7200 mean loss: 0.001267128624022007 score: 0.9963235294117647
2021-08-08 04:48:19,320 | train | INFO | Epoch 11 train batch 127/450: 2032/7200 mean loss: 0.0015734354965388775 score: 1.0
2021-08-08 04:48:20,099 | train | INFO | Epoch 11 train batch 128/450: 2048/7200 mean loss: 0.001082415459677577 score: 1.0
2021-08-08 04:48:20,897 | train | INFO | Epoch 11 train batch 129/450: 2064/7200 mean loss: 0.0015200405614450574 score: 1.0
2021-08-08 04:48:21,671 | train | INFO | Epoch 11 train batch 130/450: 2080/7200 mean loss: 0.0013013113057240844 score: 1.0
2021-08-08 04:48:22,450 | train | INFO | Epoch 11 train batch 131/450: 2096/7200 mean loss: 0.0014002751559019089 score: 1.0
2021-08-08 04:48:23,236 | train | INFO | Epoch 11 train batch 132/450: 2112/7200 mean loss: 0.001209175563417375 score: 1.0
2021-08-08 04:48:24,010 | train | INFO | Epoch 11 train batch 133/450: 2128/7200 mean loss: 0.0014183854218572378 score: 0.9887254901960785
2021-08-08 04:48:24,815 | train | INFO | Epoch 11 train batch 134/450: 2144/7200 mean loss: 0.001547252875752747 score: 1.0
2021-08-08 04:48:25,602 | train | INFO | Epoch 11 train batch 135/450: 2160/7200 mean loss: 0.001559088472276926 score: 1.0
2021-08-08 04:48:26,394 | train | INFO | Epoch 11 train batch 136/450: 2176/7200 mean loss: 0.0014636468840762973 score: 1.0
2021-08-08 04:48:27,160 | train | INFO | Epoch 11 train batch 137/450: 2192/7200 mean loss: 0.0013120220974087715 score: 0.9926470588235294
2021-08-08 04:48:27,925 | train | INFO | Epoch 11 train batch 138/450: 2208/7200 mean loss: 0.0014252540422603488 score: 1.0
2021-08-08 04:48:28,737 | train | INFO | Epoch 11 train batch 139/450: 2224/7200 mean loss: 0.0013831795658916235 score: 1.0
2021-08-08 04:48:29,507 | train | INFO | Epoch 11 train batch 140/450: 2240/7200 mean loss: 0.0012470250949263573 score: 1.0
2021-08-08 04:48:30,280 | train | INFO | Epoch 11 train batch 141/450: 2256/7200 mean loss: 0.0015802812995389104 score: 1.0
2021-08-08 04:48:31,047 | train | INFO | Epoch 11 train batch 142/450: 2272/7200 mean loss: 0.0013416485162451863 score: 1.0
2021-08-08 04:48:31,815 | train | INFO | Epoch 11 train batch 143/450: 2288/7200 mean loss: 0.0013344313483685255 score: 1.0
2021-08-08 04:48:32,651 | train | INFO | Epoch 11 train batch 144/450: 2304/7200 mean loss: 0.0013952780282124877 score: 0.9887254901960785
2021-08-08 04:48:33,428 | train | INFO | Epoch 11 train batch 145/450: 2320/7200 mean loss: 0.0014112078351899981 score: 1.0
2021-08-08 04:48:34,209 | train | INFO | Epoch 11 train batch 146/450: 2336/7200 mean loss: 0.0012934268452227116 score: 0.9926470588235294
2021-08-08 04:48:35,003 | train | INFO | Epoch 11 train batch 147/450: 2352/7200 mean loss: 0.0014479534002020955 score: 0.9852941176470589
2021-08-08 04:48:35,784 | train | INFO | Epoch 11 train batch 148/450: 2368/7200 mean loss: 0.0014115674421191216 score: 1.0
2021-08-08 04:48:36,568 | train | INFO | Epoch 11 train batch 149/450: 2384/7200 mean loss: 0.00151624099817127 score: 1.0
2021-08-08 04:48:37,375 | train | INFO | Epoch 11 train batch 150/450: 2400/7200 mean loss: 0.0015891649527475238 score: 0.9963235294117647
2021-08-08 04:48:38,161 | train | INFO | Epoch 11 train batch 151/450: 2416/7200 mean loss: 0.0013116893824189901 score: 1.0
2021-08-08 04:48:38,935 | train | INFO | Epoch 11 train batch 152/450: 2432/7200 mean loss: 0.0015985160134732723 score: 1.0
2021-08-08 04:48:39,708 | train | INFO | Epoch 11 train batch 153/450: 2448/7200 mean loss: 0.0016726437024772167 score: 1.0
2021-08-08 04:48:40,487 | train | INFO | Epoch 11 train batch 154/450: 2464/7200 mean loss: 0.0015786726726219058 score: 0.9073529411764706
2021-08-08 04:48:41,298 | train | INFO | Epoch 11 train batch 155/450: 2480/7200 mean loss: 0.0016445391811430454 score: 1.0
2021-08-08 04:48:42,120 | train | INFO | Epoch 11 train batch 156/450: 2496/7200 mean loss: 0.0015696969348937273 score: 1.0
2021-08-08 04:48:42,895 | train | INFO | Epoch 11 train batch 157/450: 2512/7200 mean loss: 0.0014862763928249478 score: 1.0
2021-08-08 04:48:43,672 | train | INFO | Epoch 11 train batch 158/450: 2528/7200 mean loss: 0.0013290989445522428 score: 1.0
2021-08-08 04:48:44,442 | train | INFO | Epoch 11 train batch 159/450: 2544/7200 mean loss: 0.0015022337902337313 score: 1.0
2021-08-08 04:48:45,208 | train | INFO | Epoch 11 train batch 160/450: 2560/7200 mean loss: 0.0016546122496947646 score: 1.0
2021-08-08 04:48:45,988 | train | INFO | Epoch 11 train batch 161/450: 2576/7200 mean loss: 0.0017352355644106865 score: 1.0
2021-08-08 04:48:46,766 | train | INFO | Epoch 11 train batch 162/450: 2592/7200 mean loss: 0.00162110838573426 score: 0.9700630252100839
2021-08-08 04:48:47,544 | train | INFO | Epoch 11 train batch 163/450: 2608/7200 mean loss: 0.0014527926687151194 score: 0.9963235294117647
2021-08-08 04:48:48,339 | train | INFO | Epoch 11 train batch 164/450: 2624/7200 mean loss: 0.0015981059987097979 score: 1.0
2021-08-08 04:48:49,119 | train | INFO | Epoch 11 train batch 165/450: 2640/7200 mean loss: 0.0015902835875749588 score: 1.0
2021-08-08 04:48:49,933 | train | INFO | Epoch 11 train batch 166/450: 2656/7200 mean loss: 0.0013295046519488096 score: 1.0
2021-08-08 04:48:50,702 | train | INFO | Epoch 11 train batch 167/450: 2672/7200 mean loss: 0.0015186117962002754 score: 0.9963235294117647
2021-08-08 04:48:51,522 | train | INFO | Epoch 11 train batch 168/450: 2688/7200 mean loss: 0.0015556167345494032 score: 0.9963235294117647
2021-08-08 04:48:52,319 | train | INFO | Epoch 11 train batch 169/450: 2704/7200 mean loss: 0.001486441702581942 score: 1.0
2021-08-08 04:48:53,085 | train | INFO | Epoch 11 train batch 170/450: 2720/7200 mean loss: 0.0014024844858795404 score: 1.0
2021-08-08 04:48:53,897 | train | INFO | Epoch 11 train batch 171/450: 2736/7200 mean loss: 0.0014345668023452163 score: 1.0
2021-08-08 04:48:54,706 | train | INFO | Epoch 11 train batch 172/450: 2752/7200 mean loss: 0.00143704644870013 score: 1.0
2021-08-08 04:48:55,506 | train | INFO | Epoch 11 train batch 173/450: 2768/7200 mean loss: 0.0014366961549967527 score: 1.0
2021-08-08 04:48:56,282 | train | INFO | Epoch 11 train batch 174/450: 2784/7200 mean loss: 0.0015414321096614003 score: 1.0
2021-08-08 04:48:57,061 | train | INFO | Epoch 11 train batch 175/450: 2800/7200 mean loss: 0.0015826842281967402 score: 0.9852941176470589
2021-08-08 04:48:57,845 | train | INFO | Epoch 11 train batch 176/450: 2816/7200 mean loss: 0.0016329135978594422 score: 0.9811274509803922
2021-08-08 04:48:58,644 | train | INFO | Epoch 11 train batch 177/450: 2832/7200 mean loss: 0.0013840054161846638 score: 1.0
2021-08-08 04:48:59,437 | train | INFO | Epoch 11 train batch 178/450: 2848/7200 mean loss: 0.0013260901905596256 score: 1.0
2021-08-08 04:49:00,216 | train | INFO | Epoch 11 train batch 179/450: 2864/7200 mean loss: 0.0015418367693200707 score: 0.9926470588235294
2021-08-08 04:49:01,005 | train | INFO | Epoch 11 train batch 180/450: 2880/7200 mean loss: 0.0016020581824705005 score: 0.9963235294117647
2021-08-08 04:49:01,776 | train | INFO | Epoch 11 train batch 181/450: 2896/7200 mean loss: 0.0014242392498999834 score: 1.0
2021-08-08 04:49:02,593 | train | INFO | Epoch 11 train batch 182/450: 2912/7200 mean loss: 0.0016917946049943566 score: 1.0
2021-08-08 04:49:03,366 | train | INFO | Epoch 11 train batch 183/450: 2928/7200 mean loss: 0.001385919051244855 score: 0.9772058823529413
2021-08-08 04:49:04,163 | train | INFO | Epoch 11 train batch 184/450: 2944/7200 mean loss: 0.0014802719233557582 score: 1.0
2021-08-08 04:49:04,965 | train | INFO | Epoch 11 train batch 185/450: 2960/7200 mean loss: 0.001346457633189857 score: 1.0
2021-08-08 04:49:05,740 | train | INFO | Epoch 11 train batch 186/450: 2976/7200 mean loss: 0.0015723422402516007 score: 1.0
2021-08-08 04:49:06,517 | train | INFO | Epoch 11 train batch 187/450: 2992/7200 mean loss: 0.0013998898211866617 score: 1.0
2021-08-08 04:49:07,401 | train | INFO | Epoch 11 train batch 188/450: 3008/7200 mean loss: 0.0013636165531352162 score: 1.0
2021-08-08 04:49:08,221 | train | INFO | Epoch 11 train batch 189/450: 3024/7200 mean loss: 0.0014734072610735893 score: 1.0
2021-08-08 04:49:09,018 | train | INFO | Epoch 11 train batch 190/450: 3040/7200 mean loss: 0.0014594688545912504 score: 1.0
2021-08-08 04:49:09,788 | train | INFO | Epoch 11 train batch 191/450: 3056/7200 mean loss: 0.0015373202040791512 score: 1.0
2021-08-08 04:49:10,596 | train | INFO | Epoch 11 train batch 192/450: 3072/7200 mean loss: 0.0013452725252136588 score: 1.0
2021-08-08 04:49:11,408 | train | INFO | Epoch 11 train batch 193/450: 3088/7200 mean loss: 0.0013756008120253682 score: 1.0
2021-08-08 04:49:12,274 | train | INFO | Epoch 11 train batch 194/450: 3104/7200 mean loss: 0.0011738735483959317 score: 1.0
2021-08-08 04:49:13,081 | train | INFO | Epoch 11 train batch 195/450: 3120/7200 mean loss: 0.0013472838327288628 score: 1.0
2021-08-08 04:49:13,862 | train | INFO | Epoch 11 train batch 196/450: 3136/7200 mean loss: 0.001319247530773282 score: 0.9963235294117647
2021-08-08 04:49:14,642 | train | INFO | Epoch 11 train batch 197/450: 3152/7200 mean loss: 0.0014213050017133355 score: 1.0
2021-08-08 04:49:15,456 | train | INFO | Epoch 11 train batch 198/450: 3168/7200 mean loss: 0.0012853012885898352 score: 1.0
2021-08-08 04:49:16,349 | train | INFO | Epoch 11 train batch 199/450: 3184/7200 mean loss: 0.0013156903441995382 score: 1.0
2021-08-08 04:49:17,128 | train | INFO | Epoch 11 train batch 200/450: 3200/7200 mean loss: 0.001523219863884151 score: 1.0
2021-08-08 04:49:17,942 | train | INFO | Epoch 11 train batch 201/450: 3216/7200 mean loss: 0.001342223840765655 score: 0.9921568627450981
2021-08-08 04:49:18,724 | train | INFO | Epoch 11 train batch 202/450: 3232/7200 mean loss: 0.0015098542207852006 score: 1.0
2021-08-08 04:49:19,561 | train | INFO | Epoch 11 train batch 203/450: 3248/7200 mean loss: 0.0014896318316459656 score: 1.0
2021-08-08 04:49:20,376 | train | INFO | Epoch 11 train batch 204/450: 3264/7200 mean loss: 0.0012423526495695114 score: 1.0
2021-08-08 04:49:21,211 | train | INFO | Epoch 11 train batch 205/450: 3280/7200 mean loss: 0.0012988371308892965 score: 1.0
2021-08-08 04:49:22,014 | train | INFO | Epoch 11 train batch 206/450: 3296/7200 mean loss: 0.0013371887616813183 score: 1.0
2021-08-08 04:49:22,828 | train | INFO | Epoch 11 train batch 207/450: 3312/7200 mean loss: 0.0016239186516031623 score: 1.0
2021-08-08 04:49:23,616 | train | INFO | Epoch 11 train batch 208/450: 3328/7200 mean loss: 0.00138552812859416 score: 0.996078431372549
2021-08-08 04:49:24,446 | train | INFO | Epoch 11 train batch 209/450: 3344/7200 mean loss: 0.0013860007748007774 score: 1.0
2021-08-08 04:49:25,270 | train | INFO | Epoch 11 train batch 210/450: 3360/7200 mean loss: 0.0014472223119810224 score: 1.0
2021-08-08 04:49:26,080 | train | INFO | Epoch 11 train batch 211/450: 3376/7200 mean loss: 0.0015532459365203977 score: 1.0
2021-08-08 04:49:26,902 | train | INFO | Epoch 11 train batch 212/450: 3392/7200 mean loss: 0.0016169488662853837 score: 1.0
2021-08-08 04:49:27,678 | train | INFO | Epoch 11 train batch 213/450: 3408/7200 mean loss: 0.0017345923697575927 score: 1.0
2021-08-08 04:49:28,474 | train | INFO | Epoch 11 train batch 214/450: 3424/7200 mean loss: 0.0014793678419664502 score: 1.0
2021-08-08 04:49:29,276 | train | INFO | Epoch 11 train batch 215/450: 3440/7200 mean loss: 0.0013563234824687243 score: 1.0
2021-08-08 04:49:30,099 | train | INFO | Epoch 11 train batch 216/450: 3456/7200 mean loss: 0.0015956704737618566 score: 1.0
2021-08-08 04:49:30,904 | train | INFO | Epoch 11 train batch 217/450: 3472/7200 mean loss: 0.0014618097338825464 score: 1.0
2021-08-08 04:49:31,680 | train | INFO | Epoch 11 train batch 218/450: 3488/7200 mean loss: 0.0014023161493241787 score: 1.0
2021-08-08 04:49:32,446 | train | INFO | Epoch 11 train batch 219/450: 3504/7200 mean loss: 0.001588338753208518 score: 0.9697398190045249
2021-08-08 04:49:33,233 | train | INFO | Epoch 11 train batch 220/450: 3520/7200 mean loss: 0.001527437474578619 score: 1.0
2021-08-08 04:49:34,030 | train | INFO | Epoch 11 train batch 221/450: 3536/7200 mean loss: 0.0014204989420250058 score: 0.9811274509803922
2021-08-08 04:49:34,823 | train | INFO | Epoch 11 train batch 222/450: 3552/7200 mean loss: 0.0015319321537390351 score: 1.0
2021-08-08 04:49:35,638 | train | INFO | Epoch 11 train batch 223/450: 3568/7200 mean loss: 0.0015379273099824786 score: 1.0
2021-08-08 04:49:36,455 | train | INFO | Epoch 11 train batch 224/450: 3584/7200 mean loss: 0.0013763968599960208 score: 1.0
2021-08-08 04:49:37,244 | train | INFO | Epoch 11 train batch 225/450: 3600/7200 mean loss: 0.0013409256935119629 score: 1.0
2021-08-08 04:49:38,051 | train | INFO | Epoch 11 train batch 226/450: 3616/7200 mean loss: 0.001446253852918744 score: 1.0
2021-08-08 04:49:38,860 | train | INFO | Epoch 11 train batch 227/450: 3632/7200 mean loss: 0.001356884022243321 score: 1.0
2021-08-08 04:49:39,641 | train | INFO | Epoch 11 train batch 228/450: 3648/7200 mean loss: 0.0013829106464982033 score: 1.0
2021-08-08 04:49:40,446 | train | INFO | Epoch 11 train batch 229/450: 3664/7200 mean loss: 0.00134596589487046 score: 0.9889705882352942
2021-08-08 04:49:41,255 | train | INFO | Epoch 11 train batch 230/450: 3680/7200 mean loss: 0.00164180644787848 score: 1.0
2021-08-08 04:49:42,058 | train | INFO | Epoch 11 train batch 231/450: 3696/7200 mean loss: 0.0016207760199904442 score: 1.0
2021-08-08 04:49:42,853 | train | INFO | Epoch 11 train batch 232/450: 3712/7200 mean loss: 0.001161705469712615 score: 1.0
2021-08-08 04:49:43,645 | train | INFO | Epoch 11 train batch 233/450: 3728/7200 mean loss: 0.0016952293226495385 score: 1.0
2021-08-08 04:49:44,416 | train | INFO | Epoch 11 train batch 234/450: 3744/7200 mean loss: 0.0012933084508404136 score: 1.0
2021-08-08 04:49:45,195 | train | INFO | Epoch 11 train batch 235/450: 3760/7200 mean loss: 0.0014241018798202276 score: 0.9887254901960785
2021-08-08 04:49:45,967 | train | INFO | Epoch 11 train batch 236/450: 3776/7200 mean loss: 0.0011749508557841182 score: 1.0
2021-08-08 04:49:46,739 | train | INFO | Epoch 11 train batch 237/450: 3792/7200 mean loss: 0.001358604640699923 score: 1.0
2021-08-08 04:49:47,511 | train | INFO | Epoch 11 train batch 238/450: 3808/7200 mean loss: 0.0014362848596647382 score: 1.0
2021-08-08 04:49:48,280 | train | INFO | Epoch 11 train batch 239/450: 3824/7200 mean loss: 0.0013621776597574353 score: 1.0
2021-08-08 04:49:49,052 | train | INFO | Epoch 11 train batch 240/450: 3840/7200 mean loss: 0.0014361572684720159 score: 1.0
2021-08-08 04:49:49,827 | train | INFO | Epoch 11 train batch 241/450: 3856/7200 mean loss: 0.0016177272191271186 score: 0.9887254901960785
2021-08-08 04:49:50,602 | train | INFO | Epoch 11 train batch 242/450: 3872/7200 mean loss: 0.0014511171029880643 score: 1.0
2021-08-08 04:49:51,374 | train | INFO | Epoch 11 train batch 243/450: 3888/7200 mean loss: 0.0014822767116129398 score: 1.0
2021-08-08 04:49:52,142 | train | INFO | Epoch 11 train batch 244/450: 3904/7200 mean loss: 0.0015153094427660108 score: 1.0
2021-08-08 04:49:52,910 | train | INFO | Epoch 11 train batch 245/450: 3920/7200 mean loss: 0.0012793571222573519 score: 1.0
2021-08-08 04:49:53,674 | train | INFO | Epoch 11 train batch 246/450: 3936/7200 mean loss: 0.0012927798088639975 score: 1.0
2021-08-08 04:49:54,437 | train | INFO | Epoch 11 train batch 247/450: 3952/7200 mean loss: 0.0015406864695250988 score: 1.0
2021-08-08 04:49:55,202 | train | INFO | Epoch 11 train batch 248/450: 3968/7200 mean loss: 0.0015272322343662381 score: 1.0
2021-08-08 04:49:55,992 | train | INFO | Epoch 11 train batch 249/450: 3984/7200 mean loss: 0.0013810760574415326 score: 1.0
2021-08-08 04:49:56,770 | train | INFO | Epoch 11 train batch 250/450: 4000/7200 mean loss: 0.0015566885704174638 score: 1.0
2021-08-08 04:49:57,551 | train | INFO | Epoch 11 train batch 251/450: 4016/7200 mean loss: 0.0014502847334370017 score: 1.0
2021-08-08 04:49:58,336 | train | INFO | Epoch 11 train batch 252/450: 4032/7200 mean loss: 0.0014260050375014544 score: 1.0
2021-08-08 04:49:59,113 | train | INFO | Epoch 11 train batch 253/450: 4048/7200 mean loss: 0.001520805642940104 score: 0.9924019607843138
2021-08-08 04:49:59,937 | train | INFO | Epoch 11 train batch 254/450: 4064/7200 mean loss: 0.0015617117751389742 score: 1.0
2021-08-08 04:50:00,748 | train | INFO | Epoch 11 train batch 255/450: 4080/7200 mean loss: 0.0015473425155505538 score: 0.9926470588235294
2021-08-08 04:50:01,521 | train | INFO | Epoch 11 train batch 256/450: 4096/7200 mean loss: 0.0014607307966798544 score: 1.0
2021-08-08 04:50:02,341 | train | INFO | Epoch 11 train batch 257/450: 4112/7200 mean loss: 0.0016272275242954493 score: 1.0
2021-08-08 04:50:03,145 | train | INFO | Epoch 11 train batch 258/450: 4128/7200 mean loss: 0.001408648444339633 score: 1.0
2021-08-08 04:50:03,933 | train | INFO | Epoch 11 train batch 259/450: 4144/7200 mean loss: 0.0013649726752191782 score: 1.0
2021-08-08 04:50:04,708 | train | INFO | Epoch 11 train batch 260/450: 4160/7200 mean loss: 0.001599957118742168 score: 1.0
2021-08-08 04:50:05,479 | train | INFO | Epoch 11 train batch 261/450: 4176/7200 mean loss: 0.0012821599375456572 score: 0.9742647058823529
2021-08-08 04:50:06,253 | train | INFO | Epoch 11 train batch 262/450: 4192/7200 mean loss: 0.001260788063518703 score: 0.9926470588235294
2021-08-08 04:50:07,081 | train | INFO | Epoch 11 train batch 263/450: 4208/7200 mean loss: 0.001182718202471733 score: 1.0
2021-08-08 04:50:07,871 | train | INFO | Epoch 11 train batch 264/450: 4224/7200 mean loss: 0.0013471586862578988 score: 1.0
2021-08-08 04:50:08,641 | train | INFO | Epoch 11 train batch 265/450: 4240/7200 mean loss: 0.0013322117738425732 score: 1.0
2021-08-08 04:50:09,415 | train | INFO | Epoch 11 train batch 266/450: 4256/7200 mean loss: 0.001661439542658627 score: 1.0
2021-08-08 04:50:10,180 | train | INFO | Epoch 11 train batch 267/450: 4272/7200 mean loss: 0.0014096717350184917 score: 0.9882002801120447
2021-08-08 04:50:10,967 | train | INFO | Epoch 11 train batch 268/450: 4288/7200 mean loss: 0.0014137397520244122 score: 1.0
2021-08-08 04:50:11,812 | train | INFO | Epoch 11 train batch 269/450: 4304/7200 mean loss: 0.0012805088190361857 score: 1.0
2021-08-08 04:50:12,608 | train | INFO | Epoch 11 train batch 270/450: 4320/7200 mean loss: 0.0015344705898314714 score: 1.0
2021-08-08 04:50:13,389 | train | INFO | Epoch 11 train batch 271/450: 4336/7200 mean loss: 0.0014677738072350621 score: 1.0
2021-08-08 04:50:14,162 | train | INFO | Epoch 11 train batch 272/450: 4352/7200 mean loss: 0.001710288692265749 score: 0.9963235294117647
2021-08-08 04:50:15,057 | train | INFO | Epoch 11 train batch 273/450: 4368/7200 mean loss: 0.0017207367345690727 score: 1.0
2021-08-08 04:50:15,872 | train | INFO | Epoch 11 train batch 274/450: 4384/7200 mean loss: 0.0013391210231930017 score: 0.9963235294117647
2021-08-08 04:50:16,646 | train | INFO | Epoch 11 train batch 275/450: 4400/7200 mean loss: 0.0014190126676112413 score: 1.0
2021-08-08 04:50:17,453 | train | INFO | Epoch 11 train batch 276/450: 4416/7200 mean loss: 0.0013507386902347207 score: 1.0
2021-08-08 04:50:18,238 | train | INFO | Epoch 11 train batch 277/450: 4432/7200 mean loss: 0.0015394040383398533 score: 0.9926470588235294
2021-08-08 04:50:19,021 | train | INFO | Epoch 11 train batch 278/450: 4448/7200 mean loss: 0.001393618993461132 score: 1.0
2021-08-08 04:50:19,795 | train | INFO | Epoch 11 train batch 279/450: 4464/7200 mean loss: 0.0014328031102195382 score: 1.0
2021-08-08 04:50:20,568 | train | INFO | Epoch 11 train batch 280/450: 4480/7200 mean loss: 0.001301004202105105 score: 1.0
2021-08-08 04:50:21,358 | train | INFO | Epoch 11 train batch 281/450: 4496/7200 mean loss: 0.0013357773423194885 score: 0.9852941176470589
2021-08-08 04:50:22,133 | train | INFO | Epoch 11 train batch 282/450: 4512/7200 mean loss: 0.0015762380789965391 score: 1.0
2021-08-08 04:50:22,909 | train | INFO | Epoch 11 train batch 283/450: 4528/7200 mean loss: 0.0015759201487526298 score: 1.0
2021-08-08 04:50:23,699 | train | INFO | Epoch 11 train batch 284/450: 4544/7200 mean loss: 0.001514527713879943 score: 1.0
2021-08-08 04:50:24,475 | train | INFO | Epoch 11 train batch 285/450: 4560/7200 mean loss: 0.0014186970656737685 score: 0.9848039215686275
2021-08-08 04:50:25,247 | train | INFO | Epoch 11 train batch 286/450: 4576/7200 mean loss: 0.0014331121928989887 score: 1.0
2021-08-08 04:50:26,029 | train | INFO | Epoch 11 train batch 287/450: 4592/7200 mean loss: 0.0015376382507383823 score: 1.0
2021-08-08 04:50:26,821 | train | INFO | Epoch 11 train batch 288/450: 4608/7200 mean loss: 0.0015906193293631077 score: 0.9963235294117647
2021-08-08 04:50:27,695 | train | INFO | Epoch 11 train batch 289/450: 4624/7200 mean loss: 0.0014764248626306653 score: 1.0
2021-08-08 04:50:28,479 | train | INFO | Epoch 11 train batch 290/450: 4640/7200 mean loss: 0.001630062935873866 score: 1.0
2021-08-08 04:50:29,258 | train | INFO | Epoch 11 train batch 291/450: 4656/7200 mean loss: 0.0015199187910184264 score: 1.0
2021-08-08 04:50:30,064 | train | INFO | Epoch 11 train batch 292/450: 4672/7200 mean loss: 0.001449479372240603 score: 1.0
2021-08-08 04:50:30,916 | train | INFO | Epoch 11 train batch 293/450: 4688/7200 mean loss: 0.0014757683966308832 score: 1.0
2021-08-08 04:50:31,722 | train | INFO | Epoch 11 train batch 294/450: 4704/7200 mean loss: 0.0016511200228706002 score: 0.9848039215686275
2021-08-08 04:50:32,503 | train | INFO | Epoch 11 train batch 295/450: 4720/7200 mean loss: 0.0014641284942626953 score: 1.0
2021-08-08 04:50:33,293 | train | INFO | Epoch 11 train batch 296/450: 4736/7200 mean loss: 0.0014068904565647244 score: 1.0
2021-08-08 04:50:34,111 | train | INFO | Epoch 11 train batch 297/450: 4752/7200 mean loss: 0.00132509577088058 score: 1.0
2021-08-08 04:50:34,906 | train | INFO | Epoch 11 train batch 298/450: 4768/7200 mean loss: 0.0012972421245649457 score: 1.0
2021-08-08 04:50:35,691 | train | INFO | Epoch 11 train batch 299/450: 4784/7200 mean loss: 0.00131205131765455 score: 1.0
2021-08-08 04:50:36,469 | train | INFO | Epoch 11 train batch 300/450: 4800/7200 mean loss: 0.001661184593103826 score: 1.0
2021-08-08 04:50:37,244 | train | INFO | Epoch 11 train batch 301/450: 4816/7200 mean loss: 0.001565806451253593 score: 1.0
2021-08-08 04:50:38,063 | train | INFO | Epoch 11 train batch 302/450: 4832/7200 mean loss: 0.001437016180716455 score: 1.0
2021-08-08 04:50:38,877 | train | INFO | Epoch 11 train batch 303/450: 4848/7200 mean loss: 0.001504504936747253 score: 1.0
2021-08-08 04:50:39,648 | train | INFO | Epoch 11 train batch 304/450: 4864/7200 mean loss: 0.0015025017783045769 score: 1.0
2021-08-08 04:50:40,420 | train | INFO | Epoch 11 train batch 305/450: 4880/7200 mean loss: 0.0012409092159941792 score: 1.0
2021-08-08 04:50:41,194 | train | INFO | Epoch 11 train batch 306/450: 4896/7200 mean loss: 0.0016361444722861052 score: 1.0
2021-08-08 04:50:41,968 | train | INFO | Epoch 11 train batch 307/450: 4912/7200 mean loss: 0.0016516160685569048 score: 1.0
2021-08-08 04:50:42,793 | train | INFO | Epoch 11 train batch 308/450: 4928/7200 mean loss: 0.0015737147768959403 score: 1.0
2021-08-08 04:50:43,596 | train | INFO | Epoch 11 train batch 309/450: 4944/7200 mean loss: 0.0013473170110955834 score: 1.0
2021-08-08 04:50:44,375 | train | INFO | Epoch 11 train batch 310/450: 4960/7200 mean loss: 0.0014801323413848877 score: 1.0
2021-08-08 04:50:45,160 | train | INFO | Epoch 11 train batch 311/450: 4976/7200 mean loss: 0.0015635112067684531 score: 0.9889705882352942
2021-08-08 04:50:45,981 | train | INFO | Epoch 11 train batch 312/450: 4992/7200 mean loss: 0.0013947697589173913 score: 1.0
2021-08-08 04:50:46,810 | train | INFO | Epoch 11 train batch 313/450: 5008/7200 mean loss: 0.0013428754173219204 score: 1.0
2021-08-08 04:50:47,588 | train | INFO | Epoch 11 train batch 314/450: 5024/7200 mean loss: 0.0013676428934559226 score: 0.9963235294117647
2021-08-08 04:50:48,358 | train | INFO | Epoch 11 train batch 315/450: 5040/7200 mean loss: 0.0015670371940359473 score: 1.0
2021-08-08 04:50:49,152 | train | INFO | Epoch 11 train batch 316/450: 5056/7200 mean loss: 0.0012595121515914798 score: 1.0
2021-08-08 04:50:49,927 | train | INFO | Epoch 11 train batch 317/450: 5072/7200 mean loss: 0.0012148180976510048 score: 1.0
2021-08-08 04:50:50,706 | train | INFO | Epoch 11 train batch 318/450: 5088/7200 mean loss: 0.0015604115324094892 score: 1.0
2021-08-08 04:50:51,579 | train | INFO | Epoch 11 train batch 319/450: 5104/7200 mean loss: 0.001549373148009181 score: 0.9963235294117647
2021-08-08 04:50:52,358 | train | INFO | Epoch 11 train batch 320/450: 5120/7200 mean loss: 0.0016752054216340184 score: 1.0
2021-08-08 04:50:53,144 | train | INFO | Epoch 11 train batch 321/450: 5136/7200 mean loss: 0.001540491241030395 score: 1.0
2021-08-08 04:50:53,918 | train | INFO | Epoch 11 train batch 322/450: 5152/7200 mean loss: 0.0016338450368493795 score: 1.0
2021-08-08 04:50:54,743 | train | INFO | Epoch 11 train batch 323/450: 5168/7200 mean loss: 0.0015680185751989484 score: 1.0
2021-08-08 04:50:55,533 | train | INFO | Epoch 11 train batch 324/450: 5184/7200 mean loss: 0.0013025697553530335 score: 1.0
2021-08-08 04:50:56,379 | train | INFO | Epoch 11 train batch 325/450: 5200/7200 mean loss: 0.0013545788824558258 score: 1.0
2021-08-08 04:50:57,150 | train | INFO | Epoch 11 train batch 326/450: 5216/7200 mean loss: 0.0014039616798982024 score: 0.9963235294117647
2021-08-08 04:50:57,923 | train | INFO | Epoch 11 train batch 327/450: 5232/7200 mean loss: 0.0013125808909535408 score: 1.0
2021-08-08 04:50:58,741 | train | INFO | Epoch 11 train batch 328/450: 5248/7200 mean loss: 0.001497536664828658 score: 0.0
2021-08-08 04:50:59,519 | train | INFO | Epoch 11 train batch 329/450: 5264/7200 mean loss: 0.001360353548079729 score: 0.9926470588235294
2021-08-08 04:51:00,295 | train | INFO | Epoch 11 train batch 330/450: 5280/7200 mean loss: 0.0014433363685384393 score: 0.9963235294117647
2021-08-08 04:51:01,112 | train | INFO | Epoch 11 train batch 331/450: 5296/7200 mean loss: 0.0013555128825828433 score: 1.0
2021-08-08 04:51:01,891 | train | INFO | Epoch 11 train batch 332/450: 5312/7200 mean loss: 0.001272849622182548 score: 1.0
2021-08-08 04:51:02,661 | train | INFO | Epoch 11 train batch 333/450: 5328/7200 mean loss: 0.0015240693464875221 score: 1.0
2021-08-08 04:51:03,449 | train | INFO | Epoch 11 train batch 334/450: 5344/7200 mean loss: 0.0014702621847391129 score: 1.0
2021-08-08 04:51:04,264 | train | INFO | Epoch 11 train batch 335/450: 5360/7200 mean loss: 0.0014876864152029157 score: 1.0
2021-08-08 04:51:05,049 | train | INFO | Epoch 11 train batch 336/450: 5376/7200 mean loss: 0.001407165196724236 score: 0.996078431372549
2021-08-08 04:51:05,851 | train | INFO | Epoch 11 train batch 337/450: 5392/7200 mean loss: 0.0013053815346211195 score: 1.0
2021-08-08 04:51:06,621 | train | INFO | Epoch 11 train batch 338/450: 5408/7200 mean loss: 0.0013625100255012512 score: 1.0
2021-08-08 04:51:07,416 | train | INFO | Epoch 11 train batch 339/450: 5424/7200 mean loss: 0.001536173396743834 score: 1.0
2021-08-08 04:51:08,238 | train | INFO | Epoch 11 train batch 340/450: 5440/7200 mean loss: 0.0014274519635364413 score: 1.0
2021-08-08 04:51:09,073 | train | INFO | Epoch 11 train batch 341/450: 5456/7200 mean loss: 0.0015475432155653834 score: 1.0
2021-08-08 04:51:09,846 | train | INFO | Epoch 11 train batch 342/450: 5472/7200 mean loss: 0.0017063259147107601 score: 1.0
2021-08-08 04:51:10,625 | train | INFO | Epoch 11 train batch 343/450: 5488/7200 mean loss: 0.0015662751393392682 score: 1.0
2021-08-08 04:51:11,428 | train | INFO | Epoch 11 train batch 344/450: 5504/7200 mean loss: 0.0014731584815308452 score: 1.0
2021-08-08 04:51:12,208 | train | INFO | Epoch 11 train batch 345/450: 5520/7200 mean loss: 0.0016338146524503827 score: 1.0
2021-08-08 04:51:12,982 | train | INFO | Epoch 11 train batch 346/450: 5536/7200 mean loss: 0.0015099021838977933 score: 1.0
2021-08-08 04:51:13,818 | train | INFO | Epoch 11 train batch 347/450: 5552/7200 mean loss: 0.0016465160297229886 score: 1.0
2021-08-08 04:51:14,628 | train | INFO | Epoch 11 train batch 348/450: 5568/7200 mean loss: 0.0015114895068109035 score: 1.0
2021-08-08 04:51:15,447 | train | INFO | Epoch 11 train batch 349/450: 5584/7200 mean loss: 0.0014554442605003715 score: 1.0
2021-08-08 04:51:16,251 | train | INFO | Epoch 11 train batch 350/450: 5600/7200 mean loss: 0.0016638837987557054 score: 1.0
2021-08-08 04:51:17,042 | train | INFO | Epoch 11 train batch 351/450: 5616/7200 mean loss: 0.0014021714450791478 score: 0.9850490196078432
2021-08-08 04:51:17,829 | train | INFO | Epoch 11 train batch 352/450: 5632/7200 mean loss: 0.0013797307619825006 score: 1.0
2021-08-08 04:51:18,614 | train | INFO | Epoch 11 train batch 353/450: 5648/7200 mean loss: 0.001282097538933158 score: 1.0
2021-08-08 04:51:19,431 | train | INFO | Epoch 11 train batch 354/450: 5664/7200 mean loss: 0.0014010033337399364 score: 1.0
2021-08-08 04:51:20,252 | train | INFO | Epoch 11 train batch 355/450: 5680/7200 mean loss: 0.001266622799448669 score: 1.0
2021-08-08 04:51:21,047 | train | INFO | Epoch 11 train batch 356/450: 5696/7200 mean loss: 0.0013818562729284167 score: 1.0
2021-08-08 04:51:21,867 | train | INFO | Epoch 11 train batch 357/450: 5712/7200 mean loss: 0.0013372936518862844 score: 1.0
2021-08-08 04:51:22,646 | train | INFO | Epoch 11 train batch 358/450: 5728/7200 mean loss: 0.0015103474725037813 score: 1.0
2021-08-08 04:51:23,466 | train | INFO | Epoch 11 train batch 359/450: 5744/7200 mean loss: 0.001439901301637292 score: 1.0
2021-08-08 04:51:24,289 | train | INFO | Epoch 11 train batch 360/450: 5760/7200 mean loss: 0.001565067213959992 score: 1.0
2021-08-08 04:51:25,096 | train | INFO | Epoch 11 train batch 361/450: 5776/7200 mean loss: 0.0015820603584870696 score: 1.0
2021-08-08 04:51:25,901 | train | INFO | Epoch 11 train batch 362/450: 5792/7200 mean loss: 0.0015992526896297932 score: 0.9963235294117647
2021-08-08 04:51:26,757 | train | INFO | Epoch 11 train batch 363/450: 5808/7200 mean loss: 0.00148729607462883 score: 0.9879201680672269
2021-08-08 04:51:27,579 | train | INFO | Epoch 11 train batch 364/450: 5824/7200 mean loss: 0.001455516554415226 score: 1.0
2021-08-08 04:51:28,366 | train | INFO | Epoch 11 train batch 365/450: 5840/7200 mean loss: 0.0014813243178650737 score: 1.0
2021-08-08 04:51:29,161 | train | INFO | Epoch 11 train batch 366/450: 5856/7200 mean loss: 0.0016857454320415854 score: 1.0
2021-08-08 04:51:29,967 | train | INFO | Epoch 11 train batch 367/450: 5872/7200 mean loss: 0.0014393060700967908 score: 1.0
2021-08-08 04:51:30,742 | train | INFO | Epoch 11 train batch 368/450: 5888/7200 mean loss: 0.0014918759698048234 score: 1.0
2021-08-08 04:51:31,562 | train | INFO | Epoch 11 train batch 369/450: 5904/7200 mean loss: 0.0015329055022448301 score: 1.0
2021-08-08 04:51:32,338 | train | INFO | Epoch 11 train batch 370/450: 5920/7200 mean loss: 0.0014438533689826727 score: 1.0
2021-08-08 04:51:33,139 | train | INFO | Epoch 11 train batch 371/450: 5936/7200 mean loss: 0.001511675538495183 score: 0.899264705882353
2021-08-08 04:51:33,917 | train | INFO | Epoch 11 train batch 372/450: 5952/7200 mean loss: 0.0015655173920094967 score: 1.0
2021-08-08 04:51:34,714 | train | INFO | Epoch 11 train batch 373/450: 5968/7200 mean loss: 0.0013072394067421556 score: 1.0
2021-08-08 04:51:35,509 | train | INFO | Epoch 11 train batch 374/450: 5984/7200 mean loss: 0.0014160687569528818 score: 0.9688914027149321
2021-08-08 04:51:36,298 | train | INFO | Epoch 11 train batch 375/450: 6000/7200 mean loss: 0.0011797279585152864 score: 0.9963235294117647
2021-08-08 04:51:37,138 | train | INFO | Epoch 11 train batch 376/450: 6016/7200 mean loss: 0.0012831958010792732 score: 1.0
2021-08-08 04:51:37,927 | train | INFO | Epoch 11 train batch 377/450: 6032/7200 mean loss: 0.0015054336981847882 score: 1.0
2021-08-08 04:51:38,693 | train | INFO | Epoch 11 train batch 378/450: 6048/7200 mean loss: 0.0013881161576136947 score: 0.9926470588235294
2021-08-08 04:51:39,462 | train | INFO | Epoch 11 train batch 379/450: 6064/7200 mean loss: 0.0013616039650514722 score: 1.0
2021-08-08 04:51:40,232 | train | INFO | Epoch 11 train batch 380/450: 6080/7200 mean loss: 0.001340988790616393 score: 0.8529411764705881
2021-08-08 04:51:41,003 | train | INFO | Epoch 11 train batch 381/450: 6096/7200 mean loss: 0.0012009229976683855 score: 1.0
2021-08-08 04:51:41,788 | train | INFO | Epoch 11 train batch 382/450: 6112/7200 mean loss: 0.0013273349031805992 score: 0.9811274509803922
2021-08-08 04:51:42,598 | train | INFO | Epoch 11 train batch 383/450: 6128/7200 mean loss: 0.0014587631449103355 score: 1.0
2021-08-08 04:51:43,365 | train | INFO | Epoch 11 train batch 384/450: 6144/7200 mean loss: 0.001637371489778161 score: 1.0
2021-08-08 04:51:44,137 | train | INFO | Epoch 11 train batch 385/450: 6160/7200 mean loss: 0.001724195433780551 score: 1.0
2021-08-08 04:51:44,912 | train | INFO | Epoch 11 train batch 386/450: 6176/7200 mean loss: 0.0014354336308315396 score: 0.9963235294117647
2021-08-08 04:51:45,692 | train | INFO | Epoch 11 train batch 387/450: 6192/7200 mean loss: 0.001763814245350659 score: 1.0
2021-08-08 04:51:46,544 | train | INFO | Epoch 11 train batch 388/450: 6208/7200 mean loss: 0.001642941264435649 score: 0.996078431372549
2021-08-08 04:51:47,335 | train | INFO | Epoch 11 train batch 389/450: 6224/7200 mean loss: 0.0017109395703300834 score: 0.996078431372549
2021-08-08 04:51:48,115 | train | INFO | Epoch 11 train batch 390/450: 6240/7200 mean loss: 0.0014270722167566419 score: 1.0
2021-08-08 04:51:48,891 | train | INFO | Epoch 11 train batch 391/450: 6256/7200 mean loss: 0.0013950070133432746 score: 1.0
2021-08-08 04:51:49,662 | train | INFO | Epoch 11 train batch 392/450: 6272/7200 mean loss: 0.001130954478867352 score: 0.9963235294117647
2021-08-08 04:51:50,433 | train | INFO | Epoch 11 train batch 393/450: 6288/7200 mean loss: 0.0014436568599194288 score: 1.0
2021-08-08 04:51:51,273 | train | INFO | Epoch 11 train batch 394/450: 6304/7200 mean loss: 0.0012321529211476445 score: 1.0
2021-08-08 04:51:52,054 | train | INFO | Epoch 11 train batch 395/450: 6320/7200 mean loss: 0.0012149407994002104 score: 1.0
2021-08-08 04:51:52,836 | train | INFO | Epoch 11 train batch 396/450: 6336/7200 mean loss: 0.0015697604976594448 score: 1.0
2021-08-08 04:51:53,616 | train | INFO | Epoch 11 train batch 397/450: 6352/7200 mean loss: 0.0016985991969704628 score: 0.703921568627451
2021-08-08 04:51:54,418 | train | INFO | Epoch 11 train batch 398/450: 6368/7200 mean loss: 0.0015515502309426665 score: 0.9921218487394957
2021-08-08 04:51:55,195 | train | INFO | Epoch 11 train batch 399/450: 6384/7200 mean loss: 0.00137796881608665 score: 0.9887254901960785
2021-08-08 04:51:55,976 | train | INFO | Epoch 11 train batch 400/450: 6400/7200 mean loss: 0.001472364878281951 score: 0.9884803921568628
2021-08-08 04:51:56,758 | train | INFO | Epoch 11 train batch 401/450: 6416/7200 mean loss: 0.0015156406443566084 score: 0.9813725490196079
2021-08-08 04:51:57,551 | train | INFO | Epoch 11 train batch 402/450: 6432/7200 mean loss: 0.0012071292148903012 score: 1.0
2021-08-08 04:51:58,328 | train | INFO | Epoch 11 train batch 403/450: 6448/7200 mean loss: 0.0012904680334031582 score: 1.0
2021-08-08 04:51:59,100 | train | INFO | Epoch 11 train batch 404/450: 6464/7200 mean loss: 0.0012271048035472631 score: 1.0
2021-08-08 04:51:59,923 | train | INFO | Epoch 11 train batch 405/450: 6480/7200 mean loss: 0.0013987395213916898 score: 1.0
2021-08-08 04:52:00,709 | train | INFO | Epoch 11 train batch 406/450: 6496/7200 mean loss: 0.0012729563750326633 score: 1.0
2021-08-08 04:52:01,491 | train | INFO | Epoch 11 train batch 407/450: 6512/7200 mean loss: 0.0015505513874813914 score: 1.0
2021-08-08 04:52:02,272 | train | INFO | Epoch 11 train batch 408/450: 6528/7200 mean loss: 0.0013731207000091672 score: 1.0
2021-08-08 04:52:03,057 | train | INFO | Epoch 11 train batch 409/450: 6544/7200 mean loss: 0.0014004799304530025 score: 1.0
2021-08-08 04:52:03,827 | train | INFO | Epoch 11 train batch 410/450: 6560/7200 mean loss: 0.0013246003072708845 score: 0.9963235294117647
2021-08-08 04:52:04,630 | train | INFO | Epoch 11 train batch 411/450: 6576/7200 mean loss: 0.001414379570633173 score: 1.0
2021-08-08 04:52:05,446 | train | INFO | Epoch 11 train batch 412/450: 6592/7200 mean loss: 0.001352563500404358 score: 0.9963235294117647
2021-08-08 04:52:06,223 | train | INFO | Epoch 11 train batch 413/450: 6608/7200 mean loss: 0.001366201089695096 score: 1.0
2021-08-08 04:52:07,002 | train | INFO | Epoch 11 train batch 414/450: 6624/7200 mean loss: 0.001532569993287325 score: 0.9963235294117647
2021-08-08 04:52:07,779 | train | INFO | Epoch 11 train batch 415/450: 6640/7200 mean loss: 0.0013502193614840508 score: 0.9774509803921569
2021-08-08 04:52:08,564 | train | INFO | Epoch 11 train batch 416/450: 6656/7200 mean loss: 0.0014071346959099174 score: 1.0
2021-08-08 04:52:09,399 | train | INFO | Epoch 11 train batch 417/450: 6672/7200 mean loss: 0.0014680558815598488 score: 1.0
2021-08-08 04:52:10,179 | train | INFO | Epoch 11 train batch 418/450: 6688/7200 mean loss: 0.0015075014671310782 score: 1.0
2021-08-08 04:52:10,951 | train | INFO | Epoch 11 train batch 419/450: 6704/7200 mean loss: 0.0013830867828801274 score: 1.0
2021-08-08 04:52:11,734 | train | INFO | Epoch 11 train batch 420/450: 6720/7200 mean loss: 0.001571891363710165 score: 0.9779411764705882
2021-08-08 04:52:12,554 | train | INFO | Epoch 11 train batch 421/450: 6736/7200 mean loss: 0.0014272488187998533 score: 1.0
2021-08-08 04:52:13,353 | train | INFO | Epoch 11 train batch 422/450: 6752/7200 mean loss: 0.0016905396478250623 score: 1.0
2021-08-08 04:52:14,151 | train | INFO | Epoch 11 train batch 423/450: 6768/7200 mean loss: 0.0014093865174800158 score: 1.0
2021-08-08 04:52:14,960 | train | INFO | Epoch 11 train batch 424/450: 6784/7200 mean loss: 0.0015008372720330954 score: 1.0
2021-08-08 04:52:15,757 | train | INFO | Epoch 11 train batch 425/450: 6800/7200 mean loss: 0.0015758420340716839 score: 1.0
2021-08-08 04:52:16,531 | train | INFO | Epoch 11 train batch 426/450: 6816/7200 mean loss: 0.0013592299073934555 score: 0.9924019607843138
2021-08-08 04:52:17,302 | train | INFO | Epoch 11 train batch 427/450: 6832/7200 mean loss: 0.0015544220805168152 score: 1.0
2021-08-08 04:52:18,080 | train | INFO | Epoch 11 train batch 428/450: 6848/7200 mean loss: 0.0015061908634379506 score: 0.9921568627450981
2021-08-08 04:52:18,901 | train | INFO | Epoch 11 train batch 429/450: 6864/7200 mean loss: 0.0016623964766040444 score: 1.0
2021-08-08 04:52:19,697 | train | INFO | Epoch 11 train batch 430/450: 6880/7200 mean loss: 0.0014652281533926725 score: 1.0
2021-08-08 04:52:20,514 | train | INFO | Epoch 11 train batch 431/450: 6896/7200 mean loss: 0.0016110159922391176 score: 0.9926470588235294
2021-08-08 04:52:21,340 | train | INFO | Epoch 11 train batch 432/450: 6912/7200 mean loss: 0.0014338995097205043 score: 1.0
2021-08-08 04:52:22,150 | train | INFO | Epoch 11 train batch 433/450: 6928/7200 mean loss: 0.0013859606115147471 score: 1.0
2021-08-08 04:52:22,958 | train | INFO | Epoch 11 train batch 434/450: 6944/7200 mean loss: 0.0014651850797235966 score: 1.0
2021-08-08 04:52:23,737 | train | INFO | Epoch 11 train batch 435/450: 6960/7200 mean loss: 0.0016764601459726691 score: 1.0
2021-08-08 04:52:24,561 | train | INFO | Epoch 11 train batch 436/450: 6976/7200 mean loss: 0.0016614155611023307 score: 0.9926470588235294
2021-08-08 04:52:25,343 | train | INFO | Epoch 11 train batch 437/450: 6992/7200 mean loss: 0.0014482977567240596 score: 1.0
2021-08-08 04:52:26,132 | train | INFO | Epoch 11 train batch 438/450: 7008/7200 mean loss: 0.0016457270830869675 score: 1.0
2021-08-08 04:52:26,921 | train | INFO | Epoch 11 train batch 439/450: 7024/7200 mean loss: 0.0017095220973715186 score: 1.0
2021-08-08 04:52:27,691 | train | INFO | Epoch 11 train batch 440/450: 7040/7200 mean loss: 0.001524351886473596 score: 0.9779411764705882
2021-08-08 04:52:28,462 | train | INFO | Epoch 11 train batch 441/450: 7056/7200 mean loss: 0.0013583707623183727 score: 0.996078431372549
2021-08-08 04:52:29,231 | train | INFO | Epoch 11 train batch 442/450: 7072/7200 mean loss: 0.0015719948569312692 score: 1.0
2021-08-08 04:52:30,001 | train | INFO | Epoch 11 train batch 443/450: 7088/7200 mean loss: 0.001592362066730857 score: 1.0
2021-08-08 04:52:30,780 | train | INFO | Epoch 11 train batch 444/450: 7104/7200 mean loss: 0.0014721208717674017 score: 0.9629901960784314
2021-08-08 04:52:31,548 | train | INFO | Epoch 11 train batch 445/450: 7120/7200 mean loss: 0.0013961944496259093 score: 1.0
2021-08-08 04:52:32,316 | train | INFO | Epoch 11 train batch 446/450: 7136/7200 mean loss: 0.0013509514974430203 score: 1.0
2021-08-08 04:52:33,084 | train | INFO | Epoch 11 train batch 447/450: 7152/7200 mean loss: 0.0014202840393409133 score: 1.0
2021-08-08 04:52:33,858 | train | INFO | Epoch 11 train batch 448/450: 7168/7200 mean loss: 0.001179637387394905 score: 1.0
2021-08-08 04:52:34,628 | train | INFO | Epoch 11 train batch 449/450: 7184/7200 mean loss: 0.0016536071198061109 score: 1.0
2021-08-08 04:52:34,767 | train | INFO | Epoch 11, Train, Mean loss: 0.02329812162866195, Score: 0.9933080693815988
2021-08-08 04:52:36,225 | train | INFO | Epoch 11 validation batch 0/113: 0/1800 mean loss: 0.0010080907959491014 score: 1.0
2021-08-08 04:52:36,469 | train | INFO | Epoch 11 validation batch 1/113: 16/1800 mean loss: 0.0010144059779122472 score: 0.9963235294117647
2021-08-08 04:52:36,706 | train | INFO | Epoch 11 validation batch 2/113: 32/1800 mean loss: 0.0013022188795730472 score: 1.0
2021-08-08 04:52:36,945 | train | INFO | Epoch 11 validation batch 3/113: 48/1800 mean loss: 0.0011042607948184013 score: 1.0
2021-08-08 04:52:37,206 | train | INFO | Epoch 11 validation batch 4/113: 64/1800 mean loss: 0.0009962155018001795 score: 1.0
2021-08-08 04:52:37,436 | train | INFO | Epoch 11 validation batch 5/113: 80/1800 mean loss: 0.0009836371755227447 score: 1.0
2021-08-08 04:52:37,683 | train | INFO | Epoch 11 validation batch 6/113: 96/1800 mean loss: 0.0009332510526292026 score: 1.0
2021-08-08 04:52:37,915 | train | INFO | Epoch 11 validation batch 7/113: 112/1800 mean loss: 0.0010825921781361103 score: 1.0
2021-08-08 04:52:38,155 | train | INFO | Epoch 11 validation batch 8/113: 128/1800 mean loss: 0.0010529131395742297 score: 1.0
2021-08-08 04:52:38,393 | train | INFO | Epoch 11 validation batch 9/113: 144/1800 mean loss: 0.0010446305386722088 score: 1.0
2021-08-08 04:52:38,640 | train | INFO | Epoch 11 validation batch 10/113: 160/1800 mean loss: 0.0010995263000950217 score: 0.9816176470588235
2021-08-08 04:52:38,872 | train | INFO | Epoch 11 validation batch 11/113: 176/1800 mean loss: 0.0010855860309675336 score: 0.9963235294117647
2021-08-08 04:52:39,124 | train | INFO | Epoch 11 validation batch 12/113: 192/1800 mean loss: 0.0010434825671836734 score: 1.0
2021-08-08 04:52:39,374 | train | INFO | Epoch 11 validation batch 13/113: 208/1800 mean loss: 0.0009639818454161286 score: 1.0
2021-08-08 04:52:39,620 | train | INFO | Epoch 11 validation batch 14/113: 224/1800 mean loss: 0.000884176348336041 score: 1.0
2021-08-08 04:52:39,880 | train | INFO | Epoch 11 validation batch 15/113: 240/1800 mean loss: 0.0010475683957338333 score: 1.0
2021-08-08 04:52:40,131 | train | INFO | Epoch 11 validation batch 16/113: 256/1800 mean loss: 0.001043651020154357 score: 1.0
2021-08-08 04:52:40,364 | train | INFO | Epoch 11 validation batch 17/113: 272/1800 mean loss: 0.0011478036176413298 score: 1.0
2021-08-08 04:52:40,606 | train | INFO | Epoch 11 validation batch 18/113: 288/1800 mean loss: 0.0008151354850269854 score: 1.0
2021-08-08 04:52:40,842 | train | INFO | Epoch 11 validation batch 19/113: 304/1800 mean loss: 0.0010273567168042064 score: 1.0
2021-08-08 04:52:41,073 | train | INFO | Epoch 11 validation batch 20/113: 320/1800 mean loss: 0.0011300903279334307 score: 0.9926470588235294
2021-08-08 04:52:41,349 | train | INFO | Epoch 11 validation batch 21/113: 336/1800 mean loss: 0.0009977651061490178 score: 1.0
2021-08-08 04:52:41,596 | train | INFO | Epoch 11 validation batch 22/113: 352/1800 mean loss: 0.0009919260628521442 score: 1.0
2021-08-08 04:52:41,829 | train | INFO | Epoch 11 validation batch 23/113: 368/1800 mean loss: 0.0009567862725816667 score: 1.0
2021-08-08 04:52:42,066 | train | INFO | Epoch 11 validation batch 24/113: 384/1800 mean loss: 0.0010392185067757964 score: 1.0
2021-08-08 04:52:42,314 | train | INFO | Epoch 11 validation batch 25/113: 400/1800 mean loss: 0.0011197327403351665 score: 1.0
2021-08-08 04:52:42,581 | train | INFO | Epoch 11 validation batch 26/113: 416/1800 mean loss: 0.0008805233519524336 score: 1.0
2021-08-08 04:52:42,826 | train | INFO | Epoch 11 validation batch 27/113: 432/1800 mean loss: 0.0011217521969228983 score: 1.0
2021-08-08 04:52:43,060 | train | INFO | Epoch 11 validation batch 28/113: 448/1800 mean loss: 0.0010152587201446295 score: 1.0
2021-08-08 04:52:43,292 | train | INFO | Epoch 11 validation batch 29/113: 464/1800 mean loss: 0.0010396642610430717 score: 1.0
2021-08-08 04:52:43,529 | train | INFO | Epoch 11 validation batch 30/113: 480/1800 mean loss: 0.0009979924652725458 score: 1.0
2021-08-08 04:52:43,777 | train | INFO | Epoch 11 validation batch 31/113: 496/1800 mean loss: 0.0009853297378867865 score: 1.0
2021-08-08 04:52:44,040 | train | INFO | Epoch 11 validation batch 32/113: 512/1800 mean loss: 0.001080674002878368 score: 1.0
2021-08-08 04:52:44,272 | train | INFO | Epoch 11 validation batch 33/113: 528/1800 mean loss: 0.0009084108169190586 score: 1.0
2021-08-08 04:52:44,503 | train | INFO | Epoch 11 validation batch 34/113: 544/1800 mean loss: 0.000781780865509063 score: 1.0
2021-08-08 04:52:44,733 | train | INFO | Epoch 11 validation batch 35/113: 560/1800 mean loss: 0.001206651097163558 score: 1.0
2021-08-08 04:52:44,983 | train | INFO | Epoch 11 validation batch 36/113: 576/1800 mean loss: 0.0011550771305337548 score: 0.9183823529411765
2021-08-08 04:52:45,216 | train | INFO | Epoch 11 validation batch 37/113: 592/1800 mean loss: 0.0008633900433778763 score: 1.0
2021-08-08 04:52:45,461 | train | INFO | Epoch 11 validation batch 38/113: 608/1800 mean loss: 0.001052925712428987 score: 1.0
2021-08-08 04:52:45,707 | train | INFO | Epoch 11 validation batch 39/113: 624/1800 mean loss: 0.0009974214481189847 score: 1.0
2021-08-08 04:52:45,954 | train | INFO | Epoch 11 validation batch 40/113: 640/1800 mean loss: 0.0010428159730508924 score: 1.0
2021-08-08 04:52:46,238 | train | INFO | Epoch 11 validation batch 41/113: 656/1800 mean loss: 0.0009667770355008543 score: 1.0
2021-08-08 04:52:46,480 | train | INFO | Epoch 11 validation batch 42/113: 672/1800 mean loss: 0.0009851200738921762 score: 0.9963235294117647
2021-08-08 04:52:46,746 | train | INFO | Epoch 11 validation batch 43/113: 688/1800 mean loss: 0.0009761169785633683 score: 1.0
2021-08-08 04:52:46,987 | train | INFO | Epoch 11 validation batch 44/113: 704/1800 mean loss: 0.0012568077072501183 score: 0.9669117647058824
2021-08-08 04:52:47,219 | train | INFO | Epoch 11 validation batch 45/113: 720/1800 mean loss: 0.0010595184285193682 score: 1.0
2021-08-08 04:52:47,450 | train | INFO | Epoch 11 validation batch 46/113: 736/1800 mean loss: 0.0010245388839393854 score: 0.9926470588235294
2021-08-08 04:52:47,689 | train | INFO | Epoch 11 validation batch 47/113: 752/1800 mean loss: 0.0009494473342783749 score: 1.0
2021-08-08 04:52:47,927 | train | INFO | Epoch 11 validation batch 48/113: 768/1800 mean loss: 0.0009635364986024797 score: 1.0
2021-08-08 04:52:48,157 | train | INFO | Epoch 11 validation batch 49/113: 784/1800 mean loss: 0.001045392476953566 score: 1.0
2021-08-08 04:52:48,388 | train | INFO | Epoch 11 validation batch 50/113: 800/1800 mean loss: 0.0009436781401745975 score: 1.0
2021-08-08 04:52:48,620 | train | INFO | Epoch 11 validation batch 51/113: 816/1800 mean loss: 0.0010964657412841916 score: 0.9889705882352942
2021-08-08 04:52:48,863 | train | INFO | Epoch 11 validation batch 52/113: 832/1800 mean loss: 0.0010100742802023888 score: 1.0
2021-08-08 04:52:49,094 | train | INFO | Epoch 11 validation batch 53/113: 848/1800 mean loss: 0.0009758397936820984 score: 1.0
2021-08-08 04:52:49,327 | train | INFO | Epoch 11 validation batch 54/113: 864/1800 mean loss: 0.0009790364420041442 score: 1.0
2021-08-08 04:52:49,584 | train | INFO | Epoch 11 validation batch 55/113: 880/1800 mean loss: 0.0010793086839839816 score: 1.0
2021-08-08 04:52:49,817 | train | INFO | Epoch 11 validation batch 56/113: 896/1800 mean loss: 0.0010390080278739333 score: 1.0
2021-08-08 04:52:50,063 | train | INFO | Epoch 11 validation batch 57/113: 912/1800 mean loss: 0.0010883761569857597 score: 1.0
2021-08-08 04:52:50,305 | train | INFO | Epoch 11 validation batch 58/113: 928/1800 mean loss: 0.0010975943878293037 score: 0.9816176470588235
2021-08-08 04:52:50,547 | train | INFO | Epoch 11 validation batch 59/113: 944/1800 mean loss: 0.001002190401777625 score: 1.0
2021-08-08 04:52:50,785 | train | INFO | Epoch 11 validation batch 60/113: 960/1800 mean loss: 0.000875983911100775 score: 1.0
2021-08-08 04:52:51,022 | train | INFO | Epoch 11 validation batch 61/113: 976/1800 mean loss: 0.0009296509088017046 score: 1.0
2021-08-08 04:52:51,273 | train | INFO | Epoch 11 validation batch 62/113: 992/1800 mean loss: 0.0009775831131264567 score: 1.0
2021-08-08 04:52:51,521 | train | INFO | Epoch 11 validation batch 63/113: 1008/1800 mean loss: 0.0009609904373064637 score: 1.0
2021-08-08 04:52:51,761 | train | INFO | Epoch 11 validation batch 64/113: 1024/1800 mean loss: 0.000999646494165063 score: 1.0
2021-08-08 04:52:51,994 | train | INFO | Epoch 11 validation batch 65/113: 1040/1800 mean loss: 0.0010576708009466529 score: 1.0
2021-08-08 04:52:52,246 | train | INFO | Epoch 11 validation batch 66/113: 1056/1800 mean loss: 0.0010453213471919298 score: 1.0
2021-08-08 04:52:52,479 | train | INFO | Epoch 11 validation batch 67/113: 1072/1800 mean loss: 0.0011310771806165576 score: 1.0
2021-08-08 04:52:52,719 | train | INFO | Epoch 11 validation batch 68/113: 1088/1800 mean loss: 0.0008664533379487693 score: 1.0
2021-08-08 04:52:52,954 | train | INFO | Epoch 11 validation batch 69/113: 1104/1800 mean loss: 0.0009576633456163108 score: 1.0
2021-08-08 04:52:53,204 | train | INFO | Epoch 11 validation batch 70/113: 1120/1800 mean loss: 0.0011878872755914927 score: 0.9963235294117647
2021-08-08 04:52:53,455 | train | INFO | Epoch 11 validation batch 71/113: 1136/1800 mean loss: 0.0009317981894128025 score: 1.0
2021-08-08 04:52:53,688 | train | INFO | Epoch 11 validation batch 72/113: 1152/1800 mean loss: 0.000938965124078095 score: 1.0
2021-08-08 04:52:53,934 | train | INFO | Epoch 11 validation batch 73/113: 1168/1800 mean loss: 0.0011848481371998787 score: 1.0
2021-08-08 04:52:54,168 | train | INFO | Epoch 11 validation batch 74/113: 1184/1800 mean loss: 0.0011094075161963701 score: 1.0
2021-08-08 04:52:54,399 | train | INFO | Epoch 11 validation batch 75/113: 1200/1800 mean loss: 0.0009795448277145624 score: 1.0
2021-08-08 04:52:54,629 | train | INFO | Epoch 11 validation batch 76/113: 1216/1800 mean loss: 0.0008727955282665789 score: 1.0
2021-08-08 04:52:54,860 | train | INFO | Epoch 11 validation batch 77/113: 1232/1800 mean loss: 0.0008572557708248496 score: 1.0
2021-08-08 04:52:55,091 | train | INFO | Epoch 11 validation batch 78/113: 1248/1800 mean loss: 0.0009868900524452329 score: 0.9852941176470589
2021-08-08 04:52:55,348 | train | INFO | Epoch 11 validation batch 79/113: 1264/1800 mean loss: 0.0011426605051383376 score: 0.9921568627450981
2021-08-08 04:52:55,598 | train | INFO | Epoch 11 validation batch 80/113: 1280/1800 mean loss: 0.0011793188750743866 score: 1.0
2021-08-08 04:52:55,837 | train | INFO | Epoch 11 validation batch 81/113: 1296/1800 mean loss: 0.0009989377576857805 score: 1.0
2021-08-08 04:52:56,070 | train | INFO | Epoch 11 validation batch 82/113: 1312/1800 mean loss: 0.0010150157613679767 score: 1.0
2021-08-08 04:52:56,301 | train | INFO | Epoch 11 validation batch 83/113: 1328/1800 mean loss: 0.00113878701813519 score: 1.0
2021-08-08 04:52:56,550 | train | INFO | Epoch 11 validation batch 84/113: 1344/1800 mean loss: 0.0011499981628730893 score: 0.9926470588235294
2021-08-08 04:52:56,781 | train | INFO | Epoch 11 validation batch 85/113: 1360/1800 mean loss: 0.0010521488729864359 score: 1.0
2021-08-08 04:52:57,040 | train | INFO | Epoch 11 validation batch 86/113: 1376/1800 mean loss: 0.0012736722128465772 score: 1.0
2021-08-08 04:52:57,304 | train | INFO | Epoch 11 validation batch 87/113: 1392/1800 mean loss: 0.0011742697097361088 score: 1.0
2021-08-08 04:52:57,539 | train | INFO | Epoch 11 validation batch 88/113: 1408/1800 mean loss: 0.001004128367640078 score: 1.0
2021-08-08 04:52:57,770 | train | INFO | Epoch 11 validation batch 89/113: 1424/1800 mean loss: 0.0008648802759125829 score: 1.0
2021-08-08 04:52:58,001 | train | INFO | Epoch 11 validation batch 90/113: 1440/1800 mean loss: 0.0009480172302573919 score: 1.0
2021-08-08 04:52:58,248 | train | INFO | Epoch 11 validation batch 91/113: 1456/1800 mean loss: 0.0012458328856155276 score: 1.0
2021-08-08 04:52:58,482 | train | INFO | Epoch 11 validation batch 92/113: 1472/1800 mean loss: 0.0009736489155329764 score: 1.0
2021-08-08 04:52:58,720 | train | INFO | Epoch 11 validation batch 93/113: 1488/1800 mean loss: 0.001025739940814674 score: 1.0
2021-08-08 04:52:58,961 | train | INFO | Epoch 11 validation batch 94/113: 1504/1800 mean loss: 0.0009968606755137444 score: 1.0
2021-08-08 04:52:59,206 | train | INFO | Epoch 11 validation batch 95/113: 1520/1800 mean loss: 0.0010664142901077867 score: 1.0
2021-08-08 04:52:59,464 | train | INFO | Epoch 11 validation batch 96/113: 1536/1800 mean loss: 0.0011191569501534104 score: 1.0
2021-08-08 04:52:59,733 | train | INFO | Epoch 11 validation batch 97/113: 1552/1800 mean loss: 0.0010552837047725916 score: 1.0
2021-08-08 04:52:59,986 | train | INFO | Epoch 11 validation batch 98/113: 1568/1800 mean loss: 0.001018146751448512 score: 1.0
2021-08-08 04:53:00,233 | train | INFO | Epoch 11 validation batch 99/113: 1584/1800 mean loss: 0.000978430500254035 score: 1.0
2021-08-08 04:53:00,472 | train | INFO | Epoch 11 validation batch 100/113: 1600/1800 mean loss: 0.0011764756636694074 score: 1.0
2021-08-08 04:53:00,704 | train | INFO | Epoch 11 validation batch 101/113: 1616/1800 mean loss: 0.0009902778547257185 score: 1.0
2021-08-08 04:53:00,934 | train | INFO | Epoch 11 validation batch 102/113: 1632/1800 mean loss: 0.0009333841153420508 score: 1.0
2021-08-08 04:53:01,166 | train | INFO | Epoch 11 validation batch 103/113: 1648/1800 mean loss: 0.000968447420746088 score: 1.0
2021-08-08 04:53:01,397 | train | INFO | Epoch 11 validation batch 104/113: 1664/1800 mean loss: 0.0011182050220668316 score: 1.0
2021-08-08 04:53:01,628 | train | INFO | Epoch 11 validation batch 105/113: 1680/1800 mean loss: 0.0010333972750231624 score: 1.0
2021-08-08 04:53:01,860 | train | INFO | Epoch 11 validation batch 106/113: 1696/1800 mean loss: 0.001045352895744145 score: 1.0
2021-08-08 04:53:02,091 | train | INFO | Epoch 11 validation batch 107/113: 1712/1800 mean loss: 0.0012811925262212753 score: 1.0
2021-08-08 04:53:02,324 | train | INFO | Epoch 11 validation batch 108/113: 1728/1800 mean loss: 0.001252194051630795 score: 1.0
2021-08-08 04:53:02,557 | train | INFO | Epoch 11 validation batch 109/113: 1744/1800 mean loss: 0.0011544040171429515 score: 1.0
2021-08-08 04:53:02,789 | train | INFO | Epoch 11 validation batch 110/113: 1760/1800 mean loss: 0.0009438144625164568 score: 1.0
2021-08-08 04:53:03,026 | train | INFO | Epoch 11 validation batch 111/113: 1776/1800 mean loss: 0.001000010292045772 score: 1.0
2021-08-08 04:53:03,196 | train | INFO | Epoch 11 validation batch 112/113: 1792/1800 mean loss: 0.000938182813115418 score: 1.0
2021-08-08 04:53:03,383 | train | INFO | Epoch 11, Validation, Mean loss: 0.016522848813802796, Score: 0.9980370466770779
2021-08-08 04:53:03,383 | train | INFO | Write row 11
2021-08-08 04:53:06,030 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:53:06,034 | train | INFO | Update best record row 12, checkpoints 0.01659424438149528 -> 0.016522848813802796
2021-08-08 04:53:08,049 | train | INFO | Epoch 12 train batch 0/450: 0/7200 mean loss: 0.0012867413461208344 score: 1.0
2021-08-08 04:53:08,878 | train | INFO | Epoch 12 train batch 1/450: 16/7200 mean loss: 0.0013052783906459808 score: 0.9963235294117647
2021-08-08 04:53:09,681 | train | INFO | Epoch 12 train batch 2/450: 32/7200 mean loss: 0.001446436275728047 score: 1.0
2021-08-08 04:53:10,487 | train | INFO | Epoch 12 train batch 3/450: 48/7200 mean loss: 0.0013177980436012149 score: 1.0
2021-08-08 04:53:11,270 | train | INFO | Epoch 12 train batch 4/450: 64/7200 mean loss: 0.00138662860263139 score: 1.0
2021-08-08 04:53:12,073 | train | INFO | Epoch 12 train batch 5/450: 80/7200 mean loss: 0.0012767623411491513 score: 1.0
2021-08-08 04:53:12,871 | train | INFO | Epoch 12 train batch 6/450: 96/7200 mean loss: 0.001525290310382843 score: 1.0
2021-08-08 04:53:13,645 | train | INFO | Epoch 12 train batch 7/450: 112/7200 mean loss: 0.0017513612983748317 score: 0.9963235294117647
2021-08-08 04:53:14,428 | train | INFO | Epoch 12 train batch 8/450: 128/7200 mean loss: 0.0016160239465534687 score: 0.9963235294117647
2021-08-08 04:53:15,195 | train | INFO | Epoch 12 train batch 9/450: 144/7200 mean loss: 0.0014362698420882225 score: 1.0
2021-08-08 04:53:15,971 | train | INFO | Epoch 12 train batch 10/450: 160/7200 mean loss: 0.001434348989278078 score: 1.0
2021-08-08 04:53:16,752 | train | INFO | Epoch 12 train batch 11/450: 176/7200 mean loss: 0.0014084868598729372 score: 1.0
2021-08-08 04:53:17,525 | train | INFO | Epoch 12 train batch 12/450: 192/7200 mean loss: 0.0015771820908412337 score: 1.0
2021-08-08 04:53:18,301 | train | INFO | Epoch 12 train batch 13/450: 208/7200 mean loss: 0.0015662513906136155 score: 1.0
2021-08-08 04:53:19,082 | train | INFO | Epoch 12 train batch 14/450: 224/7200 mean loss: 0.0013603664701804519 score: 1.0
2021-08-08 04:53:19,857 | train | INFO | Epoch 12 train batch 15/450: 240/7200 mean loss: 0.0016815594863146544 score: 1.0
2021-08-08 04:53:20,635 | train | INFO | Epoch 12 train batch 16/450: 256/7200 mean loss: 0.0015376220690086484 score: 1.0
2021-08-08 04:53:21,435 | train | INFO | Epoch 12 train batch 17/450: 272/7200 mean loss: 0.0013697176473215222 score: 1.0
2021-08-08 04:53:22,220 | train | INFO | Epoch 12 train batch 18/450: 288/7200 mean loss: 0.0014020859962329268 score: 1.0
2021-08-08 04:53:22,998 | train | INFO | Epoch 12 train batch 19/450: 304/7200 mean loss: 0.0015362134436145425 score: 0.996078431372549
2021-08-08 04:53:23,773 | train | INFO | Epoch 12 train batch 20/450: 320/7200 mean loss: 0.001483324682340026 score: 1.0
2021-08-08 04:53:24,549 | train | INFO | Epoch 12 train batch 21/450: 336/7200 mean loss: 0.00165371666662395 score: 1.0
2021-08-08 04:53:25,375 | train | INFO | Epoch 12 train batch 22/450: 352/7200 mean loss: 0.0015718606300652027 score: 1.0
2021-08-08 04:53:26,178 | train | INFO | Epoch 12 train batch 23/450: 368/7200 mean loss: 0.001561635290272534 score: 1.0
2021-08-08 04:53:26,961 | train | INFO | Epoch 12 train batch 24/450: 384/7200 mean loss: 0.001340353861451149 score: 1.0
2021-08-08 04:53:27,730 | train | INFO | Epoch 12 train batch 25/450: 400/7200 mean loss: 0.001357847242616117 score: 1.0
2021-08-08 04:53:28,511 | train | INFO | Epoch 12 train batch 26/450: 416/7200 mean loss: 0.0014966478338465095 score: 1.0
2021-08-08 04:53:29,296 | train | INFO | Epoch 12 train batch 27/450: 432/7200 mean loss: 0.0016059076879173517 score: 1.0
2021-08-08 04:53:30,071 | train | INFO | Epoch 12 train batch 28/450: 448/7200 mean loss: 0.001465700101107359 score: 1.0
2021-08-08 04:53:30,847 | train | INFO | Epoch 12 train batch 29/450: 464/7200 mean loss: 0.0015697079943493009 score: 1.0
2021-08-08 04:53:31,708 | train | INFO | Epoch 12 train batch 30/450: 480/7200 mean loss: 0.0013327008346095681 score: 1.0
2021-08-08 04:53:32,531 | train | INFO | Epoch 12 train batch 31/450: 496/7200 mean loss: 0.0015727601712569594 score: 0.9963235294117647
2021-08-08 04:53:33,315 | train | INFO | Epoch 12 train batch 32/450: 512/7200 mean loss: 0.0016174176707863808 score: 0.9963235294117647
2021-08-08 04:53:34,093 | train | INFO | Epoch 12 train batch 33/450: 528/7200 mean loss: 0.0015562415355816483 score: 1.0
2021-08-08 04:53:34,900 | train | INFO | Epoch 12 train batch 34/450: 544/7200 mean loss: 0.0014728611567988992 score: 1.0
2021-08-08 04:53:35,674 | train | INFO | Epoch 12 train batch 35/450: 560/7200 mean loss: 0.0014596779365092516 score: 1.0
2021-08-08 04:53:36,444 | train | INFO | Epoch 12 train batch 36/450: 576/7200 mean loss: 0.0014115364756435156 score: 1.0
2021-08-08 04:53:37,250 | train | INFO | Epoch 12 train batch 37/450: 592/7200 mean loss: 0.001300404197536409 score: 1.0
2021-08-08 04:53:38,048 | train | INFO | Epoch 12 train batch 38/450: 608/7200 mean loss: 0.0014038096414878964 score: 0.9926470588235294
2021-08-08 04:53:38,843 | train | INFO | Epoch 12 train batch 39/450: 624/7200 mean loss: 0.001386514981277287 score: 1.0
2021-08-08 04:53:39,615 | train | INFO | Epoch 12 train batch 40/450: 640/7200 mean loss: 0.0014415549812838435 score: 1.0
2021-08-08 04:53:40,394 | train | INFO | Epoch 12 train batch 41/450: 656/7200 mean loss: 0.0014291562838479877 score: 0.9448529411764706
2021-08-08 04:53:41,165 | train | INFO | Epoch 12 train batch 42/450: 672/7200 mean loss: 0.0015440831193700433 score: 1.0
2021-08-08 04:53:41,969 | train | INFO | Epoch 12 train batch 43/450: 688/7200 mean loss: 0.0014997102553024888 score: 1.0
2021-08-08 04:53:42,747 | train | INFO | Epoch 12 train batch 44/450: 704/7200 mean loss: 0.001447896589525044 score: 1.0
2021-08-08 04:53:43,527 | train | INFO | Epoch 12 train batch 45/450: 720/7200 mean loss: 0.0014771379064768553 score: 1.0
2021-08-08 04:53:44,332 | train | INFO | Epoch 12 train batch 46/450: 736/7200 mean loss: 0.0014409228460863233 score: 1.0
2021-08-08 04:53:45,157 | train | INFO | Epoch 12 train batch 47/450: 752/7200 mean loss: 0.0014653383987024426 score: 1.0
2021-08-08 04:53:45,932 | train | INFO | Epoch 12 train batch 48/450: 768/7200 mean loss: 0.0013485116651281714 score: 1.0
2021-08-08 04:53:46,711 | train | INFO | Epoch 12 train batch 49/450: 784/7200 mean loss: 0.0012167957611382008 score: 1.0
2021-08-08 04:53:47,520 | train | INFO | Epoch 12 train batch 50/450: 800/7200 mean loss: 0.0013385629281401634 score: 1.0
2021-08-08 04:53:48,415 | train | INFO | Epoch 12 train batch 51/450: 816/7200 mean loss: 0.0013515776954591274 score: 1.0
2021-08-08 04:53:49,210 | train | INFO | Epoch 12 train batch 52/450: 832/7200 mean loss: 0.0012883211020380259 score: 1.0
2021-08-08 04:53:49,987 | train | INFO | Epoch 12 train batch 53/450: 848/7200 mean loss: 0.0015666994731873274 score: 1.0
2021-08-08 04:53:50,764 | train | INFO | Epoch 12 train batch 54/450: 864/7200 mean loss: 0.0014784458326175809 score: 0.9963235294117647
2021-08-08 04:53:51,538 | train | INFO | Epoch 12 train batch 55/450: 880/7200 mean loss: 0.0012067334027960896 score: 0.9852941176470589
2021-08-08 04:53:52,310 | train | INFO | Epoch 12 train batch 56/450: 896/7200 mean loss: 0.0013207312440499663 score: 1.0
2021-08-08 04:53:53,088 | train | INFO | Epoch 12 train batch 57/450: 912/7200 mean loss: 0.0011554249795153737 score: 1.0
2021-08-08 04:53:53,922 | train | INFO | Epoch 12 train batch 58/450: 928/7200 mean loss: 0.001388781238347292 score: 1.0
2021-08-08 04:53:54,721 | train | INFO | Epoch 12 train batch 59/450: 944/7200 mean loss: 0.0011690944666042924 score: 0.9957983193277312
2021-08-08 04:53:55,498 | train | INFO | Epoch 12 train batch 60/450: 960/7200 mean loss: 0.00151596509385854 score: 1.0
2021-08-08 04:53:56,274 | train | INFO | Epoch 12 train batch 61/450: 976/7200 mean loss: 0.0014368309639394283 score: 0.9963235294117647
2021-08-08 04:53:57,046 | train | INFO | Epoch 12 train batch 62/450: 992/7200 mean loss: 0.0014653934631496668 score: 1.0
2021-08-08 04:53:57,873 | train | INFO | Epoch 12 train batch 63/450: 1008/7200 mean loss: 0.001527051324956119 score: 1.0
2021-08-08 04:53:58,676 | train | INFO | Epoch 12 train batch 64/450: 1024/7200 mean loss: 0.0014627096243202686 score: 0.9816176470588235
2021-08-08 04:53:59,477 | train | INFO | Epoch 12 train batch 65/450: 1040/7200 mean loss: 0.0014023022959008813 score: 1.0
2021-08-08 04:54:00,289 | train | INFO | Epoch 12 train batch 66/450: 1056/7200 mean loss: 0.001585505437105894 score: 1.0
2021-08-08 04:54:01,070 | train | INFO | Epoch 12 train batch 67/450: 1072/7200 mean loss: 0.0013475751038640738 score: 1.0
2021-08-08 04:54:01,857 | train | INFO | Epoch 12 train batch 68/450: 1088/7200 mean loss: 0.0012694724136963487 score: 1.0
2021-08-08 04:54:02,639 | train | INFO | Epoch 12 train batch 69/450: 1104/7200 mean loss: 0.0014414713950827718 score: 0.9842436974789917
2021-08-08 04:54:03,454 | train | INFO | Epoch 12 train batch 70/450: 1120/7200 mean loss: 0.0016793370014056563 score: 1.0
2021-08-08 04:54:04,238 | train | INFO | Epoch 12 train batch 71/450: 1136/7200 mean loss: 0.0012563238851726055 score: 1.0
2021-08-08 04:54:05,050 | train | INFO | Epoch 12 train batch 72/450: 1152/7200 mean loss: 0.001321768038906157 score: 1.0
2021-08-08 04:54:05,867 | train | INFO | Epoch 12 train batch 73/450: 1168/7200 mean loss: 0.001551317167468369 score: 0.9963235294117647
2021-08-08 04:54:06,656 | train | INFO | Epoch 12 train batch 74/450: 1184/7200 mean loss: 0.0015951485838741064 score: 1.0
2021-08-08 04:54:07,435 | train | INFO | Epoch 12 train batch 75/450: 1200/7200 mean loss: 0.0014605546602979302 score: 1.0
2021-08-08 04:54:08,232 | train | INFO | Epoch 12 train batch 76/450: 1216/7200 mean loss: 0.0016694356454536319 score: 1.0
2021-08-08 04:54:09,009 | train | INFO | Epoch 12 train batch 77/450: 1232/7200 mean loss: 0.0012676564510911703 score: 1.0
2021-08-08 04:54:09,779 | train | INFO | Epoch 12 train batch 78/450: 1248/7200 mean loss: 0.0013118243077769876 score: 1.0
2021-08-08 04:54:10,604 | train | INFO | Epoch 12 train batch 79/450: 1264/7200 mean loss: 0.0015397329116240144 score: 0.9776960784313725
2021-08-08 04:54:11,406 | train | INFO | Epoch 12 train batch 80/450: 1280/7200 mean loss: 0.001563355908729136 score: 1.0
2021-08-08 04:54:12,232 | train | INFO | Epoch 12 train batch 81/450: 1296/7200 mean loss: 0.0011872894829139113 score: 1.0
2021-08-08 04:54:13,001 | train | INFO | Epoch 12 train batch 82/450: 1312/7200 mean loss: 0.0014863885007798672 score: 0.9963235294117647
2021-08-08 04:54:13,822 | train | INFO | Epoch 12 train batch 83/450: 1328/7200 mean loss: 0.001270347274839878 score: 1.0
2021-08-08 04:54:14,596 | train | INFO | Epoch 12 train batch 84/450: 1344/7200 mean loss: 0.001324575743637979 score: 1.0
2021-08-08 04:54:15,374 | train | INFO | Epoch 12 train batch 85/450: 1360/7200 mean loss: 0.001455181511119008 score: 1.0
2021-08-08 04:54:16,194 | train | INFO | Epoch 12 train batch 86/450: 1376/7200 mean loss: 0.00127703498583287 score: 0.9963235294117647
2021-08-08 04:54:17,022 | train | INFO | Epoch 12 train batch 87/450: 1392/7200 mean loss: 0.0012481645680963993 score: 0.9957983193277312
2021-08-08 04:54:17,826 | train | INFO | Epoch 12 train batch 88/450: 1408/7200 mean loss: 0.0013868474634364247 score: 1.0
2021-08-08 04:54:18,637 | train | INFO | Epoch 12 train batch 89/450: 1424/7200 mean loss: 0.0013144034892320633 score: 1.0
2021-08-08 04:54:19,458 | train | INFO | Epoch 12 train batch 90/450: 1440/7200 mean loss: 0.0014547731261700392 score: 1.0
2021-08-08 04:54:20,261 | train | INFO | Epoch 12 train batch 91/450: 1456/7200 mean loss: 0.0016353476094081998 score: 0.9517156862745099
2021-08-08 04:54:21,030 | train | INFO | Epoch 12 train batch 92/450: 1472/7200 mean loss: 0.001414238940924406 score: 1.0
2021-08-08 04:54:21,804 | train | INFO | Epoch 12 train batch 93/450: 1488/7200 mean loss: 0.0012708317954093218 score: 1.0
2021-08-08 04:54:22,582 | train | INFO | Epoch 12 train batch 94/450: 1504/7200 mean loss: 0.0014658791478723288 score: 1.0
2021-08-08 04:54:23,359 | train | INFO | Epoch 12 train batch 95/450: 1520/7200 mean loss: 0.001311762840487063 score: 1.0
2021-08-08 04:54:24,152 | train | INFO | Epoch 12 train batch 96/450: 1536/7200 mean loss: 0.0014089627657085657 score: 1.0
2021-08-08 04:54:24,921 | train | INFO | Epoch 12 train batch 97/450: 1552/7200 mean loss: 0.001456234254874289 score: 1.0
2021-08-08 04:54:25,705 | train | INFO | Epoch 12 train batch 98/450: 1568/7200 mean loss: 0.0013236760860309005 score: 0.9661764705882353
2021-08-08 04:54:26,491 | train | INFO | Epoch 12 train batch 99/450: 1584/7200 mean loss: 0.0015962960897013545 score: 1.0
2021-08-08 04:54:27,262 | train | INFO | Epoch 12 train batch 100/450: 1600/7200 mean loss: 0.0013706275494769216 score: 1.0
2021-08-08 04:54:28,078 | train | INFO | Epoch 12 train batch 101/450: 1616/7200 mean loss: 0.0014506300212815404 score: 0.9624649859943977
2021-08-08 04:54:28,907 | train | INFO | Epoch 12 train batch 102/450: 1632/7200 mean loss: 0.0015095383860170841 score: 0.9852941176470589
2021-08-08 04:54:29,689 | train | INFO | Epoch 12 train batch 103/450: 1648/7200 mean loss: 0.0013680718839168549 score: 1.0
2021-08-08 04:54:30,489 | train | INFO | Epoch 12 train batch 104/450: 1664/7200 mean loss: 0.001232650363817811 score: 1.0
2021-08-08 04:54:31,304 | train | INFO | Epoch 12 train batch 105/450: 1680/7200 mean loss: 0.0013809212250635028 score: 1.0
2021-08-08 04:54:32,124 | train | INFO | Epoch 12 train batch 106/450: 1696/7200 mean loss: 0.0013563886750489473 score: 1.0
2021-08-08 04:54:32,921 | train | INFO | Epoch 12 train batch 107/450: 1712/7200 mean loss: 0.001522252568975091 score: 0.9963235294117647
2021-08-08 04:54:33,707 | train | INFO | Epoch 12 train batch 108/450: 1728/7200 mean loss: 0.0014792010188102722 score: 0.6507352941176471
2021-08-08 04:54:34,480 | train | INFO | Epoch 12 train batch 109/450: 1744/7200 mean loss: 0.0015794142382219434 score: 1.0
2021-08-08 04:54:35,298 | train | INFO | Epoch 12 train batch 110/450: 1760/7200 mean loss: 0.001492556999437511 score: 1.0
2021-08-08 04:54:36,075 | train | INFO | Epoch 12 train batch 111/450: 1776/7200 mean loss: 0.0014759692130610347 score: 1.0
2021-08-08 04:54:36,854 | train | INFO | Epoch 12 train batch 112/450: 1792/7200 mean loss: 0.0015605984954163432 score: 1.0
2021-08-08 04:54:37,644 | train | INFO | Epoch 12 train batch 113/450: 1808/7200 mean loss: 0.0015263494569808245 score: 0.9850490196078432
2021-08-08 04:54:38,444 | train | INFO | Epoch 12 train batch 114/450: 1824/7200 mean loss: 0.0013995490735396743 score: 0.9963235294117647
2021-08-08 04:54:39,219 | train | INFO | Epoch 12 train batch 115/450: 1840/7200 mean loss: 0.0013505825772881508 score: 1.0
2021-08-08 04:54:40,011 | train | INFO | Epoch 12 train batch 116/450: 1856/7200 mean loss: 0.00144796387758106 score: 1.0
2021-08-08 04:54:40,860 | train | INFO | Epoch 12 train batch 117/450: 1872/7200 mean loss: 0.0013990134466439486 score: 1.0
2021-08-08 04:54:41,669 | train | INFO | Epoch 12 train batch 118/450: 1888/7200 mean loss: 0.0015276430640369654 score: 1.0
2021-08-08 04:54:42,464 | train | INFO | Epoch 12 train batch 119/450: 1904/7200 mean loss: 0.0013562114909291267 score: 1.0
2021-08-08 04:54:43,253 | train | INFO | Epoch 12 train batch 120/450: 1920/7200 mean loss: 0.0014017976354807615 score: 0.9884453781512604
2021-08-08 04:54:44,050 | train | INFO | Epoch 12 train batch 121/450: 1936/7200 mean loss: 0.0014050581958144903 score: 1.0
2021-08-08 04:54:44,867 | train | INFO | Epoch 12 train batch 122/450: 1952/7200 mean loss: 0.0015186561504378915 score: 1.0
2021-08-08 04:54:45,636 | train | INFO | Epoch 12 train batch 123/450: 1968/7200 mean loss: 0.0014605222968384624 score: 1.0
2021-08-08 04:54:46,443 | train | INFO | Epoch 12 train batch 124/450: 1984/7200 mean loss: 0.001361982082016766 score: 1.0
2021-08-08 04:54:47,240 | train | INFO | Epoch 12 train batch 125/450: 2000/7200 mean loss: 0.0014305998338386416 score: 1.0
2021-08-08 04:54:48,051 | train | INFO | Epoch 12 train batch 126/450: 2016/7200 mean loss: 0.001281422097235918 score: 1.0
2021-08-08 04:54:48,828 | train | INFO | Epoch 12 train batch 127/450: 2032/7200 mean loss: 0.0014448033180087805 score: 1.0
2021-08-08 04:54:49,636 | train | INFO | Epoch 12 train batch 128/450: 2048/7200 mean loss: 0.0012749541783705354 score: 1.0
2021-08-08 04:54:50,457 | train | INFO | Epoch 12 train batch 129/450: 2064/7200 mean loss: 0.0013579309452325106 score: 0.9963235294117647
2021-08-08 04:54:51,249 | train | INFO | Epoch 12 train batch 130/450: 2080/7200 mean loss: 0.001488586887717247 score: 1.0
2021-08-08 04:54:52,037 | train | INFO | Epoch 12 train batch 131/450: 2096/7200 mean loss: 0.0015107233775779605 score: 1.0
2021-08-08 04:54:52,823 | train | INFO | Epoch 12 train batch 132/450: 2112/7200 mean loss: 0.0011151331709697843 score: 1.0
2021-08-08 04:54:53,589 | train | INFO | Epoch 12 train batch 133/450: 2128/7200 mean loss: 0.001288924366235733 score: 1.0
2021-08-08 04:54:54,383 | train | INFO | Epoch 12 train batch 134/450: 2144/7200 mean loss: 0.0013902868377044797 score: 1.0
2021-08-08 04:54:55,299 | train | INFO | Epoch 12 train batch 135/450: 2160/7200 mean loss: 0.0015092387329787016 score: 1.0
2021-08-08 04:54:56,132 | train | INFO | Epoch 12 train batch 136/450: 2176/7200 mean loss: 0.00124917842913419 score: 1.0
2021-08-08 04:54:56,901 | train | INFO | Epoch 12 train batch 137/450: 2192/7200 mean loss: 0.0015582895139232278 score: 0.9776960784313725
2021-08-08 04:54:57,718 | train | INFO | Epoch 12 train batch 138/450: 2208/7200 mean loss: 0.0012543509947136045 score: 0.9963235294117647
2021-08-08 04:54:58,530 | train | INFO | Epoch 12 train batch 139/450: 2224/7200 mean loss: 0.0014301578048616648 score: 1.0
2021-08-08 04:54:59,306 | train | INFO | Epoch 12 train batch 140/450: 2240/7200 mean loss: 0.0012956102145835757 score: 1.0
2021-08-08 04:55:00,142 | train | INFO | Epoch 12 train batch 141/450: 2256/7200 mean loss: 0.0013890863629058003 score: 0.9926470588235294
2021-08-08 04:55:00,946 | train | INFO | Epoch 12 train batch 142/450: 2272/7200 mean loss: 0.0013023457722738385 score: 1.0
2021-08-08 04:55:01,829 | train | INFO | Epoch 12 train batch 143/450: 2288/7200 mean loss: 0.0012021290604025126 score: 1.0
2021-08-08 04:55:02,635 | train | INFO | Epoch 12 train batch 144/450: 2304/7200 mean loss: 0.0013761756708845496 score: 0.9889705882352942
2021-08-08 04:55:03,457 | train | INFO | Epoch 12 train batch 145/450: 2320/7200 mean loss: 0.0014138642000034451 score: 1.0
2021-08-08 04:55:04,295 | train | INFO | Epoch 12 train batch 146/450: 2336/7200 mean loss: 0.001237813150510192 score: 1.0
2021-08-08 04:55:05,106 | train | INFO | Epoch 12 train batch 147/450: 2352/7200 mean loss: 0.0013654384529218078 score: 1.0
2021-08-08 04:55:05,897 | train | INFO | Epoch 12 train batch 148/450: 2368/7200 mean loss: 0.0012312585022300482 score: 1.0
2021-08-08 04:55:06,664 | train | INFO | Epoch 12 train batch 149/450: 2384/7200 mean loss: 0.0014586870092898607 score: 1.0
2021-08-08 04:55:07,451 | train | INFO | Epoch 12 train batch 150/450: 2400/7200 mean loss: 0.0015153466956689954 score: 0.9926470588235294
2021-08-08 04:55:08,265 | train | INFO | Epoch 12 train batch 151/450: 2416/7200 mean loss: 0.0014040716923773289 score: 1.0
2021-08-08 04:55:09,093 | train | INFO | Epoch 12 train batch 152/450: 2432/7200 mean loss: 0.001454027253203094 score: 1.0
2021-08-08 04:55:09,879 | train | INFO | Epoch 12 train batch 153/450: 2448/7200 mean loss: 0.001649221871048212 score: 1.0
2021-08-08 04:55:10,660 | train | INFO | Epoch 12 train batch 154/450: 2464/7200 mean loss: 0.001520667807199061 score: 1.0
2021-08-08 04:55:11,467 | train | INFO | Epoch 12 train batch 155/450: 2480/7200 mean loss: 0.0016054592560976744 score: 0.9700630252100839
2021-08-08 04:55:12,247 | train | INFO | Epoch 12 train batch 156/450: 2496/7200 mean loss: 0.0016230229521170259 score: 0.9629901960784314
2021-08-08 04:55:13,027 | train | INFO | Epoch 12 train batch 157/450: 2512/7200 mean loss: 0.0014400655636563897 score: 1.0
2021-08-08 04:55:13,831 | train | INFO | Epoch 12 train batch 158/450: 2528/7200 mean loss: 0.001385374809615314 score: 0.9963235294117647
2021-08-08 04:55:14,631 | train | INFO | Epoch 12 train batch 159/450: 2544/7200 mean loss: 0.0015711844898760319 score: 1.0
2021-08-08 04:55:15,475 | train | INFO | Epoch 12 train batch 160/450: 2560/7200 mean loss: 0.0014990668278187513 score: 0.9963235294117647
2021-08-08 04:55:16,271 | train | INFO | Epoch 12 train batch 161/450: 2576/7200 mean loss: 0.0014797004405409098 score: 1.0
2021-08-08 04:55:17,101 | train | INFO | Epoch 12 train batch 162/450: 2592/7200 mean loss: 0.0016068192198872566 score: 1.0
2021-08-08 04:55:17,888 | train | INFO | Epoch 12 train batch 163/450: 2608/7200 mean loss: 0.0014836128102615476 score: 1.0
2021-08-08 04:55:18,686 | train | INFO | Epoch 12 train batch 164/450: 2624/7200 mean loss: 0.001458256389014423 score: 1.0
2021-08-08 04:55:19,457 | train | INFO | Epoch 12 train batch 165/450: 2640/7200 mean loss: 0.001437272527255118 score: 1.0
2021-08-08 04:55:20,365 | train | INFO | Epoch 12 train batch 166/450: 2656/7200 mean loss: 0.0016032737912610173 score: 1.0
2021-08-08 04:55:21,261 | train | INFO | Epoch 12 train batch 167/450: 2672/7200 mean loss: 0.0015639903722330928 score: 0.9963235294117647
2021-08-08 04:55:22,099 | train | INFO | Epoch 12 train batch 168/450: 2688/7200 mean loss: 0.0014408950228244066 score: 1.0
2021-08-08 04:55:22,878 | train | INFO | Epoch 12 train batch 169/450: 2704/7200 mean loss: 0.0014932338381186128 score: 1.0
2021-08-08 04:55:23,673 | train | INFO | Epoch 12 train batch 170/450: 2720/7200 mean loss: 0.0014109502080827951 score: 1.0
2021-08-08 04:55:24,542 | train | INFO | Epoch 12 train batch 171/450: 2736/7200 mean loss: 0.0014646543422713876 score: 1.0
2021-08-08 04:55:25,324 | train | INFO | Epoch 12 train batch 172/450: 2752/7200 mean loss: 0.001183513319119811 score: 1.0
2021-08-08 04:55:26,120 | train | INFO | Epoch 12 train batch 173/450: 2768/7200 mean loss: 0.0013738434063270688 score: 1.0
2021-08-08 04:55:26,888 | train | INFO | Epoch 12 train batch 174/450: 2784/7200 mean loss: 0.0014153567608445883 score: 1.0
2021-08-08 04:55:27,673 | train | INFO | Epoch 12 train batch 175/450: 2800/7200 mean loss: 0.0014534114161506295 score: 0.9577380952380952
2021-08-08 04:55:28,487 | train | INFO | Epoch 12 train batch 176/450: 2816/7200 mean loss: 0.001407028641551733 score: 1.0
2021-08-08 04:55:29,363 | train | INFO | Epoch 12 train batch 177/450: 2832/7200 mean loss: 0.0015029561473056674 score: 1.0
2021-08-08 04:55:30,138 | train | INFO | Epoch 12 train batch 178/450: 2848/7200 mean loss: 0.0014339926419779658 score: 1.0
2021-08-08 04:55:30,940 | train | INFO | Epoch 12 train batch 179/450: 2864/7200 mean loss: 0.0014163750456646085 score: 1.0
2021-08-08 04:55:31,723 | train | INFO | Epoch 12 train batch 180/450: 2880/7200 mean loss: 0.001364880008623004 score: 0.9227941176470589
2021-08-08 04:55:32,496 | train | INFO | Epoch 12 train batch 181/450: 2896/7200 mean loss: 0.0013301182771101594 score: 0.9963235294117647
2021-08-08 04:55:33,310 | train | INFO | Epoch 12 train batch 182/450: 2912/7200 mean loss: 0.0013956346083432436 score: 1.0
2021-08-08 04:55:34,111 | train | INFO | Epoch 12 train batch 183/450: 2928/7200 mean loss: 0.0012282442767173052 score: 1.0
2021-08-08 04:55:34,884 | train | INFO | Epoch 12 train batch 184/450: 2944/7200 mean loss: 0.0015401010168716311 score: 1.0
2021-08-08 04:55:35,771 | train | INFO | Epoch 12 train batch 185/450: 2960/7200 mean loss: 0.0015392003115266562 score: 1.0
2021-08-08 04:55:36,603 | train | INFO | Epoch 12 train batch 186/450: 2976/7200 mean loss: 0.0014779582852497697 score: 0.9887254901960785
2021-08-08 04:55:37,379 | train | INFO | Epoch 12 train batch 187/450: 2992/7200 mean loss: 0.0014181638834998012 score: 1.0
2021-08-08 04:55:38,165 | train | INFO | Epoch 12 train batch 188/450: 3008/7200 mean loss: 0.001602689502760768 score: 0.9963235294117647
2021-08-08 04:55:38,933 | train | INFO | Epoch 12 train batch 189/450: 3024/7200 mean loss: 0.001542876590974629 score: 0.996078431372549
2021-08-08 04:55:39,710 | train | INFO | Epoch 12 train batch 190/450: 3040/7200 mean loss: 0.0015468804631382227 score: 1.0
2021-08-08 04:55:40,489 | train | INFO | Epoch 12 train batch 191/450: 3056/7200 mean loss: 0.0015136050060391426 score: 1.0
2021-08-08 04:55:41,262 | train | INFO | Epoch 12 train batch 192/450: 3072/7200 mean loss: 0.0012213136069476604 score: 1.0
2021-08-08 04:55:42,038 | train | INFO | Epoch 12 train batch 193/450: 3088/7200 mean loss: 0.001229874207638204 score: 1.0
2021-08-08 04:55:42,846 | train | INFO | Epoch 12 train batch 194/450: 3104/7200 mean loss: 0.0013345900224521756 score: 1.0
2021-08-08 04:55:43,625 | train | INFO | Epoch 12 train batch 195/450: 3120/7200 mean loss: 0.001254692324437201 score: 1.0
2021-08-08 04:55:44,442 | train | INFO | Epoch 12 train batch 196/450: 3136/7200 mean loss: 0.0014322362840175629 score: 0.9963235294117647
2021-08-08 04:55:45,257 | train | INFO | Epoch 12 train batch 197/450: 3152/7200 mean loss: 0.0014884177362546325 score: 1.0
2021-08-08 04:55:46,057 | train | INFO | Epoch 12 train batch 198/450: 3168/7200 mean loss: 0.0014584311284124851 score: 1.0
2021-08-08 04:55:46,941 | train | INFO | Epoch 12 train batch 199/450: 3184/7200 mean loss: 0.001308114849962294 score: 1.0
2021-08-08 04:55:47,716 | train | INFO | Epoch 12 train batch 200/450: 3200/7200 mean loss: 0.0012847739271819592 score: 1.0
2021-08-08 04:55:48,481 | train | INFO | Epoch 12 train batch 201/450: 3216/7200 mean loss: 0.001466212561354041 score: 0.9926470588235294
2021-08-08 04:55:49,249 | train | INFO | Epoch 12 train batch 202/450: 3232/7200 mean loss: 0.001553602167405188 score: 1.0
2021-08-08 04:55:50,046 | train | INFO | Epoch 12 train batch 203/450: 3248/7200 mean loss: 0.0015370756154879928 score: 1.0
2021-08-08 04:55:50,845 | train | INFO | Epoch 12 train batch 204/450: 3264/7200 mean loss: 0.0013925876701250672 score: 0.9926470588235294
2021-08-08 04:55:51,652 | train | INFO | Epoch 12 train batch 205/450: 3280/7200 mean loss: 0.001459180493839085 score: 1.0
2021-08-08 04:55:52,478 | train | INFO | Epoch 12 train batch 206/450: 3296/7200 mean loss: 0.0014305482618510723 score: 1.0
2021-08-08 04:55:53,270 | train | INFO | Epoch 12 train batch 207/450: 3312/7200 mean loss: 0.001339673763141036 score: 1.0
2021-08-08 04:55:54,050 | train | INFO | Epoch 12 train batch 208/450: 3328/7200 mean loss: 0.001386505551636219 score: 1.0
2021-08-08 04:55:54,837 | train | INFO | Epoch 12 train batch 209/450: 3344/7200 mean loss: 0.0016519640339538455 score: 0.9590686274509804
2021-08-08 04:55:55,646 | train | INFO | Epoch 12 train batch 210/450: 3360/7200 mean loss: 0.0016594937769696116 score: 0.9705882352941176
2021-08-08 04:55:56,450 | train | INFO | Epoch 12 train batch 211/450: 3376/7200 mean loss: 0.0014402616070583463 score: 0.9963235294117647
2021-08-08 04:55:57,221 | train | INFO | Epoch 12 train batch 212/450: 3392/7200 mean loss: 0.00149191461969167 score: 1.0
2021-08-08 04:55:57,997 | train | INFO | Epoch 12 train batch 213/450: 3408/7200 mean loss: 0.001668049138970673 score: 1.0
2021-08-08 04:55:58,770 | train | INFO | Epoch 12 train batch 214/450: 3424/7200 mean loss: 0.0014932183548808098 score: 1.0
2021-08-08 04:55:59,558 | train | INFO | Epoch 12 train batch 215/450: 3440/7200 mean loss: 0.0016913395375013351 score: 1.0
2021-08-08 04:56:00,335 | train | INFO | Epoch 12 train batch 216/450: 3456/7200 mean loss: 0.0016759434947744012 score: 1.0
2021-08-08 04:56:01,109 | train | INFO | Epoch 12 train batch 217/450: 3472/7200 mean loss: 0.0016237422823905945 score: 1.0
2021-08-08 04:56:01,893 | train | INFO | Epoch 12 train batch 218/450: 3488/7200 mean loss: 0.0019084031227976084 score: 1.0
2021-08-08 04:56:02,679 | train | INFO | Epoch 12 train batch 219/450: 3504/7200 mean loss: 0.0013440896291285753 score: 1.0
2021-08-08 04:56:03,465 | train | INFO | Epoch 12 train batch 220/450: 3520/7200 mean loss: 0.0016068716067820787 score: 1.0
2021-08-08 04:56:04,249 | train | INFO | Epoch 12 train batch 221/450: 3536/7200 mean loss: 0.0014594942331314087 score: 1.0
2021-08-08 04:56:05,034 | train | INFO | Epoch 12 train batch 222/450: 3552/7200 mean loss: 0.0013648219173774123 score: 1.0
2021-08-08 04:56:05,968 | train | INFO | Epoch 12 train batch 223/450: 3568/7200 mean loss: 0.0012986171059310436 score: 0.9926470588235294
2021-08-08 04:56:06,762 | train | INFO | Epoch 12 train batch 224/450: 3584/7200 mean loss: 0.001406386960297823 score: 1.0
2021-08-08 04:56:07,545 | train | INFO | Epoch 12 train batch 225/450: 3600/7200 mean loss: 0.001286286860704422 score: 1.0
2021-08-08 04:56:08,332 | train | INFO | Epoch 12 train batch 226/450: 3616/7200 mean loss: 0.0014370972057804465 score: 1.0
2021-08-08 04:56:09,128 | train | INFO | Epoch 12 train batch 227/450: 3632/7200 mean loss: 0.0012787373270839453 score: 0.9921568627450981
2021-08-08 04:56:09,935 | train | INFO | Epoch 12 train batch 228/450: 3648/7200 mean loss: 0.0013530310243368149 score: 0.996078431372549
2021-08-08 04:56:10,746 | train | INFO | Epoch 12 train batch 229/450: 3664/7200 mean loss: 0.0014968158211559057 score: 0.9917986425339367
2021-08-08 04:56:11,549 | train | INFO | Epoch 12 train batch 230/450: 3680/7200 mean loss: 0.0012404709123075008 score: 1.0
2021-08-08 04:56:12,348 | train | INFO | Epoch 12 train batch 231/450: 3696/7200 mean loss: 0.0016101315850391984 score: 1.0
2021-08-08 04:56:13,113 | train | INFO | Epoch 12 train batch 232/450: 3712/7200 mean loss: 0.0014230826636776328 score: 1.0
2021-08-08 04:56:13,910 | train | INFO | Epoch 12 train batch 233/450: 3728/7200 mean loss: 0.001424712361767888 score: 1.0
2021-08-08 04:56:14,694 | train | INFO | Epoch 12 train batch 234/450: 3744/7200 mean loss: 0.0013581799576058984 score: 1.0
2021-08-08 04:56:15,524 | train | INFO | Epoch 12 train batch 235/450: 3760/7200 mean loss: 0.0011641550809144974 score: 1.0
2021-08-08 04:56:16,354 | train | INFO | Epoch 12 train batch 236/450: 3776/7200 mean loss: 0.0014960496919229627 score: 1.0
2021-08-08 04:56:17,162 | train | INFO | Epoch 12 train batch 237/450: 3792/7200 mean loss: 0.0012733959592878819 score: 1.0
2021-08-08 04:56:17,953 | train | INFO | Epoch 12 train batch 238/450: 3808/7200 mean loss: 0.0013543502427637577 score: 1.0
2021-08-08 04:56:18,771 | train | INFO | Epoch 12 train batch 239/450: 3824/7200 mean loss: 0.0012724980479106307 score: 0.9963235294117647
2021-08-08 04:56:19,557 | train | INFO | Epoch 12 train batch 240/450: 3840/7200 mean loss: 0.0013566805282607675 score: 1.0
2021-08-08 04:56:20,357 | train | INFO | Epoch 12 train batch 241/450: 3856/7200 mean loss: 0.0015747632132843137 score: 1.0
2021-08-08 04:56:21,132 | train | INFO | Epoch 12 train batch 242/450: 3872/7200 mean loss: 0.001591548090800643 score: 1.0
2021-08-08 04:56:21,898 | train | INFO | Epoch 12 train batch 243/450: 3888/7200 mean loss: 0.0013129563303664327 score: 1.0
2021-08-08 04:56:22,704 | train | INFO | Epoch 12 train batch 244/450: 3904/7200 mean loss: 0.0016017071902751923 score: 1.0
2021-08-08 04:56:23,509 | train | INFO | Epoch 12 train batch 245/450: 3920/7200 mean loss: 0.0015568967210128903 score: 1.0
2021-08-08 04:56:24,297 | train | INFO | Epoch 12 train batch 246/450: 3936/7200 mean loss: 0.0012747022556141019 score: 1.0
2021-08-08 04:56:25,078 | train | INFO | Epoch 12 train batch 247/450: 3952/7200 mean loss: 0.0013096549082547426 score: 1.0
2021-08-08 04:56:25,868 | train | INFO | Epoch 12 train batch 248/450: 3968/7200 mean loss: 0.0014898516237735748 score: 1.0
2021-08-08 04:56:26,684 | train | INFO | Epoch 12 train batch 249/450: 3984/7200 mean loss: 0.0013548885472118855 score: 1.0
2021-08-08 04:56:27,487 | train | INFO | Epoch 12 train batch 250/450: 4000/7200 mean loss: 0.0015010779025033116 score: 0.9963235294117647
2021-08-08 04:56:28,271 | train | INFO | Epoch 12 train batch 251/450: 4016/7200 mean loss: 0.0013396956492215395 score: 1.0
2021-08-08 04:56:29,092 | train | INFO | Epoch 12 train batch 252/450: 4032/7200 mean loss: 0.0015057669952511787 score: 0.9963235294117647
2021-08-08 04:56:29,883 | train | INFO | Epoch 12 train batch 253/450: 4048/7200 mean loss: 0.001323453732766211 score: 1.0
2021-08-08 04:56:30,705 | train | INFO | Epoch 12 train batch 254/450: 4064/7200 mean loss: 0.0014626514166593552 score: 1.0
2021-08-08 04:56:31,483 | train | INFO | Epoch 12 train batch 255/450: 4080/7200 mean loss: 0.0016170109156519175 score: 1.0
2021-08-08 04:56:32,265 | train | INFO | Epoch 12 train batch 256/450: 4096/7200 mean loss: 0.0014633458340540528 score: 1.0
2021-08-08 04:56:33,062 | train | INFO | Epoch 12 train batch 257/450: 4112/7200 mean loss: 0.0014752789866179228 score: 0.9963235294117647
2021-08-08 04:56:33,917 | train | INFO | Epoch 12 train batch 258/450: 4128/7200 mean loss: 0.0016674966318532825 score: 1.0
2021-08-08 04:56:34,689 | train | INFO | Epoch 12 train batch 259/450: 4144/7200 mean loss: 0.0012922725873067975 score: 1.0
2021-08-08 04:56:35,493 | train | INFO | Epoch 12 train batch 260/450: 4160/7200 mean loss: 0.0014585071476176381 score: 1.0
2021-08-08 04:56:36,267 | train | INFO | Epoch 12 train batch 261/450: 4176/7200 mean loss: 0.0013842862099409103 score: 1.0
2021-08-08 04:56:37,072 | train | INFO | Epoch 12 train batch 262/450: 4192/7200 mean loss: 0.0014910678146407008 score: 0.995798319327731
2021-08-08 04:56:37,861 | train | INFO | Epoch 12 train batch 263/450: 4208/7200 mean loss: 0.0016247443854808807 score: 0.9388305322128851
2021-08-08 04:56:38,624 | train | INFO | Epoch 12 train batch 264/450: 4224/7200 mean loss: 0.0012391094351187348 score: 1.0
2021-08-08 04:56:39,411 | train | INFO | Epoch 12 train batch 265/450: 4240/7200 mean loss: 0.0012883167946711183 score: 0.9170518207282914
2021-08-08 04:56:40,199 | train | INFO | Epoch 12 train batch 266/450: 4256/7200 mean loss: 0.0014350448036566377 score: 1.0
2021-08-08 04:56:40,978 | train | INFO | Epoch 12 train batch 267/450: 4272/7200 mean loss: 0.0014830800937488675 score: 1.0
2021-08-08 04:56:41,745 | train | INFO | Epoch 12 train batch 268/450: 4288/7200 mean loss: 0.001526141306385398 score: 0.9669117647058824
2021-08-08 04:56:42,570 | train | INFO | Epoch 12 train batch 269/450: 4304/7200 mean loss: 0.0013780688168480992 score: 1.0
2021-08-08 04:56:43,340 | train | INFO | Epoch 12 train batch 270/450: 4320/7200 mean loss: 0.0015568642411381006 score: 1.0
2021-08-08 04:56:44,114 | train | INFO | Epoch 12 train batch 271/450: 4336/7200 mean loss: 0.0016178881051018834 score: 1.0
2021-08-08 04:56:44,917 | train | INFO | Epoch 12 train batch 272/450: 4352/7200 mean loss: 0.0016095663886517286 score: 1.0
2021-08-08 04:56:45,693 | train | INFO | Epoch 12 train batch 273/450: 4368/7200 mean loss: 0.0014571638312190771 score: 1.0
2021-08-08 04:56:46,474 | train | INFO | Epoch 12 train batch 274/450: 4384/7200 mean loss: 0.0015473916428163648 score: 0.9889705882352942
2021-08-08 04:56:47,254 | train | INFO | Epoch 12 train batch 275/450: 4400/7200 mean loss: 0.0014736473094671965 score: 1.0
2021-08-08 04:56:48,035 | train | INFO | Epoch 12 train batch 276/450: 4416/7200 mean loss: 0.0013614279450848699 score: 1.0
2021-08-08 04:56:48,859 | train | INFO | Epoch 12 train batch 277/450: 4432/7200 mean loss: 0.0014184375759214163 score: 1.0
2021-08-08 04:56:49,652 | train | INFO | Epoch 12 train batch 278/450: 4448/7200 mean loss: 0.0013375550042837858 score: 1.0
2021-08-08 04:56:50,461 | train | INFO | Epoch 12 train batch 279/450: 4464/7200 mean loss: 0.0016066688112914562 score: 1.0
2021-08-08 04:56:51,227 | train | INFO | Epoch 12 train batch 280/450: 4480/7200 mean loss: 0.0013308663619682193 score: 0.9915966386554622
2021-08-08 04:56:51,993 | train | INFO | Epoch 12 train batch 281/450: 4496/7200 mean loss: 0.0015292775351554155 score: 1.0
2021-08-08 04:56:52,760 | train | INFO | Epoch 12 train batch 282/450: 4512/7200 mean loss: 0.0013838001759722829 score: 1.0
2021-08-08 04:56:53,553 | train | INFO | Epoch 12 train batch 283/450: 4528/7200 mean loss: 0.0013771905796602368 score: 1.0
2021-08-08 04:56:54,366 | train | INFO | Epoch 12 train batch 284/450: 4544/7200 mean loss: 0.001423929468728602 score: 0.9629901960784314
2021-08-08 04:56:55,145 | train | INFO | Epoch 12 train batch 285/450: 4560/7200 mean loss: 0.0013427500380203128 score: 1.0
2021-08-08 04:56:55,918 | train | INFO | Epoch 12 train batch 286/450: 4576/7200 mean loss: 0.001301038428209722 score: 1.0
2021-08-08 04:56:56,698 | train | INFO | Epoch 12 train batch 287/450: 4592/7200 mean loss: 0.0015302806859835982 score: 0.9808823529411765
2021-08-08 04:56:57,566 | train | INFO | Epoch 12 train batch 288/450: 4608/7200 mean loss: 0.0014827019767835736 score: 0.9926470588235294
2021-08-08 04:56:58,464 | train | INFO | Epoch 12 train batch 289/450: 4624/7200 mean loss: 0.0014688089722767472 score: 1.0
2021-08-08 04:56:59,246 | train | INFO | Epoch 12 train batch 290/450: 4640/7200 mean loss: 0.0015020525315776467 score: 0.9884803921568628
2021-08-08 04:57:00,028 | train | INFO | Epoch 12 train batch 291/450: 4656/7200 mean loss: 0.0015984417404979467 score: 1.0
2021-08-08 04:57:00,834 | train | INFO | Epoch 12 train batch 292/450: 4672/7200 mean loss: 0.0014399451902136207 score: 0.8259803921568627
2021-08-08 04:57:01,619 | train | INFO | Epoch 12 train batch 293/450: 4688/7200 mean loss: 0.0015818779356777668 score: 1.0
2021-08-08 04:57:02,435 | train | INFO | Epoch 12 train batch 294/450: 4704/7200 mean loss: 0.0014973189681768417 score: 1.0
2021-08-08 04:57:03,223 | train | INFO | Epoch 12 train batch 295/450: 4720/7200 mean loss: 0.001677136868238449 score: 0.778046218487395
2021-08-08 04:57:04,002 | train | INFO | Epoch 12 train batch 296/450: 4736/7200 mean loss: 0.0013948448467999697 score: 1.0
2021-08-08 04:57:04,772 | train | INFO | Epoch 12 train batch 297/450: 4752/7200 mean loss: 0.0014168123016133904 score: 0.9884453781512604
2021-08-08 04:57:05,684 | train | INFO | Epoch 12 train batch 298/450: 4768/7200 mean loss: 0.0014066174626350403 score: 0.9926470588235294
2021-08-08 04:57:06,468 | train | INFO | Epoch 12 train batch 299/450: 4784/7200 mean loss: 0.0014047109289094806 score: 1.0
2021-08-08 04:57:07,241 | train | INFO | Epoch 12 train batch 300/450: 4800/7200 mean loss: 0.0012948315124958754 score: 1.0
2021-08-08 04:57:08,019 | train | INFO | Epoch 12 train batch 301/450: 4816/7200 mean loss: 0.0014738376485183835 score: 1.0
2021-08-08 04:57:08,796 | train | INFO | Epoch 12 train batch 302/450: 4832/7200 mean loss: 0.0012899431167170405 score: 1.0
2021-08-08 04:57:09,560 | train | INFO | Epoch 12 train batch 303/450: 4848/7200 mean loss: 0.0014500058023259044 score: 1.0
2021-08-08 04:57:10,326 | train | INFO | Epoch 12 train batch 304/450: 4864/7200 mean loss: 0.0014819968491792679 score: 0.996078431372549
2021-08-08 04:57:11,095 | train | INFO | Epoch 12 train batch 305/450: 4880/7200 mean loss: 0.0015908764908090234 score: 1.0
2021-08-08 04:57:11,875 | train | INFO | Epoch 12 train batch 306/450: 4896/7200 mean loss: 0.0013475703308358788 score: 1.0
2021-08-08 04:57:12,659 | train | INFO | Epoch 12 train batch 307/450: 4912/7200 mean loss: 0.0015932286623865366 score: 1.0
2021-08-08 04:57:13,456 | train | INFO | Epoch 12 train batch 308/450: 4928/7200 mean loss: 0.0016741007566452026 score: 1.0
2021-08-08 04:57:14,259 | train | INFO | Epoch 12 train batch 309/450: 4944/7200 mean loss: 0.0017156734829768538 score: 0.9889705882352942
2021-08-08 04:57:15,060 | train | INFO | Epoch 12 train batch 310/450: 4960/7200 mean loss: 0.001559167867526412 score: 0.7571078431372549
2021-08-08 04:57:15,889 | train | INFO | Epoch 12 train batch 311/450: 4976/7200 mean loss: 0.0014952323399484158 score: 1.0
2021-08-08 04:57:16,666 | train | INFO | Epoch 12 train batch 312/450: 4992/7200 mean loss: 0.001314971363171935 score: 0.996078431372549
2021-08-08 04:57:17,442 | train | INFO | Epoch 12 train batch 313/450: 5008/7200 mean loss: 0.0012548593804240227 score: 1.0
2021-08-08 04:57:18,233 | train | INFO | Epoch 12 train batch 314/450: 5024/7200 mean loss: 0.0014615951804444194 score: 1.0
2021-08-08 04:57:19,017 | train | INFO | Epoch 12 train batch 315/450: 5040/7200 mean loss: 0.0014033362967893481 score: 1.0
2021-08-08 04:57:19,817 | train | INFO | Epoch 12 train batch 316/450: 5056/7200 mean loss: 0.0013777208514511585 score: 0.9816176470588235
2021-08-08 04:57:20,612 | train | INFO | Epoch 12 train batch 317/450: 5072/7200 mean loss: 0.0014026756398379803 score: 1.0
2021-08-08 04:57:21,397 | train | INFO | Epoch 12 train batch 318/450: 5088/7200 mean loss: 0.001758777303621173 score: 1.0
2021-08-08 04:57:22,198 | train | INFO | Epoch 12 train batch 319/450: 5104/7200 mean loss: 0.0018286508275195956 score: 1.0
2021-08-08 04:57:22,992 | train | INFO | Epoch 12 train batch 320/450: 5120/7200 mean loss: 0.0017599492566660047 score: 0.9963235294117647
2021-08-08 04:57:23,808 | train | INFO | Epoch 12 train batch 321/450: 5136/7200 mean loss: 0.0015326529974117875 score: 1.0
2021-08-08 04:57:24,622 | train | INFO | Epoch 12 train batch 322/450: 5152/7200 mean loss: 0.0016888962127268314 score: 1.0
2021-08-08 04:57:25,433 | train | INFO | Epoch 12 train batch 323/450: 5168/7200 mean loss: 0.0016416959697380662 score: 1.0
2021-08-08 04:57:26,211 | train | INFO | Epoch 12 train batch 324/450: 5184/7200 mean loss: 0.0014158748090267181 score: 1.0
2021-08-08 04:57:26,992 | train | INFO | Epoch 12 train batch 325/450: 5200/7200 mean loss: 0.0013742889277637005 score: 0.9850490196078432
2021-08-08 04:57:27,786 | train | INFO | Epoch 12 train batch 326/450: 5216/7200 mean loss: 0.0010825542267411947 score: 0.9963235294117647
2021-08-08 04:57:28,598 | train | INFO | Epoch 12 train batch 327/450: 5232/7200 mean loss: 0.0013862496707588434 score: 0.9963235294117647
2021-08-08 04:57:29,400 | train | INFO | Epoch 12 train batch 328/450: 5248/7200 mean loss: 0.001301604905165732 score: 1.0
2021-08-08 04:57:30,178 | train | INFO | Epoch 12 train batch 329/450: 5264/7200 mean loss: 0.0011748438701033592 score: 1.0
2021-08-08 04:57:30,949 | train | INFO | Epoch 12 train batch 330/450: 5280/7200 mean loss: 0.0014819273492321372 score: 0.9963235294117647
2021-08-08 04:57:31,726 | train | INFO | Epoch 12 train batch 331/450: 5296/7200 mean loss: 0.0011840639635920525 score: 0.9963235294117647
2021-08-08 04:57:32,562 | train | INFO | Epoch 12 train batch 332/450: 5312/7200 mean loss: 0.001375497318804264 score: 1.0
2021-08-08 04:57:33,348 | train | INFO | Epoch 12 train batch 333/450: 5328/7200 mean loss: 0.0012881816364824772 score: 1.0
2021-08-08 04:57:34,149 | train | INFO | Epoch 12 train batch 334/450: 5344/7200 mean loss: 0.0014536017552018166 score: 1.0
2021-08-08 04:57:34,958 | train | INFO | Epoch 12 train batch 335/450: 5360/7200 mean loss: 0.0013097379123792052 score: 0.9926470588235294
2021-08-08 04:57:35,729 | train | INFO | Epoch 12 train batch 336/450: 5376/7200 mean loss: 0.0013735746033489704 score: 1.0
2021-08-08 04:57:36,508 | train | INFO | Epoch 12 train batch 337/450: 5392/7200 mean loss: 0.001487475587055087 score: 1.0
2021-08-08 04:57:37,288 | train | INFO | Epoch 12 train batch 338/450: 5408/7200 mean loss: 0.00128312804736197 score: 1.0
2021-08-08 04:57:38,084 | train | INFO | Epoch 12 train batch 339/450: 5424/7200 mean loss: 0.0015697538619861007 score: 1.0
2021-08-08 04:57:38,871 | train | INFO | Epoch 12 train batch 340/450: 5440/7200 mean loss: 0.0015745485434308648 score: 0.996078431372549
2021-08-08 04:57:39,686 | train | INFO | Epoch 12 train batch 341/450: 5456/7200 mean loss: 0.0011723550269380212 score: 0.9926470588235294
2021-08-08 04:57:40,457 | train | INFO | Epoch 12 train batch 342/450: 5472/7200 mean loss: 0.0015804452123120427 score: 1.0
2021-08-08 04:57:41,242 | train | INFO | Epoch 12 train batch 343/450: 5488/7200 mean loss: 0.001530551933683455 score: 0.996078431372549
2021-08-08 04:57:42,041 | train | INFO | Epoch 12 train batch 344/450: 5504/7200 mean loss: 0.0016783709870651364 score: 1.0
2021-08-08 04:57:42,859 | train | INFO | Epoch 12 train batch 345/450: 5520/7200 mean loss: 0.0015630219131708145 score: 0.9884803921568628
2021-08-08 04:57:43,638 | train | INFO | Epoch 12 train batch 346/450: 5536/7200 mean loss: 0.001517165801487863 score: 1.0
2021-08-08 04:57:44,444 | train | INFO | Epoch 12 train batch 347/450: 5552/7200 mean loss: 0.001403711037710309 score: 1.0
2021-08-08 04:57:45,225 | train | INFO | Epoch 12 train batch 348/450: 5568/7200 mean loss: 0.0015822265995666385 score: 1.0
2021-08-08 04:57:46,035 | train | INFO | Epoch 12 train batch 349/450: 5584/7200 mean loss: 0.0014065408613532782 score: 0.9963235294117647
2021-08-08 04:57:46,809 | train | INFO | Epoch 12 train batch 350/450: 5600/7200 mean loss: 0.0014769688714295626 score: 0.9629901960784314
2021-08-08 04:57:47,608 | train | INFO | Epoch 12 train batch 351/450: 5616/7200 mean loss: 0.0015554871642962098 score: 1.0
2021-08-08 04:57:48,414 | train | INFO | Epoch 12 train batch 352/450: 5632/7200 mean loss: 0.0013814499834552407 score: 1.0
2021-08-08 04:57:49,212 | train | INFO | Epoch 12 train batch 353/450: 5648/7200 mean loss: 0.001430380274541676 score: 1.0
2021-08-08 04:57:49,988 | train | INFO | Epoch 12 train batch 354/450: 5664/7200 mean loss: 0.0012703005922958255 score: 1.0
2021-08-08 04:57:50,820 | train | INFO | Epoch 12 train batch 355/450: 5680/7200 mean loss: 0.0013560948427766562 score: 1.0
2021-08-08 04:57:51,619 | train | INFO | Epoch 12 train batch 356/450: 5696/7200 mean loss: 0.0012814189540222287 score: 1.0
2021-08-08 04:57:52,463 | train | INFO | Epoch 12 train batch 357/450: 5712/7200 mean loss: 0.0011956951348111033 score: 1.0
2021-08-08 04:57:53,290 | train | INFO | Epoch 12 train batch 358/450: 5728/7200 mean loss: 0.0014213616959750652 score: 1.0
2021-08-08 04:57:54,078 | train | INFO | Epoch 12 train batch 359/450: 5744/7200 mean loss: 0.0013796791899949312 score: 1.0
2021-08-08 04:57:54,875 | train | INFO | Epoch 12 train batch 360/450: 5760/7200 mean loss: 0.0014697147998958826 score: 1.0
2021-08-08 04:57:55,654 | train | INFO | Epoch 12 train batch 361/450: 5776/7200 mean loss: 0.0012033676030114293 score: 1.0
2021-08-08 04:57:56,430 | train | INFO | Epoch 12 train batch 362/450: 5792/7200 mean loss: 0.0015841948334127665 score: 1.0
2021-08-08 04:57:57,247 | train | INFO | Epoch 12 train batch 363/450: 5808/7200 mean loss: 0.0015050603542476892 score: 0.9963235294117647
2021-08-08 04:57:58,063 | train | INFO | Epoch 12 train batch 364/450: 5824/7200 mean loss: 0.0013102731900289655 score: 1.0
2021-08-08 04:57:58,858 | train | INFO | Epoch 12 train batch 365/450: 5840/7200 mean loss: 0.0013077579205855727 score: 0.9963235294117647
2021-08-08 04:57:59,703 | train | INFO | Epoch 12 train batch 366/450: 5856/7200 mean loss: 0.0013400893658399582 score: 1.0
2021-08-08 04:58:00,520 | train | INFO | Epoch 12 train batch 367/450: 5872/7200 mean loss: 0.001567717525176704 score: 1.0
2021-08-08 04:58:01,298 | train | INFO | Epoch 12 train batch 368/450: 5888/7200 mean loss: 0.0014646620256826282 score: 1.0
2021-08-08 04:58:02,114 | train | INFO | Epoch 12 train batch 369/450: 5904/7200 mean loss: 0.0014399364590644836 score: 0.9889705882352942
2021-08-08 04:58:02,898 | train | INFO | Epoch 12 train batch 370/450: 5920/7200 mean loss: 0.0014613544335588813 score: 1.0
2021-08-08 04:58:03,725 | train | INFO | Epoch 12 train batch 371/450: 5936/7200 mean loss: 0.001558669377118349 score: 1.0
2021-08-08 04:58:04,536 | train | INFO | Epoch 12 train batch 372/450: 5952/7200 mean loss: 0.001425701193511486 score: 1.0
2021-08-08 04:58:05,309 | train | INFO | Epoch 12 train batch 373/450: 5968/7200 mean loss: 0.001523353741504252 score: 1.0
2021-08-08 04:58:06,080 | train | INFO | Epoch 12 train batch 374/450: 5984/7200 mean loss: 0.0013277636608108878 score: 0.9291666666666666
2021-08-08 04:58:06,846 | train | INFO | Epoch 12 train batch 375/450: 6000/7200 mean loss: 0.0014777197502553463 score: 0.9847689075630252
2021-08-08 04:58:07,637 | train | INFO | Epoch 12 train batch 376/450: 6016/7200 mean loss: 0.0014610636280849576 score: 0.9924019607843138
2021-08-08 04:58:08,414 | train | INFO | Epoch 12 train batch 377/450: 6032/7200 mean loss: 0.0015003650914877653 score: 1.0
2021-08-08 04:58:09,186 | train | INFO | Epoch 12 train batch 378/450: 6048/7200 mean loss: 0.0015223437221720815 score: 0.9926470588235294
2021-08-08 04:58:09,965 | train | INFO | Epoch 12 train batch 379/450: 6064/7200 mean loss: 0.0011549904011189938 score: 1.0
2021-08-08 04:58:10,740 | train | INFO | Epoch 12 train batch 380/450: 6080/7200 mean loss: 0.0015620013000443578 score: 0.8669117647058824
2021-08-08 04:58:11,512 | train | INFO | Epoch 12 train batch 381/450: 6096/7200 mean loss: 0.0014964798465371132 score: 0.9926470588235294
2021-08-08 04:58:12,284 | train | INFO | Epoch 12 train batch 382/450: 6112/7200 mean loss: 0.0015108361840248108 score: 0.9915966386554622
2021-08-08 04:58:13,091 | train | INFO | Epoch 12 train batch 383/450: 6128/7200 mean loss: 0.0012937329011037946 score: 1.0
2021-08-08 04:58:13,968 | train | INFO | Epoch 12 train batch 384/450: 6144/7200 mean loss: 0.0016107270494103432 score: 1.0
2021-08-08 04:58:14,809 | train | INFO | Epoch 12 train batch 385/450: 6160/7200 mean loss: 0.001530391862615943 score: 1.0
2021-08-08 04:58:15,612 | train | INFO | Epoch 12 train batch 386/450: 6176/7200 mean loss: 0.0016511970898136497 score: 1.0
2021-08-08 04:58:16,408 | train | INFO | Epoch 12 train batch 387/450: 6192/7200 mean loss: 0.0016495969612151384 score: 1.0
2021-08-08 04:58:17,184 | train | INFO | Epoch 12 train batch 388/450: 6208/7200 mean loss: 0.0017128788167610765 score: 1.0
2021-08-08 04:58:17,966 | train | INFO | Epoch 12 train batch 389/450: 6224/7200 mean loss: 0.0014891951577737927 score: 1.0
2021-08-08 04:58:18,789 | train | INFO | Epoch 12 train batch 390/450: 6240/7200 mean loss: 0.001390057965181768 score: 1.0
2021-08-08 04:58:19,589 | train | INFO | Epoch 12 train batch 391/450: 6256/7200 mean loss: 0.0012794670183211565 score: 1.0
2021-08-08 04:58:20,404 | train | INFO | Epoch 12 train batch 392/450: 6272/7200 mean loss: 0.001276410766877234 score: 1.0
2021-08-08 04:58:21,185 | train | INFO | Epoch 12 train batch 393/450: 6288/7200 mean loss: 0.001354117994196713 score: 1.0
2021-08-08 04:58:21,998 | train | INFO | Epoch 12 train batch 394/450: 6304/7200 mean loss: 0.0011289619142189622 score: 1.0
2021-08-08 04:58:22,777 | train | INFO | Epoch 12 train batch 395/450: 6320/7200 mean loss: 0.0012452779337763786 score: 1.0
2021-08-08 04:58:23,572 | train | INFO | Epoch 12 train batch 396/450: 6336/7200 mean loss: 0.0013906436506658792 score: 1.0
2021-08-08 04:58:24,398 | train | INFO | Epoch 12 train batch 397/450: 6352/7200 mean loss: 0.001528985914774239 score: 1.0
2021-08-08 04:58:25,183 | train | INFO | Epoch 12 train batch 398/450: 6368/7200 mean loss: 0.001484594540670514 score: 1.0
2021-08-08 04:58:25,975 | train | INFO | Epoch 12 train batch 399/450: 6384/7200 mean loss: 0.0014356934698298573 score: 1.0
2021-08-08 04:58:26,757 | train | INFO | Epoch 12 train batch 400/450: 6400/7200 mean loss: 0.0014767824904993176 score: 0.996078431372549
2021-08-08 04:58:27,543 | train | INFO | Epoch 12 train batch 401/450: 6416/7200 mean loss: 0.0016911657294258475 score: 0.9595588235294118
2021-08-08 04:58:28,345 | train | INFO | Epoch 12 train batch 402/450: 6432/7200 mean loss: 0.001450592651963234 score: 0.9852941176470589
2021-08-08 04:58:29,118 | train | INFO | Epoch 12 train batch 403/450: 6448/7200 mean loss: 0.0014145735185593367 score: 1.0
2021-08-08 04:58:29,900 | train | INFO | Epoch 12 train batch 404/450: 6464/7200 mean loss: 0.0012448456836864352 score: 1.0
2021-08-08 04:58:30,696 | train | INFO | Epoch 12 train batch 405/450: 6480/7200 mean loss: 0.0015688725979998708 score: 1.0
2021-08-08 04:58:31,485 | train | INFO | Epoch 12 train batch 406/450: 6496/7200 mean loss: 0.0012823152355849743 score: 1.0
2021-08-08 04:58:32,255 | train | INFO | Epoch 12 train batch 407/450: 6512/7200 mean loss: 0.0014420285588130355 score: 1.0
2021-08-08 04:58:33,072 | train | INFO | Epoch 12 train batch 408/450: 6528/7200 mean loss: 0.0013643454294651747 score: 1.0
2021-08-08 04:58:33,859 | train | INFO | Epoch 12 train batch 409/450: 6544/7200 mean loss: 0.001414941973052919 score: 1.0
2021-08-08 04:58:34,676 | train | INFO | Epoch 12 train batch 410/450: 6560/7200 mean loss: 0.0015130735700950027 score: 1.0
2021-08-08 04:58:35,492 | train | INFO | Epoch 12 train batch 411/450: 6576/7200 mean loss: 0.001264889957383275 score: 0.9926470588235294
2021-08-08 04:58:36,278 | train | INFO | Epoch 12 train batch 412/450: 6592/7200 mean loss: 0.001626299344934523 score: 0.9323529411764707
2021-08-08 04:58:37,151 | train | INFO | Epoch 12 train batch 413/450: 6608/7200 mean loss: 0.0013595526106655598 score: 0.9924019607843138
2021-08-08 04:58:37,969 | train | INFO | Epoch 12 train batch 414/450: 6624/7200 mean loss: 0.001474806573241949 score: 0.9963235294117647
2021-08-08 04:58:38,741 | train | INFO | Epoch 12 train batch 415/450: 6640/7200 mean loss: 0.001277663977816701 score: 1.0
2021-08-08 04:58:39,514 | train | INFO | Epoch 12 train batch 416/450: 6656/7200 mean loss: 0.001417848514392972 score: 0.996078431372549
2021-08-08 04:58:40,337 | train | INFO | Epoch 12 train batch 417/450: 6672/7200 mean loss: 0.0014661627355962992 score: 0.9963235294117647
2021-08-08 04:58:41,148 | train | INFO | Epoch 12 train batch 418/450: 6688/7200 mean loss: 0.0016865984071046114 score: 0.9583333333333334
2021-08-08 04:58:41,931 | train | INFO | Epoch 12 train batch 419/450: 6704/7200 mean loss: 0.001564921229146421 score: 1.0
2021-08-08 04:58:42,726 | train | INFO | Epoch 12 train batch 420/450: 6720/7200 mean loss: 0.0014590212376788259 score: 1.0
2021-08-08 04:58:43,498 | train | INFO | Epoch 12 train batch 421/450: 6736/7200 mean loss: 0.0015788113232702017 score: 1.0
2021-08-08 04:58:44,272 | train | INFO | Epoch 12 train batch 422/450: 6752/7200 mean loss: 0.0015645723324269056 score: 1.0
2021-08-08 04:58:45,057 | train | INFO | Epoch 12 train batch 423/450: 6768/7200 mean loss: 0.001381664420478046 score: 1.0
2021-08-08 04:58:45,878 | train | INFO | Epoch 12 train batch 424/450: 6784/7200 mean loss: 0.0017602375010028481 score: 1.0
2021-08-08 04:58:46,659 | train | INFO | Epoch 12 train batch 425/450: 6800/7200 mean loss: 0.00152678566519171 score: 1.0
2021-08-08 04:58:47,445 | train | INFO | Epoch 12 train batch 426/450: 6816/7200 mean loss: 0.001376900589093566 score: 1.0
2021-08-08 04:58:48,231 | train | INFO | Epoch 12 train batch 427/450: 6832/7200 mean loss: 0.001425669644959271 score: 1.0
2021-08-08 04:58:49,136 | train | INFO | Epoch 12 train batch 428/450: 6848/7200 mean loss: 0.0017353766597807407 score: 0.9593137254901961
2021-08-08 04:58:50,024 | train | INFO | Epoch 12 train batch 429/450: 6864/7200 mean loss: 0.0015799858374521136 score: 0.9774159663865545
2021-08-08 04:58:50,916 | train | INFO | Epoch 12 train batch 430/450: 6880/7200 mean loss: 0.001497980090789497 score: 1.0
2021-08-08 04:58:51,692 | train | INFO | Epoch 12 train batch 431/450: 6896/7200 mean loss: 0.0013681028503924608 score: 1.0
2021-08-08 04:58:52,464 | train | INFO | Epoch 12 train batch 432/450: 6912/7200 mean loss: 0.0014431431191042066 score: 0.996078431372549
2021-08-08 04:58:53,259 | train | INFO | Epoch 12 train batch 433/450: 6928/7200 mean loss: 0.0014410371659323573 score: 1.0
2021-08-08 04:58:54,035 | train | INFO | Epoch 12 train batch 434/450: 6944/7200 mean loss: 0.0016766750486567616 score: 1.0
2021-08-08 04:58:54,811 | train | INFO | Epoch 12 train batch 435/450: 6960/7200 mean loss: 0.0015419136034324765 score: 1.0
2021-08-08 04:58:55,585 | train | INFO | Epoch 12 train batch 436/450: 6976/7200 mean loss: 0.0012845533201470971 score: 1.0
2021-08-08 04:58:56,356 | train | INFO | Epoch 12 train batch 437/450: 6992/7200 mean loss: 0.0015414980007335544 score: 1.0
2021-08-08 04:58:57,127 | train | INFO | Epoch 12 train batch 438/450: 7008/7200 mean loss: 0.0014191271038725972 score: 1.0
2021-08-08 04:58:57,897 | train | INFO | Epoch 12 train batch 439/450: 7024/7200 mean loss: 0.001385631738230586 score: 1.0
2021-08-08 04:58:58,667 | train | INFO | Epoch 12 train batch 440/450: 7040/7200 mean loss: 0.0015723861288279295 score: 1.0
2021-08-08 04:58:59,434 | train | INFO | Epoch 12 train batch 441/450: 7056/7200 mean loss: 0.001666867989115417 score: 1.0
2021-08-08 04:59:00,199 | train | INFO | Epoch 12 train batch 442/450: 7072/7200 mean loss: 0.0013958222698420286 score: 0.996078431372549
2021-08-08 04:59:00,964 | train | INFO | Epoch 12 train batch 443/450: 7088/7200 mean loss: 0.0016428985400125384 score: 1.0
2021-08-08 04:59:01,727 | train | INFO | Epoch 12 train batch 444/450: 7104/7200 mean loss: 0.001396346022374928 score: 1.0
2021-08-08 04:59:02,504 | train | INFO | Epoch 12 train batch 445/450: 7120/7200 mean loss: 0.001299224910326302 score: 1.0
2021-08-08 04:59:03,274 | train | INFO | Epoch 12 train batch 446/450: 7136/7200 mean loss: 0.0014692823169752955 score: 1.0
2021-08-08 04:59:04,045 | train | INFO | Epoch 12 train batch 447/450: 7152/7200 mean loss: 0.001285687554627657 score: 0.8455882352941176
2021-08-08 04:59:04,810 | train | INFO | Epoch 12 train batch 448/450: 7168/7200 mean loss: 0.0014562375145033002 score: 1.0
2021-08-08 04:59:05,574 | train | INFO | Epoch 12 train batch 449/450: 7184/7200 mean loss: 0.0015612953575327992 score: 1.0
2021-08-08 04:59:05,726 | train | INFO | Epoch 12, Train, Mean loss: 0.023086609633432495, Score: 0.9936058799588212
2021-08-08 04:59:07,196 | train | INFO | Epoch 12 validation batch 0/113: 0/1800 mean loss: 0.0009806682355701923 score: 1.0
2021-08-08 04:59:07,499 | train | INFO | Epoch 12 validation batch 1/113: 16/1800 mean loss: 0.0010158100631088018 score: 0.9963235294117647
2021-08-08 04:59:07,742 | train | INFO | Epoch 12 validation batch 2/113: 32/1800 mean loss: 0.0013222635025158525 score: 1.0
2021-08-08 04:59:07,996 | train | INFO | Epoch 12 validation batch 3/113: 48/1800 mean loss: 0.0011091915657743812 score: 1.0
2021-08-08 04:59:08,243 | train | INFO | Epoch 12 validation batch 4/113: 64/1800 mean loss: 0.0009918962605297565 score: 1.0
2021-08-08 04:59:08,474 | train | INFO | Epoch 12 validation batch 5/113: 80/1800 mean loss: 0.0009938448201864958 score: 1.0
2021-08-08 04:59:08,705 | train | INFO | Epoch 12 validation batch 6/113: 96/1800 mean loss: 0.0009206237737089396 score: 1.0
2021-08-08 04:59:08,937 | train | INFO | Epoch 12 validation batch 7/113: 112/1800 mean loss: 0.001100271358154714 score: 1.0
2021-08-08 04:59:09,168 | train | INFO | Epoch 12 validation batch 8/113: 128/1800 mean loss: 0.0010510688880458474 score: 1.0
2021-08-08 04:59:09,443 | train | INFO | Epoch 12 validation batch 9/113: 144/1800 mean loss: 0.001030891784466803 score: 1.0
2021-08-08 04:59:09,713 | train | INFO | Epoch 12 validation batch 10/113: 160/1800 mean loss: 0.0011066938750445843 score: 0.9779411764705882
2021-08-08 04:59:09,946 | train | INFO | Epoch 12 validation batch 11/113: 176/1800 mean loss: 0.0010950110154226422 score: 0.9963235294117647
2021-08-08 04:59:10,182 | train | INFO | Epoch 12 validation batch 12/113: 192/1800 mean loss: 0.0010607031872496009 score: 1.0
2021-08-08 04:59:10,412 | train | INFO | Epoch 12 validation batch 13/113: 208/1800 mean loss: 0.0009586321539245546 score: 1.0
2021-08-08 04:59:10,706 | train | INFO | Epoch 12 validation batch 14/113: 224/1800 mean loss: 0.0009007953922264278 score: 1.0
2021-08-08 04:59:10,955 | train | INFO | Epoch 12 validation batch 15/113: 240/1800 mean loss: 0.0010135245975106955 score: 1.0
2021-08-08 04:59:11,187 | train | INFO | Epoch 12 validation batch 16/113: 256/1800 mean loss: 0.0010137464851140976 score: 1.0
2021-08-08 04:59:11,418 | train | INFO | Epoch 12 validation batch 17/113: 272/1800 mean loss: 0.001154010184109211 score: 1.0
2021-08-08 04:59:11,653 | train | INFO | Epoch 12 validation batch 18/113: 288/1800 mean loss: 0.0008133999654091895 score: 1.0
2021-08-08 04:59:11,885 | train | INFO | Epoch 12 validation batch 19/113: 304/1800 mean loss: 0.0010248024482280016 score: 1.0
2021-08-08 04:59:12,133 | train | INFO | Epoch 12 validation batch 20/113: 320/1800 mean loss: 0.001137639512307942 score: 0.9926470588235294
2021-08-08 04:59:12,383 | train | INFO | Epoch 12 validation batch 21/113: 336/1800 mean loss: 0.0009744171984493732 score: 1.0
2021-08-08 04:59:12,624 | train | INFO | Epoch 12 validation batch 22/113: 352/1800 mean loss: 0.000995791982859373 score: 1.0
2021-08-08 04:59:12,873 | train | INFO | Epoch 12 validation batch 23/113: 368/1800 mean loss: 0.0009486344642937183 score: 1.0
2021-08-08 04:59:13,105 | train | INFO | Epoch 12 validation batch 24/113: 384/1800 mean loss: 0.0010308384662494063 score: 1.0
2021-08-08 04:59:13,364 | train | INFO | Epoch 12 validation batch 25/113: 400/1800 mean loss: 0.001116064377129078 score: 1.0
2021-08-08 04:59:13,613 | train | INFO | Epoch 12 validation batch 26/113: 416/1800 mean loss: 0.0008705105283297598 score: 1.0
2021-08-08 04:59:13,851 | train | INFO | Epoch 12 validation batch 27/113: 432/1800 mean loss: 0.0011307265376672149 score: 1.0
2021-08-08 04:59:14,109 | train | INFO | Epoch 12 validation batch 28/113: 448/1800 mean loss: 0.0010309434728696942 score: 1.0
2021-08-08 04:59:14,340 | train | INFO | Epoch 12 validation batch 29/113: 464/1800 mean loss: 0.0010478623444214463 score: 1.0
2021-08-08 04:59:14,602 | train | INFO | Epoch 12 validation batch 30/113: 480/1800 mean loss: 0.0010036843596026301 score: 1.0
2021-08-08 04:59:14,836 | train | INFO | Epoch 12 validation batch 31/113: 496/1800 mean loss: 0.000991161447018385 score: 1.0
2021-08-08 04:59:15,066 | train | INFO | Epoch 12 validation batch 32/113: 512/1800 mean loss: 0.0010627976153045893 score: 1.0
2021-08-08 04:59:15,298 | train | INFO | Epoch 12 validation batch 33/113: 528/1800 mean loss: 0.0008981641731224954 score: 1.0
2021-08-08 04:59:15,544 | train | INFO | Epoch 12 validation batch 34/113: 544/1800 mean loss: 0.0007716353866271675 score: 1.0
2021-08-08 04:59:15,788 | train | INFO | Epoch 12 validation batch 35/113: 560/1800 mean loss: 0.001244402606971562 score: 1.0
2021-08-08 04:59:16,070 | train | INFO | Epoch 12 validation batch 36/113: 576/1800 mean loss: 0.001163952169008553 score: 0.9
2021-08-08 04:59:16,326 | train | INFO | Epoch 12 validation batch 37/113: 592/1800 mean loss: 0.0008322856738232076 score: 1.0
2021-08-08 04:59:16,563 | train | INFO | Epoch 12 validation batch 38/113: 608/1800 mean loss: 0.0010417852317914367 score: 1.0
2021-08-08 04:59:16,794 | train | INFO | Epoch 12 validation batch 39/113: 624/1800 mean loss: 0.0009937264258041978 score: 1.0
2021-08-08 04:59:17,043 | train | INFO | Epoch 12 validation batch 40/113: 640/1800 mean loss: 0.001037648762576282 score: 1.0
2021-08-08 04:59:17,285 | train | INFO | Epoch 12 validation batch 41/113: 656/1800 mean loss: 0.0009621127392165363 score: 1.0
2021-08-08 04:59:17,526 | train | INFO | Epoch 12 validation batch 42/113: 672/1800 mean loss: 0.0009814969962462783 score: 1.0
2021-08-08 04:59:17,761 | train | INFO | Epoch 12 validation batch 43/113: 688/1800 mean loss: 0.0009870798094198108 score: 1.0
2021-08-08 04:59:18,011 | train | INFO | Epoch 12 validation batch 44/113: 704/1800 mean loss: 0.0012542885961011052 score: 0.9705882352941176
2021-08-08 04:59:18,267 | train | INFO | Epoch 12 validation batch 45/113: 720/1800 mean loss: 0.0010810296516865492 score: 1.0
2021-08-08 04:59:18,515 | train | INFO | Epoch 12 validation batch 46/113: 736/1800 mean loss: 0.0010257750982418656 score: 0.9926470588235294
2021-08-08 04:59:18,762 | train | INFO | Epoch 12 validation batch 47/113: 752/1800 mean loss: 0.0009324802667833865 score: 1.0
2021-08-08 04:59:18,994 | train | INFO | Epoch 12 validation batch 48/113: 768/1800 mean loss: 0.0009485491900704801 score: 1.0
2021-08-08 04:59:19,226 | train | INFO | Epoch 12 validation batch 49/113: 784/1800 mean loss: 0.001034623826853931 score: 1.0
2021-08-08 04:59:19,464 | train | INFO | Epoch 12 validation batch 50/113: 800/1800 mean loss: 0.0009178313775919378 score: 1.0
2021-08-08 04:59:19,713 | train | INFO | Epoch 12 validation batch 51/113: 816/1800 mean loss: 0.0011117318645119667 score: 0.9889705882352942
2021-08-08 04:59:19,960 | train | INFO | Epoch 12 validation batch 52/113: 832/1800 mean loss: 0.0010188414016738534 score: 1.0
2021-08-08 04:59:20,195 | train | INFO | Epoch 12 validation batch 53/113: 848/1800 mean loss: 0.0009656797046773136 score: 1.0
2021-08-08 04:59:20,480 | train | INFO | Epoch 12 validation batch 54/113: 864/1800 mean loss: 0.0009828520705923438 score: 1.0
2021-08-08 04:59:20,713 | train | INFO | Epoch 12 validation batch 55/113: 880/1800 mean loss: 0.0010796556016430259 score: 1.0
2021-08-08 04:59:20,947 | train | INFO | Epoch 12 validation batch 56/113: 896/1800 mean loss: 0.001046869670972228 score: 1.0
2021-08-08 04:59:21,182 | train | INFO | Epoch 12 validation batch 57/113: 912/1800 mean loss: 0.0010829131351783872 score: 1.0
2021-08-08 04:59:21,428 | train | INFO | Epoch 12 validation batch 58/113: 928/1800 mean loss: 0.0011008811416104436 score: 0.9816176470588235
2021-08-08 04:59:21,677 | train | INFO | Epoch 12 validation batch 59/113: 944/1800 mean loss: 0.0010141032980754972 score: 1.0
2021-08-08 04:59:21,934 | train | INFO | Epoch 12 validation batch 60/113: 960/1800 mean loss: 0.0008616445120424032 score: 1.0
2021-08-08 04:59:22,184 | train | INFO | Epoch 12 validation batch 61/113: 976/1800 mean loss: 0.0009344180580228567 score: 1.0
2021-08-08 04:59:22,425 | train | INFO | Epoch 12 validation batch 62/113: 992/1800 mean loss: 0.0009905719198286533 score: 1.0
2021-08-08 04:59:22,661 | train | INFO | Epoch 12 validation batch 63/113: 1008/1800 mean loss: 0.000944846251513809 score: 1.0
2021-08-08 04:59:22,907 | train | INFO | Epoch 12 validation batch 64/113: 1024/1800 mean loss: 0.0009806305170059204 score: 1.0
2021-08-08 04:59:23,139 | train | INFO | Epoch 12 validation batch 65/113: 1040/1800 mean loss: 0.001061135670170188 score: 1.0
2021-08-08 04:59:23,371 | train | INFO | Epoch 12 validation batch 66/113: 1056/1800 mean loss: 0.001030628103762865 score: 1.0
2021-08-08 04:59:23,645 | train | INFO | Epoch 12 validation batch 67/113: 1072/1800 mean loss: 0.0011118052061647177 score: 1.0
2021-08-08 04:59:23,891 | train | INFO | Epoch 12 validation batch 68/113: 1088/1800 mean loss: 0.0008671292453072965 score: 1.0
2021-08-08 04:59:24,145 | train | INFO | Epoch 12 validation batch 69/113: 1104/1800 mean loss: 0.000968531530816108 score: 1.0
2021-08-08 04:59:24,388 | train | INFO | Epoch 12 validation batch 70/113: 1120/1800 mean loss: 0.0011955733643844724 score: 0.9963235294117647
2021-08-08 04:59:24,625 | train | INFO | Epoch 12 validation batch 71/113: 1136/1800 mean loss: 0.0009442916489206254 score: 1.0
2021-08-08 04:59:24,858 | train | INFO | Epoch 12 validation batch 72/113: 1152/1800 mean loss: 0.0009647120023146272 score: 1.0
2021-08-08 04:59:25,111 | train | INFO | Epoch 12 validation batch 73/113: 1168/1800 mean loss: 0.0011964929290115833 score: 1.0
2021-08-08 04:59:25,357 | train | INFO | Epoch 12 validation batch 74/113: 1184/1800 mean loss: 0.0011099545517936349 score: 1.0
2021-08-08 04:59:25,587 | train | INFO | Epoch 12 validation batch 75/113: 1200/1800 mean loss: 0.0009777818340808153 score: 1.0
2021-08-08 04:59:25,831 | train | INFO | Epoch 12 validation batch 76/113: 1216/1800 mean loss: 0.0008677492733113468 score: 1.0
2021-08-08 04:59:26,062 | train | INFO | Epoch 12 validation batch 77/113: 1232/1800 mean loss: 0.0008625249611213803 score: 1.0
2021-08-08 04:59:26,293 | train | INFO | Epoch 12 validation batch 78/113: 1248/1800 mean loss: 0.0009603787329979241 score: 0.9850490196078432
2021-08-08 04:59:26,532 | train | INFO | Epoch 12 validation batch 79/113: 1264/1800 mean loss: 0.001123664085753262 score: 0.996078431372549
2021-08-08 04:59:26,769 | train | INFO | Epoch 12 validation batch 80/113: 1280/1800 mean loss: 0.001182546024210751 score: 1.0
2021-08-08 04:59:27,004 | train | INFO | Epoch 12 validation batch 81/113: 1296/1800 mean loss: 0.0009976871078833938 score: 1.0
2021-08-08 04:59:27,246 | train | INFO | Epoch 12 validation batch 82/113: 1312/1800 mean loss: 0.001034857239574194 score: 1.0
2021-08-08 04:59:27,476 | train | INFO | Epoch 12 validation batch 83/113: 1328/1800 mean loss: 0.0011624679900705814 score: 1.0
2021-08-08 04:59:27,730 | train | INFO | Epoch 12 validation batch 84/113: 1344/1800 mean loss: 0.0011215447448194027 score: 0.9926470588235294
2021-08-08 04:59:27,969 | train | INFO | Epoch 12 validation batch 85/113: 1360/1800 mean loss: 0.0010459937620908022 score: 1.0
2021-08-08 04:59:28,220 | train | INFO | Epoch 12 validation batch 86/113: 1376/1800 mean loss: 0.0012761123944073915 score: 1.0
2021-08-08 04:59:28,456 | train | INFO | Epoch 12 validation batch 87/113: 1392/1800 mean loss: 0.0011667190119624138 score: 1.0
2021-08-08 04:59:28,689 | train | INFO | Epoch 12 validation batch 88/113: 1408/1800 mean loss: 0.0009923420147970319 score: 1.0
2021-08-08 04:59:28,922 | train | INFO | Epoch 12 validation batch 89/113: 1424/1800 mean loss: 0.0008627793285995722 score: 1.0
2021-08-08 04:59:29,172 | train | INFO | Epoch 12 validation batch 90/113: 1440/1800 mean loss: 0.000945567328017205 score: 1.0
2021-08-08 04:59:29,433 | train | INFO | Epoch 12 validation batch 91/113: 1456/1800 mean loss: 0.001273276866413653 score: 1.0
2021-08-08 04:59:29,671 | train | INFO | Epoch 12 validation batch 92/113: 1472/1800 mean loss: 0.0009813864016905427 score: 1.0
2021-08-08 04:59:29,901 | train | INFO | Epoch 12 validation batch 93/113: 1488/1800 mean loss: 0.0010315504623576999 score: 1.0
2021-08-08 04:59:30,140 | train | INFO | Epoch 12 validation batch 94/113: 1504/1800 mean loss: 0.0010095381876453757 score: 1.0
2021-08-08 04:59:30,411 | train | INFO | Epoch 12 validation batch 95/113: 1520/1800 mean loss: 0.001068602316081524 score: 1.0
2021-08-08 04:59:30,665 | train | INFO | Epoch 12 validation batch 96/113: 1536/1800 mean loss: 0.001140971784479916 score: 1.0
2021-08-08 04:59:30,897 | train | INFO | Epoch 12 validation batch 97/113: 1552/1800 mean loss: 0.001071651466190815 score: 1.0
2021-08-08 04:59:31,131 | train | INFO | Epoch 12 validation batch 98/113: 1568/1800 mean loss: 0.0010134805925190449 score: 1.0
2021-08-08 04:59:31,395 | train | INFO | Epoch 12 validation batch 99/113: 1584/1800 mean loss: 0.0009915231494233012 score: 1.0
2021-08-08 04:59:31,629 | train | INFO | Epoch 12 validation batch 100/113: 1600/1800 mean loss: 0.001194229582324624 score: 1.0
2021-08-08 04:59:31,861 | train | INFO | Epoch 12 validation batch 101/113: 1616/1800 mean loss: 0.000986198429018259 score: 1.0
2021-08-08 04:59:32,092 | train | INFO | Epoch 12 validation batch 102/113: 1632/1800 mean loss: 0.0009228968410752714 score: 1.0
2021-08-08 04:59:32,324 | train | INFO | Epoch 12 validation batch 103/113: 1648/1800 mean loss: 0.0009973515989258885 score: 1.0
2021-08-08 04:59:32,556 | train | INFO | Epoch 12 validation batch 104/113: 1664/1800 mean loss: 0.0011089323088526726 score: 1.0
2021-08-08 04:59:32,788 | train | INFO | Epoch 12 validation batch 105/113: 1680/1800 mean loss: 0.0010514113819226623 score: 1.0
2021-08-08 04:59:33,043 | train | INFO | Epoch 12 validation batch 106/113: 1696/1800 mean loss: 0.0010770846856757998 score: 1.0
2021-08-08 04:59:33,275 | train | INFO | Epoch 12 validation batch 107/113: 1712/1800 mean loss: 0.0012663695961236954 score: 1.0
2021-08-08 04:59:33,505 | train | INFO | Epoch 12 validation batch 108/113: 1728/1800 mean loss: 0.001253921422176063 score: 1.0
2021-08-08 04:59:33,737 | train | INFO | Epoch 12 validation batch 109/113: 1744/1800 mean loss: 0.0011512571945786476 score: 1.0
2021-08-08 04:59:33,967 | train | INFO | Epoch 12 validation batch 110/113: 1760/1800 mean loss: 0.0009386600577272475 score: 1.0
2021-08-08 04:59:34,199 | train | INFO | Epoch 12 validation batch 111/113: 1776/1800 mean loss: 0.0009818733669817448 score: 1.0
2021-08-08 04:59:34,364 | train | INFO | Epoch 12 validation batch 112/113: 1792/1800 mean loss: 0.0009191125864163041 score: 1.0
2021-08-08 04:59:34,523 | train | INFO | Epoch 12, Validation, Mean loss: 0.016521866103650723, Score: 0.997939441263231
2021-08-08 04:59:34,524 | train | INFO | Write row 12
2021-08-08 04:59:37,153 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 04:59:37,156 | train | INFO | Update best record row 13, checkpoints 0.016522848813802796 -> 0.016521866103650723
2021-08-08 04:59:39,240 | train | INFO | Epoch 13 train batch 0/450: 0/7200 mean loss: 0.0014420263469219208 score: 1.0
2021-08-08 04:59:40,039 | train | INFO | Epoch 13 train batch 1/450: 16/7200 mean loss: 0.0014699185267090797 score: 1.0
2021-08-08 04:59:40,874 | train | INFO | Epoch 13 train batch 2/450: 32/7200 mean loss: 0.001157795893959701 score: 0.9816176470588235
2021-08-08 04:59:41,691 | train | INFO | Epoch 13 train batch 3/450: 48/7200 mean loss: 0.001113644801080227 score: 1.0
2021-08-08 04:59:42,463 | train | INFO | Epoch 13 train batch 4/450: 64/7200 mean loss: 0.0014834251487627625 score: 1.0
2021-08-08 04:59:43,236 | train | INFO | Epoch 13 train batch 5/450: 80/7200 mean loss: 0.0013441090704873204 score: 1.0
2021-08-08 04:59:44,010 | train | INFO | Epoch 13 train batch 6/450: 96/7200 mean loss: 0.0014800153439864516 score: 1.0
2021-08-08 04:59:44,785 | train | INFO | Epoch 13 train batch 7/450: 112/7200 mean loss: 0.0014489518944174051 score: 1.0
2021-08-08 04:59:45,553 | train | INFO | Epoch 13 train batch 8/450: 128/7200 mean loss: 0.0014573431108146906 score: 1.0
2021-08-08 04:59:46,345 | train | INFO | Epoch 13 train batch 9/450: 144/7200 mean loss: 0.0013840283500030637 score: 1.0
2021-08-08 04:59:47,134 | train | INFO | Epoch 13 train batch 10/450: 160/7200 mean loss: 0.0014856701018288732 score: 1.0
2021-08-08 04:59:47,919 | train | INFO | Epoch 13 train batch 11/450: 176/7200 mean loss: 0.001609807601198554 score: 1.0
2021-08-08 04:59:48,738 | train | INFO | Epoch 13 train batch 12/450: 192/7200 mean loss: 0.0014185934560373425 score: 1.0
2021-08-08 04:59:49,550 | train | INFO | Epoch 13 train batch 13/450: 208/7200 mean loss: 0.0016138933133333921 score: 0.9963235294117647
2021-08-08 04:59:50,331 | train | INFO | Epoch 13 train batch 14/450: 224/7200 mean loss: 0.0015707124257460237 score: 1.0
2021-08-08 04:59:51,141 | train | INFO | Epoch 13 train batch 15/450: 240/7200 mean loss: 0.0015350099420174956 score: 1.0
2021-08-08 04:59:51,924 | train | INFO | Epoch 13 train batch 16/450: 256/7200 mean loss: 0.0013915743911638856 score: 1.0
2021-08-08 04:59:52,718 | train | INFO | Epoch 13 train batch 17/450: 272/7200 mean loss: 0.0014221911551430821 score: 1.0
2021-08-08 04:59:53,520 | train | INFO | Epoch 13 train batch 18/450: 288/7200 mean loss: 0.001383056747727096 score: 0.9921568627450981
2021-08-08 04:59:54,322 | train | INFO | Epoch 13 train batch 19/450: 304/7200 mean loss: 0.0015491483500227332 score: 1.0
2021-08-08 04:59:55,117 | train | INFO | Epoch 13 train batch 20/450: 320/7200 mean loss: 0.0014896802604198456 score: 1.0
2021-08-08 04:59:55,923 | train | INFO | Epoch 13 train batch 21/450: 336/7200 mean loss: 0.0017231840174645185 score: 1.0
2021-08-08 04:59:56,700 | train | INFO | Epoch 13 train batch 22/450: 352/7200 mean loss: 0.0015215518651530147 score: 1.0
2021-08-08 04:59:57,566 | train | INFO | Epoch 13 train batch 23/450: 368/7200 mean loss: 0.0016674023354426026 score: 0.9963235294117647
2021-08-08 04:59:58,337 | train | INFO | Epoch 13 train batch 24/450: 384/7200 mean loss: 0.0014138412661850452 score: 1.0
2021-08-08 04:59:59,147 | train | INFO | Epoch 13 train batch 25/450: 400/7200 mean loss: 0.0014168530469760299 score: 1.0
2021-08-08 04:59:59,923 | train | INFO | Epoch 13 train batch 26/450: 416/7200 mean loss: 0.001624565222300589 score: 1.0
2021-08-08 05:00:00,706 | train | INFO | Epoch 13 train batch 27/450: 432/7200 mean loss: 0.0015959599986672401 score: 1.0
2021-08-08 05:00:01,531 | train | INFO | Epoch 13 train batch 28/450: 448/7200 mean loss: 0.001518912031315267 score: 1.0
2021-08-08 05:00:02,341 | train | INFO | Epoch 13 train batch 29/450: 464/7200 mean loss: 0.001638720859773457 score: 0.9887254901960785
2021-08-08 05:00:03,124 | train | INFO | Epoch 13 train batch 30/450: 480/7200 mean loss: 0.0016061628703027964 score: 0.9963235294117647
2021-08-08 05:00:03,899 | train | INFO | Epoch 13 train batch 31/450: 496/7200 mean loss: 0.0016273364890366793 score: 0.9887254901960785
2021-08-08 05:00:04,809 | train | INFO | Epoch 13 train batch 32/450: 512/7200 mean loss: 0.0016256918897852302 score: 1.0
2021-08-08 05:00:05,624 | train | INFO | Epoch 13 train batch 33/450: 528/7200 mean loss: 0.0016164501430466771 score: 1.0
2021-08-08 05:00:06,400 | train | INFO | Epoch 13 train batch 34/450: 544/7200 mean loss: 0.0016806402709335089 score: 0.9852941176470589
2021-08-08 05:00:07,209 | train | INFO | Epoch 13 train batch 35/450: 560/7200 mean loss: 0.0013165156124159694 score: 1.0
2021-08-08 05:00:08,005 | train | INFO | Epoch 13 train batch 36/450: 576/7200 mean loss: 0.0014324564253911376 score: 1.0
2021-08-08 05:00:08,786 | train | INFO | Epoch 13 train batch 37/450: 592/7200 mean loss: 0.0013167611323297024 score: 1.0
2021-08-08 05:00:09,578 | train | INFO | Epoch 13 train batch 38/450: 608/7200 mean loss: 0.001341701834462583 score: 0.9632352941176471
2021-08-08 05:00:10,355 | train | INFO | Epoch 13 train batch 39/450: 624/7200 mean loss: 0.0013525760732591152 score: 1.0
2021-08-08 05:00:11,145 | train | INFO | Epoch 13 train batch 40/450: 640/7200 mean loss: 0.0013198093511164188 score: 1.0
2021-08-08 05:00:11,946 | train | INFO | Epoch 13 train batch 41/450: 656/7200 mean loss: 0.0014376648468896747 score: 1.0
2021-08-08 05:00:12,808 | train | INFO | Epoch 13 train batch 42/450: 672/7200 mean loss: 0.0013058936456218362 score: 1.0
2021-08-08 05:00:13,582 | train | INFO | Epoch 13 train batch 43/450: 688/7200 mean loss: 0.0015161364572122693 score: 1.0
2021-08-08 05:00:14,350 | train | INFO | Epoch 13 train batch 44/450: 704/7200 mean loss: 0.0011503116693347692 score: 1.0
2021-08-08 05:00:15,148 | train | INFO | Epoch 13 train batch 45/450: 720/7200 mean loss: 0.001326011959463358 score: 1.0
2021-08-08 05:00:15,938 | train | INFO | Epoch 13 train batch 46/450: 736/7200 mean loss: 0.0015620748745277524 score: 1.0
2021-08-08 05:00:16,713 | train | INFO | Epoch 13 train batch 47/450: 752/7200 mean loss: 0.0015381760895252228 score: 1.0
2021-08-08 05:00:17,489 | train | INFO | Epoch 13 train batch 48/450: 768/7200 mean loss: 0.0013404169585555792 score: 1.0
2021-08-08 05:00:18,329 | train | INFO | Epoch 13 train batch 49/450: 784/7200 mean loss: 0.0014683391200378537 score: 0.973529411764706
2021-08-08 05:00:19,140 | train | INFO | Epoch 13 train batch 50/450: 800/7200 mean loss: 0.0012091048993170261 score: 1.0
2021-08-08 05:00:19,949 | train | INFO | Epoch 13 train batch 51/450: 816/7200 mean loss: 0.0014009407022967935 score: 1.0
2021-08-08 05:00:20,739 | train | INFO | Epoch 13 train batch 52/450: 832/7200 mean loss: 0.0013259388506412506 score: 0.9889705882352942
2021-08-08 05:00:21,536 | train | INFO | Epoch 13 train batch 53/450: 848/7200 mean loss: 0.0014064452843740582 score: 1.0
2021-08-08 05:00:22,334 | train | INFO | Epoch 13 train batch 54/450: 864/7200 mean loss: 0.0013171578757464886 score: 0.9963235294117647
2021-08-08 05:00:23,119 | train | INFO | Epoch 13 train batch 55/450: 880/7200 mean loss: 0.0014751022681593895 score: 1.0
2021-08-08 05:00:23,889 | train | INFO | Epoch 13 train batch 56/450: 896/7200 mean loss: 0.0011761013884097338 score: 1.0
2021-08-08 05:00:24,675 | train | INFO | Epoch 13 train batch 57/450: 912/7200 mean loss: 0.001293219975195825 score: 1.0
2021-08-08 05:00:25,486 | train | INFO | Epoch 13 train batch 58/450: 928/7200 mean loss: 0.0013497944455593824 score: 0.9921218487394957
2021-08-08 05:00:26,281 | train | INFO | Epoch 13 train batch 59/450: 944/7200 mean loss: 0.0011544456938281655 score: 0.9921568627450981
2021-08-08 05:00:27,049 | train | INFO | Epoch 13 train batch 60/450: 960/7200 mean loss: 0.001574591500684619 score: 1.0
2021-08-08 05:00:27,829 | train | INFO | Epoch 13 train batch 61/450: 976/7200 mean loss: 0.0016261867713183165 score: 0.9889705882352942
2021-08-08 05:00:28,653 | train | INFO | Epoch 13 train batch 62/450: 992/7200 mean loss: 0.0013057843316346407 score: 1.0
2021-08-08 05:00:29,464 | train | INFO | Epoch 13 train batch 63/450: 1008/7200 mean loss: 0.0013653449714183807 score: 0.9963235294117647
2021-08-08 05:00:30,248 | train | INFO | Epoch 13 train batch 64/450: 1024/7200 mean loss: 0.0013807499781250954 score: 0.9514705882352942
2021-08-08 05:00:31,043 | train | INFO | Epoch 13 train batch 65/450: 1040/7200 mean loss: 0.0014202099991962314 score: 0.9926470588235294
2021-08-08 05:00:31,816 | train | INFO | Epoch 13 train batch 66/450: 1056/7200 mean loss: 0.0012569004902616143 score: 1.0
2021-08-08 05:00:32,626 | train | INFO | Epoch 13 train batch 67/450: 1072/7200 mean loss: 0.0014945970615372062 score: 0.9669117647058824
2021-08-08 05:00:33,404 | train | INFO | Epoch 13 train batch 68/450: 1088/7200 mean loss: 0.0013971771113574505 score: 1.0
2021-08-08 05:00:34,185 | train | INFO | Epoch 13 train batch 69/450: 1104/7200 mean loss: 0.0015041556907817721 score: 1.0
2021-08-08 05:00:34,966 | train | INFO | Epoch 13 train batch 70/450: 1120/7200 mean loss: 0.001418398111127317 score: 1.0
2021-08-08 05:00:35,735 | train | INFO | Epoch 13 train batch 71/450: 1136/7200 mean loss: 0.0014419280923902988 score: 1.0
2021-08-08 05:00:36,511 | train | INFO | Epoch 13 train batch 72/450: 1152/7200 mean loss: 0.0012066782219335437 score: 1.0
2021-08-08 05:00:37,295 | train | INFO | Epoch 13 train batch 73/450: 1168/7200 mean loss: 0.001570323365740478 score: 1.0
2021-08-08 05:00:38,067 | train | INFO | Epoch 13 train batch 74/450: 1184/7200 mean loss: 0.0010451925918459892 score: 1.0
2021-08-08 05:00:38,855 | train | INFO | Epoch 13 train batch 75/450: 1200/7200 mean loss: 0.001232427661307156 score: 1.0
2021-08-08 05:00:39,650 | train | INFO | Epoch 13 train batch 76/450: 1216/7200 mean loss: 0.0012077240971848369 score: 1.0
2021-08-08 05:00:40,425 | train | INFO | Epoch 13 train batch 77/450: 1232/7200 mean loss: 0.0015190361300483346 score: 1.0
2021-08-08 05:00:41,200 | train | INFO | Epoch 13 train batch 78/450: 1248/7200 mean loss: 0.0013715592212975025 score: 1.0
2021-08-08 05:00:41,970 | train | INFO | Epoch 13 train batch 79/450: 1264/7200 mean loss: 0.0013386766659095883 score: 1.0
2021-08-08 05:00:42,789 | train | INFO | Epoch 13 train batch 80/450: 1280/7200 mean loss: 0.0014868681319057941 score: 1.0
2021-08-08 05:00:43,630 | train | INFO | Epoch 13 train batch 81/450: 1296/7200 mean loss: 0.0016721413703635335 score: 1.0
2021-08-08 05:00:44,457 | train | INFO | Epoch 13 train batch 82/450: 1312/7200 mean loss: 0.0013367129722610116 score: 1.0
2021-08-08 05:00:45,236 | train | INFO | Epoch 13 train batch 83/450: 1328/7200 mean loss: 0.0013291029026731849 score: 0.9963235294117647
2021-08-08 05:00:46,031 | train | INFO | Epoch 13 train batch 84/450: 1344/7200 mean loss: 0.0014171022921800613 score: 1.0
2021-08-08 05:00:46,819 | train | INFO | Epoch 13 train batch 85/450: 1360/7200 mean loss: 0.0012263861717656255 score: 1.0
2021-08-08 05:00:47,675 | train | INFO | Epoch 13 train batch 86/450: 1376/7200 mean loss: 0.0013509594136849046 score: 1.0
2021-08-08 05:00:48,500 | train | INFO | Epoch 13 train batch 87/450: 1392/7200 mean loss: 0.0013249402400106192 score: 1.0
2021-08-08 05:00:49,383 | train | INFO | Epoch 13 train batch 88/450: 1408/7200 mean loss: 0.0012391797499731183 score: 1.0
2021-08-08 05:00:50,194 | train | INFO | Epoch 13 train batch 89/450: 1424/7200 mean loss: 0.0013454697327688336 score: 1.0
2021-08-08 05:00:50,977 | train | INFO | Epoch 13 train batch 90/450: 1440/7200 mean loss: 0.0014318700414150953 score: 1.0
2021-08-08 05:00:51,779 | train | INFO | Epoch 13 train batch 91/450: 1456/7200 mean loss: 0.0014925504801794887 score: 0.9926470588235294
2021-08-08 05:00:52,554 | train | INFO | Epoch 13 train batch 92/450: 1472/7200 mean loss: 0.0015495320549234748 score: 0.9926470588235294
2021-08-08 05:00:53,361 | train | INFO | Epoch 13 train batch 93/450: 1488/7200 mean loss: 0.0014557617250829935 score: 1.0
2021-08-08 05:00:54,160 | train | INFO | Epoch 13 train batch 94/450: 1504/7200 mean loss: 0.0014668594812974334 score: 1.0
2021-08-08 05:00:54,999 | train | INFO | Epoch 13 train batch 95/450: 1520/7200 mean loss: 0.0014073839411139488 score: 0.9889705882352942
2021-08-08 05:00:55,782 | train | INFO | Epoch 13 train batch 96/450: 1536/7200 mean loss: 0.00153442716691643 score: 0.996078431372549
2021-08-08 05:00:56,579 | train | INFO | Epoch 13 train batch 97/450: 1552/7200 mean loss: 0.0013499025953933597 score: 0.9779411764705882
2021-08-08 05:00:57,369 | train | INFO | Epoch 13 train batch 98/450: 1568/7200 mean loss: 0.0013189050368964672 score: 1.0
2021-08-08 05:00:58,160 | train | INFO | Epoch 13 train batch 99/450: 1584/7200 mean loss: 0.0014352056896314025 score: 0.9850490196078432
2021-08-08 05:00:58,962 | train | INFO | Epoch 13 train batch 100/450: 1600/7200 mean loss: 0.0015214947052299976 score: 1.0
2021-08-08 05:00:59,758 | train | INFO | Epoch 13 train batch 101/450: 1616/7200 mean loss: 0.001565716927871108 score: 0.9619397759103642
2021-08-08 05:01:00,526 | train | INFO | Epoch 13 train batch 102/450: 1632/7200 mean loss: 0.001360701979137957 score: 1.0
2021-08-08 05:01:01,294 | train | INFO | Epoch 13 train batch 103/450: 1648/7200 mean loss: 0.001368129625916481 score: 1.0
2021-08-08 05:01:02,083 | train | INFO | Epoch 13 train batch 104/450: 1664/7200 mean loss: 0.0014220845187082887 score: 1.0
2021-08-08 05:01:02,878 | train | INFO | Epoch 13 train batch 105/450: 1680/7200 mean loss: 0.0011974010849371552 score: 1.0
2021-08-08 05:01:03,670 | train | INFO | Epoch 13 train batch 106/450: 1696/7200 mean loss: 0.001482010935433209 score: 1.0
2021-08-08 05:01:04,489 | train | INFO | Epoch 13 train batch 107/450: 1712/7200 mean loss: 0.001303974655456841 score: 1.0
2021-08-08 05:01:05,301 | train | INFO | Epoch 13 train batch 108/450: 1728/7200 mean loss: 0.0014713422860950232 score: 1.0
2021-08-08 05:01:06,083 | train | INFO | Epoch 13 train batch 109/450: 1744/7200 mean loss: 0.0015742708928883076 score: 1.0
2021-08-08 05:01:06,898 | train | INFO | Epoch 13 train batch 110/450: 1760/7200 mean loss: 0.0014846946578472853 score: 1.0
2021-08-08 05:01:07,739 | train | INFO | Epoch 13 train batch 111/450: 1776/7200 mean loss: 0.0018647804390639067 score: 0.9926470588235294
2021-08-08 05:01:08,554 | train | INFO | Epoch 13 train batch 112/450: 1792/7200 mean loss: 0.0014403372770175338 score: 1.0
2021-08-08 05:01:09,452 | train | INFO | Epoch 13 train batch 113/450: 1808/7200 mean loss: 0.0015758015215396881 score: 0.9926470588235294
2021-08-08 05:01:10,344 | train | INFO | Epoch 13 train batch 114/450: 1824/7200 mean loss: 0.001486069755628705 score: 1.0
2021-08-08 05:01:11,132 | train | INFO | Epoch 13 train batch 115/450: 1840/7200 mean loss: 0.0013569412985816598 score: 0.9924019607843138
2021-08-08 05:01:11,948 | train | INFO | Epoch 13 train batch 116/450: 1856/7200 mean loss: 0.001402278896421194 score: 1.0
2021-08-08 05:01:12,728 | train | INFO | Epoch 13 train batch 117/450: 1872/7200 mean loss: 0.001308381324633956 score: 0.9963235294117647
2021-08-08 05:01:13,534 | train | INFO | Epoch 13 train batch 118/450: 1888/7200 mean loss: 0.0014824550598859787 score: 0.9963235294117647
2021-08-08 05:01:14,325 | train | INFO | Epoch 13 train batch 119/450: 1904/7200 mean loss: 0.001410576282069087 score: 1.0
2021-08-08 05:01:15,103 | train | INFO | Epoch 13 train batch 120/450: 1920/7200 mean loss: 0.0016374684637412429 score: 1.0
2021-08-08 05:01:15,901 | train | INFO | Epoch 13 train batch 121/450: 1936/7200 mean loss: 0.0014954941580072045 score: 1.0
2021-08-08 05:01:16,696 | train | INFO | Epoch 13 train batch 122/450: 1952/7200 mean loss: 0.0013171914033591747 score: 1.0
2021-08-08 05:01:17,506 | train | INFO | Epoch 13 train batch 123/450: 1968/7200 mean loss: 0.0015897707780823112 score: 0.9924019607843138
2021-08-08 05:01:18,321 | train | INFO | Epoch 13 train batch 124/450: 1984/7200 mean loss: 0.0014901526737958193 score: 1.0
2021-08-08 05:01:19,133 | train | INFO | Epoch 13 train batch 125/450: 2000/7200 mean loss: 0.001616904279217124 score: 1.0
2021-08-08 05:01:19,934 | train | INFO | Epoch 13 train batch 126/450: 2016/7200 mean loss: 0.0014824707759544253 score: 1.0
2021-08-08 05:01:20,720 | train | INFO | Epoch 13 train batch 127/450: 2032/7200 mean loss: 0.001452257507480681 score: 1.0
2021-08-08 05:01:21,538 | train | INFO | Epoch 13 train batch 128/450: 2048/7200 mean loss: 0.0011246012290939689 score: 1.0
2021-08-08 05:01:22,333 | train | INFO | Epoch 13 train batch 129/450: 2064/7200 mean loss: 0.0013752734521403909 score: 0.98109243697479
2021-08-08 05:01:23,120 | train | INFO | Epoch 13 train batch 130/450: 2080/7200 mean loss: 0.0013541609514504671 score: 1.0
2021-08-08 05:01:23,917 | train | INFO | Epoch 13 train batch 131/450: 2096/7200 mean loss: 0.001278586219996214 score: 1.0
2021-08-08 05:01:24,791 | train | INFO | Epoch 13 train batch 132/450: 2112/7200 mean loss: 0.0012688606511801481 score: 0.9926470588235294
2021-08-08 05:01:25,592 | train | INFO | Epoch 13 train batch 133/450: 2128/7200 mean loss: 0.00123408914078027 score: 1.0
2021-08-08 05:01:26,383 | train | INFO | Epoch 13 train batch 134/450: 2144/7200 mean loss: 0.0013327570632100105 score: 1.0
2021-08-08 05:01:27,171 | train | INFO | Epoch 13 train batch 135/450: 2160/7200 mean loss: 0.0014254192356020212 score: 1.0
2021-08-08 05:01:27,972 | train | INFO | Epoch 13 train batch 136/450: 2176/7200 mean loss: 0.0012621248606592417 score: 1.0
2021-08-08 05:01:28,766 | train | INFO | Epoch 13 train batch 137/450: 2192/7200 mean loss: 0.001462371088564396 score: 1.0
2021-08-08 05:01:29,541 | train | INFO | Epoch 13 train batch 138/450: 2208/7200 mean loss: 0.0013662828132510185 score: 1.0
2021-08-08 05:01:30,328 | train | INFO | Epoch 13 train batch 139/450: 2224/7200 mean loss: 0.001141046523116529 score: 1.0
2021-08-08 05:01:31,117 | train | INFO | Epoch 13 train batch 140/450: 2240/7200 mean loss: 0.0013981189113110304 score: 0.9963235294117647
2021-08-08 05:01:31,925 | train | INFO | Epoch 13 train batch 141/450: 2256/7200 mean loss: 0.0012385102454572916 score: 1.0
2021-08-08 05:01:32,732 | train | INFO | Epoch 13 train batch 142/450: 2272/7200 mean loss: 0.0014283586060628295 score: 1.0
2021-08-08 05:01:33,540 | train | INFO | Epoch 13 train batch 143/450: 2288/7200 mean loss: 0.0013415368739515543 score: 1.0
2021-08-08 05:01:34,324 | train | INFO | Epoch 13 train batch 144/450: 2304/7200 mean loss: 0.001300766016356647 score: 0.9926470588235294
2021-08-08 05:01:35,133 | train | INFO | Epoch 13 train batch 145/450: 2320/7200 mean loss: 0.0014127399772405624 score: 1.0
2021-08-08 05:01:35,908 | train | INFO | Epoch 13 train batch 146/450: 2336/7200 mean loss: 0.0015171103877946734 score: 0.9705882352941176
2021-08-08 05:01:36,713 | train | INFO | Epoch 13 train batch 147/450: 2352/7200 mean loss: 0.0013966549886390567 score: 0.996078431372549
2021-08-08 05:01:37,521 | train | INFO | Epoch 13 train batch 148/450: 2368/7200 mean loss: 0.0014678011648356915 score: 1.0
2021-08-08 05:01:38,338 | train | INFO | Epoch 13 train batch 149/450: 2384/7200 mean loss: 0.001439858926460147 score: 1.0
2021-08-08 05:01:39,142 | train | INFO | Epoch 13 train batch 150/450: 2400/7200 mean loss: 0.0014363819500431418 score: 1.0
2021-08-08 05:01:39,916 | train | INFO | Epoch 13 train batch 151/450: 2416/7200 mean loss: 0.0016848427476361394 score: 1.0
2021-08-08 05:01:40,699 | train | INFO | Epoch 13 train batch 152/450: 2432/7200 mean loss: 0.0013488749973475933 score: 1.0
2021-08-08 05:01:41,553 | train | INFO | Epoch 13 train batch 153/450: 2448/7200 mean loss: 0.001553513458929956 score: 0.9889705882352942
2021-08-08 05:01:42,324 | train | INFO | Epoch 13 train batch 154/450: 2464/7200 mean loss: 0.0017257954459637403 score: 1.0
2021-08-08 05:01:43,118 | train | INFO | Epoch 13 train batch 155/450: 2480/7200 mean loss: 0.0012080518063157797 score: 1.0
2021-08-08 05:01:43,903 | train | INFO | Epoch 13 train batch 156/450: 2496/7200 mean loss: 0.0014730425318703055 score: 0.9963235294117647
2021-08-08 05:01:44,705 | train | INFO | Epoch 13 train batch 157/450: 2512/7200 mean loss: 0.0015272189630195498 score: 1.0
2021-08-08 05:01:45,527 | train | INFO | Epoch 13 train batch 158/450: 2528/7200 mean loss: 0.001486883033066988 score: 1.0
2021-08-08 05:01:46,313 | train | INFO | Epoch 13 train batch 159/450: 2544/7200 mean loss: 0.0012866209726780653 score: 1.0
2021-08-08 05:01:47,101 | train | INFO | Epoch 13 train batch 160/450: 2560/7200 mean loss: 0.001445926376618445 score: 0.9926470588235294
2021-08-08 05:01:47,894 | train | INFO | Epoch 13 train batch 161/450: 2576/7200 mean loss: 0.001545966719277203 score: 1.0
2021-08-08 05:01:48,666 | train | INFO | Epoch 13 train batch 162/450: 2592/7200 mean loss: 0.0015618079341948032 score: 1.0
2021-08-08 05:01:49,495 | train | INFO | Epoch 13 train batch 163/450: 2608/7200 mean loss: 0.0015991805121302605 score: 1.0
2021-08-08 05:01:50,311 | train | INFO | Epoch 13 train batch 164/450: 2624/7200 mean loss: 0.0014729920076206326 score: 1.0
2021-08-08 05:01:51,119 | train | INFO | Epoch 13 train batch 165/450: 2640/7200 mean loss: 0.0015750763705000281 score: 1.0
2021-08-08 05:01:51,921 | train | INFO | Epoch 13 train batch 166/450: 2656/7200 mean loss: 0.0016574753681197762 score: 0.9924019607843138
2021-08-08 05:01:52,689 | train | INFO | Epoch 13 train batch 167/450: 2672/7200 mean loss: 0.0013133512111380696 score: 1.0
2021-08-08 05:01:53,482 | train | INFO | Epoch 13 train batch 168/450: 2688/7200 mean loss: 0.0013108282582834363 score: 1.0
2021-08-08 05:01:54,279 | train | INFO | Epoch 13 train batch 169/450: 2704/7200 mean loss: 0.0013991146115586162 score: 1.0
2021-08-08 05:01:55,087 | train | INFO | Epoch 13 train batch 170/450: 2720/7200 mean loss: 0.0010994396870955825 score: 1.0
2021-08-08 05:01:55,850 | train | INFO | Epoch 13 train batch 171/450: 2736/7200 mean loss: 0.0015699677169322968 score: 1.0
2021-08-08 05:01:56,659 | train | INFO | Epoch 13 train batch 172/450: 2752/7200 mean loss: 0.0013365804916247725 score: 1.0
2021-08-08 05:01:57,534 | train | INFO | Epoch 13 train batch 173/450: 2768/7200 mean loss: 0.0015685252146795392 score: 1.0
2021-08-08 05:01:58,318 | train | INFO | Epoch 13 train batch 174/450: 2784/7200 mean loss: 0.0014943230198696256 score: 0.995798319327731
2021-08-08 05:01:59,133 | train | INFO | Epoch 13 train batch 175/450: 2800/7200 mean loss: 0.0012827529571950436 score: 1.0
2021-08-08 05:01:59,918 | train | INFO | Epoch 13 train batch 176/450: 2816/7200 mean loss: 0.0013874613214284182 score: 1.0
2021-08-08 05:02:00,699 | train | INFO | Epoch 13 train batch 177/450: 2832/7200 mean loss: 0.001473154523409903 score: 0.9889705882352942
2021-08-08 05:02:01,509 | train | INFO | Epoch 13 train batch 178/450: 2848/7200 mean loss: 0.0014518322423100471 score: 1.0
2021-08-08 05:02:02,297 | train | INFO | Epoch 13 train batch 179/450: 2864/7200 mean loss: 0.0015893890522420406 score: 0.996078431372549
2021-08-08 05:02:03,085 | train | INFO | Epoch 13 train batch 180/450: 2880/7200 mean loss: 0.0014456117060035467 score: 0.829656862745098
2021-08-08 05:02:03,877 | train | INFO | Epoch 13 train batch 181/450: 2896/7200 mean loss: 0.0013301655417308211 score: 1.0
2021-08-08 05:02:04,655 | train | INFO | Epoch 13 train batch 182/450: 2912/7200 mean loss: 0.0014067026786506176 score: 1.0
2021-08-08 05:02:05,440 | train | INFO | Epoch 13 train batch 183/450: 2928/7200 mean loss: 0.0013441480696201324 score: 1.0
2021-08-08 05:02:06,217 | train | INFO | Epoch 13 train batch 184/450: 2944/7200 mean loss: 0.0014038957888260484 score: 1.0
2021-08-08 05:02:07,036 | train | INFO | Epoch 13 train batch 185/450: 2960/7200 mean loss: 0.0012608306715264916 score: 1.0
2021-08-08 05:02:07,868 | train | INFO | Epoch 13 train batch 186/450: 2976/7200 mean loss: 0.0014092777855694294 score: 1.0
2021-08-08 05:02:08,654 | train | INFO | Epoch 13 train batch 187/450: 2992/7200 mean loss: 0.0014439186779782176 score: 1.0
2021-08-08 05:02:09,435 | train | INFO | Epoch 13 train batch 188/450: 3008/7200 mean loss: 0.0013297756668180227 score: 1.0
2021-08-08 05:02:10,217 | train | INFO | Epoch 13 train batch 189/450: 3024/7200 mean loss: 0.001579631119966507 score: 1.0
2021-08-08 05:02:11,013 | train | INFO | Epoch 13 train batch 190/450: 3040/7200 mean loss: 0.0014536051312461495 score: 1.0
2021-08-08 05:02:11,843 | train | INFO | Epoch 13 train batch 191/450: 3056/7200 mean loss: 0.001474832184612751 score: 1.0
2021-08-08 05:02:12,642 | train | INFO | Epoch 13 train batch 192/450: 3072/7200 mean loss: 0.0013748439960181713 score: 1.0
2021-08-08 05:02:13,481 | train | INFO | Epoch 13 train batch 193/450: 3088/7200 mean loss: 0.001077229855582118 score: 0.996078431372549
2021-08-08 05:02:14,373 | train | INFO | Epoch 13 train batch 194/450: 3104/7200 mean loss: 0.0014178670244291425 score: 1.0
2021-08-08 05:02:15,193 | train | INFO | Epoch 13 train batch 195/450: 3120/7200 mean loss: 0.001257163006812334 score: 1.0
2021-08-08 05:02:15,976 | train | INFO | Epoch 13 train batch 196/450: 3136/7200 mean loss: 0.0013684165896847844 score: 1.0
2021-08-08 05:02:16,777 | train | INFO | Epoch 13 train batch 197/450: 3152/7200 mean loss: 0.0013498992193490267 score: 1.0
2021-08-08 05:02:17,566 | train | INFO | Epoch 13 train batch 198/450: 3168/7200 mean loss: 0.0015418517868965864 score: 1.0
2021-08-08 05:02:18,382 | train | INFO | Epoch 13 train batch 199/450: 3184/7200 mean loss: 0.001352724269963801 score: 1.0
2021-08-08 05:02:19,211 | train | INFO | Epoch 13 train batch 200/450: 3200/7200 mean loss: 0.0014507590094581246 score: 0.9036764705882353
2021-08-08 05:02:20,029 | train | INFO | Epoch 13 train batch 201/450: 3216/7200 mean loss: 0.0014192364178597927 score: 0.9811274509803922
2021-08-08 05:02:20,812 | train | INFO | Epoch 13 train batch 202/450: 3232/7200 mean loss: 0.0013010791735723615 score: 0.7193627450980392
2021-08-08 05:02:21,600 | train | INFO | Epoch 13 train batch 203/450: 3248/7200 mean loss: 0.0013973037712275982 score: 0.996078431372549
2021-08-08 05:02:22,386 | train | INFO | Epoch 13 train batch 204/450: 3264/7200 mean loss: 0.0016226328443735838 score: 1.0
2021-08-08 05:02:23,194 | train | INFO | Epoch 13 train batch 205/450: 3280/7200 mean loss: 0.0015490043442696333 score: 1.0
2021-08-08 05:02:23,969 | train | INFO | Epoch 13 train batch 206/450: 3296/7200 mean loss: 0.0014741981867700815 score: 0.996078431372549
2021-08-08 05:02:24,744 | train | INFO | Epoch 13 train batch 207/450: 3312/7200 mean loss: 0.0014258797746151686 score: 0.9553921568627451
2021-08-08 05:02:25,528 | train | INFO | Epoch 13 train batch 208/450: 3328/7200 mean loss: 0.0015035757096484303 score: 1.0
2021-08-08 05:02:26,322 | train | INFO | Epoch 13 train batch 209/450: 3344/7200 mean loss: 0.001451159710995853 score: 1.0
2021-08-08 05:02:27,111 | train | INFO | Epoch 13 train batch 210/450: 3360/7200 mean loss: 0.0014732382260262966 score: 1.0
2021-08-08 05:02:27,901 | train | INFO | Epoch 13 train batch 211/450: 3376/7200 mean loss: 0.0013663024874404073 score: 1.0
2021-08-08 05:02:28,678 | train | INFO | Epoch 13 train batch 212/450: 3392/7200 mean loss: 0.0014413255266845226 score: 0.9963235294117647
2021-08-08 05:02:29,486 | train | INFO | Epoch 13 train batch 213/450: 3408/7200 mean loss: 0.0015957081923261285 score: 1.0
2021-08-08 05:02:30,260 | train | INFO | Epoch 13 train batch 214/450: 3424/7200 mean loss: 0.0014967374736443162 score: 1.0
2021-08-08 05:02:31,091 | train | INFO | Epoch 13 train batch 215/450: 3440/7200 mean loss: 0.0014730773400515318 score: 0.9852941176470589
2021-08-08 05:02:31,859 | train | INFO | Epoch 13 train batch 216/450: 3456/7200 mean loss: 0.0016781913582235575 score: 1.0
2021-08-08 05:02:32,635 | train | INFO | Epoch 13 train batch 217/450: 3472/7200 mean loss: 0.001406161580234766 score: 1.0
2021-08-08 05:02:33,407 | train | INFO | Epoch 13 train batch 218/450: 3488/7200 mean loss: 0.001502480823546648 score: 1.0
2021-08-08 05:02:34,230 | train | INFO | Epoch 13 train batch 219/450: 3504/7200 mean loss: 0.001755899516865611 score: 0.9926470588235294
2021-08-08 05:02:35,062 | train | INFO | Epoch 13 train batch 220/450: 3520/7200 mean loss: 0.0014741582563146949 score: 1.0
2021-08-08 05:02:35,883 | train | INFO | Epoch 13 train batch 221/450: 3536/7200 mean loss: 0.0015085190534591675 score: 1.0
2021-08-08 05:02:36,674 | train | INFO | Epoch 13 train batch 222/450: 3552/7200 mean loss: 0.0013149004662409425 score: 1.0
2021-08-08 05:02:37,481 | train | INFO | Epoch 13 train batch 223/450: 3568/7200 mean loss: 0.001491014612838626 score: 1.0
2021-08-08 05:02:38,316 | train | INFO | Epoch 13 train batch 224/450: 3584/7200 mean loss: 0.0011850394075736403 score: 0.996078431372549
2021-08-08 05:02:39,098 | train | INFO | Epoch 13 train batch 225/450: 3600/7200 mean loss: 0.0014452147297561169 score: 0.9921568627450981
2021-08-08 05:02:39,908 | train | INFO | Epoch 13 train batch 226/450: 3616/7200 mean loss: 0.001378603046759963 score: 0.9779411764705882
2021-08-08 05:02:40,733 | train | INFO | Epoch 13 train batch 227/450: 3632/7200 mean loss: 0.0013218872481957078 score: 1.0
2021-08-08 05:02:41,511 | train | INFO | Epoch 13 train batch 228/450: 3648/7200 mean loss: 0.0014115181984379888 score: 1.0
2021-08-08 05:02:42,283 | train | INFO | Epoch 13 train batch 229/450: 3664/7200 mean loss: 0.0014503791462630033 score: 0.9963235294117647
2021-08-08 05:02:43,059 | train | INFO | Epoch 13 train batch 230/450: 3680/7200 mean loss: 0.0014212168753147125 score: 1.0
2021-08-08 05:02:43,844 | train | INFO | Epoch 13 train batch 231/450: 3696/7200 mean loss: 0.0013016703305765986 score: 1.0
2021-08-08 05:02:44,745 | train | INFO | Epoch 13 train batch 232/450: 3712/7200 mean loss: 0.0013425289653241634 score: 1.0
2021-08-08 05:02:45,527 | train | INFO | Epoch 13 train batch 233/450: 3728/7200 mean loss: 0.001375464373268187 score: 1.0
2021-08-08 05:02:46,393 | train | INFO | Epoch 13 train batch 234/450: 3744/7200 mean loss: 0.0014548517065122724 score: 1.0
2021-08-08 05:02:47,222 | train | INFO | Epoch 13 train batch 235/450: 3760/7200 mean loss: 0.0012681445805355906 score: 1.0
2021-08-08 05:02:48,012 | train | INFO | Epoch 13 train batch 236/450: 3776/7200 mean loss: 0.0011313179275020957 score: 1.0
2021-08-08 05:02:48,790 | train | INFO | Epoch 13 train batch 237/450: 3792/7200 mean loss: 0.0013650289038196206 score: 1.0
2021-08-08 05:02:49,598 | train | INFO | Epoch 13 train batch 238/450: 3808/7200 mean loss: 0.0013825525529682636 score: 1.0
2021-08-08 05:02:50,373 | train | INFO | Epoch 13 train batch 239/450: 3824/7200 mean loss: 0.00150801963172853 score: 0.996078431372549
2021-08-08 05:02:51,143 | train | INFO | Epoch 13 train batch 240/450: 3840/7200 mean loss: 0.0015506782801821828 score: 1.0
2021-08-08 05:02:51,949 | train | INFO | Epoch 13 train batch 241/450: 3856/7200 mean loss: 0.0015929609071463346 score: 1.0
2021-08-08 05:02:52,747 | train | INFO | Epoch 13 train batch 242/450: 3872/7200 mean loss: 0.0013793879188597202 score: 0.9882002801120447
2021-08-08 05:02:53,534 | train | INFO | Epoch 13 train batch 243/450: 3888/7200 mean loss: 0.0013652043417096138 score: 1.0
2021-08-08 05:02:54,339 | train | INFO | Epoch 13 train batch 244/450: 3904/7200 mean loss: 0.001450157375074923 score: 1.0
2021-08-08 05:02:55,120 | train | INFO | Epoch 13 train batch 245/450: 3920/7200 mean loss: 0.001656369655393064 score: 0.996078431372549
2021-08-08 05:02:55,939 | train | INFO | Epoch 13 train batch 246/450: 3936/7200 mean loss: 0.0014489853056147695 score: 1.0
2021-08-08 05:02:56,745 | train | INFO | Epoch 13 train batch 247/450: 3952/7200 mean loss: 0.0014645452611148357 score: 1.0
2021-08-08 05:02:57,558 | train | INFO | Epoch 13 train batch 248/450: 3968/7200 mean loss: 0.0013797713909298182 score: 1.0
2021-08-08 05:02:58,366 | train | INFO | Epoch 13 train batch 249/450: 3984/7200 mean loss: 0.0014205160550773144 score: 1.0
2021-08-08 05:02:59,142 | train | INFO | Epoch 13 train batch 250/450: 4000/7200 mean loss: 0.0012954968260601163 score: 1.0
2021-08-08 05:02:59,941 | train | INFO | Epoch 13 train batch 251/450: 4016/7200 mean loss: 0.0013765163021162152 score: 0.825735294117647
2021-08-08 05:03:00,717 | train | INFO | Epoch 13 train batch 252/450: 4032/7200 mean loss: 0.0015799005050212145 score: 1.0
2021-08-08 05:03:01,498 | train | INFO | Epoch 13 train batch 253/450: 4048/7200 mean loss: 0.0015639300690963864 score: 1.0
2021-08-08 05:03:02,263 | train | INFO | Epoch 13 train batch 254/450: 4064/7200 mean loss: 0.001524275285191834 score: 0.9926470588235294
2021-08-08 05:03:03,076 | train | INFO | Epoch 13 train batch 255/450: 4080/7200 mean loss: 0.0013314987299963832 score: 1.0
2021-08-08 05:03:03,917 | train | INFO | Epoch 13 train batch 256/450: 4096/7200 mean loss: 0.0014927575830370188 score: 1.0
2021-08-08 05:03:04,688 | train | INFO | Epoch 13 train batch 257/450: 4112/7200 mean loss: 0.0014249617233872414 score: 1.0
2021-08-08 05:03:05,497 | train | INFO | Epoch 13 train batch 258/450: 4128/7200 mean loss: 0.0015753689222037792 score: 0.9963235294117647
2021-08-08 05:03:06,280 | train | INFO | Epoch 13 train batch 259/450: 4144/7200 mean loss: 0.0012135853758081794 score: 1.0
2021-08-08 05:03:07,138 | train | INFO | Epoch 13 train batch 260/450: 4160/7200 mean loss: 0.0015622696373611689 score: 0.9435574229691878
2021-08-08 05:03:07,932 | train | INFO | Epoch 13 train batch 261/450: 4176/7200 mean loss: 0.0013791604433208704 score: 1.0
2021-08-08 05:03:08,754 | train | INFO | Epoch 13 train batch 262/450: 4192/7200 mean loss: 0.001553077599965036 score: 1.0
2021-08-08 05:03:09,553 | train | INFO | Epoch 13 train batch 263/450: 4208/7200 mean loss: 0.0012052527163177729 score: 0.9924019607843138
2021-08-08 05:03:10,333 | train | INFO | Epoch 13 train batch 264/450: 4224/7200 mean loss: 0.0014446796849370003 score: 0.9700980392156863
2021-08-08 05:03:11,135 | train | INFO | Epoch 13 train batch 265/450: 4240/7200 mean loss: 0.0013309851055964828 score: 0.9963235294117647
2021-08-08 05:03:12,012 | train | INFO | Epoch 13 train batch 266/450: 4256/7200 mean loss: 0.0015522181056439877 score: 1.0
2021-08-08 05:03:12,783 | train | INFO | Epoch 13 train batch 267/450: 4272/7200 mean loss: 0.0014181170845404267 score: 1.0
2021-08-08 05:03:13,596 | train | INFO | Epoch 13 train batch 268/450: 4288/7200 mean loss: 0.0012624873779714108 score: 1.0
2021-08-08 05:03:14,406 | train | INFO | Epoch 13 train batch 269/450: 4304/7200 mean loss: 0.001536974566988647 score: 1.0
2021-08-08 05:03:15,239 | train | INFO | Epoch 13 train batch 270/450: 4320/7200 mean loss: 0.001546818995848298 score: 1.0
2021-08-08 05:03:16,058 | train | INFO | Epoch 13 train batch 271/450: 4336/7200 mean loss: 0.0016510890563949943 score: 1.0
2021-08-08 05:03:16,837 | train | INFO | Epoch 13 train batch 272/450: 4352/7200 mean loss: 0.0014840723015367985 score: 1.0
2021-08-08 05:03:17,765 | train | INFO | Epoch 13 train batch 273/450: 4368/7200 mean loss: 0.0014738017925992608 score: 0.9921568627450981
2021-08-08 05:03:18,612 | train | INFO | Epoch 13 train batch 274/450: 4384/7200 mean loss: 0.0015410446794703603 score: 1.0
2021-08-08 05:03:19,459 | train | INFO | Epoch 13 train batch 275/450: 4400/7200 mean loss: 0.0016281381249427795 score: 1.0
2021-08-08 05:03:20,237 | train | INFO | Epoch 13 train batch 276/450: 4416/7200 mean loss: 0.0013344945618882775 score: 1.0
2021-08-08 05:03:21,027 | train | INFO | Epoch 13 train batch 277/450: 4432/7200 mean loss: 0.001221040147356689 score: 1.0
2021-08-08 05:03:21,808 | train | INFO | Epoch 13 train batch 278/450: 4448/7200 mean loss: 0.0013554992619901896 score: 1.0
2021-08-08 05:03:22,612 | train | INFO | Epoch 13 train batch 279/450: 4464/7200 mean loss: 0.0013367637293413281 score: 1.0
2021-08-08 05:03:23,381 | train | INFO | Epoch 13 train batch 280/450: 4480/7200 mean loss: 0.0014566786121577024 score: 1.0
2021-08-08 05:03:24,155 | train | INFO | Epoch 13 train batch 281/450: 4496/7200 mean loss: 0.001207667519338429 score: 1.0
2021-08-08 05:03:24,945 | train | INFO | Epoch 13 train batch 282/450: 4512/7200 mean loss: 0.0014740722253918648 score: 1.0
2021-08-08 05:03:25,758 | train | INFO | Epoch 13 train batch 283/450: 4528/7200 mean loss: 0.0014249923406168818 score: 1.0
2021-08-08 05:03:26,546 | train | INFO | Epoch 13 train batch 284/450: 4544/7200 mean loss: 0.0013599920785054564 score: 1.0
2021-08-08 05:03:27,332 | train | INFO | Epoch 13 train batch 285/450: 4560/7200 mean loss: 0.001588046783581376 score: 1.0
2021-08-08 05:03:28,143 | train | INFO | Epoch 13 train batch 286/450: 4576/7200 mean loss: 0.0015025708125904202 score: 1.0
2021-08-08 05:03:28,922 | train | INFO | Epoch 13 train batch 287/450: 4592/7200 mean loss: 0.001422854489646852 score: 1.0
2021-08-08 05:03:29,698 | train | INFO | Epoch 13 train batch 288/450: 4608/7200 mean loss: 0.001507414155639708 score: 1.0
2021-08-08 05:03:30,508 | train | INFO | Epoch 13 train batch 289/450: 4624/7200 mean loss: 0.0016623528208583593 score: 0.9411764705882353
2021-08-08 05:03:31,305 | train | INFO | Epoch 13 train batch 290/450: 4640/7200 mean loss: 0.0015489364741370082 score: 1.0
2021-08-08 05:03:32,076 | train | INFO | Epoch 13 train batch 291/450: 4656/7200 mean loss: 0.0014843906974419951 score: 1.0
2021-08-08 05:03:32,839 | train | INFO | Epoch 13 train batch 292/450: 4672/7200 mean loss: 0.0013737068511545658 score: 1.0
2021-08-08 05:03:33,637 | train | INFO | Epoch 13 train batch 293/450: 4688/7200 mean loss: 0.00157648092135787 score: 0.9847689075630254
2021-08-08 05:03:34,448 | train | INFO | Epoch 13 train batch 294/450: 4704/7200 mean loss: 0.0014142912114039063 score: 1.0
2021-08-08 05:03:35,211 | train | INFO | Epoch 13 train batch 295/450: 4720/7200 mean loss: 0.0016104377573356032 score: 1.0
2021-08-08 05:03:35,980 | train | INFO | Epoch 13 train batch 296/450: 4736/7200 mean loss: 0.0015036336844787002 score: 1.0
2021-08-08 05:03:36,758 | train | INFO | Epoch 13 train batch 297/450: 4752/7200 mean loss: 0.0013938354095444083 score: 1.0
2021-08-08 05:03:37,531 | train | INFO | Epoch 13 train batch 298/450: 4768/7200 mean loss: 0.001449482049793005 score: 1.0
2021-08-08 05:03:38,314 | train | INFO | Epoch 13 train batch 299/450: 4784/7200 mean loss: 0.0014588577905669808 score: 1.0
2021-08-08 05:03:39,085 | train | INFO | Epoch 13 train batch 300/450: 4800/7200 mean loss: 0.0013438866008073092 score: 1.0
2021-08-08 05:03:39,886 | train | INFO | Epoch 13 train batch 301/450: 4816/7200 mean loss: 0.0013685353333130479 score: 0.970343137254902
2021-08-08 05:03:40,656 | train | INFO | Epoch 13 train batch 302/450: 4832/7200 mean loss: 0.0014722022460773587 score: 1.0
2021-08-08 05:03:41,470 | train | INFO | Epoch 13 train batch 303/450: 4848/7200 mean loss: 0.001336464425548911 score: 1.0
2021-08-08 05:03:42,275 | train | INFO | Epoch 13 train batch 304/450: 4864/7200 mean loss: 0.0013829275267198682 score: 1.0
2021-08-08 05:03:43,055 | train | INFO | Epoch 13 train batch 305/450: 4880/7200 mean loss: 0.001385374809615314 score: 1.0
2021-08-08 05:03:43,849 | train | INFO | Epoch 13 train batch 306/450: 4896/7200 mean loss: 0.001637843786738813 score: 1.0
2021-08-08 05:03:44,621 | train | INFO | Epoch 13 train batch 307/450: 4912/7200 mean loss: 0.0014498045202344656 score: 0.996078431372549
2021-08-08 05:03:45,399 | train | INFO | Epoch 13 train batch 308/450: 4928/7200 mean loss: 0.001504114712588489 score: 1.0
2021-08-08 05:03:46,181 | train | INFO | Epoch 13 train batch 309/450: 4944/7200 mean loss: 0.0016806382918730378 score: 1.0
2021-08-08 05:03:46,965 | train | INFO | Epoch 13 train batch 310/450: 4960/7200 mean loss: 0.0015081458259373903 score: 1.0
2021-08-08 05:03:47,757 | train | INFO | Epoch 13 train batch 311/450: 4976/7200 mean loss: 0.00143639394082129 score: 1.0
2021-08-08 05:03:48,583 | train | INFO | Epoch 13 train batch 312/450: 4992/7200 mean loss: 0.001482416526414454 score: 1.0
2021-08-08 05:03:49,384 | train | INFO | Epoch 13 train batch 313/450: 5008/7200 mean loss: 0.0011592666851356626 score: 0.9926470588235294
2021-08-08 05:03:50,160 | train | INFO | Epoch 13 train batch 314/450: 5024/7200 mean loss: 0.0013675199588760734 score: 0.9963235294117647
2021-08-08 05:03:50,937 | train | INFO | Epoch 13 train batch 315/450: 5040/7200 mean loss: 0.0013684026198461652 score: 0.9742647058823529
2021-08-08 05:03:51,786 | train | INFO | Epoch 13 train batch 316/450: 5056/7200 mean loss: 0.0015374469803646207 score: 1.0
2021-08-08 05:03:52,569 | train | INFO | Epoch 13 train batch 317/450: 5072/7200 mean loss: 0.0013032450806349516 score: 0.91289592760181
2021-08-08 05:03:53,344 | train | INFO | Epoch 13 train batch 318/450: 5088/7200 mean loss: 0.001573773450218141 score: 0.9816176470588235
2021-08-08 05:03:54,138 | train | INFO | Epoch 13 train batch 319/450: 5104/7200 mean loss: 0.0016961118672043085 score: 1.0
2021-08-08 05:03:54,944 | train | INFO | Epoch 13 train batch 320/450: 5120/7200 mean loss: 0.0017001128289848566 score: 1.0
2021-08-08 05:03:55,718 | train | INFO | Epoch 13 train batch 321/450: 5136/7200 mean loss: 0.0017768453108146787 score: 1.0
2021-08-08 05:03:56,490 | train | INFO | Epoch 13 train batch 322/450: 5152/7200 mean loss: 0.0014832228189334273 score: 1.0
2021-08-08 05:03:57,289 | train | INFO | Epoch 13 train batch 323/450: 5168/7200 mean loss: 0.0014857895439490676 score: 0.9884453781512604
2021-08-08 05:03:58,070 | train | INFO | Epoch 13 train batch 324/450: 5184/7200 mean loss: 0.0010818156879395247 score: 0.7921568627450979
2021-08-08 05:03:58,909 | train | INFO | Epoch 13 train batch 325/450: 5200/7200 mean loss: 0.001214924966916442 score: 1.0
2021-08-08 05:03:59,707 | train | INFO | Epoch 13 train batch 326/450: 5216/7200 mean loss: 0.0013792344834655523 score: 0.995798319327731
2021-08-08 05:04:00,512 | train | INFO | Epoch 13 train batch 327/450: 5232/7200 mean loss: 0.0013078697957098484 score: 1.0
2021-08-08 05:04:01,285 | train | INFO | Epoch 13 train batch 328/450: 5248/7200 mean loss: 0.0012490750523284078 score: 0.9884453781512604
2021-08-08 05:04:02,081 | train | INFO | Epoch 13 train batch 329/450: 5264/7200 mean loss: 0.001270795939490199 score: 1.0
2021-08-08 05:04:02,885 | train | INFO | Epoch 13 train batch 330/450: 5280/7200 mean loss: 0.0015078451251611114 score: 0.996078431372549
2021-08-08 05:04:03,660 | train | INFO | Epoch 13 train batch 331/450: 5296/7200 mean loss: 0.0013771975645795465 score: 1.0
2021-08-08 05:04:04,439 | train | INFO | Epoch 13 train batch 332/450: 5312/7200 mean loss: 0.0012872403021901846 score: 1.0
2021-08-08 05:04:05,234 | train | INFO | Epoch 13 train batch 333/450: 5328/7200 mean loss: 0.0015711917076259851 score: 1.0
2021-08-08 05:04:06,016 | train | INFO | Epoch 13 train batch 334/450: 5344/7200 mean loss: 0.0014765921514481306 score: 1.0
2021-08-08 05:04:06,791 | train | INFO | Epoch 13 train batch 335/450: 5360/7200 mean loss: 0.0012670170981436968 score: 1.0
2021-08-08 05:04:07,613 | train | INFO | Epoch 13 train batch 336/450: 5376/7200 mean loss: 0.0015023746527731419 score: 1.0
2021-08-08 05:04:08,393 | train | INFO | Epoch 13 train batch 337/450: 5392/7200 mean loss: 0.0014348820550367236 score: 0.7848039215686274
2021-08-08 05:04:09,159 | train | INFO | Epoch 13 train batch 338/450: 5408/7200 mean loss: 0.0013328978093340993 score: 1.0
2021-08-08 05:04:09,929 | train | INFO | Epoch 13 train batch 339/450: 5424/7200 mean loss: 0.001470991293899715 score: 1.0
2021-08-08 05:04:10,696 | train | INFO | Epoch 13 train batch 340/450: 5440/7200 mean loss: 0.00165787513833493 score: 0.9963235294117647
2021-08-08 05:04:11,526 | train | INFO | Epoch 13 train batch 341/450: 5456/7200 mean loss: 0.0013245621230453253 score: 0.9963235294117647
2021-08-08 05:04:12,322 | train | INFO | Epoch 13 train batch 342/450: 5472/7200 mean loss: 0.001831140834838152 score: 1.0
2021-08-08 05:04:13,115 | train | INFO | Epoch 13 train batch 343/450: 5488/7200 mean loss: 0.0016190921887755394 score: 0.9921568627450981
2021-08-08 05:04:13,937 | train | INFO | Epoch 13 train batch 344/450: 5504/7200 mean loss: 0.001532670808956027 score: 1.0
2021-08-08 05:04:14,733 | train | INFO | Epoch 13 train batch 345/450: 5520/7200 mean loss: 0.0015058242715895176 score: 0.9808823529411765
2021-08-08 05:04:15,573 | train | INFO | Epoch 13 train batch 346/450: 5536/7200 mean loss: 0.001662582391873002 score: 0.9963235294117647
2021-08-08 05:04:16,372 | train | INFO | Epoch 13 train batch 347/450: 5552/7200 mean loss: 0.0016467187087982893 score: 1.0
2021-08-08 05:04:17,192 | train | INFO | Epoch 13 train batch 348/450: 5568/7200 mean loss: 0.001434430480003357 score: 1.0
2021-08-08 05:04:18,001 | train | INFO | Epoch 13 train batch 349/450: 5584/7200 mean loss: 0.0014029364101588726 score: 1.0
2021-08-08 05:04:18,855 | train | INFO | Epoch 13 train batch 350/450: 5600/7200 mean loss: 0.0014959550462663174 score: 1.0
2021-08-08 05:04:19,653 | train | INFO | Epoch 13 train batch 351/450: 5616/7200 mean loss: 0.0013588303700089455 score: 0.9921218487394959
2021-08-08 05:04:20,432 | train | INFO | Epoch 13 train batch 352/450: 5632/7200 mean loss: 0.0015133920824155211 score: 0.9876750700280112
2021-08-08 05:04:21,280 | train | INFO | Epoch 13 train batch 353/450: 5648/7200 mean loss: 0.0014711660332977772 score: 1.0
2021-08-08 05:04:22,094 | train | INFO | Epoch 13 train batch 354/450: 5664/7200 mean loss: 0.0012984509812667966 score: 1.0
2021-08-08 05:04:22,875 | train | INFO | Epoch 13 train batch 355/450: 5680/7200 mean loss: 0.0013013824354857206 score: 1.0
2021-08-08 05:04:23,696 | train | INFO | Epoch 13 train batch 356/450: 5696/7200 mean loss: 0.0012392583303153515 score: 1.0
2021-08-08 05:04:24,482 | train | INFO | Epoch 13 train batch 357/450: 5712/7200 mean loss: 0.001568224048241973 score: 1.0
2021-08-08 05:04:25,274 | train | INFO | Epoch 13 train batch 358/450: 5728/7200 mean loss: 0.0012445049360394478 score: 1.0
2021-08-08 05:04:26,077 | train | INFO | Epoch 13 train batch 359/450: 5744/7200 mean loss: 0.0014215741539373994 score: 1.0
2021-08-08 05:04:26,864 | train | INFO | Epoch 13 train batch 360/450: 5760/7200 mean loss: 0.0014342601643875241 score: 1.0
2021-08-08 05:04:27,694 | train | INFO | Epoch 13 train batch 361/450: 5776/7200 mean loss: 0.0014193825190886855 score: 0.9558823529411765
2021-08-08 05:04:28,481 | train | INFO | Epoch 13 train batch 362/450: 5792/7200 mean loss: 0.0015632358845323324 score: 0.996078431372549
2021-08-08 05:04:29,294 | train | INFO | Epoch 13 train batch 363/450: 5808/7200 mean loss: 0.0015643647639080882 score: 0.9963235294117647
2021-08-08 05:04:30,069 | train | INFO | Epoch 13 train batch 364/450: 5824/7200 mean loss: 0.0015773355262354016 score: 0.9737745098039216
2021-08-08 05:04:30,884 | train | INFO | Epoch 13 train batch 365/450: 5840/7200 mean loss: 0.0014898121589794755 score: 1.0
2021-08-08 05:04:31,775 | train | INFO | Epoch 13 train batch 366/450: 5856/7200 mean loss: 0.001491259434260428 score: 1.0
2021-08-08 05:04:32,589 | train | INFO | Epoch 13 train batch 367/450: 5872/7200 mean loss: 0.0015476779080927372 score: 0.9803221288515407
2021-08-08 05:04:33,390 | train | INFO | Epoch 13 train batch 368/450: 5888/7200 mean loss: 0.001392779522575438 score: 1.0
2021-08-08 05:04:34,225 | train | INFO | Epoch 13 train batch 369/450: 5904/7200 mean loss: 0.001469534239731729 score: 1.0
2021-08-08 05:04:35,000 | train | INFO | Epoch 13 train batch 370/450: 5920/7200 mean loss: 0.0013631576439365745 score: 0.9963235294117647
2021-08-08 05:04:35,799 | train | INFO | Epoch 13 train batch 371/450: 5936/7200 mean loss: 0.001442439155653119 score: 0.9963235294117647
2021-08-08 05:04:36,603 | train | INFO | Epoch 13 train batch 372/450: 5952/7200 mean loss: 0.0013405842473730445 score: 1.0
2021-08-08 05:04:37,381 | train | INFO | Epoch 13 train batch 373/450: 5968/7200 mean loss: 0.0016369929071515799 score: 0.9963235294117647
2021-08-08 05:04:38,173 | train | INFO | Epoch 13 train batch 374/450: 5984/7200 mean loss: 0.0017338584875687957 score: 0.9889705882352942
2021-08-08 05:04:38,947 | train | INFO | Epoch 13 train batch 375/450: 6000/7200 mean loss: 0.0013933269074186683 score: 0.996078431372549
2021-08-08 05:04:39,727 | train | INFO | Epoch 13 train batch 376/450: 6016/7200 mean loss: 0.0014772623544558883 score: 1.0
2021-08-08 05:04:40,521 | train | INFO | Epoch 13 train batch 377/450: 6032/7200 mean loss: 0.0015491542872041464 score: 1.0
2021-08-08 05:04:41,332 | train | INFO | Epoch 13 train batch 378/450: 6048/7200 mean loss: 0.0014095689402893186 score: 1.0
2021-08-08 05:04:42,139 | train | INFO | Epoch 13 train batch 379/450: 6064/7200 mean loss: 0.0012137081939727068 score: 1.0
2021-08-08 05:04:42,955 | train | INFO | Epoch 13 train batch 380/450: 6080/7200 mean loss: 0.0012305214768275619 score: 1.0
2021-08-08 05:04:43,738 | train | INFO | Epoch 13 train batch 381/450: 6096/7200 mean loss: 0.001312019769102335 score: 1.0
2021-08-08 05:04:44,511 | train | INFO | Epoch 13 train batch 382/450: 6112/7200 mean loss: 0.0014078496024012566 score: 0.9963235294117647
2021-08-08 05:04:45,291 | train | INFO | Epoch 13 train batch 383/450: 6128/7200 mean loss: 0.0013667831663042307 score: 0.9963235294117647
2021-08-08 05:04:46,123 | train | INFO | Epoch 13 train batch 384/450: 6144/7200 mean loss: 0.0015827355673536658 score: 1.0
2021-08-08 05:04:46,936 | train | INFO | Epoch 13 train batch 385/450: 6160/7200 mean loss: 0.0017499240348115563 score: 1.0
2021-08-08 05:04:47,735 | train | INFO | Epoch 13 train batch 386/450: 6176/7200 mean loss: 0.0016585540724918246 score: 0.9740196078431372
2021-08-08 05:04:48,519 | train | INFO | Epoch 13 train batch 387/450: 6192/7200 mean loss: 0.0016021083574742079 score: 0.9963235294117647
2021-08-08 05:04:49,292 | train | INFO | Epoch 13 train batch 388/450: 6208/7200 mean loss: 0.0016872409032657743 score: 1.0
2021-08-08 05:04:50,089 | train | INFO | Epoch 13 train batch 389/450: 6224/7200 mean loss: 0.0016581554664298892 score: 1.0
2021-08-08 05:04:50,960 | train | INFO | Epoch 13 train batch 390/450: 6240/7200 mean loss: 0.00125030311755836 score: 1.0
2021-08-08 05:04:51,730 | train | INFO | Epoch 13 train batch 391/450: 6256/7200 mean loss: 0.0012227686820551753 score: 1.0
2021-08-08 05:04:52,530 | train | INFO | Epoch 13 train batch 392/450: 6272/7200 mean loss: 0.0012455831747502089 score: 1.0
2021-08-08 05:04:53,351 | train | INFO | Epoch 13 train batch 393/450: 6288/7200 mean loss: 0.0012132942210882902 score: 0.9816176470588235
2021-08-08 05:04:54,124 | train | INFO | Epoch 13 train batch 394/450: 6304/7200 mean loss: 0.0013350107474252582 score: 1.0
2021-08-08 05:04:54,936 | train | INFO | Epoch 13 train batch 395/450: 6320/7200 mean loss: 0.0011065128492191434 score: 0.9811274509803922
2021-08-08 05:04:55,744 | train | INFO | Epoch 13 train batch 396/450: 6336/7200 mean loss: 0.0014548320323228836 score: 1.0
2021-08-08 05:04:56,553 | train | INFO | Epoch 13 train batch 397/450: 6352/7200 mean loss: 0.001442694803699851 score: 1.0
2021-08-08 05:04:57,327 | train | INFO | Epoch 13 train batch 398/450: 6368/7200 mean loss: 0.0015471485676243901 score: 1.0
2021-08-08 05:04:58,137 | train | INFO | Epoch 13 train batch 399/450: 6384/7200 mean loss: 0.0013989071594551206 score: 1.0
2021-08-08 05:04:58,906 | train | INFO | Epoch 13 train batch 400/450: 6400/7200 mean loss: 0.0013842214830219746 score: 1.0
2021-08-08 05:04:59,712 | train | INFO | Epoch 13 train batch 401/450: 6416/7200 mean loss: 0.0014423619722947478 score: 1.0
2021-08-08 05:05:00,496 | train | INFO | Epoch 13 train batch 402/450: 6432/7200 mean loss: 0.0014128992334008217 score: 1.0
2021-08-08 05:05:01,297 | train | INFO | Epoch 13 train batch 403/450: 6448/7200 mean loss: 0.0015983176417648792 score: 1.0
2021-08-08 05:05:02,099 | train | INFO | Epoch 13 train batch 404/450: 6464/7200 mean loss: 0.0012467856286093593 score: 1.0
2021-08-08 05:05:02,883 | train | INFO | Epoch 13 train batch 405/450: 6480/7200 mean loss: 0.0015414677327498794 score: 1.0
2021-08-08 05:05:03,765 | train | INFO | Epoch 13 train batch 406/450: 6496/7200 mean loss: 0.0013806867646053433 score: 1.0
2021-08-08 05:05:04,573 | train | INFO | Epoch 13 train batch 407/450: 6512/7200 mean loss: 0.001631087390705943 score: 0.996078431372549
2021-08-08 05:05:05,427 | train | INFO | Epoch 13 train batch 408/450: 6528/7200 mean loss: 0.0013066796818748116 score: 1.0
2021-08-08 05:05:06,228 | train | INFO | Epoch 13 train batch 409/450: 6544/7200 mean loss: 0.0012800891418009996 score: 1.0
2021-08-08 05:05:07,035 | train | INFO | Epoch 13 train batch 410/450: 6560/7200 mean loss: 0.0013302891748026013 score: 1.0
2021-08-08 05:05:07,834 | train | INFO | Epoch 13 train batch 411/450: 6576/7200 mean loss: 0.0011500554392114282 score: 1.0
2021-08-08 05:05:08,623 | train | INFO | Epoch 13 train batch 412/450: 6592/7200 mean loss: 0.0013353016693145037 score: 1.0
2021-08-08 05:05:09,431 | train | INFO | Epoch 13 train batch 413/450: 6608/7200 mean loss: 0.0012916962150484324 score: 1.0
2021-08-08 05:05:10,238 | train | INFO | Epoch 13 train batch 414/450: 6624/7200 mean loss: 0.0012919057626277208 score: 1.0
2021-08-08 05:05:11,029 | train | INFO | Epoch 13 train batch 415/450: 6640/7200 mean loss: 0.001414193189702928 score: 0.9774159663865545
2021-08-08 05:05:11,803 | train | INFO | Epoch 13 train batch 416/450: 6656/7200 mean loss: 0.0013193305348977447 score: 1.0
2021-08-08 05:05:12,567 | train | INFO | Epoch 13 train batch 417/450: 6672/7200 mean loss: 0.0014661188470199704 score: 0.996078431372549
2021-08-08 05:05:13,335 | train | INFO | Epoch 13 train batch 418/450: 6688/7200 mean loss: 0.00150637689512223 score: 1.0
2021-08-08 05:05:14,120 | train | INFO | Epoch 13 train batch 419/450: 6704/7200 mean loss: 0.0014524136204272509 score: 1.0
2021-08-08 05:05:14,919 | train | INFO | Epoch 13 train batch 420/450: 6720/7200 mean loss: 0.0014327551471069455 score: 1.0
2021-08-08 05:05:15,776 | train | INFO | Epoch 13 train batch 421/450: 6736/7200 mean loss: 0.0016357512213289738 score: 1.0
2021-08-08 05:05:16,595 | train | INFO | Epoch 13 train batch 422/450: 6752/7200 mean loss: 0.0015415576053783298 score: 1.0
2021-08-08 05:05:17,377 | train | INFO | Epoch 13 train batch 423/450: 6768/7200 mean loss: 0.0013189971214160323 score: 1.0
2021-08-08 05:05:18,150 | train | INFO | Epoch 13 train batch 424/450: 6784/7200 mean loss: 0.0014940547989681363 score: 1.0
2021-08-08 05:05:18,959 | train | INFO | Epoch 13 train batch 425/450: 6800/7200 mean loss: 0.0016204878920689225 score: 1.0
2021-08-08 05:05:19,750 | train | INFO | Epoch 13 train batch 426/450: 6816/7200 mean loss: 0.0015834929654374719 score: 1.0
2021-08-08 05:05:20,592 | train | INFO | Epoch 13 train batch 427/450: 6832/7200 mean loss: 0.0014640477020293474 score: 1.0
2021-08-08 05:05:21,398 | train | INFO | Epoch 13 train batch 428/450: 6848/7200 mean loss: 0.0015654650051146746 score: 0.9926470588235294
2021-08-08 05:05:22,209 | train | INFO | Epoch 13 train batch 429/450: 6864/7200 mean loss: 0.0014835087349638343 score: 1.0
2021-08-08 05:05:23,000 | train | INFO | Epoch 13 train batch 430/450: 6880/7200 mean loss: 0.00156354287173599 score: 1.0
2021-08-08 05:05:23,809 | train | INFO | Epoch 13 train batch 431/450: 6896/7200 mean loss: 0.0016574785113334656 score: 1.0
2021-08-08 05:05:24,606 | train | INFO | Epoch 13 train batch 432/450: 6912/7200 mean loss: 0.0014444319531321526 score: 1.0
2021-08-08 05:05:25,387 | train | INFO | Epoch 13 train batch 433/450: 6928/7200 mean loss: 0.001472656847909093 score: 1.0
2021-08-08 05:05:26,157 | train | INFO | Epoch 13 train batch 434/450: 6944/7200 mean loss: 0.0015520791057497263 score: 1.0
2021-08-08 05:05:26,935 | train | INFO | Epoch 13 train batch 435/450: 6960/7200 mean loss: 0.0014425810659304261 score: 0.9963235294117647
2021-08-08 05:05:27,724 | train | INFO | Epoch 13 train batch 436/450: 6976/7200 mean loss: 0.0014435453340411186 score: 1.0
2021-08-08 05:05:28,557 | train | INFO | Epoch 13 train batch 437/450: 6992/7200 mean loss: 0.0015507987700402737 score: 0.9926470588235294
2021-08-08 05:05:29,326 | train | INFO | Epoch 13 train batch 438/450: 7008/7200 mean loss: 0.0015844915760681033 score: 1.0
2021-08-08 05:05:30,094 | train | INFO | Epoch 13 train batch 439/450: 7024/7200 mean loss: 0.001435910351574421 score: 1.0
2021-08-08 05:05:30,862 | train | INFO | Epoch 13 train batch 440/450: 7040/7200 mean loss: 0.001346956822089851 score: 1.0
2021-08-08 05:05:31,632 | train | INFO | Epoch 13 train batch 441/450: 7056/7200 mean loss: 0.001627122052013874 score: 0.996078431372549
2021-08-08 05:05:32,415 | train | INFO | Epoch 13 train batch 442/450: 7072/7200 mean loss: 0.0015787186566740274 score: 1.0
2021-08-08 05:05:33,186 | train | INFO | Epoch 13 train batch 443/450: 7088/7200 mean loss: 0.0015655140159651637 score: 1.0
2021-08-08 05:05:34,078 | train | INFO | Epoch 13 train batch 444/450: 7104/7200 mean loss: 0.0015792077174410224 score: 1.0
2021-08-08 05:05:34,900 | train | INFO | Epoch 13 train batch 445/450: 7120/7200 mean loss: 0.0012698119971901178 score: 1.0
2021-08-08 05:05:35,690 | train | INFO | Epoch 13 train batch 446/450: 7136/7200 mean loss: 0.001439741812646389 score: 1.0
2021-08-08 05:05:36,466 | train | INFO | Epoch 13 train batch 447/450: 7152/7200 mean loss: 0.0013009055983275175 score: 1.0
2021-08-08 05:05:37,241 | train | INFO | Epoch 13 train batch 448/450: 7168/7200 mean loss: 0.0014054463244974613 score: 0.9771708683473389
2021-08-08 05:05:38,014 | train | INFO | Epoch 13 train batch 449/450: 7184/7200 mean loss: 0.001368762576021254 score: 1.0
2021-08-08 05:05:38,153 | train | INFO | Epoch 13, Train, Mean loss: 0.022979772099190287, Score: 0.994291340467811
2021-08-08 05:05:39,653 | train | INFO | Epoch 13 validation batch 0/113: 0/1800 mean loss: 0.000992811401374638 score: 1.0
2021-08-08 05:05:39,887 | train | INFO | Epoch 13 validation batch 1/113: 16/1800 mean loss: 0.0010374767007306218 score: 0.9963235294117647
2021-08-08 05:05:40,143 | train | INFO | Epoch 13 validation batch 2/113: 32/1800 mean loss: 0.0012854627566412091 score: 1.0
2021-08-08 05:05:40,376 | train | INFO | Epoch 13 validation batch 3/113: 48/1800 mean loss: 0.0011016058269888163 score: 1.0
2021-08-08 05:05:40,626 | train | INFO | Epoch 13 validation batch 4/113: 64/1800 mean loss: 0.00097879848908633 score: 1.0
2021-08-08 05:05:40,866 | train | INFO | Epoch 13 validation batch 5/113: 80/1800 mean loss: 0.0009881543228402734 score: 1.0
2021-08-08 05:05:41,114 | train | INFO | Epoch 13 validation batch 6/113: 96/1800 mean loss: 0.000930210342630744 score: 1.0
2021-08-08 05:05:41,345 | train | INFO | Epoch 13 validation batch 7/113: 112/1800 mean loss: 0.0010729044442996383 score: 1.0
2021-08-08 05:05:41,576 | train | INFO | Epoch 13 validation batch 8/113: 128/1800 mean loss: 0.001055216183885932 score: 1.0
2021-08-08 05:05:41,847 | train | INFO | Epoch 13 validation batch 9/113: 144/1800 mean loss: 0.0010377655271440744 score: 1.0
2021-08-08 05:05:42,090 | train | INFO | Epoch 13 validation batch 10/113: 160/1800 mean loss: 0.0011194850085303187 score: 0.9816176470588235
2021-08-08 05:05:42,341 | train | INFO | Epoch 13 validation batch 11/113: 176/1800 mean loss: 0.001111731631681323 score: 0.9963235294117647
2021-08-08 05:05:42,593 | train | INFO | Epoch 13 validation batch 12/113: 192/1800 mean loss: 0.001044982229359448 score: 1.0
2021-08-08 05:05:42,825 | train | INFO | Epoch 13 validation batch 13/113: 208/1800 mean loss: 0.000956961652263999 score: 1.0
2021-08-08 05:05:43,055 | train | INFO | Epoch 13 validation batch 14/113: 224/1800 mean loss: 0.0008681079489178956 score: 1.0
2021-08-08 05:05:43,300 | train | INFO | Epoch 13 validation batch 15/113: 240/1800 mean loss: 0.0010255054803565145 score: 1.0
2021-08-08 05:05:43,531 | train | INFO | Epoch 13 validation batch 16/113: 256/1800 mean loss: 0.0010294396197423339 score: 1.0
2021-08-08 05:05:43,769 | train | INFO | Epoch 13 validation batch 17/113: 272/1800 mean loss: 0.0011272410629317164 score: 1.0
2021-08-08 05:05:44,034 | train | INFO | Epoch 13 validation batch 18/113: 288/1800 mean loss: 0.0008409028523601592 score: 1.0
2021-08-08 05:05:44,285 | train | INFO | Epoch 13 validation batch 19/113: 304/1800 mean loss: 0.0010037339525297284 score: 1.0
2021-08-08 05:05:44,516 | train | INFO | Epoch 13 validation batch 20/113: 320/1800 mean loss: 0.0011254084529355168 score: 0.9926470588235294
2021-08-08 05:05:44,747 | train | INFO | Epoch 13 validation batch 21/113: 336/1800 mean loss: 0.0009573759161867201 score: 1.0
2021-08-08 05:05:44,982 | train | INFO | Epoch 13 validation batch 22/113: 352/1800 mean loss: 0.0009854347445070744 score: 1.0
2021-08-08 05:05:45,237 | train | INFO | Epoch 13 validation batch 23/113: 368/1800 mean loss: 0.0009398310212418437 score: 1.0
2021-08-08 05:05:45,470 | train | INFO | Epoch 13 validation batch 24/113: 384/1800 mean loss: 0.0010302428854629397 score: 1.0
2021-08-08 05:05:45,700 | train | INFO | Epoch 13 validation batch 25/113: 400/1800 mean loss: 0.0011055985232815146 score: 1.0
2021-08-08 05:05:45,932 | train | INFO | Epoch 13 validation batch 26/113: 416/1800 mean loss: 0.0008651878451928496 score: 1.0
2021-08-08 05:05:46,164 | train | INFO | Epoch 13 validation batch 27/113: 432/1800 mean loss: 0.001099039800465107 score: 1.0
2021-08-08 05:05:46,409 | train | INFO | Epoch 13 validation batch 28/113: 448/1800 mean loss: 0.0010068680858239532 score: 1.0
2021-08-08 05:05:46,661 | train | INFO | Epoch 13 validation batch 29/113: 464/1800 mean loss: 0.001024227007292211 score: 1.0
2021-08-08 05:05:46,892 | train | INFO | Epoch 13 validation batch 30/113: 480/1800 mean loss: 0.0010200374526903033 score: 1.0
2021-08-08 05:05:47,137 | train | INFO | Epoch 13 validation batch 31/113: 496/1800 mean loss: 0.0010025434894487262 score: 1.0
2021-08-08 05:05:47,385 | train | INFO | Epoch 13 validation batch 32/113: 512/1800 mean loss: 0.0010462731588631868 score: 1.0
2021-08-08 05:05:47,619 | train | INFO | Epoch 13 validation batch 33/113: 528/1800 mean loss: 0.0009079813025891781 score: 1.0
2021-08-08 05:05:47,860 | train | INFO | Epoch 13 validation batch 34/113: 544/1800 mean loss: 0.0007748960051685572 score: 1.0
2021-08-08 05:05:48,105 | train | INFO | Epoch 13 validation batch 35/113: 560/1800 mean loss: 0.001198295853100717 score: 1.0
2021-08-08 05:05:48,337 | train | INFO | Epoch 13 validation batch 36/113: 576/1800 mean loss: 0.0011531487107276917 score: 0.9259803921568628
2021-08-08 05:05:48,567 | train | INFO | Epoch 13 validation batch 37/113: 592/1800 mean loss: 0.0008474084315821528 score: 1.0
2021-08-08 05:05:48,800 | train | INFO | Epoch 13 validation batch 38/113: 608/1800 mean loss: 0.0010519539937376976 score: 1.0
2021-08-08 05:05:49,051 | train | INFO | Epoch 13 validation batch 39/113: 624/1800 mean loss: 0.000983649049885571 score: 1.0
2021-08-08 05:05:49,295 | train | INFO | Epoch 13 validation batch 40/113: 640/1800 mean loss: 0.0009983546333387494 score: 1.0
2021-08-08 05:05:49,528 | train | INFO | Epoch 13 validation batch 41/113: 656/1800 mean loss: 0.0009519868763163686 score: 1.0
2021-08-08 05:05:49,775 | train | INFO | Epoch 13 validation batch 42/113: 672/1800 mean loss: 0.00098054064437747 score: 1.0
2021-08-08 05:05:50,018 | train | INFO | Epoch 13 validation batch 43/113: 688/1800 mean loss: 0.0009725295240059495 score: 1.0
2021-08-08 05:05:50,254 | train | INFO | Epoch 13 validation batch 44/113: 704/1800 mean loss: 0.0012415036326274276 score: 0.9705882352941176
2021-08-08 05:05:50,497 | train | INFO | Epoch 13 validation batch 45/113: 720/1800 mean loss: 0.0010516606271266937 score: 1.0
2021-08-08 05:05:50,746 | train | INFO | Epoch 13 validation batch 46/113: 736/1800 mean loss: 0.0010095613542944193 score: 0.9926470588235294
2021-08-08 05:05:50,988 | train | INFO | Epoch 13 validation batch 47/113: 752/1800 mean loss: 0.000943331397138536 score: 1.0
2021-08-08 05:05:51,218 | train | INFO | Epoch 13 validation batch 48/113: 768/1800 mean loss: 0.0009458550484851003 score: 1.0
2021-08-08 05:05:51,477 | train | INFO | Epoch 13 validation batch 49/113: 784/1800 mean loss: 0.00101717549841851 score: 1.0
2021-08-08 05:05:51,724 | train | INFO | Epoch 13 validation batch 50/113: 800/1800 mean loss: 0.0009299698867835104 score: 1.0
2021-08-08 05:05:51,956 | train | INFO | Epoch 13 validation batch 51/113: 816/1800 mean loss: 0.0010938083287328482 score: 0.9889705882352942
2021-08-08 05:05:52,189 | train | INFO | Epoch 13 validation batch 52/113: 832/1800 mean loss: 0.0009949118830263615 score: 1.0
2021-08-08 05:05:52,421 | train | INFO | Epoch 13 validation batch 53/113: 848/1800 mean loss: 0.0009576823213137686 score: 1.0
2021-08-08 05:05:52,670 | train | INFO | Epoch 13 validation batch 54/113: 864/1800 mean loss: 0.0009646533872000873 score: 1.0
2021-08-08 05:05:52,901 | train | INFO | Epoch 13 validation batch 55/113: 880/1800 mean loss: 0.0010716150281950831 score: 1.0
2021-08-08 05:05:53,156 | train | INFO | Epoch 13 validation batch 56/113: 896/1800 mean loss: 0.001027111429721117 score: 1.0
2021-08-08 05:05:53,386 | train | INFO | Epoch 13 validation batch 57/113: 912/1800 mean loss: 0.0010774721158668399 score: 1.0
2021-08-08 05:05:53,616 | train | INFO | Epoch 13 validation batch 58/113: 928/1800 mean loss: 0.0010831770487129688 score: 0.9889705882352942
2021-08-08 05:05:53,846 | train | INFO | Epoch 13 validation batch 59/113: 944/1800 mean loss: 0.000969738292042166 score: 1.0
2021-08-08 05:05:54,086 | train | INFO | Epoch 13 validation batch 60/113: 960/1800 mean loss: 0.0008715532021597028 score: 1.0
2021-08-08 05:05:54,325 | train | INFO | Epoch 13 validation batch 61/113: 976/1800 mean loss: 0.0009171880665235221 score: 1.0
2021-08-08 05:05:54,556 | train | INFO | Epoch 13 validation batch 62/113: 992/1800 mean loss: 0.0009792906930670142 score: 1.0
2021-08-08 05:05:54,788 | train | INFO | Epoch 13 validation batch 63/113: 1008/1800 mean loss: 0.000957418349571526 score: 1.0
2021-08-08 05:05:55,019 | train | INFO | Epoch 13 validation batch 64/113: 1024/1800 mean loss: 0.000980983255431056 score: 1.0
2021-08-08 05:05:55,251 | train | INFO | Epoch 13 validation batch 65/113: 1040/1800 mean loss: 0.0010726754553616047 score: 1.0
2021-08-08 05:05:55,483 | train | INFO | Epoch 13 validation batch 66/113: 1056/1800 mean loss: 0.001017988659441471 score: 1.0
2021-08-08 05:05:55,752 | train | INFO | Epoch 13 validation batch 67/113: 1072/1800 mean loss: 0.001087670330889523 score: 1.0
2021-08-08 05:05:55,987 | train | INFO | Epoch 13 validation batch 68/113: 1088/1800 mean loss: 0.0008523802971467376 score: 1.0
2021-08-08 05:05:56,219 | train | INFO | Epoch 13 validation batch 69/113: 1104/1800 mean loss: 0.0009352730121463537 score: 1.0
2021-08-08 05:05:56,453 | train | INFO | Epoch 13 validation batch 70/113: 1120/1800 mean loss: 0.0011683893389999866 score: 0.9963235294117647
2021-08-08 05:05:56,727 | train | INFO | Epoch 13 validation batch 71/113: 1136/1800 mean loss: 0.0009259464568458498 score: 1.0
2021-08-08 05:05:56,982 | train | INFO | Epoch 13 validation batch 72/113: 1152/1800 mean loss: 0.0009198621846735477 score: 1.0
2021-08-08 05:05:57,213 | train | INFO | Epoch 13 validation batch 73/113: 1168/1800 mean loss: 0.0011634915135800838 score: 1.0
2021-08-08 05:05:57,457 | train | INFO | Epoch 13 validation batch 74/113: 1184/1800 mean loss: 0.0011019319063052535 score: 1.0
2021-08-08 05:05:57,704 | train | INFO | Epoch 13 validation batch 75/113: 1200/1800 mean loss: 0.0009539286256767809 score: 1.0
2021-08-08 05:05:57,985 | train | INFO | Epoch 13 validation batch 76/113: 1216/1800 mean loss: 0.0008652135147713125 score: 1.0
2021-08-08 05:05:58,241 | train | INFO | Epoch 13 validation batch 77/113: 1232/1800 mean loss: 0.0008640569285489619 score: 1.0
2021-08-08 05:05:58,502 | train | INFO | Epoch 13 validation batch 78/113: 1248/1800 mean loss: 0.0009730883175507188 score: 0.9852941176470589
2021-08-08 05:05:58,761 | train | INFO | Epoch 13 validation batch 79/113: 1264/1800 mean loss: 0.0011312618153169751 score: 0.9921568627450981
2021-08-08 05:05:58,996 | train | INFO | Epoch 13 validation batch 80/113: 1280/1800 mean loss: 0.0011970063205808401 score: 1.0
2021-08-08 05:05:59,227 | train | INFO | Epoch 13 validation batch 81/113: 1296/1800 mean loss: 0.0009943480836227536 score: 1.0
2021-08-08 05:05:59,473 | train | INFO | Epoch 13 validation batch 82/113: 1312/1800 mean loss: 0.0010159373050555587 score: 1.0
2021-08-08 05:05:59,704 | train | INFO | Epoch 13 validation batch 83/113: 1328/1800 mean loss: 0.0011558221885934472 score: 1.0
2021-08-08 05:05:59,952 | train | INFO | Epoch 13 validation batch 84/113: 1344/1800 mean loss: 0.0011506146984174848 score: 0.9889705882352942
2021-08-08 05:06:00,186 | train | INFO | Epoch 13 validation batch 85/113: 1360/1800 mean loss: 0.0010297151748090982 score: 1.0
2021-08-08 05:06:00,421 | train | INFO | Epoch 13 validation batch 86/113: 1376/1800 mean loss: 0.0012535863788798451 score: 1.0
2021-08-08 05:06:00,654 | train | INFO | Epoch 13 validation batch 87/113: 1392/1800 mean loss: 0.0011957595124840736 score: 1.0
2021-08-08 05:06:00,897 | train | INFO | Epoch 13 validation batch 88/113: 1408/1800 mean loss: 0.0009811847703531384 score: 1.0
2021-08-08 05:06:01,130 | train | INFO | Epoch 13 validation batch 89/113: 1424/1800 mean loss: 0.0008735582232475281 score: 1.0
2021-08-08 05:06:01,362 | train | INFO | Epoch 13 validation batch 90/113: 1440/1800 mean loss: 0.0009309988236054778 score: 1.0
2021-08-08 05:06:01,593 | train | INFO | Epoch 13 validation batch 91/113: 1456/1800 mean loss: 0.0012649532873183489 score: 1.0
2021-08-08 05:06:01,829 | train | INFO | Epoch 13 validation batch 92/113: 1472/1800 mean loss: 0.0009680407820269465 score: 1.0
2021-08-08 05:06:02,062 | train | INFO | Epoch 13 validation batch 93/113: 1488/1800 mean loss: 0.001021758420392871 score: 1.0
2021-08-08 05:06:02,350 | train | INFO | Epoch 13 validation batch 94/113: 1504/1800 mean loss: 0.0009690314764156938 score: 1.0
2021-08-08 05:06:02,616 | train | INFO | Epoch 13 validation batch 95/113: 1520/1800 mean loss: 0.001069356338120997 score: 1.0
2021-08-08 05:06:02,867 | train | INFO | Epoch 13 validation batch 96/113: 1536/1800 mean loss: 0.0011369063286110759 score: 1.0
2021-08-08 05:06:03,099 | train | INFO | Epoch 13 validation batch 97/113: 1552/1800 mean loss: 0.0010298305423930287 score: 1.0
2021-08-08 05:06:03,330 | train | INFO | Epoch 13 validation batch 98/113: 1568/1800 mean loss: 0.0009978580055758357 score: 1.0
2021-08-08 05:06:03,574 | train | INFO | Epoch 13 validation batch 99/113: 1584/1800 mean loss: 0.0009895350085571408 score: 1.0
2021-08-08 05:06:03,805 | train | INFO | Epoch 13 validation batch 100/113: 1600/1800 mean loss: 0.0011734608560800552 score: 1.0
2021-08-08 05:06:04,037 | train | INFO | Epoch 13 validation batch 101/113: 1616/1800 mean loss: 0.0009724457049742341 score: 1.0
2021-08-08 05:06:04,268 | train | INFO | Epoch 13 validation batch 102/113: 1632/1800 mean loss: 0.0009200755157507956 score: 1.0
2021-08-08 05:06:04,499 | train | INFO | Epoch 13 validation batch 103/113: 1648/1800 mean loss: 0.0009777393424883485 score: 1.0
2021-08-08 05:06:04,730 | train | INFO | Epoch 13 validation batch 104/113: 1664/1800 mean loss: 0.0010937446495518088 score: 1.0
2021-08-08 05:06:04,961 | train | INFO | Epoch 13 validation batch 105/113: 1680/1800 mean loss: 0.001027646940201521 score: 1.0
2021-08-08 05:06:05,192 | train | INFO | Epoch 13 validation batch 106/113: 1696/1800 mean loss: 0.0010627550072968006 score: 1.0
2021-08-08 05:06:05,423 | train | INFO | Epoch 13 validation batch 107/113: 1712/1800 mean loss: 0.0013043710496276617 score: 1.0
2021-08-08 05:06:05,654 | train | INFO | Epoch 13 validation batch 108/113: 1728/1800 mean loss: 0.0012424513697624207 score: 1.0
2021-08-08 05:06:05,885 | train | INFO | Epoch 13 validation batch 109/113: 1744/1800 mean loss: 0.0011444375850260258 score: 1.0
2021-08-08 05:06:06,117 | train | INFO | Epoch 13 validation batch 110/113: 1760/1800 mean loss: 0.0009299046942032874 score: 1.0
2021-08-08 05:06:06,348 | train | INFO | Epoch 13 validation batch 111/113: 1776/1800 mean loss: 0.0009684424730949104 score: 1.0
2021-08-08 05:06:06,513 | train | INFO | Epoch 13 validation batch 112/113: 1792/1800 mean loss: 0.0009242438827641308 score: 1.0
2021-08-08 05:06:06,687 | train | INFO | Epoch 13, Validation, Mean loss: 0.01638564966882752, Score: 0.9982018913760194
2021-08-08 05:06:06,688 | train | INFO | Write row 13
2021-08-08 05:06:09,595 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 05:06:09,599 | train | INFO | Update best record row 14, checkpoints 0.016521866103650723 -> 0.01638564966882752
2021-08-08 05:06:11,587 | train | INFO | Epoch 14 train batch 0/450: 0/7200 mean loss: 0.0012318026274442673 score: 0.9963235294117647
2021-08-08 05:06:12,397 | train | INFO | Epoch 14 train batch 1/450: 16/7200 mean loss: 0.0012876290129497647 score: 0.9879201680672269
2021-08-08 05:06:13,179 | train | INFO | Epoch 14 train batch 2/450: 32/7200 mean loss: 0.0012750072637572885 score: 1.0
2021-08-08 05:06:13,973 | train | INFO | Epoch 14 train batch 3/450: 48/7200 mean loss: 0.0013715371023863554 score: 0.9926470588235294
2021-08-08 05:06:14,761 | train | INFO | Epoch 14 train batch 4/450: 64/7200 mean loss: 0.0014314785366877913 score: 1.0
2021-08-08 05:06:15,633 | train | INFO | Epoch 14 train batch 5/450: 80/7200 mean loss: 0.0012669858988374472 score: 1.0
2021-08-08 05:06:16,419 | train | INFO | Epoch 14 train batch 6/450: 96/7200 mean loss: 0.0015668177511543036 score: 1.0
2021-08-08 05:06:17,197 | train | INFO | Epoch 14 train batch 7/450: 112/7200 mean loss: 0.0014267521910369396 score: 0.9779411764705882
2021-08-08 05:06:17,984 | train | INFO | Epoch 14 train batch 8/450: 128/7200 mean loss: 0.0016101900255307555 score: 1.0
2021-08-08 05:06:18,800 | train | INFO | Epoch 14 train batch 9/450: 144/7200 mean loss: 0.0017008708091452718 score: 1.0
2021-08-08 05:06:19,587 | train | INFO | Epoch 14 train batch 10/450: 160/7200 mean loss: 0.0016040242044255137 score: 1.0
2021-08-08 05:06:20,398 | train | INFO | Epoch 14 train batch 11/450: 176/7200 mean loss: 0.0015974646667018533 score: 1.0
2021-08-08 05:06:21,170 | train | INFO | Epoch 14 train batch 12/450: 192/7200 mean loss: 0.0015473064268007874 score: 1.0
2021-08-08 05:06:21,996 | train | INFO | Epoch 14 train batch 13/450: 208/7200 mean loss: 0.0012916363775730133 score: 0.9963235294117647
2021-08-08 05:06:22,774 | train | INFO | Epoch 14 train batch 14/450: 224/7200 mean loss: 0.0015224182279780507 score: 1.0
2021-08-08 05:06:23,603 | train | INFO | Epoch 14 train batch 15/450: 240/7200 mean loss: 0.0014339584158733487 score: 1.0
2021-08-08 05:06:24,430 | train | INFO | Epoch 14 train batch 16/450: 256/7200 mean loss: 0.0011735568987205625 score: 0.9963235294117647
2021-08-08 05:06:25,211 | train | INFO | Epoch 14 train batch 17/450: 272/7200 mean loss: 0.0015359357930719852 score: 1.0
2021-08-08 05:06:25,988 | train | INFO | Epoch 14 train batch 18/450: 288/7200 mean loss: 0.0015665950486436486 score: 0.9852941176470589
2021-08-08 05:06:26,816 | train | INFO | Epoch 14 train batch 19/450: 304/7200 mean loss: 0.0013856686418876052 score: 1.0
2021-08-08 05:06:27,617 | train | INFO | Epoch 14 train batch 20/450: 320/7200 mean loss: 0.0014313323190435767 score: 1.0
2021-08-08 05:06:28,455 | train | INFO | Epoch 14 train batch 21/450: 336/7200 mean loss: 0.0014117647660896182 score: 1.0
2021-08-08 05:06:29,267 | train | INFO | Epoch 14 train batch 22/450: 352/7200 mean loss: 0.0014351544668897986 score: 1.0
2021-08-08 05:06:30,055 | train | INFO | Epoch 14 train batch 23/450: 368/7200 mean loss: 0.001548901665955782 score: 0.996078431372549
2021-08-08 05:06:30,855 | train | INFO | Epoch 14 train batch 24/450: 384/7200 mean loss: 0.0013798505533486605 score: 1.0
2021-08-08 05:06:31,659 | train | INFO | Epoch 14 train batch 25/450: 400/7200 mean loss: 0.001416554325260222 score: 1.0
2021-08-08 05:06:32,462 | train | INFO | Epoch 14 train batch 26/450: 416/7200 mean loss: 0.00152615609113127 score: 1.0
2021-08-08 05:06:33,285 | train | INFO | Epoch 14 train batch 27/450: 432/7200 mean loss: 0.0015635612653568387 score: 1.0
2021-08-08 05:06:34,092 | train | INFO | Epoch 14 train batch 28/450: 448/7200 mean loss: 0.0013540994841605425 score: 0.9963235294117647
2021-08-08 05:06:34,866 | train | INFO | Epoch 14 train batch 29/450: 464/7200 mean loss: 0.0015311646275222301 score: 1.0
2021-08-08 05:06:35,648 | train | INFO | Epoch 14 train batch 30/450: 480/7200 mean loss: 0.0014449050650000572 score: 0.9963235294117647
2021-08-08 05:06:36,420 | train | INFO | Epoch 14 train batch 31/450: 496/7200 mean loss: 0.001381269539706409 score: 1.0
2021-08-08 05:06:37,209 | train | INFO | Epoch 14 train batch 32/450: 512/7200 mean loss: 0.0014905306743457913 score: 1.0
2021-08-08 05:06:37,999 | train | INFO | Epoch 14 train batch 33/450: 528/7200 mean loss: 0.0015777050284668803 score: 1.0
2021-08-08 05:06:38,782 | train | INFO | Epoch 14 train batch 34/450: 544/7200 mean loss: 0.001429980038665235 score: 1.0
2021-08-08 05:06:39,567 | train | INFO | Epoch 14 train batch 35/450: 560/7200 mean loss: 0.001420504879206419 score: 1.0
2021-08-08 05:06:40,340 | train | INFO | Epoch 14 train batch 36/450: 576/7200 mean loss: 0.0014369945274665952 score: 1.0
2021-08-08 05:06:41,146 | train | INFO | Epoch 14 train batch 37/450: 592/7200 mean loss: 0.0013719400158151984 score: 1.0
2021-08-08 05:06:41,921 | train | INFO | Epoch 14 train batch 38/450: 608/7200 mean loss: 0.0014129980700090528 score: 0.9921568627450981
2021-08-08 05:06:42,726 | train | INFO | Epoch 14 train batch 39/450: 624/7200 mean loss: 0.0013206048170104623 score: 1.0
2021-08-08 05:06:43,535 | train | INFO | Epoch 14 train batch 40/450: 640/7200 mean loss: 0.0014380494831129909 score: 1.0
2021-08-08 05:06:44,309 | train | INFO | Epoch 14 train batch 41/450: 656/7200 mean loss: 0.0013143032556399703 score: 1.0
2021-08-08 05:06:45,172 | train | INFO | Epoch 14 train batch 42/450: 672/7200 mean loss: 0.001231881440617144 score: 1.0
2021-08-08 05:06:45,949 | train | INFO | Epoch 14 train batch 43/450: 688/7200 mean loss: 0.0014441199600696564 score: 1.0
2021-08-08 05:06:46,753 | train | INFO | Epoch 14 train batch 44/450: 704/7200 mean loss: 0.0013258648104965687 score: 1.0
2021-08-08 05:06:47,560 | train | INFO | Epoch 14 train batch 45/450: 720/7200 mean loss: 0.0013981388183310628 score: 1.0
2021-08-08 05:06:48,376 | train | INFO | Epoch 14 train batch 46/450: 736/7200 mean loss: 0.00147153134457767 score: 1.0
2021-08-08 05:06:49,227 | train | INFO | Epoch 14 train batch 47/450: 752/7200 mean loss: 0.0014186225598677993 score: 0.9926470588235294
2021-08-08 05:06:50,036 | train | INFO | Epoch 14 train batch 48/450: 768/7200 mean loss: 0.0013231978518888354 score: 1.0
2021-08-08 05:06:50,811 | train | INFO | Epoch 14 train batch 49/450: 784/7200 mean loss: 0.001308182836510241 score: 1.0
2021-08-08 05:06:51,600 | train | INFO | Epoch 14 train batch 50/450: 800/7200 mean loss: 0.0014230371452867985 score: 1.0
2021-08-08 05:06:52,396 | train | INFO | Epoch 14 train batch 51/450: 816/7200 mean loss: 0.0014007658464834094 score: 0.9926470588235294
2021-08-08 05:06:53,191 | train | INFO | Epoch 14 train batch 52/450: 832/7200 mean loss: 0.0013660910772159696 score: 1.0
2021-08-08 05:06:53,974 | train | INFO | Epoch 14 train batch 53/450: 848/7200 mean loss: 0.0016427335795015097 score: 1.0
2021-08-08 05:06:54,768 | train | INFO | Epoch 14 train batch 54/450: 864/7200 mean loss: 0.0012782083358615637 score: 1.0
2021-08-08 05:06:55,572 | train | INFO | Epoch 14 train batch 55/450: 880/7200 mean loss: 0.001421287888661027 score: 1.0
2021-08-08 05:06:56,347 | train | INFO | Epoch 14 train batch 56/450: 896/7200 mean loss: 0.0014059781096875668 score: 1.0
2021-08-08 05:06:57,126 | train | INFO | Epoch 14 train batch 57/450: 912/7200 mean loss: 0.0012683096574619412 score: 1.0
2021-08-08 05:06:57,932 | train | INFO | Epoch 14 train batch 58/450: 928/7200 mean loss: 0.0014372310834005475 score: 1.0
2021-08-08 05:06:58,706 | train | INFO | Epoch 14 train batch 59/450: 944/7200 mean loss: 0.0013285264139994979 score: 1.0
2021-08-08 05:06:59,481 | train | INFO | Epoch 14 train batch 60/450: 960/7200 mean loss: 0.0015308890724554658 score: 1.0
2021-08-08 05:07:00,257 | train | INFO | Epoch 14 train batch 61/450: 976/7200 mean loss: 0.0015245153335854411 score: 1.0
2021-08-08 05:07:01,070 | train | INFO | Epoch 14 train batch 62/450: 992/7200 mean loss: 0.0017361114732921124 score: 1.0
2021-08-08 05:07:01,849 | train | INFO | Epoch 14 train batch 63/450: 1008/7200 mean loss: 0.0015586960362270474 score: 1.0
2021-08-08 05:07:02,647 | train | INFO | Epoch 14 train batch 64/450: 1024/7200 mean loss: 0.001620542723685503 score: 1.0
2021-08-08 05:07:03,454 | train | INFO | Epoch 14 train batch 65/450: 1040/7200 mean loss: 0.001557071809656918 score: 1.0
2021-08-08 05:07:04,258 | train | INFO | Epoch 14 train batch 66/450: 1056/7200 mean loss: 0.0014155012322589755 score: 1.0
2021-08-08 05:07:05,030 | train | INFO | Epoch 14 train batch 67/450: 1072/7200 mean loss: 0.001441766507923603 score: 1.0
2021-08-08 05:07:05,803 | train | INFO | Epoch 14 train batch 68/450: 1088/7200 mean loss: 0.001231660251505673 score: 0.9705882352941176
2021-08-08 05:07:06,581 | train | INFO | Epoch 14 train batch 69/450: 1104/7200 mean loss: 0.001222797785885632 score: 1.0
2021-08-08 05:07:07,370 | train | INFO | Epoch 14 train batch 70/450: 1120/7200 mean loss: 0.001224509789608419 score: 1.0
2021-08-08 05:07:08,191 | train | INFO | Epoch 14 train batch 71/450: 1136/7200 mean loss: 0.0016025119693949819 score: 0.6838235294117647
2021-08-08 05:07:08,999 | train | INFO | Epoch 14 train batch 72/450: 1152/7200 mean loss: 0.0013215261278674006 score: 1.0
2021-08-08 05:07:09,786 | train | INFO | Epoch 14 train batch 73/450: 1168/7200 mean loss: 0.0014377048937603831 score: 1.0
2021-08-08 05:07:10,597 | train | INFO | Epoch 14 train batch 74/450: 1184/7200 mean loss: 0.0014973554061725736 score: 0.9924019607843138
2021-08-08 05:07:11,395 | train | INFO | Epoch 14 train batch 75/450: 1200/7200 mean loss: 0.0013360695447772741 score: 1.0
2021-08-08 05:07:12,241 | train | INFO | Epoch 14 train batch 76/450: 1216/7200 mean loss: 0.0015269035939127207 score: 1.0
2021-08-08 05:07:13,080 | train | INFO | Epoch 14 train batch 77/450: 1232/7200 mean loss: 0.0016713679069653153 score: 1.0
2021-08-08 05:07:13,862 | train | INFO | Epoch 14 train batch 78/450: 1248/7200 mean loss: 0.0014286007499322295 score: 1.0
2021-08-08 05:07:14,664 | train | INFO | Epoch 14 train batch 79/450: 1264/7200 mean loss: 0.0012527703074738383 score: 1.0
2021-08-08 05:07:15,502 | train | INFO | Epoch 14 train batch 80/450: 1280/7200 mean loss: 0.0014655159320682287 score: 1.0
2021-08-08 05:07:16,346 | train | INFO | Epoch 14 train batch 81/450: 1296/7200 mean loss: 0.0013358568539842963 score: 0.9887254901960785
2021-08-08 05:07:17,166 | train | INFO | Epoch 14 train batch 82/450: 1312/7200 mean loss: 0.0012996550649404526 score: 1.0
2021-08-08 05:07:17,985 | train | INFO | Epoch 14 train batch 83/450: 1328/7200 mean loss: 0.0012774755014106631 score: 1.0
2021-08-08 05:07:18,784 | train | INFO | Epoch 14 train batch 84/450: 1344/7200 mean loss: 0.0012307012220844626 score: 1.0
2021-08-08 05:07:19,663 | train | INFO | Epoch 14 train batch 85/450: 1360/7200 mean loss: 0.0012901051668450236 score: 0.9921568627450981
2021-08-08 05:07:20,530 | train | INFO | Epoch 14 train batch 86/450: 1376/7200 mean loss: 0.0011362034128978848 score: 1.0
2021-08-08 05:07:21,315 | train | INFO | Epoch 14 train batch 87/450: 1392/7200 mean loss: 0.0013546794652938843 score: 0.9522058823529411
2021-08-08 05:07:22,114 | train | INFO | Epoch 14 train batch 88/450: 1408/7200 mean loss: 0.001556776580400765 score: 0.9889705882352942
2021-08-08 05:07:22,933 | train | INFO | Epoch 14 train batch 89/450: 1424/7200 mean loss: 0.0013088914565742016 score: 1.0
2021-08-08 05:07:23,716 | train | INFO | Epoch 14 train batch 90/450: 1440/7200 mean loss: 0.001349969650618732 score: 0.9963235294117647
2021-08-08 05:07:24,494 | train | INFO | Epoch 14 train batch 91/450: 1456/7200 mean loss: 0.0014220975572243333 score: 1.0
2021-08-08 05:07:25,273 | train | INFO | Epoch 14 train batch 92/450: 1472/7200 mean loss: 0.0013128569116815925 score: 1.0
2021-08-08 05:07:26,067 | train | INFO | Epoch 14 train batch 93/450: 1488/7200 mean loss: 0.001242469297721982 score: 0.9963235294117647
2021-08-08 05:07:26,957 | train | INFO | Epoch 14 train batch 94/450: 1504/7200 mean loss: 0.0015964284539222717 score: 1.0
2021-08-08 05:07:27,813 | train | INFO | Epoch 14 train batch 95/450: 1520/7200 mean loss: 0.0014859186485409737 score: 0.9850490196078432
2021-08-08 05:07:28,593 | train | INFO | Epoch 14 train batch 96/450: 1536/7200 mean loss: 0.0013509250711649656 score: 1.0
2021-08-08 05:07:29,385 | train | INFO | Epoch 14 train batch 97/450: 1552/7200 mean loss: 0.001588858780451119 score: 1.0
2021-08-08 05:07:30,153 | train | INFO | Epoch 14 train batch 98/450: 1568/7200 mean loss: 0.0016677647363394499 score: 1.0
2021-08-08 05:07:30,934 | train | INFO | Epoch 14 train batch 99/450: 1584/7200 mean loss: 0.001478932099416852 score: 1.0
2021-08-08 05:07:31,712 | train | INFO | Epoch 14 train batch 100/450: 1600/7200 mean loss: 0.001261068624444306 score: 1.0
2021-08-08 05:07:32,519 | train | INFO | Epoch 14 train batch 101/450: 1616/7200 mean loss: 0.0012740700040012598 score: 1.0
2021-08-08 05:07:33,349 | train | INFO | Epoch 14 train batch 102/450: 1632/7200 mean loss: 0.0012637246400117874 score: 1.0
2021-08-08 05:07:34,156 | train | INFO | Epoch 14 train batch 103/450: 1648/7200 mean loss: 0.0013238232349976897 score: 1.0
2021-08-08 05:07:34,962 | train | INFO | Epoch 14 train batch 104/450: 1664/7200 mean loss: 0.0012504345504567027 score: 1.0
2021-08-08 05:07:35,779 | train | INFO | Epoch 14 train batch 105/450: 1680/7200 mean loss: 0.0015427903272211552 score: 1.0
2021-08-08 05:07:36,597 | train | INFO | Epoch 14 train batch 106/450: 1696/7200 mean loss: 0.0013505211099982262 score: 1.0
2021-08-08 05:07:37,421 | train | INFO | Epoch 14 train batch 107/450: 1712/7200 mean loss: 0.0013475514715537429 score: 1.0
2021-08-08 05:07:38,237 | train | INFO | Epoch 14 train batch 108/450: 1728/7200 mean loss: 0.001545836334116757 score: 0.996078431372549
2021-08-08 05:07:39,007 | train | INFO | Epoch 14 train batch 109/450: 1744/7200 mean loss: 0.001721935230307281 score: 1.0
2021-08-08 05:07:39,786 | train | INFO | Epoch 14 train batch 110/450: 1760/7200 mean loss: 0.0015526171773672104 score: 0.9884803921568628
2021-08-08 05:07:40,673 | train | INFO | Epoch 14 train batch 111/450: 1776/7200 mean loss: 0.0016273028450086713 score: 1.0
2021-08-08 05:07:41,562 | train | INFO | Epoch 14 train batch 112/450: 1792/7200 mean loss: 0.0015646329848095775 score: 1.0
2021-08-08 05:07:42,352 | train | INFO | Epoch 14 train batch 113/450: 1808/7200 mean loss: 0.0015644782688468695 score: 1.0
2021-08-08 05:07:43,146 | train | INFO | Epoch 14 train batch 114/450: 1824/7200 mean loss: 0.00114525540266186 score: 1.0
2021-08-08 05:07:43,961 | train | INFO | Epoch 14 train batch 115/450: 1840/7200 mean loss: 0.0011816766345873475 score: 1.0
2021-08-08 05:07:44,762 | train | INFO | Epoch 14 train batch 116/450: 1856/7200 mean loss: 0.001337618799880147 score: 1.0
2021-08-08 05:07:45,527 | train | INFO | Epoch 14 train batch 117/450: 1872/7200 mean loss: 0.0013166341232135892 score: 1.0
2021-08-08 05:07:46,337 | train | INFO | Epoch 14 train batch 118/450: 1888/7200 mean loss: 0.001509191351942718 score: 1.0
2021-08-08 05:07:47,120 | train | INFO | Epoch 14 train batch 119/450: 1904/7200 mean loss: 0.0013887115055695176 score: 1.0
2021-08-08 05:07:47,974 | train | INFO | Epoch 14 train batch 120/450: 1920/7200 mean loss: 0.0014807622646912932 score: 1.0
2021-08-08 05:07:48,809 | train | INFO | Epoch 14 train batch 121/450: 1936/7200 mean loss: 0.001546761835925281 score: 1.0
2021-08-08 05:07:49,584 | train | INFO | Epoch 14 train batch 122/450: 1952/7200 mean loss: 0.0014535333029925823 score: 1.0
2021-08-08 05:07:50,355 | train | INFO | Epoch 14 train batch 123/450: 1968/7200 mean loss: 0.0016536380862817168 score: 1.0
2021-08-08 05:07:51,137 | train | INFO | Epoch 14 train batch 124/450: 1984/7200 mean loss: 0.001391152385622263 score: 1.0
2021-08-08 05:07:51,933 | train | INFO | Epoch 14 train batch 125/450: 2000/7200 mean loss: 0.0012987159425392747 score: 1.0
2021-08-08 05:07:52,734 | train | INFO | Epoch 14 train batch 126/450: 2016/7200 mean loss: 0.001325325109064579 score: 0.9963235294117647
2021-08-08 05:07:53,555 | train | INFO | Epoch 14 train batch 127/450: 2032/7200 mean loss: 0.0015112144174054265 score: 1.0
2021-08-08 05:07:54,340 | train | INFO | Epoch 14 train batch 128/450: 2048/7200 mean loss: 0.0014320305781438947 score: 1.0
2021-08-08 05:07:55,115 | train | INFO | Epoch 14 train batch 129/450: 2064/7200 mean loss: 0.0014366379473358393 score: 1.0
2021-08-08 05:07:55,896 | train | INFO | Epoch 14 train batch 130/450: 2080/7200 mean loss: 0.0016429302049800754 score: 0.9963235294117647
2021-08-08 05:07:56,694 | train | INFO | Epoch 14 train batch 131/450: 2096/7200 mean loss: 0.0011374122695997357 score: 1.0
2021-08-08 05:07:57,466 | train | INFO | Epoch 14 train batch 132/450: 2112/7200 mean loss: 0.0014954274520277977 score: 0.7867647058823529
2021-08-08 05:07:58,279 | train | INFO | Epoch 14 train batch 133/450: 2128/7200 mean loss: 0.0015395042719319463 score: 1.0
2021-08-08 05:07:59,075 | train | INFO | Epoch 14 train batch 134/450: 2144/7200 mean loss: 0.001413725782185793 score: 0.9963235294117647
2021-08-08 05:07:59,856 | train | INFO | Epoch 14 train batch 135/450: 2160/7200 mean loss: 0.0013482713839039207 score: 1.0
2021-08-08 05:08:00,627 | train | INFO | Epoch 14 train batch 136/450: 2176/7200 mean loss: 0.0013403474586084485 score: 1.0
2021-08-08 05:08:01,404 | train | INFO | Epoch 14 train batch 137/450: 2192/7200 mean loss: 0.001574550406076014 score: 1.0
2021-08-08 05:08:02,196 | train | INFO | Epoch 14 train batch 138/450: 2208/7200 mean loss: 0.0012831491185352206 score: 0.995798319327731
2021-08-08 05:08:02,983 | train | INFO | Epoch 14 train batch 139/450: 2224/7200 mean loss: 0.0014682657783851027 score: 1.0
2021-08-08 05:08:03,756 | train | INFO | Epoch 14 train batch 140/450: 2240/7200 mean loss: 0.001396725419908762 score: 0.9963235294117647
2021-08-08 05:08:04,562 | train | INFO | Epoch 14 train batch 141/450: 2256/7200 mean loss: 0.0015357699012383819 score: 1.0
2021-08-08 05:08:05,343 | train | INFO | Epoch 14 train batch 142/450: 2272/7200 mean loss: 0.001389169367030263 score: 1.0
2021-08-08 05:08:06,136 | train | INFO | Epoch 14 train batch 143/450: 2288/7200 mean loss: 0.0013726355973631144 score: 1.0
2021-08-08 05:08:06,922 | train | INFO | Epoch 14 train batch 144/450: 2304/7200 mean loss: 0.0013928974512964487 score: 1.0
2021-08-08 05:08:07,762 | train | INFO | Epoch 14 train batch 145/450: 2320/7200 mean loss: 0.0013953533489257097 score: 1.0
2021-08-08 05:08:08,555 | train | INFO | Epoch 14 train batch 146/450: 2336/7200 mean loss: 0.0015316448407247663 score: 1.0
2021-08-08 05:08:09,380 | train | INFO | Epoch 14 train batch 147/450: 2352/7200 mean loss: 0.0013706256868317723 score: 0.9254901960784313
2021-08-08 05:08:10,179 | train | INFO | Epoch 14 train batch 148/450: 2368/7200 mean loss: 0.00143056467641145 score: 1.0
2021-08-08 05:08:10,954 | train | INFO | Epoch 14 train batch 149/450: 2384/7200 mean loss: 0.001359467743895948 score: 1.0
2021-08-08 05:08:11,733 | train | INFO | Epoch 14 train batch 150/450: 2400/7200 mean loss: 0.0014627177733927965 score: 0.970343137254902
2021-08-08 05:08:12,500 | train | INFO | Epoch 14 train batch 151/450: 2416/7200 mean loss: 0.001668252982199192 score: 1.0
2021-08-08 05:08:13,288 | train | INFO | Epoch 14 train batch 152/450: 2432/7200 mean loss: 0.0015553723787888885 score: 1.0
2021-08-08 05:08:14,090 | train | INFO | Epoch 14 train batch 153/450: 2448/7200 mean loss: 0.0015648211119696498 score: 1.0
2021-08-08 05:08:14,896 | train | INFO | Epoch 14 train batch 154/450: 2464/7200 mean loss: 0.001504238578490913 score: 1.0
2021-08-08 05:08:15,696 | train | INFO | Epoch 14 train batch 155/450: 2480/7200 mean loss: 0.001445357222110033 score: 1.0
2021-08-08 05:08:16,521 | train | INFO | Epoch 14 train batch 156/450: 2496/7200 mean loss: 0.0015452852239832282 score: 1.0
2021-08-08 05:08:17,330 | train | INFO | Epoch 14 train batch 157/450: 2512/7200 mean loss: 0.001696893130429089 score: 1.0
2021-08-08 05:08:18,235 | train | INFO | Epoch 14 train batch 158/450: 2528/7200 mean loss: 0.0013036105083301663 score: 0.9963235294117647
2021-08-08 05:08:19,004 | train | INFO | Epoch 14 train batch 159/450: 2544/7200 mean loss: 0.0015617309836670756 score: 1.0
2021-08-08 05:08:19,816 | train | INFO | Epoch 14 train batch 160/450: 2560/7200 mean loss: 0.0014048604061827064 score: 1.0
2021-08-08 05:08:20,597 | train | INFO | Epoch 14 train batch 161/450: 2576/7200 mean loss: 0.001462927320972085 score: 1.0
2021-08-08 05:08:21,396 | train | INFO | Epoch 14 train batch 162/450: 2592/7200 mean loss: 0.0015725713456049562 score: 1.0
2021-08-08 05:08:22,205 | train | INFO | Epoch 14 train batch 163/450: 2608/7200 mean loss: 0.0015468500787392259 score: 0.9354341736694679
2021-08-08 05:08:22,994 | train | INFO | Epoch 14 train batch 164/450: 2624/7200 mean loss: 0.0016697957180440426 score: 1.0
2021-08-08 05:08:23,766 | train | INFO | Epoch 14 train batch 165/450: 2640/7200 mean loss: 0.0013043909566476941 score: 1.0
2021-08-08 05:08:24,547 | train | INFO | Epoch 14 train batch 166/450: 2656/7200 mean loss: 0.0013757116394117475 score: 1.0
2021-08-08 05:08:25,372 | train | INFO | Epoch 14 train batch 167/450: 2672/7200 mean loss: 0.0015171284321695566 score: 0.996078431372549
2021-08-08 05:08:26,181 | train | INFO | Epoch 14 train batch 168/450: 2688/7200 mean loss: 0.0013332562521100044 score: 1.0
2021-08-08 05:08:26,967 | train | INFO | Epoch 14 train batch 169/450: 2704/7200 mean loss: 0.0013687496539205313 score: 0.9963235294117647
2021-08-08 05:08:27,784 | train | INFO | Epoch 14 train batch 170/450: 2720/7200 mean loss: 0.0013900112826377153 score: 1.0
2021-08-08 05:08:28,618 | train | INFO | Epoch 14 train batch 171/450: 2736/7200 mean loss: 0.0012153807329013944 score: 1.0
2021-08-08 05:08:29,399 | train | INFO | Epoch 14 train batch 172/450: 2752/7200 mean loss: 0.0013975831679999828 score: 1.0
2021-08-08 05:08:30,178 | train | INFO | Epoch 14 train batch 173/450: 2768/7200 mean loss: 0.0015151847619563341 score: 1.0
2021-08-08 05:08:30,989 | train | INFO | Epoch 14 train batch 174/450: 2784/7200 mean loss: 0.0012881984002888203 score: 1.0
2021-08-08 05:08:31,787 | train | INFO | Epoch 14 train batch 175/450: 2800/7200 mean loss: 0.0014380979118868709 score: 1.0
2021-08-08 05:08:32,581 | train | INFO | Epoch 14 train batch 176/450: 2816/7200 mean loss: 0.0014862114330753684 score: 1.0
2021-08-08 05:08:33,366 | train | INFO | Epoch 14 train batch 177/450: 2832/7200 mean loss: 0.001530146924778819 score: 1.0
2021-08-08 05:08:34,144 | train | INFO | Epoch 14 train batch 178/450: 2848/7200 mean loss: 0.0015067636268213391 score: 1.0
2021-08-08 05:08:34,979 | train | INFO | Epoch 14 train batch 179/450: 2864/7200 mean loss: 0.0014543463476002216 score: 1.0
2021-08-08 05:08:35,796 | train | INFO | Epoch 14 train batch 180/450: 2880/7200 mean loss: 0.0013805923517793417 score: 1.0
2021-08-08 05:08:36,595 | train | INFO | Epoch 14 train batch 181/450: 2896/7200 mean loss: 0.0013044849038124084 score: 0.9963235294117647
2021-08-08 05:08:37,411 | train | INFO | Epoch 14 train batch 182/450: 2912/7200 mean loss: 0.0013464369112625718 score: 1.0
2021-08-08 05:08:38,230 | train | INFO | Epoch 14 train batch 183/450: 2928/7200 mean loss: 0.0012963376939296722 score: 1.0
2021-08-08 05:08:39,008 | train | INFO | Epoch 14 train batch 184/450: 2944/7200 mean loss: 0.0014590503415092826 score: 1.0
2021-08-08 05:08:39,792 | train | INFO | Epoch 14 train batch 185/450: 2960/7200 mean loss: 0.0016536893090233207 score: 1.0
2021-08-08 05:08:40,573 | train | INFO | Epoch 14 train batch 186/450: 2976/7200 mean loss: 0.0014505535364151 score: 1.0
2021-08-08 05:08:41,378 | train | INFO | Epoch 14 train batch 187/450: 2992/7200 mean loss: 0.0013483387883752584 score: 1.0
2021-08-08 05:08:42,160 | train | INFO | Epoch 14 train batch 188/450: 3008/7200 mean loss: 0.0018032931257039309 score: 0.9889705882352942
2021-08-08 05:08:42,946 | train | INFO | Epoch 14 train batch 189/450: 3024/7200 mean loss: 0.0013026210945099592 score: 1.0
2021-08-08 05:08:43,730 | train | INFO | Epoch 14 train batch 190/450: 3040/7200 mean loss: 0.0015020847786217928 score: 1.0
2021-08-08 05:08:44,512 | train | INFO | Epoch 14 train batch 191/450: 3056/7200 mean loss: 0.0014895115746185184 score: 1.0
2021-08-08 05:08:45,307 | train | INFO | Epoch 14 train batch 192/450: 3072/7200 mean loss: 0.0011267953086644411 score: 1.0
2021-08-08 05:08:46,095 | train | INFO | Epoch 14 train batch 193/450: 3088/7200 mean loss: 0.0013421595795080066 score: 1.0
2021-08-08 05:08:46,921 | train | INFO | Epoch 14 train batch 194/450: 3104/7200 mean loss: 0.0012880127178505063 score: 1.0
2021-08-08 05:08:47,727 | train | INFO | Epoch 14 train batch 195/450: 3120/7200 mean loss: 0.001272557768970728 score: 0.9330882352941177
2021-08-08 05:08:48,521 | train | INFO | Epoch 14 train batch 196/450: 3136/7200 mean loss: 0.0013349053915590048 score: 1.0
2021-08-08 05:08:49,297 | train | INFO | Epoch 14 train batch 197/450: 3152/7200 mean loss: 0.0014341415371745825 score: 1.0
2021-08-08 05:08:50,077 | train | INFO | Epoch 14 train batch 198/450: 3168/7200 mean loss: 0.0015879843849688768 score: 1.0
2021-08-08 05:08:50,862 | train | INFO | Epoch 14 train batch 199/450: 3184/7200 mean loss: 0.001504784100688994 score: 1.0
2021-08-08 05:08:51,648 | train | INFO | Epoch 14 train batch 200/450: 3200/7200 mean loss: 0.0014908146113157272 score: 1.0
2021-08-08 05:08:52,453 | train | INFO | Epoch 14 train batch 201/450: 3216/7200 mean loss: 0.001322966767475009 score: 1.0
2021-08-08 05:08:53,233 | train | INFO | Epoch 14 train batch 202/450: 3232/7200 mean loss: 0.0015347203006967902 score: 1.0
2021-08-08 05:08:54,016 | train | INFO | Epoch 14 train batch 203/450: 3248/7200 mean loss: 0.0016185470158234239 score: 0.9963235294117647
2021-08-08 05:08:54,796 | train | INFO | Epoch 14 train batch 204/450: 3264/7200 mean loss: 0.001438128063455224 score: 1.0
2021-08-08 05:08:55,568 | train | INFO | Epoch 14 train batch 205/450: 3280/7200 mean loss: 0.0014090174809098244 score: 1.0
2021-08-08 05:08:56,434 | train | INFO | Epoch 14 train batch 206/450: 3296/7200 mean loss: 0.001225971383973956 score: 1.0
2021-08-08 05:08:57,208 | train | INFO | Epoch 14 train batch 207/450: 3312/7200 mean loss: 0.0015065133338794112 score: 1.0
2021-08-08 05:08:58,028 | train | INFO | Epoch 14 train batch 208/450: 3328/7200 mean loss: 0.0014147082110866904 score: 1.0
2021-08-08 05:08:58,927 | train | INFO | Epoch 14 train batch 209/450: 3344/7200 mean loss: 0.0014166743494570255 score: 0.9887254901960785
2021-08-08 05:08:59,757 | train | INFO | Epoch 14 train batch 210/450: 3360/7200 mean loss: 0.0015408736653625965 score: 0.9963235294117647
2021-08-08 05:09:00,538 | train | INFO | Epoch 14 train batch 211/450: 3376/7200 mean loss: 0.0015508085489273071 score: 1.0
2021-08-08 05:09:01,308 | train | INFO | Epoch 14 train batch 212/450: 3392/7200 mean loss: 0.001529908855445683 score: 1.0
2021-08-08 05:09:02,082 | train | INFO | Epoch 14 train batch 213/450: 3408/7200 mean loss: 0.0013602080289274454 score: 1.0
2021-08-08 05:09:02,858 | train | INFO | Epoch 14 train batch 214/450: 3424/7200 mean loss: 0.0014388379640877247 score: 1.0
2021-08-08 05:09:03,643 | train | INFO | Epoch 14 train batch 215/450: 3440/7200 mean loss: 0.0014537008246406913 score: 1.0
2021-08-08 05:09:04,425 | train | INFO | Epoch 14 train batch 216/450: 3456/7200 mean loss: 0.0015017568366602063 score: 1.0
2021-08-08 05:09:05,204 | train | INFO | Epoch 14 train batch 217/450: 3472/7200 mean loss: 0.0014208066277205944 score: 1.0
2021-08-08 05:09:05,986 | train | INFO | Epoch 14 train batch 218/450: 3488/7200 mean loss: 0.001568545470945537 score: 1.0
2021-08-08 05:09:06,769 | train | INFO | Epoch 14 train batch 219/450: 3504/7200 mean loss: 0.0015267777489498258 score: 1.0
2021-08-08 05:09:07,552 | train | INFO | Epoch 14 train batch 220/450: 3520/7200 mean loss: 0.0014094081707298756 score: 1.0
2021-08-08 05:09:08,386 | train | INFO | Epoch 14 train batch 221/450: 3536/7200 mean loss: 0.0014758716570213437 score: 1.0
2021-08-08 05:09:09,181 | train | INFO | Epoch 14 train batch 222/450: 3552/7200 mean loss: 0.0012477942509576678 score: 1.0
2021-08-08 05:09:09,962 | train | INFO | Epoch 14 train batch 223/450: 3568/7200 mean loss: 0.0014308233512565494 score: 1.0
2021-08-08 05:09:10,755 | train | INFO | Epoch 14 train batch 224/450: 3584/7200 mean loss: 0.0015207602409645915 score: 1.0
2021-08-08 05:09:11,541 | train | INFO | Epoch 14 train batch 225/450: 3600/7200 mean loss: 0.0012890924699604511 score: 1.0
2021-08-08 05:09:12,333 | train | INFO | Epoch 14 train batch 226/450: 3616/7200 mean loss: 0.0015775792999193072 score: 1.0
2021-08-08 05:09:13,145 | train | INFO | Epoch 14 train batch 227/450: 3632/7200 mean loss: 0.0015754185151308775 score: 1.0
2021-08-08 05:09:13,949 | train | INFO | Epoch 14 train batch 228/450: 3648/7200 mean loss: 0.001583542674779892 score: 0.9705882352941176
2021-08-08 05:09:14,766 | train | INFO | Epoch 14 train batch 229/450: 3664/7200 mean loss: 0.0014337986940518022 score: 0.9963235294117647
2021-08-08 05:09:15,614 | train | INFO | Epoch 14 train batch 230/450: 3680/7200 mean loss: 0.0015119266463443637 score: 1.0
2021-08-08 05:09:16,416 | train | INFO | Epoch 14 train batch 231/450: 3696/7200 mean loss: 0.0015017641708254814 score: 1.0
2021-08-08 05:09:17,191 | train | INFO | Epoch 14 train batch 232/450: 3712/7200 mean loss: 0.0013197236694395542 score: 1.0
2021-08-08 05:09:17,970 | train | INFO | Epoch 14 train batch 233/450: 3728/7200 mean loss: 0.0013617922086268663 score: 0.9669117647058824
2021-08-08 05:09:18,766 | train | INFO | Epoch 14 train batch 234/450: 3744/7200 mean loss: 0.001271917368285358 score: 1.0
2021-08-08 05:09:19,555 | train | INFO | Epoch 14 train batch 235/450: 3760/7200 mean loss: 0.001234819064848125 score: 0.9816176470588235
2021-08-08 05:09:20,338 | train | INFO | Epoch 14 train batch 236/450: 3776/7200 mean loss: 0.0013003561180084944 score: 1.0
2021-08-08 05:09:21,243 | train | INFO | Epoch 14 train batch 237/450: 3792/7200 mean loss: 0.0013693332439288497 score: 1.0
2021-08-08 05:09:22,062 | train | INFO | Epoch 14 train batch 238/450: 3808/7200 mean loss: 0.0011780987260863185 score: 1.0
2021-08-08 05:09:22,859 | train | INFO | Epoch 14 train batch 239/450: 3824/7200 mean loss: 0.0009604984079487622 score: 1.0
2021-08-08 05:09:23,659 | train | INFO | Epoch 14 train batch 240/450: 3840/7200 mean loss: 0.0015971577959135175 score: 1.0
2021-08-08 05:09:24,444 | train | INFO | Epoch 14 train batch 241/450: 3856/7200 mean loss: 0.0016959176864475012 score: 1.0
2021-08-08 05:09:25,231 | train | INFO | Epoch 14 train batch 242/450: 3872/7200 mean loss: 0.0014397181803360581 score: 1.0
2021-08-08 05:09:26,002 | train | INFO | Epoch 14 train batch 243/450: 3888/7200 mean loss: 0.0014921220717951655 score: 1.0
2021-08-08 05:09:26,777 | train | INFO | Epoch 14 train batch 244/450: 3904/7200 mean loss: 0.00144905352499336 score: 1.0
2021-08-08 05:09:27,556 | train | INFO | Epoch 14 train batch 245/450: 3920/7200 mean loss: 0.0013045603409409523 score: 1.0
2021-08-08 05:09:28,358 | train | INFO | Epoch 14 train batch 246/450: 3936/7200 mean loss: 0.0013283251319080591 score: 1.0
2021-08-08 05:09:29,163 | train | INFO | Epoch 14 train batch 247/450: 3952/7200 mean loss: 0.0012569775572046638 score: 1.0
2021-08-08 05:09:29,963 | train | INFO | Epoch 14 train batch 248/450: 3968/7200 mean loss: 0.0016039918409660459 score: 1.0
2021-08-08 05:09:30,759 | train | INFO | Epoch 14 train batch 249/450: 3984/7200 mean loss: 0.0012777938973158598 score: 1.0
2021-08-08 05:09:31,649 | train | INFO | Epoch 14 train batch 250/450: 4000/7200 mean loss: 0.0014157748082652688 score: 0.995798319327731
2021-08-08 05:09:32,432 | train | INFO | Epoch 14 train batch 251/450: 4016/7200 mean loss: 0.001186884823255241 score: 1.0
2021-08-08 05:09:33,241 | train | INFO | Epoch 14 train batch 252/450: 4032/7200 mean loss: 0.0015260973013937473 score: 1.0
2021-08-08 05:09:34,029 | train | INFO | Epoch 14 train batch 253/450: 4048/7200 mean loss: 0.0015423569129779935 score: 1.0
2021-08-08 05:09:34,808 | train | INFO | Epoch 14 train batch 254/450: 4064/7200 mean loss: 0.0014223901089280844 score: 0.9963235294117647
2021-08-08 05:09:35,583 | train | INFO | Epoch 14 train batch 255/450: 4080/7200 mean loss: 0.001377760199829936 score: 1.0
2021-08-08 05:09:36,357 | train | INFO | Epoch 14 train batch 256/450: 4096/7200 mean loss: 0.0014918952947482467 score: 0.9926470588235294
2021-08-08 05:09:37,131 | train | INFO | Epoch 14 train batch 257/450: 4112/7200 mean loss: 0.0013925554230809212 score: 0.9963235294117647
2021-08-08 05:09:37,926 | train | INFO | Epoch 14 train batch 258/450: 4128/7200 mean loss: 0.0013049424160271883 score: 1.0
2021-08-08 05:09:38,707 | train | INFO | Epoch 14 train batch 259/450: 4144/7200 mean loss: 0.0014920387184247375 score: 1.0
2021-08-08 05:09:39,477 | train | INFO | Epoch 14 train batch 260/450: 4160/7200 mean loss: 0.00144185998942703 score: 1.0
2021-08-08 05:09:40,295 | train | INFO | Epoch 14 train batch 261/450: 4176/7200 mean loss: 0.00154867151286453 score: 1.0
2021-08-08 05:09:41,100 | train | INFO | Epoch 14 train batch 262/450: 4192/7200 mean loss: 0.001365217729471624 score: 1.0
2021-08-08 05:09:41,905 | train | INFO | Epoch 14 train batch 263/450: 4208/7200 mean loss: 0.0012313108891248703 score: 1.0
2021-08-08 05:09:42,680 | train | INFO | Epoch 14 train batch 264/450: 4224/7200 mean loss: 0.0014298578025773168 score: 1.0
2021-08-08 05:09:43,454 | train | INFO | Epoch 14 train batch 265/450: 4240/7200 mean loss: 0.0013913740403950214 score: 1.0
2021-08-08 05:09:44,225 | train | INFO | Epoch 14 train batch 266/450: 4256/7200 mean loss: 0.001212051953189075 score: 1.0
2021-08-08 05:09:45,040 | train | INFO | Epoch 14 train batch 267/450: 4272/7200 mean loss: 0.0012214630842208862 score: 0.9926470588235294
2021-08-08 05:09:45,846 | train | INFO | Epoch 14 train batch 268/450: 4288/7200 mean loss: 0.0012375032529234886 score: 0.9963235294117647
2021-08-08 05:09:46,658 | train | INFO | Epoch 14 train batch 269/450: 4304/7200 mean loss: 0.0013142201351001859 score: 1.0
2021-08-08 05:09:47,440 | train | INFO | Epoch 14 train batch 270/450: 4320/7200 mean loss: 0.0015461418079212308 score: 0.9811274509803922
2021-08-08 05:09:48,226 | train | INFO | Epoch 14 train batch 271/450: 4336/7200 mean loss: 0.0015302704414352775 score: 1.0
2021-08-08 05:09:49,042 | train | INFO | Epoch 14 train batch 272/450: 4352/7200 mean loss: 0.0015107812359929085 score: 0.9924019607843138
2021-08-08 05:09:49,879 | train | INFO | Epoch 14 train batch 273/450: 4368/7200 mean loss: 0.0014913956401869655 score: 1.0
2021-08-08 05:09:50,678 | train | INFO | Epoch 14 train batch 274/450: 4384/7200 mean loss: 0.0016167544526979327 score: 1.0
2021-08-08 05:09:51,456 | train | INFO | Epoch 14 train batch 275/450: 4400/7200 mean loss: 0.0016859215684235096 score: 1.0
2021-08-08 05:09:52,230 | train | INFO | Epoch 14 train batch 276/450: 4416/7200 mean loss: 0.001741437241435051 score: 1.0
2021-08-08 05:09:53,000 | train | INFO | Epoch 14 train batch 277/450: 4432/7200 mean loss: 0.0015629769768565893 score: 1.0
2021-08-08 05:09:53,767 | train | INFO | Epoch 14 train batch 278/450: 4448/7200 mean loss: 0.0015528419753536582 score: 0.9779411764705882
2021-08-08 05:09:54,548 | train | INFO | Epoch 14 train batch 279/450: 4464/7200 mean loss: 0.0014056047657504678 score: 1.0
2021-08-08 05:09:55,332 | train | INFO | Epoch 14 train batch 280/450: 4480/7200 mean loss: 0.00139390560798347 score: 0.996078431372549
2021-08-08 05:09:56,112 | train | INFO | Epoch 14 train batch 281/450: 4496/7200 mean loss: 0.0012132000410929322 score: 0.996078431372549
2021-08-08 05:09:56,894 | train | INFO | Epoch 14 train batch 282/450: 4512/7200 mean loss: 0.0013735247775912285 score: 1.0
2021-08-08 05:09:57,675 | train | INFO | Epoch 14 train batch 283/450: 4528/7200 mean loss: 0.0013545199763029814 score: 1.0
2021-08-08 05:09:58,457 | train | INFO | Epoch 14 train batch 284/450: 4544/7200 mean loss: 0.0015831125201657414 score: 1.0
2021-08-08 05:09:59,275 | train | INFO | Epoch 14 train batch 285/450: 4560/7200 mean loss: 0.001378718763589859 score: 1.0
2021-08-08 05:10:00,103 | train | INFO | Epoch 14 train batch 286/450: 4576/7200 mean loss: 0.0014697886072099209 score: 1.0
2021-08-08 05:10:00,891 | train | INFO | Epoch 14 train batch 287/450: 4592/7200 mean loss: 0.001538934651762247 score: 1.0
2021-08-08 05:10:01,704 | train | INFO | Epoch 14 train batch 288/450: 4608/7200 mean loss: 0.0015282577369362116 score: 1.0
2021-08-08 05:10:02,484 | train | INFO | Epoch 14 train batch 289/450: 4624/7200 mean loss: 0.0014931776095181704 score: 1.0
2021-08-08 05:10:03,258 | train | INFO | Epoch 14 train batch 290/450: 4640/7200 mean loss: 0.0015120792668312788 score: 1.0
2021-08-08 05:10:04,034 | train | INFO | Epoch 14 train batch 291/450: 4656/7200 mean loss: 0.0013922203797847033 score: 0.7534313725490196
2021-08-08 05:10:04,825 | train | INFO | Epoch 14 train batch 292/450: 4672/7200 mean loss: 0.0015655211172997952 score: 1.0
2021-08-08 05:10:05,659 | train | INFO | Epoch 14 train batch 293/450: 4688/7200 mean loss: 0.0015718622598797083 score: 1.0
2021-08-08 05:10:06,437 | train | INFO | Epoch 14 train batch 294/450: 4704/7200 mean loss: 0.0014425773406401277 score: 1.0
2021-08-08 05:10:07,280 | train | INFO | Epoch 14 train batch 295/450: 4720/7200 mean loss: 0.0013278332771733403 score: 0.9012254901960786
2021-08-08 05:10:08,061 | train | INFO | Epoch 14 train batch 296/450: 4736/7200 mean loss: 0.001347001874819398 score: 1.0
2021-08-08 05:10:08,842 | train | INFO | Epoch 14 train batch 297/450: 4752/7200 mean loss: 0.0012772437185049057 score: 1.0
2021-08-08 05:10:09,706 | train | INFO | Epoch 14 train batch 298/450: 4768/7200 mean loss: 0.0012481220765039325 score: 1.0
2021-08-08 05:10:10,539 | train | INFO | Epoch 14 train batch 299/450: 4784/7200 mean loss: 0.0014417649945244193 score: 0.9963235294117647
2021-08-08 05:10:11,359 | train | INFO | Epoch 14 train batch 300/450: 4800/7200 mean loss: 0.0012431660434231162 score: 1.0
2021-08-08 05:10:12,165 | train | INFO | Epoch 14 train batch 301/450: 4816/7200 mean loss: 0.0012699373764917254 score: 1.0
2021-08-08 05:10:12,945 | train | INFO | Epoch 14 train batch 302/450: 4832/7200 mean loss: 0.0015134791610762477 score: 1.0
2021-08-08 05:10:13,752 | train | INFO | Epoch 14 train batch 303/450: 4848/7200 mean loss: 0.001337752677500248 score: 1.0
2021-08-08 05:10:14,568 | train | INFO | Epoch 14 train batch 304/450: 4864/7200 mean loss: 0.0011469910386949778 score: 1.0
2021-08-08 05:10:15,374 | train | INFO | Epoch 14 train batch 305/450: 4880/7200 mean loss: 0.001309442799538374 score: 1.0
2021-08-08 05:10:16,179 | train | INFO | Epoch 14 train batch 306/450: 4896/7200 mean loss: 0.001420323853380978 score: 1.0
2021-08-08 05:10:16,956 | train | INFO | Epoch 14 train batch 307/450: 4912/7200 mean loss: 0.0014469141606241465 score: 1.0
2021-08-08 05:10:17,736 | train | INFO | Epoch 14 train batch 308/450: 4928/7200 mean loss: 0.0017099784454330802 score: 0.896078431372549
2021-08-08 05:10:18,518 | train | INFO | Epoch 14 train batch 309/450: 4944/7200 mean loss: 0.0014499020762741566 score: 1.0
2021-08-08 05:10:19,287 | train | INFO | Epoch 14 train batch 310/450: 4960/7200 mean loss: 0.0016358266584575176 score: 1.0
2021-08-08 05:10:20,086 | train | INFO | Epoch 14 train batch 311/450: 4976/7200 mean loss: 0.001405447954311967 score: 1.0
2021-08-08 05:10:20,856 | train | INFO | Epoch 14 train batch 312/450: 4992/7200 mean loss: 0.0014616264961659908 score: 1.0
2021-08-08 05:10:21,686 | train | INFO | Epoch 14 train batch 313/450: 5008/7200 mean loss: 0.0014764394145458937 score: 1.0
2021-08-08 05:10:22,493 | train | INFO | Epoch 14 train batch 314/450: 5024/7200 mean loss: 0.001422635861672461 score: 1.0
2021-08-08 05:10:23,277 | train | INFO | Epoch 14 train batch 315/450: 5040/7200 mean loss: 0.0014094786019995809 score: 1.0
2021-08-08 05:10:24,061 | train | INFO | Epoch 14 train batch 316/450: 5056/7200 mean loss: 0.0014182723825797439 score: 1.0
2021-08-08 05:10:24,838 | train | INFO | Epoch 14 train batch 317/450: 5072/7200 mean loss: 0.0012570744147524238 score: 1.0
2021-08-08 05:10:25,645 | train | INFO | Epoch 14 train batch 318/450: 5088/7200 mean loss: 0.0017442936077713966 score: 1.0
2021-08-08 05:10:26,480 | train | INFO | Epoch 14 train batch 319/450: 5104/7200 mean loss: 0.0015261017251759768 score: 1.0
2021-08-08 05:10:27,273 | train | INFO | Epoch 14 train batch 320/450: 5120/7200 mean loss: 0.0016101712826639414 score: 1.0
2021-08-08 05:10:28,172 | train | INFO | Epoch 14 train batch 321/450: 5136/7200 mean loss: 0.0016426078509539366 score: 1.0
2021-08-08 05:10:28,952 | train | INFO | Epoch 14 train batch 322/450: 5152/7200 mean loss: 0.0015222819056361914 score: 0.996078431372549
2021-08-08 05:10:29,724 | train | INFO | Epoch 14 train batch 323/450: 5168/7200 mean loss: 0.0016076145693659782 score: 1.0
2021-08-08 05:10:30,525 | train | INFO | Epoch 14 train batch 324/450: 5184/7200 mean loss: 0.0013345854822546244 score: 1.0
2021-08-08 05:10:31,309 | train | INFO | Epoch 14 train batch 325/450: 5200/7200 mean loss: 0.0012547150254249573 score: 1.0
2021-08-08 05:10:32,077 | train | INFO | Epoch 14 train batch 326/450: 5216/7200 mean loss: 0.001274283160455525 score: 1.0
2021-08-08 05:10:32,933 | train | INFO | Epoch 14 train batch 327/450: 5232/7200 mean loss: 0.0012204429367557168 score: 1.0
2021-08-08 05:10:33,731 | train | INFO | Epoch 14 train batch 328/450: 5248/7200 mean loss: 0.001186388311907649 score: 1.0
2021-08-08 05:10:34,505 | train | INFO | Epoch 14 train batch 329/450: 5264/7200 mean loss: 0.001475815661251545 score: 0.9889705882352942
2021-08-08 05:10:35,311 | train | INFO | Epoch 14 train batch 330/450: 5280/7200 mean loss: 0.0015680795768275857 score: 1.0
2021-08-08 05:10:36,090 | train | INFO | Epoch 14 train batch 331/450: 5296/7200 mean loss: 0.0014177336124703288 score: 1.0
2021-08-08 05:10:36,904 | train | INFO | Epoch 14 train batch 332/450: 5312/7200 mean loss: 0.0013501441571861506 score: 1.0
2021-08-08 05:10:37,677 | train | INFO | Epoch 14 train batch 333/450: 5328/7200 mean loss: 0.0013610889436677098 score: 0.9926470588235294
2021-08-08 05:10:38,445 | train | INFO | Epoch 14 train batch 334/450: 5344/7200 mean loss: 0.0012129140086472034 score: 1.0
2021-08-08 05:10:39,229 | train | INFO | Epoch 14 train batch 335/450: 5360/7200 mean loss: 0.0014130520867183805 score: 1.0
2021-08-08 05:10:40,011 | train | INFO | Epoch 14 train batch 336/450: 5376/7200 mean loss: 0.0014519985998049378 score: 1.0
2021-08-08 05:10:40,788 | train | INFO | Epoch 14 train batch 337/450: 5392/7200 mean loss: 0.0013985612895339727 score: 0.9963235294117647
2021-08-08 05:10:41,561 | train | INFO | Epoch 14 train batch 338/450: 5408/7200 mean loss: 0.001506789238192141 score: 0.996078431372549
2021-08-08 05:10:42,362 | train | INFO | Epoch 14 train batch 339/450: 5424/7200 mean loss: 0.0012831372441723943 score: 0.9889705882352942
2021-08-08 05:10:43,168 | train | INFO | Epoch 14 train batch 340/450: 5440/7200 mean loss: 0.001236415933817625 score: 1.0
2021-08-08 05:10:43,970 | train | INFO | Epoch 14 train batch 341/450: 5456/7200 mean loss: 0.0013649343745782971 score: 0.9852941176470589
2021-08-08 05:10:44,741 | train | INFO | Epoch 14 train batch 342/450: 5472/7200 mean loss: 0.0015958468429744244 score: 1.0
2021-08-08 05:10:45,517 | train | INFO | Epoch 14 train batch 343/450: 5488/7200 mean loss: 0.0014817528426647186 score: 1.0
2021-08-08 05:10:46,294 | train | INFO | Epoch 14 train batch 344/450: 5504/7200 mean loss: 0.0017157192341983318 score: 0.9742647058823529
2021-08-08 05:10:47,093 | train | INFO | Epoch 14 train batch 345/450: 5520/7200 mean loss: 0.0015927738277241588 score: 0.8382352941176471
2021-08-08 05:10:47,889 | train | INFO | Epoch 14 train batch 346/450: 5536/7200 mean loss: 0.0015671681612730026 score: 1.0
2021-08-08 05:10:48,742 | train | INFO | Epoch 14 train batch 347/450: 5552/7200 mean loss: 0.00154845230281353 score: 0.9963235294117647
2021-08-08 05:10:49,528 | train | INFO | Epoch 14 train batch 348/450: 5568/7200 mean loss: 0.0014665299095213413 score: 1.0
2021-08-08 05:10:50,316 | train | INFO | Epoch 14 train batch 349/450: 5584/7200 mean loss: 0.0014648971846327186 score: 1.0
2021-08-08 05:10:51,089 | train | INFO | Epoch 14 train batch 350/450: 5600/7200 mean loss: 0.001341662835329771 score: 1.0
2021-08-08 05:10:51,874 | train | INFO | Epoch 14 train batch 351/450: 5616/7200 mean loss: 0.0014587787445634604 score: 1.0
2021-08-08 05:10:52,649 | train | INFO | Epoch 14 train batch 352/450: 5632/7200 mean loss: 0.0013771714875474572 score: 1.0
2021-08-08 05:10:53,456 | train | INFO | Epoch 14 train batch 353/450: 5648/7200 mean loss: 0.0012575089931488037 score: 1.0
2021-08-08 05:10:54,232 | train | INFO | Epoch 14 train batch 354/450: 5664/7200 mean loss: 0.0012543478514999151 score: 1.0
2021-08-08 05:10:55,050 | train | INFO | Epoch 14 train batch 355/450: 5680/7200 mean loss: 0.0014645757619291544 score: 1.0
2021-08-08 05:10:55,829 | train | INFO | Epoch 14 train batch 356/450: 5696/7200 mean loss: 0.0013367078499868512 score: 1.0
2021-08-08 05:10:56,614 | train | INFO | Epoch 14 train batch 357/450: 5712/7200 mean loss: 0.0014618916902691126 score: 1.0
2021-08-08 05:10:57,400 | train | INFO | Epoch 14 train batch 358/450: 5728/7200 mean loss: 0.0011635150294750929 score: 1.0
2021-08-08 05:10:58,213 | train | INFO | Epoch 14 train batch 359/450: 5744/7200 mean loss: 0.0012861209688708186 score: 0.9887254901960785
2021-08-08 05:10:58,991 | train | INFO | Epoch 14 train batch 360/450: 5760/7200 mean loss: 0.0012313443003222346 score: 1.0
2021-08-08 05:10:59,802 | train | INFO | Epoch 14 train batch 361/450: 5776/7200 mean loss: 0.0014761664206162095 score: 1.0
2021-08-08 05:11:00,591 | train | INFO | Epoch 14 train batch 362/450: 5792/7200 mean loss: 0.0013120092917233706 score: 1.0
2021-08-08 05:11:01,412 | train | INFO | Epoch 14 train batch 363/450: 5808/7200 mean loss: 0.0015094479313120246 score: 0.9963235294117647
2021-08-08 05:11:02,230 | train | INFO | Epoch 14 train batch 364/450: 5824/7200 mean loss: 0.0013606491265818477 score: 1.0
2021-08-08 05:11:03,034 | train | INFO | Epoch 14 train batch 365/450: 5840/7200 mean loss: 0.0013768444769084454 score: 1.0
2021-08-08 05:11:03,811 | train | INFO | Epoch 14 train batch 366/450: 5856/7200 mean loss: 0.001455215155147016 score: 1.0
2021-08-08 05:11:04,620 | train | INFO | Epoch 14 train batch 367/450: 5872/7200 mean loss: 0.0014913907507434487 score: 1.0
2021-08-08 05:11:05,453 | train | INFO | Epoch 14 train batch 368/450: 5888/7200 mean loss: 0.0016810769448056817 score: 1.0
2021-08-08 05:11:06,255 | train | INFO | Epoch 14 train batch 369/450: 5904/7200 mean loss: 0.001529073459096253 score: 1.0
2021-08-08 05:11:07,032 | train | INFO | Epoch 14 train batch 370/450: 5920/7200 mean loss: 0.001546297688037157 score: 1.0
2021-08-08 05:11:07,843 | train | INFO | Epoch 14 train batch 371/450: 5936/7200 mean loss: 0.00159976736176759 score: 1.0
2021-08-08 05:11:08,627 | train | INFO | Epoch 14 train batch 372/450: 5952/7200 mean loss: 0.001386023941449821 score: 0.9889705882352942
2021-08-08 05:11:09,435 | train | INFO | Epoch 14 train batch 373/450: 5968/7200 mean loss: 0.0012832614593207836 score: 1.0
2021-08-08 05:11:10,214 | train | INFO | Epoch 14 train batch 374/450: 5984/7200 mean loss: 0.0012221996439620852 score: 1.0
2021-08-08 05:11:11,023 | train | INFO | Epoch 14 train batch 375/450: 6000/7200 mean loss: 0.0014658947475254536 score: 1.0
2021-08-08 05:11:11,798 | train | INFO | Epoch 14 train batch 376/450: 6016/7200 mean loss: 0.0014858980430290103 score: 1.0
2021-08-08 05:11:12,584 | train | INFO | Epoch 14 train batch 377/450: 6032/7200 mean loss: 0.0014004202093929052 score: 0.9816176470588235
2021-08-08 05:11:13,397 | train | INFO | Epoch 14 train batch 378/450: 6048/7200 mean loss: 0.001459650695323944 score: 1.0
2021-08-08 05:11:14,162 | train | INFO | Epoch 14 train batch 379/450: 6064/7200 mean loss: 0.001485138083808124 score: 0.9889705882352942
2021-08-08 05:11:14,941 | train | INFO | Epoch 14 train batch 380/450: 6080/7200 mean loss: 0.0014020580565556884 score: 1.0
2021-08-08 05:11:15,752 | train | INFO | Epoch 14 train batch 381/450: 6096/7200 mean loss: 0.0013054802548140287 score: 0.9595588235294118
2021-08-08 05:11:16,563 | train | INFO | Epoch 14 train batch 382/450: 6112/7200 mean loss: 0.0013414451386779547 score: 1.0
2021-08-08 05:11:17,399 | train | INFO | Epoch 14 train batch 383/450: 6128/7200 mean loss: 0.0013645795406773686 score: 1.0
2021-08-08 05:11:18,179 | train | INFO | Epoch 14 train batch 384/450: 6144/7200 mean loss: 0.0016255894443020225 score: 1.0
2021-08-08 05:11:19,002 | train | INFO | Epoch 14 train batch 385/450: 6160/7200 mean loss: 0.0014577917754650116 score: 1.0
2021-08-08 05:11:19,773 | train | INFO | Epoch 14 train batch 386/450: 6176/7200 mean loss: 0.001647371333092451 score: 1.0
2021-08-08 05:11:20,649 | train | INFO | Epoch 14 train batch 387/450: 6192/7200 mean loss: 0.0014734023716300726 score: 1.0
2021-08-08 05:11:21,446 | train | INFO | Epoch 14 train batch 388/450: 6208/7200 mean loss: 0.001574746798723936 score: 0.9889705882352942
2021-08-08 05:11:22,251 | train | INFO | Epoch 14 train batch 389/450: 6224/7200 mean loss: 0.0015555300051346421 score: 1.0
2021-08-08 05:11:23,071 | train | INFO | Epoch 14 train batch 390/450: 6240/7200 mean loss: 0.0013576737837865949 score: 1.0
2021-08-08 05:11:23,857 | train | INFO | Epoch 14 train batch 391/450: 6256/7200 mean loss: 0.001549762673676014 score: 0.9887254901960785
2021-08-08 05:11:24,642 | train | INFO | Epoch 14 train batch 392/450: 6272/7200 mean loss: 0.001333471154794097 score: 1.0
2021-08-08 05:11:25,429 | train | INFO | Epoch 14 train batch 393/450: 6288/7200 mean loss: 0.0011845651315525174 score: 1.0
2021-08-08 05:11:26,234 | train | INFO | Epoch 14 train batch 394/450: 6304/7200 mean loss: 0.001264767488464713 score: 1.0
2021-08-08 05:11:27,032 | train | INFO | Epoch 14 train batch 395/450: 6320/7200 mean loss: 0.0012020132271572948 score: 1.0
2021-08-08 05:11:27,818 | train | INFO | Epoch 14 train batch 396/450: 6336/7200 mean loss: 0.0014258226146921515 score: 0.9926470588235294
2021-08-08 05:11:28,644 | train | INFO | Epoch 14 train batch 397/450: 6352/7200 mean loss: 0.0014921051915735006 score: 1.0
2021-08-08 05:11:29,442 | train | INFO | Epoch 14 train batch 398/450: 6368/7200 mean loss: 0.0015668886480852962 score: 1.0
2021-08-08 05:11:30,250 | train | INFO | Epoch 14 train batch 399/450: 6384/7200 mean loss: 0.00153329165186733 score: 0.9926470588235294
2021-08-08 05:11:31,031 | train | INFO | Epoch 14 train batch 400/450: 6400/7200 mean loss: 0.0016949557466432452 score: 1.0
2021-08-08 05:11:31,836 | train | INFO | Epoch 14 train batch 401/450: 6416/7200 mean loss: 0.0016300290590152144 score: 1.0
2021-08-08 05:11:32,653 | train | INFO | Epoch 14 train batch 402/450: 6432/7200 mean loss: 0.0015367681626230478 score: 1.0
2021-08-08 05:11:33,463 | train | INFO | Epoch 14 train batch 403/450: 6448/7200 mean loss: 0.0013080370845273137 score: 1.0
2021-08-08 05:11:34,257 | train | INFO | Epoch 14 train batch 404/450: 6464/7200 mean loss: 0.001346615026704967 score: 0.9963235294117647
2021-08-08 05:11:35,043 | train | INFO | Epoch 14 train batch 405/450: 6480/7200 mean loss: 0.0014482828555628657 score: 1.0
2021-08-08 05:11:35,828 | train | INFO | Epoch 14 train batch 406/450: 6496/7200 mean loss: 0.0012808102183043957 score: 1.0
2021-08-08 05:11:36,617 | train | INFO | Epoch 14 train batch 407/450: 6512/7200 mean loss: 0.0013370164670050144 score: 1.0
2021-08-08 05:11:37,413 | train | INFO | Epoch 14 train batch 408/450: 6528/7200 mean loss: 0.001363910734653473 score: 1.0
2021-08-08 05:11:38,207 | train | INFO | Epoch 14 train batch 409/450: 6544/7200 mean loss: 0.001462295651435852 score: 1.0
2021-08-08 05:11:38,981 | train | INFO | Epoch 14 train batch 410/450: 6560/7200 mean loss: 0.0014058742672204971 score: 1.0
2021-08-08 05:11:39,865 | train | INFO | Epoch 14 train batch 411/450: 6576/7200 mean loss: 0.0014545117737725377 score: 1.0
2021-08-08 05:11:40,663 | train | INFO | Epoch 14 train batch 412/450: 6592/7200 mean loss: 0.0014433847973123193 score: 1.0
2021-08-08 05:11:41,490 | train | INFO | Epoch 14 train batch 413/450: 6608/7200 mean loss: 0.0012720859376713634 score: 0.9963235294117647
2021-08-08 05:11:42,311 | train | INFO | Epoch 14 train batch 414/450: 6624/7200 mean loss: 0.0013478235341608524 score: 1.0
2021-08-08 05:11:43,095 | train | INFO | Epoch 14 train batch 415/450: 6640/7200 mean loss: 0.001524727907963097 score: 1.0
2021-08-08 05:11:43,861 | train | INFO | Epoch 14 train batch 416/450: 6656/7200 mean loss: 0.0012522529577836394 score: 0.9926470588235294
2021-08-08 05:11:44,643 | train | INFO | Epoch 14 train batch 417/450: 6672/7200 mean loss: 0.0015694318572059274 score: 1.0
2021-08-08 05:11:45,413 | train | INFO | Epoch 14 train batch 418/450: 6688/7200 mean loss: 0.0014516629744321108 score: 0.9963235294117647
2021-08-08 05:11:46,183 | train | INFO | Epoch 14 train batch 419/450: 6704/7200 mean loss: 0.001556329894810915 score: 1.0
2021-08-08 05:11:46,960 | train | INFO | Epoch 14 train batch 420/450: 6720/7200 mean loss: 0.0017509919125586748 score: 1.0
2021-08-08 05:11:47,739 | train | INFO | Epoch 14 train batch 421/450: 6736/7200 mean loss: 0.0014847879065200686 score: 1.0
2021-08-08 05:11:48,553 | train | INFO | Epoch 14 train batch 422/450: 6752/7200 mean loss: 0.0015303982654586434 score: 1.0
2021-08-08 05:11:49,352 | train | INFO | Epoch 14 train batch 423/450: 6768/7200 mean loss: 0.0014795992756262422 score: 0.9889705882352942
2021-08-08 05:11:50,161 | train | INFO | Epoch 14 train batch 424/450: 6784/7200 mean loss: 0.0014410894364118576 score: 0.9963235294117647
2021-08-08 05:11:50,970 | train | INFO | Epoch 14 train batch 425/450: 6800/7200 mean loss: 0.0013608774170279503 score: 1.0
2021-08-08 05:11:51,771 | train | INFO | Epoch 14 train batch 426/450: 6816/7200 mean loss: 0.001422555884346366 score: 0.996078431372549
2021-08-08 05:11:52,561 | train | INFO | Epoch 14 train batch 427/450: 6832/7200 mean loss: 0.0013374574482440948 score: 0.9887254901960785
2021-08-08 05:11:53,372 | train | INFO | Epoch 14 train batch 428/450: 6848/7200 mean loss: 0.0014415073674172163 score: 0.996078431372549
2021-08-08 05:11:54,160 | train | INFO | Epoch 14 train batch 429/450: 6864/7200 mean loss: 0.0014807430561631918 score: 1.0
2021-08-08 05:11:54,984 | train | INFO | Epoch 14 train batch 430/450: 6880/7200 mean loss: 0.0016524539096280932 score: 1.0
2021-08-08 05:11:55,769 | train | INFO | Epoch 14 train batch 431/450: 6896/7200 mean loss: 0.0014062856789678335 score: 1.0
2021-08-08 05:11:56,577 | train | INFO | Epoch 14 train batch 432/450: 6912/7200 mean loss: 0.0013482278445735574 score: 1.0
2021-08-08 05:11:57,347 | train | INFO | Epoch 14 train batch 433/450: 6928/7200 mean loss: 0.0016357589047402143 score: 1.0
2021-08-08 05:11:58,152 | train | INFO | Epoch 14 train batch 434/450: 6944/7200 mean loss: 0.0013757777633145452 score: 1.0
2021-08-08 05:11:58,928 | train | INFO | Epoch 14 train batch 435/450: 6960/7200 mean loss: 0.001394545310176909 score: 1.0
2021-08-08 05:11:59,726 | train | INFO | Epoch 14 train batch 436/450: 6976/7200 mean loss: 0.0014053505146875978 score: 1.0
2021-08-08 05:12:00,503 | train | INFO | Epoch 14 train batch 437/450: 6992/7200 mean loss: 0.0013545836554840207 score: 0.9842006033182504
2021-08-08 05:12:01,297 | train | INFO | Epoch 14 train batch 438/450: 7008/7200 mean loss: 0.0017220497829839587 score: 0.9963235294117647
2021-08-08 05:12:02,077 | train | INFO | Epoch 14 train batch 439/450: 7024/7200 mean loss: 0.00141229631844908 score: 1.0
2021-08-08 05:12:02,852 | train | INFO | Epoch 14 train batch 440/450: 7040/7200 mean loss: 0.0015308670699596405 score: 1.0
2021-08-08 05:12:03,633 | train | INFO | Epoch 14 train batch 441/450: 7056/7200 mean loss: 0.0015654757153242826 score: 1.0
2021-08-08 05:12:04,405 | train | INFO | Epoch 14 train batch 442/450: 7072/7200 mean loss: 0.0013906554086133838 score: 0.9963235294117647
2021-08-08 05:12:05,175 | train | INFO | Epoch 14 train batch 443/450: 7088/7200 mean loss: 0.0016099346103146672 score: 1.0
2021-08-08 05:12:05,952 | train | INFO | Epoch 14 train batch 444/450: 7104/7200 mean loss: 0.0012940014712512493 score: 1.0
2021-08-08 05:12:06,722 | train | INFO | Epoch 14 train batch 445/450: 7120/7200 mean loss: 0.0015593050047755241 score: 0.9963235294117647
2021-08-08 05:12:07,492 | train | INFO | Epoch 14 train batch 446/450: 7136/7200 mean loss: 0.0017373819136992097 score: 1.0
2021-08-08 05:12:08,268 | train | INFO | Epoch 14 train batch 447/450: 7152/7200 mean loss: 0.0013808546354994178 score: 1.0
2021-08-08 05:12:09,037 | train | INFO | Epoch 14 train batch 448/450: 7168/7200 mean loss: 0.0012704436667263508 score: 1.0
2021-08-08 05:12:09,808 | train | INFO | Epoch 14 train batch 449/450: 7184/7200 mean loss: 0.0014998522819951177 score: 1.0
2021-08-08 05:12:09,975 | train | INFO | Epoch 14, Train, Mean loss: 0.022898159509317742, Score: 0.9951892911010558
2021-08-08 05:12:11,424 | train | INFO | Epoch 14 validation batch 0/113: 0/1800 mean loss: 0.0009886595653370023 score: 1.0
2021-08-08 05:12:11,676 | train | INFO | Epoch 14 validation batch 1/113: 16/1800 mean loss: 0.0010104189859703183 score: 0.9963235294117647
2021-08-08 05:12:11,931 | train | INFO | Epoch 14 validation batch 2/113: 32/1800 mean loss: 0.0012853100197389722 score: 1.0
2021-08-08 05:12:12,183 | train | INFO | Epoch 14 validation batch 3/113: 48/1800 mean loss: 0.001128262490965426 score: 1.0
2021-08-08 05:12:12,423 | train | INFO | Epoch 14 validation batch 4/113: 64/1800 mean loss: 0.0010018869070336223 score: 1.0
2021-08-08 05:12:12,653 | train | INFO | Epoch 14 validation batch 5/113: 80/1800 mean loss: 0.0010051238350570202 score: 1.0
2021-08-08 05:12:12,899 | train | INFO | Epoch 14 validation batch 6/113: 96/1800 mean loss: 0.0009314161725342274 score: 1.0
2021-08-08 05:12:13,132 | train | INFO | Epoch 14 validation batch 7/113: 112/1800 mean loss: 0.0010864653158932924 score: 1.0
2021-08-08 05:12:13,412 | train | INFO | Epoch 14 validation batch 8/113: 128/1800 mean loss: 0.0010355323320254683 score: 1.0
2021-08-08 05:12:13,657 | train | INFO | Epoch 14 validation batch 9/113: 144/1800 mean loss: 0.0010325834155082703 score: 1.0
2021-08-08 05:12:13,891 | train | INFO | Epoch 14 validation batch 10/113: 160/1800 mean loss: 0.0011044369312003255 score: 0.9816176470588235
2021-08-08 05:12:14,150 | train | INFO | Epoch 14 validation batch 11/113: 176/1800 mean loss: 0.0010847895173355937 score: 1.0
2021-08-08 05:12:14,396 | train | INFO | Epoch 14 validation batch 12/113: 192/1800 mean loss: 0.0010337142739444971 score: 1.0
2021-08-08 05:12:14,674 | train | INFO | Epoch 14 validation batch 13/113: 208/1800 mean loss: 0.0009387644822709262 score: 1.0
2021-08-08 05:12:14,930 | train | INFO | Epoch 14 validation batch 14/113: 224/1800 mean loss: 0.000888338137883693 score: 1.0
2021-08-08 05:12:15,221 | train | INFO | Epoch 14 validation batch 15/113: 240/1800 mean loss: 0.0010225226869806647 score: 1.0
2021-08-08 05:12:15,469 | train | INFO | Epoch 14 validation batch 16/113: 256/1800 mean loss: 0.001021868665702641 score: 1.0
2021-08-08 05:12:15,709 | train | INFO | Epoch 14 validation batch 17/113: 272/1800 mean loss: 0.0011466031428426504 score: 1.0
2021-08-08 05:12:15,940 | train | INFO | Epoch 14 validation batch 18/113: 288/1800 mean loss: 0.0008441857062280178 score: 1.0
2021-08-08 05:12:16,171 | train | INFO | Epoch 14 validation batch 19/113: 304/1800 mean loss: 0.0010159341618418694 score: 1.0
2021-08-08 05:12:16,470 | train | INFO | Epoch 14 validation batch 20/113: 320/1800 mean loss: 0.0011093455832451582 score: 0.9926470588235294
2021-08-08 05:12:16,705 | train | INFO | Epoch 14 validation batch 21/113: 336/1800 mean loss: 0.0009762016125023365 score: 0.9963235294117647
2021-08-08 05:12:16,969 | train | INFO | Epoch 14 validation batch 22/113: 352/1800 mean loss: 0.000956241914536804 score: 1.0
2021-08-08 05:12:17,229 | train | INFO | Epoch 14 validation batch 23/113: 368/1800 mean loss: 0.0009474466205574572 score: 1.0
2021-08-08 05:12:17,466 | train | INFO | Epoch 14 validation batch 24/113: 384/1800 mean loss: 0.001025912701152265 score: 1.0
2021-08-08 05:12:17,722 | train | INFO | Epoch 14 validation batch 25/113: 400/1800 mean loss: 0.0011132957879453897 score: 1.0
2021-08-08 05:12:17,958 | train | INFO | Epoch 14 validation batch 26/113: 416/1800 mean loss: 0.0008544791489839554 score: 1.0
2021-08-08 05:12:18,222 | train | INFO | Epoch 14 validation batch 27/113: 432/1800 mean loss: 0.001108140917494893 score: 1.0
2021-08-08 05:12:18,465 | train | INFO | Epoch 14 validation batch 28/113: 448/1800 mean loss: 0.0010020029731094837 score: 1.0
2021-08-08 05:12:18,705 | train | INFO | Epoch 14 validation batch 29/113: 464/1800 mean loss: 0.0010080968495458364 score: 1.0
2021-08-08 05:12:18,951 | train | INFO | Epoch 14 validation batch 30/113: 480/1800 mean loss: 0.0010345496702939272 score: 1.0
2021-08-08 05:12:19,210 | train | INFO | Epoch 14 validation batch 31/113: 496/1800 mean loss: 0.0009785119909793139 score: 1.0
2021-08-08 05:12:19,469 | train | INFO | Epoch 14 validation batch 32/113: 512/1800 mean loss: 0.0010546150151640177 score: 1.0
2021-08-08 05:12:19,734 | train | INFO | Epoch 14 validation batch 33/113: 528/1800 mean loss: 0.0008877707296051085 score: 1.0
2021-08-08 05:12:19,965 | train | INFO | Epoch 14 validation batch 34/113: 544/1800 mean loss: 0.0007714173407293856 score: 1.0
2021-08-08 05:12:20,196 | train | INFO | Epoch 14 validation batch 35/113: 560/1800 mean loss: 0.0011915764771401882 score: 1.0
2021-08-08 05:12:20,442 | train | INFO | Epoch 14 validation batch 36/113: 576/1800 mean loss: 0.0011242044856771827 score: 0.9480392156862746
2021-08-08 05:12:20,687 | train | INFO | Epoch 14 validation batch 37/113: 592/1800 mean loss: 0.0008359219064004719 score: 1.0
2021-08-08 05:12:20,920 | train | INFO | Epoch 14 validation batch 38/113: 608/1800 mean loss: 0.0010354078840464354 score: 1.0
2021-08-08 05:12:21,151 | train | INFO | Epoch 14 validation batch 39/113: 624/1800 mean loss: 0.0010036986786872149 score: 1.0
2021-08-08 05:12:21,382 | train | INFO | Epoch 14 validation batch 40/113: 640/1800 mean loss: 0.0010196147486567497 score: 1.0
2021-08-08 05:12:21,612 | train | INFO | Epoch 14 validation batch 41/113: 656/1800 mean loss: 0.0009506336064077914 score: 1.0
2021-08-08 05:12:21,852 | train | INFO | Epoch 14 validation batch 42/113: 672/1800 mean loss: 0.0009469403303228319 score: 0.9963235294117647
2021-08-08 05:12:22,096 | train | INFO | Epoch 14 validation batch 43/113: 688/1800 mean loss: 0.0009734461782500148 score: 1.0
2021-08-08 05:12:22,331 | train | INFO | Epoch 14 validation batch 44/113: 704/1800 mean loss: 0.0012396546080708504 score: 0.9742647058823529
2021-08-08 05:12:22,580 | train | INFO | Epoch 14 validation batch 45/113: 720/1800 mean loss: 0.0010561553062871099 score: 1.0
2021-08-08 05:12:22,811 | train | INFO | Epoch 14 validation batch 46/113: 736/1800 mean loss: 0.001027751830406487 score: 0.9926470588235294
2021-08-08 05:12:23,043 | train | INFO | Epoch 14 validation batch 47/113: 752/1800 mean loss: 0.0009495692793279886 score: 1.0
2021-08-08 05:12:23,274 | train | INFO | Epoch 14 validation batch 48/113: 768/1800 mean loss: 0.0009427883778698742 score: 1.0
2021-08-08 05:12:23,531 | train | INFO | Epoch 14 validation batch 49/113: 784/1800 mean loss: 0.0010235602967441082 score: 1.0
2021-08-08 05:12:23,773 | train | INFO | Epoch 14 validation batch 50/113: 800/1800 mean loss: 0.0009103153715841472 score: 1.0
2021-08-08 05:12:24,003 | train | INFO | Epoch 14 validation batch 51/113: 816/1800 mean loss: 0.0010769214713945985 score: 0.9889705882352942
2021-08-08 05:12:24,258 | train | INFO | Epoch 14 validation batch 52/113: 832/1800 mean loss: 0.00098081782925874 score: 1.0
2021-08-08 05:12:24,499 | train | INFO | Epoch 14 validation batch 53/113: 848/1800 mean loss: 0.000945131469052285 score: 1.0
2021-08-08 05:12:24,731 | train | INFO | Epoch 14 validation batch 54/113: 864/1800 mean loss: 0.0009550874237902462 score: 1.0
2021-08-08 05:12:24,966 | train | INFO | Epoch 14 validation batch 55/113: 880/1800 mean loss: 0.0010584621923044324 score: 1.0
2021-08-08 05:12:25,224 | train | INFO | Epoch 14 validation batch 56/113: 896/1800 mean loss: 0.0010216734372079372 score: 1.0
2021-08-08 05:12:25,472 | train | INFO | Epoch 14 validation batch 57/113: 912/1800 mean loss: 0.0010690231574699283 score: 1.0
2021-08-08 05:12:25,709 | train | INFO | Epoch 14 validation batch 58/113: 928/1800 mean loss: 0.0010689321206882596 score: 0.9852941176470589
2021-08-08 05:12:25,960 | train | INFO | Epoch 14 validation batch 59/113: 944/1800 mean loss: 0.0009681509109213948 score: 1.0
2021-08-08 05:12:26,191 | train | INFO | Epoch 14 validation batch 60/113: 960/1800 mean loss: 0.0008291652775369585 score: 1.0
2021-08-08 05:12:26,424 | train | INFO | Epoch 14 validation batch 61/113: 976/1800 mean loss: 0.0009220950305461884 score: 1.0
2021-08-08 05:12:26,675 | train | INFO | Epoch 14 validation batch 62/113: 992/1800 mean loss: 0.0009950223611667752 score: 1.0
2021-08-08 05:12:26,908 | train | INFO | Epoch 14 validation batch 63/113: 1008/1800 mean loss: 0.0009317974327132106 score: 1.0
2021-08-08 05:12:27,175 | train | INFO | Epoch 14 validation batch 64/113: 1024/1800 mean loss: 0.0009793078061193228 score: 1.0
2021-08-08 05:12:27,406 | train | INFO | Epoch 14 validation batch 65/113: 1040/1800 mean loss: 0.0010854090796783566 score: 1.0
2021-08-08 05:12:27,649 | train | INFO | Epoch 14 validation batch 66/113: 1056/1800 mean loss: 0.0010341852903366089 score: 1.0
2021-08-08 05:12:27,904 | train | INFO | Epoch 14 validation batch 67/113: 1072/1800 mean loss: 0.0010969468858093023 score: 1.0
2021-08-08 05:12:28,134 | train | INFO | Epoch 14 validation batch 68/113: 1088/1800 mean loss: 0.0008525827433913946 score: 1.0
2021-08-08 05:12:28,379 | train | INFO | Epoch 14 validation batch 69/113: 1104/1800 mean loss: 0.0009495136328041553 score: 1.0
2021-08-08 05:12:28,610 | train | INFO | Epoch 14 validation batch 70/113: 1120/1800 mean loss: 0.0011942359851673245 score: 1.0
2021-08-08 05:12:28,908 | train | INFO | Epoch 14 validation batch 71/113: 1136/1800 mean loss: 0.000913298106752336 score: 1.0
2021-08-08 05:12:29,153 | train | INFO | Epoch 14 validation batch 72/113: 1152/1800 mean loss: 0.0009484008187428117 score: 1.0
2021-08-08 05:12:29,386 | train | INFO | Epoch 14 validation batch 73/113: 1168/1800 mean loss: 0.0011715133441612124 score: 1.0
2021-08-08 05:12:29,655 | train | INFO | Epoch 14 validation batch 74/113: 1184/1800 mean loss: 0.0010991326998919249 score: 1.0
2021-08-08 05:12:29,906 | train | INFO | Epoch 14 validation batch 75/113: 1200/1800 mean loss: 0.000948286906350404 score: 1.0
2021-08-08 05:12:30,159 | train | INFO | Epoch 14 validation batch 76/113: 1216/1800 mean loss: 0.0008426030399277806 score: 1.0
2021-08-08 05:12:30,394 | train | INFO | Epoch 14 validation batch 77/113: 1232/1800 mean loss: 0.000839634332805872 score: 1.0
2021-08-08 05:12:30,627 | train | INFO | Epoch 14 validation batch 78/113: 1248/1800 mean loss: 0.0009677551570348442 score: 0.9889705882352942
2021-08-08 05:12:30,862 | train | INFO | Epoch 14 validation batch 79/113: 1264/1800 mean loss: 0.0011374029563739896 score: 0.996078431372549
2021-08-08 05:12:31,095 | train | INFO | Epoch 14 validation batch 80/113: 1280/1800 mean loss: 0.001152847078628838 score: 1.0
2021-08-08 05:12:31,327 | train | INFO | Epoch 14 validation batch 81/113: 1296/1800 mean loss: 0.000990074360743165 score: 1.0
2021-08-08 05:12:31,599 | train | INFO | Epoch 14 validation batch 82/113: 1312/1800 mean loss: 0.0010265038581565022 score: 1.0
2021-08-08 05:12:31,845 | train | INFO | Epoch 14 validation batch 83/113: 1328/1800 mean loss: 0.0011530168121680617 score: 1.0
2021-08-08 05:12:32,081 | train | INFO | Epoch 14 validation batch 84/113: 1344/1800 mean loss: 0.0011620870791375637 score: 0.9926470588235294
2021-08-08 05:12:32,313 | train | INFO | Epoch 14 validation batch 85/113: 1360/1800 mean loss: 0.001032383763231337 score: 1.0
2021-08-08 05:12:32,546 | train | INFO | Epoch 14 validation batch 86/113: 1376/1800 mean loss: 0.0012519239680841565 score: 1.0
2021-08-08 05:12:32,796 | train | INFO | Epoch 14 validation batch 87/113: 1392/1800 mean loss: 0.0011607748456299305 score: 1.0
2021-08-08 05:12:33,053 | train | INFO | Epoch 14 validation batch 88/113: 1408/1800 mean loss: 0.0009946993086487055 score: 1.0
2021-08-08 05:12:33,298 | train | INFO | Epoch 14 validation batch 89/113: 1424/1800 mean loss: 0.000864440924488008 score: 1.0
2021-08-08 05:12:33,531 | train | INFO | Epoch 14 validation batch 90/113: 1440/1800 mean loss: 0.000931275135371834 score: 1.0
2021-08-08 05:12:33,761 | train | INFO | Epoch 14 validation batch 91/113: 1456/1800 mean loss: 0.0012745813000947237 score: 1.0
2021-08-08 05:12:33,993 | train | INFO | Epoch 14 validation batch 92/113: 1472/1800 mean loss: 0.0009668952552601695 score: 1.0
2021-08-08 05:12:34,225 | train | INFO | Epoch 14 validation batch 93/113: 1488/1800 mean loss: 0.0010071003343909979 score: 1.0
2021-08-08 05:12:34,457 | train | INFO | Epoch 14 validation batch 94/113: 1504/1800 mean loss: 0.0010094180470332503 score: 1.0
2021-08-08 05:12:34,706 | train | INFO | Epoch 14 validation batch 95/113: 1520/1800 mean loss: 0.0010544960387051105 score: 1.0
2021-08-08 05:12:34,960 | train | INFO | Epoch 14 validation batch 96/113: 1536/1800 mean loss: 0.00114102300722152 score: 1.0
2021-08-08 05:12:35,209 | train | INFO | Epoch 14 validation batch 97/113: 1552/1800 mean loss: 0.0010498750489205122 score: 1.0
2021-08-08 05:12:35,441 | train | INFO | Epoch 14 validation batch 98/113: 1568/1800 mean loss: 0.0009971477556973696 score: 1.0
2021-08-08 05:12:35,683 | train | INFO | Epoch 14 validation batch 99/113: 1584/1800 mean loss: 0.0009633347508497536 score: 1.0
2021-08-08 05:12:35,914 | train | INFO | Epoch 14 validation batch 100/113: 1600/1800 mean loss: 0.001162662752903998 score: 1.0
2021-08-08 05:12:36,145 | train | INFO | Epoch 14 validation batch 101/113: 1616/1800 mean loss: 0.0009768136078491807 score: 1.0
2021-08-08 05:12:36,376 | train | INFO | Epoch 14 validation batch 102/113: 1632/1800 mean loss: 0.0009227984701283276 score: 1.0
2021-08-08 05:12:36,606 | train | INFO | Epoch 14 validation batch 103/113: 1648/1800 mean loss: 0.0009649762068875134 score: 1.0
2021-08-08 05:12:36,838 | train | INFO | Epoch 14 validation batch 104/113: 1664/1800 mean loss: 0.001081740716472268 score: 1.0
2021-08-08 05:12:37,068 | train | INFO | Epoch 14 validation batch 105/113: 1680/1800 mean loss: 0.0010182569967582822 score: 1.0
2021-08-08 05:12:37,299 | train | INFO | Epoch 14 validation batch 106/113: 1696/1800 mean loss: 0.0010600392706692219 score: 1.0
2021-08-08 05:12:37,530 | train | INFO | Epoch 14 validation batch 107/113: 1712/1800 mean loss: 0.0012842124560847878 score: 1.0
2021-08-08 05:12:37,761 | train | INFO | Epoch 14 validation batch 108/113: 1728/1800 mean loss: 0.0012337943771854043 score: 1.0
2021-08-08 05:12:37,992 | train | INFO | Epoch 14 validation batch 109/113: 1744/1800 mean loss: 0.0011099984403699636 score: 1.0
2021-08-08 05:12:38,225 | train | INFO | Epoch 14 validation batch 110/113: 1760/1800 mean loss: 0.0009354144567623734 score: 1.0
2021-08-08 05:12:38,457 | train | INFO | Epoch 14 validation batch 111/113: 1776/1800 mean loss: 0.0009643423254601657 score: 1.0
2021-08-08 05:12:38,625 | train | INFO | Epoch 14 validation batch 112/113: 1792/1800 mean loss: 0.000928413646761328 score: 1.0
2021-08-08 05:12:38,767 | train | INFO | Epoch 14, Validation, Mean loss: 0.016336415754219073, Score: 0.9984968766267569
2021-08-08 05:12:38,768 | train | INFO | Write row 14
2021-08-08 05:12:41,530 | train | INFO | Model saved: ./results/train/cow_20210808033416/model.pt
2021-08-08 05:12:41,539 | train | INFO | Update best record row 15, checkpoints 0.01638564966882752 -> 0.016336415754219073
2021-08-08 05:12:43,607 | train | INFO | Epoch 15 train batch 0/450: 0/7200 mean loss: 0.0014796910108998418 score: 1.0
2021-08-08 05:12:44,393 | train | INFO | Epoch 15 train batch 1/450: 16/7200 mean loss: 0.0011389520950615406 score: 1.0
2021-08-08 05:12:45,190 | train | INFO | Epoch 15 train batch 2/450: 32/7200 mean loss: 0.0014459228841587901 score: 0.9963235294117647
2021-08-08 05:12:46,017 | train | INFO | Epoch 15 train batch 3/450: 48/7200 mean loss: 0.0012378807878121734 score: 0.9963235294117647
2021-08-08 05:12:46,821 | train | INFO | Epoch 15 train batch 4/450: 64/7200 mean loss: 0.0014858815120533109 score: 1.0
2021-08-08 05:12:47,629 | train | INFO | Epoch 15 train batch 5/450: 80/7200 mean loss: 0.0015012008370831609 score: 1.0
2021-08-08 05:12:48,406 | train | INFO | Epoch 15 train batch 6/450: 96/7200 mean loss: 0.0015471091028302908 score: 1.0
2021-08-08 05:12:49,188 | train | INFO | Epoch 15 train batch 7/450: 112/7200 mean loss: 0.0015333155170083046 score: 0.9963235294117647
2021-08-08 05:12:49,992 | train | INFO | Epoch 15 train batch 8/450: 128/7200 mean loss: 0.0012837897520512342 score: 1.0
2021-08-08 05:12:50,789 | train | INFO | Epoch 15 train batch 9/450: 144/7200 mean loss: 0.0014048987068235874 score: 0.996078431372549
2021-08-08 05:12:51,593 | train | INFO | Epoch 15 train batch 10/450: 160/7200 mean loss: 0.0015195216983556747 score: 1.0
2021-08-08 05:12:52,410 | train | INFO | Epoch 15 train batch 11/450: 176/7200 mean loss: 0.0013031394919380546 score: 0.9963235294117647
2021-08-08 05:12:53,189 | train | INFO | Epoch 15 train batch 12/450: 192/7200 mean loss: 0.0013028664980083704 score: 1.0
2021-08-08 05:12:54,002 | train | INFO | Epoch 15 train batch 13/450: 208/7200 mean loss: 0.0014287331141531467 score: 1.0
2021-08-08 05:12:54,835 | train | INFO | Epoch 15 train batch 14/450: 224/7200 mean loss: 0.0012528009247034788 score: 1.0
2021-08-08 05:12:55,628 | train | INFO | Epoch 15 train batch 15/450: 240/7200 mean loss: 0.0015084207989275455 score: 0.9926470588235294
2021-08-08 05:12:56,440 | train | INFO | Epoch 15 train batch 16/450: 256/7200 mean loss: 0.0014206302585080266 score: 1.0
2021-08-08 05:12:57,247 | train | INFO | Epoch 15 train batch 17/450: 272/7200 mean loss: 0.0013466683449223638 score: 1.0
2021-08-08 05:12:58,073 | train | INFO | Epoch 15 train batch 18/450: 288/7200 mean loss: 0.0014053964987397194 score: 1.0
2021-08-08 05:12:58,893 | train | INFO | Epoch 15 train batch 19/450: 304/7200 mean loss: 0.0016063418006524444 score: 0.9963235294117647
2021-08-08 05:12:59,708 | train | INFO | Epoch 15 train batch 20/450: 320/7200 mean loss: 0.0013106680708006024 score: 0.9963235294117647
2021-08-08 05:13:00,495 | train | INFO | Epoch 15 train batch 21/450: 336/7200 mean loss: 0.0017237499123439193 score: 1.0
2021-08-08 05:13:01,264 | train | INFO | Epoch 15 train batch 22/450: 352/7200 mean loss: 0.0015648078406229615 score: 0.9852941176470589
2021-08-08 05:13:02,039 | train | INFO | Epoch 15 train batch 23/450: 368/7200 mean loss: 0.0014191317604854703 score: 1.0
2021-08-08 05:13:02,887 | train | INFO | Epoch 15 train batch 24/450: 384/7200 mean loss: 0.0013790287775918841 score: 1.0
2021-08-08 05:13:03,783 | train | INFO | Epoch 15 train batch 25/450: 400/7200 mean loss: 0.0014269232051447034 score: 1.0
2021-08-08 05:13:04,597 | train | INFO | Epoch 15 train batch 26/450: 416/7200 mean loss: 0.0013358818832784891 score: 1.0
2021-08-08 05:13:05,415 | train | INFO | Epoch 15 train batch 27/450: 432/7200 mean loss: 0.0014377346960827708 score: 1.0
2021-08-08 05:13:06,234 | train | INFO | Epoch 15 train batch 28/450: 448/7200 mean loss: 0.0012642377987504005 score: 1.0
2021-08-08 05:13:07,057 | train | INFO | Epoch 15 train batch 29/450: 464/7200 mean loss: 0.0014785900712013245 score: 0.996078431372549
2021-08-08 05:13:07,863 | train | INFO | Epoch 15 train batch 30/450: 480/7200 mean loss: 0.0014475317439064384 score: 1.0
2021-08-08 05:13:08,653 | train | INFO | Epoch 15 train batch 31/450: 496/7200 mean loss: 0.0015423124423250556 score: 1.0
2021-08-08 05:13:09,488 | train | INFO | Epoch 15 train batch 32/450: 512/7200 mean loss: 0.001344142365269363 score: 1.0
2021-08-08 05:13:10,309 | train | INFO | Epoch 15 train batch 33/450: 528/7200 mean loss: 0.0015180520713329315 score: 1.0
2021-08-08 05:13:11,087 | train | INFO | Epoch 15 train batch 34/450: 544/7200 mean loss: 0.0015952683752402663 score: 1.0
2021-08-08 05:13:11,906 | train | INFO | Epoch 15 train batch 35/450: 560/7200 mean loss: 0.0014238288858905435 score: 1.0
2021-08-08 05:13:12,795 | train | INFO | Epoch 15 train batch 36/450: 576/7200 mean loss: 0.001394935417920351 score: 0.9963235294117647
2021-08-08 05:13:13,615 | train | INFO | Epoch 15 train batch 37/450: 592/7200 mean loss: 0.0015468017663806677 score: 0.9811274509803922
2021-08-08 05:13:14,409 | train | INFO | Epoch 15 train batch 38/450: 608/7200 mean loss: 0.0013383812038227916 score: 0.970343137254902
2021-08-08 05:13:15,243 | train | INFO | Epoch 15 train batch 39/450: 624/7200 mean loss: 0.001514895586296916 score: 1.0
2021-08-08 05:13:16,042 | train | INFO | Epoch 15 train batch 40/450: 640/7200 mean loss: 0.0014871669700369239 score: 1.0
2021-08-08 05:13:16,808 | train | INFO | Epoch 15 train batch 41/450: 656/7200 mean loss: 0.0015512446407228708 score: 1.0
2021-08-08 05:13:17,618 | train | INFO | Epoch 15 train batch 42/450: 672/7200 mean loss: 0.001349485944956541 score: 1.0
2021-08-08 05:13:18,423 | train | INFO | Epoch 15 train batch 43/450: 688/7200 mean loss: 0.001382586546242237 score: 0.9963235294117647
2021-08-08 05:13:19,201 | train | INFO | Epoch 15 train batch 44/450: 704/7200 mean loss: 0.0014229040825739503 score: 0.9963235294117647
2021-08-08 05:13:20,010 | train | INFO | Epoch 15 train batch 45/450: 720/7200 mean loss: 0.0016060045454651117 score: 1.0
2021-08-08 05:13:20,796 | train | INFO | Epoch 15 train batch 46/450: 736/7200 mean loss: 0.0014461060054600239 score: 1.0
2021-08-08 05:13:21,618 | train | INFO | Epoch 15 train batch 47/450: 752/7200 mean loss: 0.0013238119427114725 score: 1.0
2021-08-08 05:13:22,436 | train | INFO | Epoch 15 train batch 48/450: 768/7200 mean loss: 0.0014457536162808537 score: 1.0
2021-08-08 05:13:23,251 | train | INFO | Epoch 15 train batch 49/450: 784/7200 mean loss: 0.0013410032261162996 score: 1.0
2021-08-08 05:13:24,068 | train | INFO | Epoch 15 train batch 50/450: 800/7200 mean loss: 0.0014603035524487495 score: 1.0
2021-08-08 05:13:24,857 | train | INFO | Epoch 15 train batch 51/450: 816/7200 mean loss: 0.0012615000596269965 score: 1.0
2021-08-08 05:13:25,655 | train | INFO | Epoch 15 train batch 52/450: 832/7200 mean loss: 0.0015176180750131607 score: 1.0
2021-08-08 05:13:26,434 | train | INFO | Epoch 15 train batch 53/450: 848/7200 mean loss: 0.0012848704354837537 score: 1.0
2021-08-08 05:13:27,241 | train | INFO | Epoch 15 train batch 54/450: 864/7200 mean loss: 0.001109181554056704 score: 1.0
2021-08-08 05:13:28,022 | train | INFO | Epoch 15 train batch 55/450: 880/7200 mean loss: 0.001025420380756259 score: 1.0
2021-08-08 05:13:28,799 | train | INFO | Epoch 15 train batch 56/450: 896/7200 mean loss: 0.0012796428054571152 score: 0.9924019607843138
2021-08-08 05:13:29,583 | train | INFO | Epoch 15 train batch 57/450: 912/7200 mean loss: 0.0013372180983424187 score: 0.8656162464985995
2021-08-08 05:13:30,359 | train | INFO | Epoch 15 train batch 58/450: 928/7200 mean loss: 0.0012943107867613435 score: 1.0
2021-08-08 05:13:31,167 | train | INFO | Epoch 15 train batch 59/450: 944/7200 mean loss: 0.0013858641032129526 score: 0.9963235294117647
2021-08-08 05:13:31,983 | train | INFO | Epoch 15 train batch 60/450: 960/7200 mean loss: 0.0015361005207523704 score: 1.0
2021-08-08 05:13:32,798 | train | INFO | Epoch 15 train batch 61/450: 976/7200 mean loss: 0.001478484831750393 score: 0.9926470588235294
2021-08-08 05:13:33,610 | train | INFO | Epoch 15 train batch 62/450: 992/7200 mean loss: 0.0013840143801644444 score: 1.0
2021-08-08 05:13:34,421 | train | INFO | Epoch 15 train batch 63/450: 1008/7200 mean loss: 0.0015590762486681342 score: 1.0
2021-08-08 05:13:35,237 | train | INFO | Epoch 15 train batch 64/450: 1024/7200 mean loss: 0.0012940223095938563 score: 1.0
2021-08-08 05:13:36,060 | train | INFO | Epoch 15 train batch 65/450: 1040/7200 mean loss: 0.0015253160381689668 score: 1.0
2021-08-08 05:13:36,848 | train | INFO | Epoch 15 train batch 66/450: 1056/7200 mean loss: 0.0011143800802528858 score: 1.0
2021-08-08 05:13:37,664 | train | INFO | Epoch 15 train batch 67/450: 1072/7200 mean loss: 0.0012492304667830467 score: 1.0
2021-08-08 05:13:38,515 | train | INFO | Epoch 15 train batch 68/450: 1088/7200 mean loss: 0.001434414996765554 score: 1.0
2021-08-08 05:13:39,303 | train | INFO | Epoch 15 train batch 69/450: 1104/7200 mean loss: 0.0013412486296147108 score: 0.9852941176470589
2021-08-08 05:13:40,097 | train | INFO | Epoch 15 train batch 70/450: 1120/7200 mean loss: 0.0014779545599594712 score: 1.0
2021-08-08 05:13:40,907 | train | INFO | Epoch 15 train batch 71/450: 1136/7200 mean loss: 0.0014663847396150231 score: 1.0
2021-08-08 05:13:41,696 | train | INFO | Epoch 15 train batch 72/450: 1152/7200 mean loss: 0.0013731628423556685 score: 1.0
2021-08-08 05:13:42,526 | train | INFO | Epoch 15 train batch 73/450: 1168/7200 mean loss: 0.0014243725454434752 score: 1.0
2021-08-08 05:13:43,335 | train | INFO | Epoch 15 train batch 74/450: 1184/7200 mean loss: 0.0014919897075742483 score: 0.9924019607843138
2021-08-08 05:13:44,204 | train | INFO | Epoch 15 train batch 75/450: 1200/7200 mean loss: 0.0012804417638108134 score: 0.9963235294117647
2021-08-08 05:13:45,012 | train | INFO | Epoch 15 train batch 76/450: 1216/7200 mean loss: 0.001224801759235561 score: 1.0
2021-08-08 05:13:45,783 | train | INFO | Epoch 15 train batch 77/450: 1232/7200 mean loss: 0.0012640268541872501 score: 1.0
2021-08-08 05:13:46,569 | train | INFO | Epoch 15 train batch 78/450: 1248/7200 mean loss: 0.001369235571473837 score: 1.0
2021-08-08 05:13:47,346 | train | INFO | Epoch 15 train batch 79/450: 1264/7200 mean loss: 0.0015917426208034158 score: 1.0
2021-08-08 05:13:48,176 | train | INFO | Epoch 15 train batch 80/450: 1280/7200 mean loss: 0.0014039369998499751 score: 1.0
2021-08-08 05:13:48,975 | train | INFO | Epoch 15 train batch 81/450: 1296/7200 mean loss: 0.0014237685827538371 score: 0.9850490196078432
2021-08-08 05:13:49,867 | train | INFO | Epoch 15 train batch 82/450: 1312/7200 mean loss: 0.0015466255135834217 score: 1.0
2021-08-08 05:13:50,671 | train | INFO | Epoch 15 train batch 83/450: 1328/7200 mean loss: 0.0011950007174164057 score: 0.9850490196078432
2021-08-08 05:13:51,475 | train | INFO | Epoch 15 train batch 84/450: 1344/7200 mean loss: 0.0012542076874524355 score: 1.0
2021-08-08 05:13:52,284 | train | INFO | Epoch 15 train batch 85/450: 1360/7200 mean loss: 0.0012614558218047023 score: 1.0
2021-08-08 05:13:53,061 | train | INFO | Epoch 15 train batch 86/450: 1376/7200 mean loss: 0.0014823422534391284 score: 1.0
2021-08-08 05:13:53,858 | train | INFO | Epoch 15 train batch 87/450: 1392/7200 mean loss: 0.001207590801641345 score: 1.0
2021-08-08 05:13:54,663 | train | INFO | Epoch 15 train batch 88/450: 1408/7200 mean loss: 0.0014268095837906003 score: 1.0
2021-08-08 05:13:55,461 | train | INFO | Epoch 15 train batch 89/450: 1424/7200 mean loss: 0.001401858520694077 score: 0.996078431372549
2021-08-08 05:13:56,240 | train | INFO | Epoch 15 train batch 90/450: 1440/7200 mean loss: 0.0014676084974780679 score: 1.0
2021-08-08 05:13:57,018 | train | INFO | Epoch 15 train batch 91/450: 1456/7200 mean loss: 0.001463885186240077 score: 1.0
2021-08-08 05:13:57,794 | train | INFO | Epoch 15 train batch 92/450: 1472/7200 mean loss: 0.001357753062620759 score: 1.0
2021-08-08 05:13:58,605 | train | INFO | Epoch 15 train batch 93/450: 1488/7200 mean loss: 0.0015885430620983243 score: 1.0
2021-08-08 05:13:59,381 | train | INFO | Epoch 15 train batch 94/450: 1504/7200 mean loss: 0.001498163677752018 score: 1.0
2021-08-08 05:14:00,164 | train | INFO | Epoch 15 train batch 95/450: 1520/7200 mean loss: 0.0014202025486156344 score: 1.0
2021-08-08 05:14:00,963 | train | INFO | Epoch 15 train batch 96/450: 1536/7200 mean loss: 0.0014078783569857478 score: 1.0
2021-08-08 05:14:01,756 | train | INFO | Epoch 15 train batch 97/450: 1552/7200 mean loss: 0.0016059718327596784 score: 1.0
2021-08-08 05:14:02,532 | train | INFO | Epoch 15 train batch 98/450: 1568/7200 mean loss: 0.0014030702877789736 score: 1.0
2021-08-08 05:14:03,323 | train | INFO | Epoch 15 train batch 99/450: 1584/7200 mean loss: 0.0013884005602449179 score: 1.0
2021-08-08 05:14:04,132 | train | INFO | Epoch 15 train batch 100/450: 1600/7200 mean loss: 0.0013390902895480394 score: 1.0
2021-08-08 05:14:04,905 | train | INFO | Epoch 15 train batch 101/450: 1616/7200 mean loss: 0.0014917912194505334 score: 0.996078431372549
2021-08-08 05:14:05,685 | train | INFO | Epoch 15 train batch 102/450: 1632/7200 mean loss: 0.0014436476631090045 score: 1.0
2021-08-08 05:14:06,467 | train | INFO | Epoch 15 train batch 103/450: 1648/7200 mean loss: 0.0014274875866249204 score: 1.0
2021-08-08 05:14:07,250 | train | INFO | Epoch 15 train batch 104/450: 1664/7200 mean loss: 0.0015333406627178192 score: 1.0
2021-08-08 05:14:08,026 | train | INFO | Epoch 15 train batch 105/450: 1680/7200 mean loss: 0.0012970250099897385 score: 1.0
2021-08-08 05:14:08,872 | train | INFO | Epoch 15 train batch 106/450: 1696/7200 mean loss: 0.0014276563888415694 score: 1.0
2021-08-08 05:14:09,647 | train | INFO | Epoch 15 train batch 107/450: 1712/7200 mean loss: 0.0013150136219337583 score: 0.9772058823529413
2021-08-08 05:14:10,479 | train | INFO | Epoch 15 train batch 108/450: 1728/7200 mean loss: 0.0016524147940799594 score: 0.9852941176470589
2021-08-08 05:14:11,253 | train | INFO | Epoch 15 train batch 109/450: 1744/7200 mean loss: 0.0013484176015481353 score: 1.0
2021-08-08 05:14:12,050 | train | INFO | Epoch 15 train batch 110/450: 1760/7200 mean loss: 0.0014215493574738503 score: 1.0
2021-08-08 05:14:12,867 | train | INFO | Epoch 15 train batch 111/450: 1776/7200 mean loss: 0.0016179557424038649 score: 1.0
2021-08-08 05:14:13,682 | train | INFO | Epoch 15 train batch 112/450: 1792/7200 mean loss: 0.0015512427780777216 score: 1.0
2021-08-08 05:14:14,450 | train | INFO | Epoch 15 train batch 113/450: 1808/7200 mean loss: 0.0015430401545017958 score: 1.0
2021-08-08 05:14:15,300 | train | INFO | Epoch 15 train batch 114/450: 1824/7200 mean loss: 0.0013435014989227057 score: 1.0
2021-08-08 05:14:16,113 | train | INFO | Epoch 15 train batch 115/450: 1840/7200 mean loss: 0.0012834393419325352 score: 1.0
2021-08-08 05:14:16,910 | train | INFO | Epoch 15 train batch 116/450: 1856/7200 mean loss: 0.0012985009234398603 score: 0.9963235294117647
2021-08-08 05:14:17,691 | train | INFO | Epoch 15 train batch 117/450: 1872/7200 mean loss: 0.0012473806273192167 score: 1.0
2021-08-08 05:14:18,477 | train | INFO | Epoch 15 train batch 118/450: 1888/7200 mean loss: 0.0013572467723861337 score: 1.0
2021-08-08 05:14:19,404 | train | INFO | Epoch 15 train batch 119/450: 1904/7200 mean loss: 0.00144667096901685 score: 0.9926470588235294
2021-08-08 05:14:20,184 | train | INFO | Epoch 15 train batch 120/450: 1920/7200 mean loss: 0.0013509242562577128 score: 1.0
2021-08-08 05:14:20,998 | train | INFO | Epoch 15 train batch 121/450: 1936/7200 mean loss: 0.001489845453761518 score: 1.0
2021-08-08 05:14:21,838 | train | INFO | Epoch 15 train batch 122/450: 1952/7200 mean loss: 0.0014364771777763963 score: 1.0
2021-08-08 05:14:22,655 | train | INFO | Epoch 15 train batch 123/450: 1968/7200 mean loss: 0.0012900944566354156 score: 0.9774509803921569
2021-08-08 05:14:23,450 | train | INFO | Epoch 15 train batch 124/450: 1984/7200 mean loss: 0.0014203519094735384 score: 1.0
2021-08-08 05:14:24,272 | train | INFO | Epoch 15 train batch 125/450: 2000/7200 mean loss: 0.0015259863575920463 score: 0.9816176470588235
2021-08-08 05:14:25,091 | train | INFO | Epoch 15 train batch 126/450: 2016/7200 mean loss: 0.0014321584021672606 score: 1.0
2021-08-08 05:14:25,900 | train | INFO | Epoch 15 train batch 127/450: 2032/7200 mean loss: 0.0013588974252343178 score: 1.0
2021-08-08 05:14:26,691 | train | INFO | Epoch 15 train batch 128/450: 2048/7200 mean loss: 0.0014422513777390122 score: 1.0
2021-08-08 05:14:27,464 | train | INFO | Epoch 15 train batch 129/450: 2064/7200 mean loss: 0.0012079058215022087 score: 1.0
2021-08-08 05:14:28,241 | train | INFO | Epoch 15 train batch 130/450: 2080/7200 mean loss: 0.001281571458093822 score: 1.0
2021-08-08 05:14:29,008 | train | INFO | Epoch 15 train batch 131/450: 2096/7200 mean loss: 0.0013582298997789621 score: 1.0
2021-08-08 05:14:29,820 | train | INFO | Epoch 15 train batch 132/450: 2112/7200 mean loss: 0.0011171698570251465 score: 0.9924019607843138
2021-08-08 05:14:30,603 | train | INFO | Epoch 15 train batch 133/450: 2128/7200 mean loss: 0.0014491163892671466 score: 1.0
2021-08-08 05:14:31,428 | train | INFO | Epoch 15 train batch 134/450: 2144/7200 mean loss: 0.0013646158622577786 score: 1.0
2021-08-08 05:14:32,234 | train | INFO | Epoch 15 train batch 135/450: 2160/7200 mean loss: 0.001281103235669434 score: 1.0
2021-08-08 05:14:33,006 | train | INFO | Epoch 15 train batch 136/450: 2176/7200 mean loss: 0.001439319341443479 score: 0.9816176470588235
2021-08-08 05:14:33,824 | train | INFO | Epoch 15 train batch 137/450: 2192/7200 mean loss: 0.0014728428795933723 score: 1.0
2021-08-08 05:14:34,631 | train | INFO | Epoch 15 train batch 138/450: 2208/7200 mean loss: 0.001215740805491805 score: 0.9963235294117647
2021-08-08 05:14:35,437 | train | INFO | Epoch 15 train batch 139/450: 2224/7200 mean loss: 0.0016985359834507108 score: 1.0
2021-08-08 05:14:36,234 | train | INFO | Epoch 15 train batch 140/450: 2240/7200 mean loss: 0.00118442892562598 score: 0.9926470588235294
2021-08-08 05:14:37,010 | train | INFO | Epoch 15 train batch 141/450: 2256/7200 mean loss: 0.001507929409854114 score: 0.996078431372549
2021-08-08 05:14:37,789 | train | INFO | Epoch 15 train batch 142/450: 2272/7200 mean loss: 0.0013628274900838733 score: 1.0
2021-08-08 05:14:38,587 | train | INFO | Epoch 15 train batch 143/450: 2288/7200 mean loss: 0.0014392881421372294 score: 1.0
2021-08-08 05:14:39,389 | train | INFO | Epoch 15 train batch 144/450: 2304/7200 mean loss: 0.0013737983535975218 score: 1.0
2021-08-08 05:14:40,188 | train | INFO | Epoch 15 train batch 145/450: 2320/7200 mean loss: 0.0012860976858064532 score: 1.0
2021-08-08 05:14:40,965 | train | INFO | Epoch 15 train batch 146/450: 2336/7200 mean loss: 0.0012675273464992642 score: 1.0
2021-08-08 05:14:41,748 | train | INFO | Epoch 15 train batch 147/450: 2352/7200 mean loss: 0.0012576659210026264 score: 1.0
2021-08-08 05:14:42,528 | train | INFO | Epoch 15 train batch 148/450: 2368/7200 mean loss: 0.0013558865757659078 score: 1.0
2021-08-08 05:14:43,321 | train | INFO | Epoch 15 train batch 149/450: 2384/7200 mean loss: 0.001405291142873466 score: 1.0
2021-08-08 05:14:44,093 | train | INFO | Epoch 15 train batch 150/450: 2400/7200 mean loss: 0.0014417280908674002 score: 0.9666666666666667
2021-08-08 05:14:44,879 | train | INFO | Epoch 15 train batch 151/450: 2416/7200 mean loss: 0.0015964288031682372 score: 0.9963235294117647
2021-08-08 05:14:45,659 | train | INFO | Epoch 15 train batch 152/450: 2432/7200 mean loss: 0.0016831040848046541 score: 1.0
2021-08-08 05:14:46,473 | train | INFO | Epoch 15 train batch 153/450: 2448/7200 mean loss: 0.001395933679305017 score: 1.0
2021-08-08 05:14:47,294 | train | INFO | Epoch 15 train batch 154/450: 2464/7200 mean loss: 0.0017210557125508785 score: 0.9963235294117647
2021-08-08 05:14:48,076 | train | INFO | Epoch 15 train batch 155/450: 2480/7200 mean loss: 0.0014595778193324804 score: 0.9963235294117647
2021-08-08 05:14:48,861 | train | INFO | Epoch 15 train batch 156/450: 2496/7200 mean loss: 0.0015928144566714764 score: 1.0
2021-08-08 05:14:49,636 | train | INFO | Epoch 15 train batch 157/450: 2512/7200 mean loss: 0.0014384995447471738 score: 1.0
2021-08-08 05:14:50,414 | train | INFO | Epoch 15 train batch 158/450: 2528/7200 mean loss: 0.0014582857256755233 score: 1.0
2021-08-08 05:14:51,194 | train | INFO | Epoch 15 train batch 159/450: 2544/7200 mean loss: 0.0013584076659753919 score: 1.0
2021-08-08 05:14:51,960 | train | INFO | Epoch 15 train batch 160/450: 2560/7200 mean loss: 0.0016020727343857288 score: 1.0
2021-08-08 05:14:52,779 | train | INFO | Epoch 15 train batch 161/450: 2576/7200 mean loss: 0.0015687465202063322 score: 1.0
2021-08-08 05:14:53,559 | train | INFO | Epoch 15 train batch 162/450: 2592/7200 mean loss: 0.0017102003330364823 score: 0.9926470588235294
2021-08-08 05:14:54,378 | train | INFO | Epoch 15 train batch 163/450: 2608/7200 mean loss: 0.001496584969572723 score: 0.995798319327731
2021-08-08 05:14:55,195 | train | INFO | Epoch 15 train batch 164/450: 2624/7200 mean loss: 0.001650279271416366 score: 0.9845588235294118
2021-08-08 05:14:55,988 | train | INFO | Epoch 15 train batch 165/450: 2640/7200 mean loss: 0.0013631531037390232 score: 0.99187675070028
2021-08-08 05:14:56,793 | train | INFO | Epoch 15 train batch 166/450: 2656/7200 mean loss: 0.0015454674139618874 score: 1.0
2021-08-08 05:14:57,664 | train | INFO | Epoch 15 train batch 167/450: 2672/7200 mean loss: 0.0017046512803062797 score: 0.9475490196078432
2021-08-08 05:14:58,454 | train | INFO | Epoch 15 train batch 168/450: 2688/7200 mean loss: 0.001331206876784563 score: 1.0
2021-08-08 05:14:59,223 | train | INFO | Epoch 15 train batch 169/450: 2704/7200 mean loss: 0.001365475938655436 score: 0.9963235294117647
2021-08-08 05:15:00,017 | train | INFO | Epoch 15 train batch 170/450: 2720/7200 mean loss: 0.0012224598322063684 score: 1.0
2021-08-08 05:15:00,886 | train | INFO | Epoch 15 train batch 171/450: 2736/7200 mean loss: 0.0014332066057249904 score: 1.0
2021-08-08 05:15:01,787 | train | INFO | Epoch 15 train batch 172/450: 2752/7200 mean loss: 0.0013273570220917463 score: 1.0
2021-08-08 05:15:02,589 | train | INFO | Epoch 15 train batch 173/450: 2768/7200 mean loss: 0.0012847959296777844 score: 0.9963235294117647
2021-08-08 05:15:03,369 | train | INFO | Epoch 15 train batch 174/450: 2784/7200 mean loss: 0.0014346354873850942 score: 0.9033613445378151
2021-08-08 05:15:04,175 | train | INFO | Epoch 15 train batch 175/450: 2800/7200 mean loss: 0.0015341307735070586 score: 1.0
2021-08-08 05:15:04,948 | train | INFO | Epoch 15 train batch 176/450: 2816/7200 mean loss: 0.0014368891716003418 score: 1.0
2021-08-08 05:15:05,798 | train | INFO | Epoch 15 train batch 177/450: 2832/7200 mean loss: 0.0014986558817327023 score: 0.9963235294117647
2021-08-08 05:15:06,608 | train | INFO | Epoch 15 train batch 178/450: 2848/7200 mean loss: 0.0013289643684402108 score: 1.0
2021-08-08 05:15:07,386 | train | INFO | Epoch 15 train batch 179/450: 2864/7200 mean loss: 0.0014612417435273528 score: 0.9186274509803922
2021-08-08 05:15:08,169 | train | INFO | Epoch 15 train batch 180/450: 2880/7200 mean loss: 0.001498055295087397 score: 1.0
2021-08-08 05:15:08,960 | train | INFO | Epoch 15 train batch 181/450: 2896/7200 mean loss: 0.0014474866911768913 score: 1.0
2021-08-08 05:15:09,766 | train | INFO | Epoch 15 train batch 182/450: 2912/7200 mean loss: 0.0014257621951401234 score: 1.0
2021-08-08 05:15:10,550 | train | INFO | Epoch 15 train batch 183/450: 2928/7200 mean loss: 0.0014767013490200043 score: 0.9926470588235294
2021-08-08 05:15:11,322 | train | INFO | Epoch 15 train batch 184/450: 2944/7200 mean loss: 0.0014895298518240452 score: 0.9963235294117647
2021-08-08 05:15:12,093 | train | INFO | Epoch 15 train batch 185/450: 2960/7200 mean loss: 0.001434345613233745 score: 1.0
2021-08-08 05:15:12,863 | train | INFO | Epoch 15 train batch 186/450: 2976/7200 mean loss: 0.0014709548559039831 score: 1.0
2021-08-08 05:15:13,665 | train | INFO | Epoch 15 train batch 187/450: 2992/7200 mean loss: 0.0013702615397050977 score: 1.0
2021-08-08 05:15:14,474 | train | INFO | Epoch 15 train batch 188/450: 3008/7200 mean loss: 0.001729641342535615 score: 0.9963235294117647
2021-08-08 05:15:15,261 | train | INFO | Epoch 15 train batch 189/450: 3024/7200 mean loss: 0.0015127027872949839 score: 1.0
2021-08-08 05:15:16,036 | train | INFO | Epoch 15 train batch 190/450: 3040/7200 mean loss: 0.0016329421196132898 score: 0.9963235294117647
2021-08-08 05:15:16,810 | train | INFO | Epoch 15 train batch 191/450: 3056/7200 mean loss: 0.0013614555355161428 score: 1.0
2021-08-08 05:15:17,617 | train | INFO | Epoch 15 train batch 192/450: 3072/7200 mean loss: 0.0013332042144611478 score: 1.0
2021-08-08 05:15:18,440 | train | INFO | Epoch 15 train batch 193/450: 3088/7200 mean loss: 0.0013091706205159426 score: 1.0
2021-08-08 05:15:19,228 | train | INFO | Epoch 15 train batch 194/450: 3104/7200 mean loss: 0.0014733870048075914 score: 0.996078431372549
2021-08-08 05:15:20,072 | train | INFO | Epoch 15 train batch 195/450: 3120/7200 mean loss: 0.0012348826276138425 score: 1.0
2021-08-08 05:15:20,865 | train | INFO | Epoch 15 train batch 196/450: 3136/7200 mean loss: 0.0014319499023258686 score: 1.0
2021-08-08 05:15:21,726 | train | INFO | Epoch 15 train batch 197/450: 3152/7200 mean loss: 0.0013120768126100302 score: 1.0
2021-08-08 05:15:22,523 | train | INFO | Epoch 15 train batch 198/450: 3168/7200 mean loss: 0.0013259703991934657 score: 1.0
2021-08-08 05:15:23,293 | train | INFO | Epoch 15 train batch 199/450: 3184/7200 mean loss: 0.0014374488964676857 score: 0.8834841628959277
2021-08-08 05:15:24,099 | train | INFO | Epoch 15 train batch 200/450: 3200/7200 mean loss: 0.0016059569315984845 score: 1.0
2021-08-08 05:15:24,896 | train | INFO | Epoch 15 train batch 201/450: 3216/7200 mean loss: 0.0013537415070459247 score: 0.9963235294117647
2021-08-08 05:15:25,697 | train | INFO | Epoch 15 train batch 202/450: 3232/7200 mean loss: 0.001413606689311564 score: 1.0
2021-08-08 05:15:26,595 | train | INFO | Epoch 15 train batch 203/450: 3248/7200 mean loss: 0.001486708759330213 score: 1.0
2021-08-08 05:15:27,486 | train | INFO | Epoch 15 train batch 204/450: 3264/7200 mean loss: 0.001400693436153233 score: 1.0
2021-08-08 05:15:28,301 | train | INFO | Epoch 15 train batch 205/450: 3280/7200 mean loss: 0.0013435260625556111 score: 1.0
2021-08-08 05:15:29,084 | train | INFO | Epoch 15 train batch 206/450: 3296/7200 mean loss: 0.0013737274566665292 score: 1.0
2021-08-08 05:15:29,909 | train | INFO | Epoch 15 train batch 207/450: 3312/7200 mean loss: 0.001388960750773549 score: 1.0
2021-08-08 05:15:30,689 | train | INFO | Epoch 15 train batch 208/450: 3328/7200 mean loss: 0.0012774128699675202 score: 0.9963235294117647
2021-08-08 05:15:31,458 | train | INFO | Epoch 15 train batch 209/450: 3344/7200 mean loss: 0.001243915525265038 score: 1.0
2021-08-08 05:15:32,247 | train | INFO | Epoch 15 train batch 210/450: 3360/7200 mean loss: 0.001391756348311901 score: 0.996078431372549
2021-08-08 05:15:33,014 | train | INFO | Epoch 15 train batch 211/450: 3376/7200 mean loss: 0.00135407829657197 score: 1.0
2021-08-08 05:15:33,809 | train | INFO | Epoch 15 train batch 212/450: 3392/7200 mean loss: 0.0017234438564628363 score: 1.0
2021-08-08 05:15:34,591 | train | INFO | Epoch 15 train batch 213/450: 3408/7200 mean loss: 0.0015517201973125339 score: 1.0
2021-08-08 05:15:35,357 | train | INFO | Epoch 15 train batch 214/450: 3424/7200 mean loss: 0.001521510654129088 score: 1.0
2021-08-08 05:15:36,130 | train | INFO | Epoch 15 train batch 215/450: 3440/7200 mean loss: 0.001536330091767013 score: 1.0
2021-08-08 05:15:36,911 | train | INFO | Epoch 15 train batch 216/450: 3456/7200 mean loss: 0.0016495765885338187 score: 1.0
2021-08-08 05:15:37,689 | train | INFO | Epoch 15 train batch 217/450: 3472/7200 mean loss: 0.0015200237976387143 score: 0.9963235294117647
2021-08-08 05:15:38,494 | train | INFO | Epoch 15 train batch 218/450: 3488/7200 mean loss: 0.001429962576366961 score: 1.0
2021-08-08 05:15:39,313 | train | INFO | Epoch 15 train batch 219/450: 3504/7200 mean loss: 0.0016084358794614673 score: 1.0
2021-08-08 05:15:40,111 | train | INFO | Epoch 15 train batch 220/450: 3520/7200 mean loss: 0.0014703059569001198 score: 1.0
2021-08-08 05:15:40,989 | train | INFO | Epoch 15 train batch 221/450: 3536/7200 mean loss: 0.0017300730105489492 score: 1.0
2021-08-08 05:15:41,781 | train | INFO | Epoch 15 train batch 222/450: 3552/7200 mean loss: 0.0015684505924582481 score: 1.0
2021-08-08 05:15:42,595 | train | INFO | Epoch 15 train batch 223/450: 3568/7200 mean loss: 0.0014654631959274411 score: 1.0
2021-08-08 05:15:43,383 | train | INFO | Epoch 15 train batch 224/450: 3584/7200 mean loss: 0.0014923569979146123 score: 1.0
2021-08-08 05:15:44,185 | train | INFO | Epoch 15 train batch 225/450: 3600/7200 mean loss: 0.0014633001992478967 score: 1.0
2021-08-08 05:15:44,965 | train | INFO | Epoch 15 train batch 226/450: 3616/7200 mean loss: 0.0014826349215582013 score: 1.0
2021-08-08 05:15:45,731 | train | INFO | Epoch 15 train batch 227/450: 3632/7200 mean loss: 0.0015212754951789975 score: 1.0
2021-08-08 05:15:46,532 | train | INFO | Epoch 15 train batch 228/450: 3648/7200 mean loss: 0.0015348837478086352 score: 1.0
2021-08-08 05:15:47,355 | train | INFO | Epoch 15 train batch 229/450: 3664/7200 mean loss: 0.0013768707867711782 score: 1.0
2021-08-08 05:15:48,161 | train | INFO | Epoch 15 train batch 230/450: 3680/7200 mean loss: 0.0012574621941894293 score: 1.0
2021-08-08 05:15:48,947 | train | INFO | Epoch 15 train batch 231/450: 3696/7200 mean loss: 0.0012789194006472826 score: 1.0
2021-08-08 05:15:49,753 | train | INFO | Epoch 15 train batch 232/450: 3712/7200 mean loss: 0.0012987194349989295 score: 1.0
2021-08-08 05:15:50,556 | train | INFO | Epoch 15 train batch 233/450: 3728/7200 mean loss: 0.0012636423343792558 score: 0.9333333333333333
2021-08-08 05:15:51,351 | train | INFO | Epoch 15 train batch 234/450: 3744/7200 mean loss: 0.0014595134416595101 score: 1.0
2021-08-08 05:15:52,128 | train | INFO | Epoch 15 train batch 235/450: 3760/7200 mean loss: 0.0013776152627542615 score: 1.0
2021-08-08 05:15:52,987 | train | INFO | Epoch 15 train batch 236/450: 3776/7200 mean loss: 0.0013300471473485231 score: 1.0
2021-08-08 05:15:53,782 | train | INFO | Epoch 15 train batch 237/450: 3792/7200 mean loss: 0.000994427944533527 score: 1.0
2021-08-08 05:15:54,556 | train | INFO | Epoch 15 train batch 238/450: 3808/7200 mean loss: 0.0013794455444440246 score: 1.0
2021-08-08 05:15:55,322 | train | INFO | Epoch 15 train batch 239/450: 3824/7200 mean loss: 0.001332539482973516 score: 1.0
2021-08-08 05:15:56,137 | train | INFO | Epoch 15 train batch 240/450: 3840/7200 mean loss: 0.001416421146132052 score: 1.0
2021-08-08 05:15:56,914 | train | INFO | Epoch 15 train batch 241/450: 3856/7200 mean loss: 0.0014522467972710729 score: 1.0
2021-08-08 05:15:57,704 | train | INFO | Epoch 15 train batch 242/450: 3872/7200 mean loss: 0.0012354542268440127 score: 1.0
2021-08-08 05:15:58,481 | train | INFO | Epoch 15 train batch 243/450: 3888/7200 mean loss: 0.0014599335845559835 score: 1.0
2021-08-08 05:15:59,260 | train | INFO | Epoch 15 train batch 244/450: 3904/7200 mean loss: 0.0016221506521105766 score: 0.99187675070028
2021-08-08 05:16:00,077 | train | INFO | Epoch 15 train batch 245/450: 3920/7200 mean loss: 0.001381964422762394 score: 1.0
2021-08-08 05:16:00,877 | train | INFO | Epoch 15 train batch 246/450: 3936/7200 mean loss: 0.001291697728447616 score: 1.0
2021-08-08 05:16:01,652 | train | INFO | Epoch 15 train batch 247/450: 3952/7200 mean loss: 0.0012282648822292686 score: 0.9926470588235294
2021-08-08 05:16:02,424 | train | INFO | Epoch 15 train batch 248/450: 3968/7200 mean loss: 0.0017134292284026742 score: 1.0
2021-08-08 05:16:03,222 | train | INFO | Epoch 15 train batch 249/450: 3984/7200 mean loss: 0.0015288138529285789 score: 0.9889705882352942
2021-08-08 05:16:04,054 | train | INFO | Epoch 15 train batch 250/450: 4000/7200 mean loss: 0.0013094022870063782 score: 1.0
2021-08-08 05:16:04,828 | train | INFO | Epoch 15 train batch 251/450: 4016/7200 mean loss: 0.0014812370063737035 score: 1.0
2021-08-08 05:16:05,602 | train | INFO | Epoch 15 train batch 252/450: 4032/7200 mean loss: 0.0016875258879736066 score: 1.0
2021-08-08 05:16:06,381 | train | INFO | Epoch 15 train batch 253/450: 4048/7200 mean loss: 0.0015833914512768388 score: 1.0
2021-08-08 05:16:07,170 | train | INFO | Epoch 15 train batch 254/450: 4064/7200 mean loss: 0.0014539073454216123 score: 0.9852941176470589
2021-08-08 05:16:07,941 | train | INFO | Epoch 15 train batch 255/450: 4080/7200 mean loss: 0.001423453213647008 score: 0.996078431372549
2021-08-08 05:16:08,722 | train | INFO | Epoch 15 train batch 256/450: 4096/7200 mean loss: 0.0016040541231632233 score: 0.9852941176470589
2021-08-08 05:16:09,507 | train | INFO | Epoch 15 train batch 257/450: 4112/7200 mean loss: 0.0015393244102597237 score: 1.0
2021-08-08 05:16:10,283 | train | INFO | Epoch 15 train batch 258/450: 4128/7200 mean loss: 0.001443078857846558 score: 1.0
2021-08-08 05:16:11,067 | train | INFO | Epoch 15 train batch 259/450: 4144/7200 mean loss: 0.0014044239651411772 score: 0.9847689075630254
2021-08-08 05:16:11,842 | train | INFO | Epoch 15 train batch 260/450: 4160/7200 mean loss: 0.0014316934393718839 score: 1.0
2021-08-08 05:16:12,649 | train | INFO | Epoch 15 train batch 261/450: 4176/7200 mean loss: 0.0012968039372935891 score: 1.0
2021-08-08 05:16:13,454 | train | INFO | Epoch 15 train batch 262/450: 4192/7200 mean loss: 0.0012670769356191158 score: 1.0
2021-08-08 05:16:14,254 | train | INFO | Epoch 15 train batch 263/450: 4208/7200 mean loss: 0.0014312817947939038 score: 1.0
2021-08-08 05:16:15,097 | train | INFO | Epoch 15 train batch 264/450: 4224/7200 mean loss: 0.0014145794557407498 score: 1.0
2021-08-08 05:16:15,896 | train | INFO | Epoch 15 train batch 265/450: 4240/7200 mean loss: 0.0014964082511141896 score: 1.0
2021-08-08 05:16:16,695 | train | INFO | Epoch 15 train batch 266/450: 4256/7200 mean loss: 0.001226725522428751 score: 1.0
2021-08-08 05:16:17,505 | train | INFO | Epoch 15 train batch 267/450: 4272/7200 mean loss: 0.0012213012669235468 score: 1.0
2021-08-08 05:16:18,289 | train | INFO | Epoch 15 train batch 268/450: 4288/7200 mean loss: 0.001372721279039979 score: 1.0
2021-08-08 05:16:19,084 | train | INFO | Epoch 15 train batch 269/450: 4304/7200 mean loss: 0.0015530799282714725 score: 1.0
2021-08-08 05:16:19,867 | train | INFO | Epoch 15 train batch 270/450: 4320/7200 mean loss: 0.0015030722133815289 score: 1.0
2021-08-08 05:16:20,658 | train | INFO | Epoch 15 train batch 271/450: 4336/7200 mean loss: 0.0015952858375385404 score: 0.9963235294117647
2021-08-08 05:16:21,436 | train | INFO | Epoch 15 train batch 272/450: 4352/7200 mean loss: 0.0015109013766050339 score: 0.9963235294117647
2021-08-08 05:16:22,299 | train | INFO | Epoch 15 train batch 273/450: 4368/7200 mean loss: 0.0016005708603188396 score: 1.0
2021-08-08 05:16:23,075 | train | INFO | Epoch 15 train batch 274/450: 4384/7200 mean loss: 0.0016301353462040424 score: 0.9926470588235294
2021-08-08 05:16:23,861 | train | INFO | Epoch 15 train batch 275/450: 4400/7200 mean loss: 0.001736230100505054 score: 0.9850490196078432
2021-08-08 05:16:24,749 | train | INFO | Epoch 15 train batch 276/450: 4416/7200 mean loss: 0.0014365874230861664 score: 1.0
2021-08-08 05:16:25,572 | train | INFO | Epoch 15 train batch 277/450: 4432/7200 mean loss: 0.0012947922805324197 score: 1.0
2021-08-08 05:16:26,347 | train | INFO | Epoch 15 train batch 278/450: 4448/7200 mean loss: 0.001200381899252534 score: 1.0
2021-08-08 05:16:27,134 | train | INFO | Epoch 15 train batch 279/450: 4464/7200 mean loss: 0.0014348332770168781 score: 1.0
2021-08-08 05:16:27,909 | train | INFO | Epoch 15 train batch 280/450: 4480/7200 mean loss: 0.001306602149270475 score: 0.9850490196078432
2021-08-08 05:16:28,690 | train | INFO | Epoch 15 train batch 281/450: 4496/7200 mean loss: 0.0012304901611059904 score: 1.0
2021-08-08 05:16:29,488 | train | INFO | Epoch 15 train batch 282/450: 4512/7200 mean loss: 0.0014172622468322515 score: 1.0
2021-08-08 05:16:30,257 | train | INFO | Epoch 15 train batch 283/450: 4528/7200 mean loss: 0.001541297067888081 score: 1.0
2021-08-08 05:16:31,052 | train | INFO | Epoch 15 train batch 284/450: 4544/7200 mean loss: 0.0014871510211378336 score: 1.0
2021-08-08 05:16:31,845 | train | INFO | Epoch 15 train batch 285/450: 4560/7200 mean loss: 0.0015060615260154009 score: 1.0
2021-08-08 05:16:32,709 | train | INFO | Epoch 15 train batch 286/450: 4576/7200 mean loss: 0.0012966705253347754 score: 0.8970588235294118
2021-08-08 05:16:33,485 | train | INFO | Epoch 15 train batch 287/450: 4592/7200 mean loss: 0.0012967173242941499 score: 1.0
2021-08-08 05:16:34,307 | train | INFO | Epoch 15 train batch 288/450: 4608/7200 mean loss: 0.0014293474378064275 score: 1.0
2021-08-08 05:16:35,109 | train | INFO | Epoch 15 train batch 289/450: 4624/7200 mean loss: 0.0014940939145162702 score: 0.9963235294117647
2021-08-08 05:16:35,896 | train | INFO | Epoch 15 train batch 290/450: 4640/7200 mean loss: 0.0013617658987641335 score: 1.0
2021-08-08 05:16:36,686 | train | INFO | Epoch 15 train batch 291/450: 4656/7200 mean loss: 0.001630223821848631 score: 0.9963235294117647
2021-08-08 05:16:37,483 | train | INFO | Epoch 15 train batch 292/450: 4672/7200 mean loss: 0.001546613872051239 score: 1.0
2021-08-08 05:16:38,252 | train | INFO | Epoch 15 train batch 293/450: 4688/7200 mean loss: 0.0015223161317408085 score: 1.0
2021-08-08 05:16:39,029 | train | INFO | Epoch 15 train batch 294/450: 4704/7200 mean loss: 0.0012239876668900251 score: 1.0
2021-08-08 05:16:39,805 | train | INFO | Epoch 15 train batch 295/450: 4720/7200 mean loss: 0.0014019232476130128 score: 0.9884803921568628
2021-08-08 05:16:40,602 | train | INFO | Epoch 15 train batch 296/450: 4736/7200 mean loss: 0.0014420541701838374 score: 1.0
2021-08-08 05:16:41,387 | train | INFO | Epoch 15 train batch 297/450: 4752/7200 mean loss: 0.0015124601777642965 score: 0.9963235294117647
2021-08-08 05:16:42,196 | train | INFO | Epoch 15 train batch 298/450: 4768/7200 mean loss: 0.0014036275679245591 score: 1.0
2021-08-08 05:16:43,022 | train | INFO | Epoch 15 train batch 299/450: 4784/7200 mean loss: 0.0014515361981466413 score: 1.0
2021-08-08 05:16:43,813 | train | INFO | Epoch 15 train batch 300/450: 4800/7200 mean loss: 0.0014318509493023157 score: 1.0
2021-08-08 05:16:44,626 | train | INFO | Epoch 15 train batch 301/450: 4816/7200 mean loss: 0.0014245595084503293 score: 0.9125700280112045
2021-08-08 05:16:45,474 | train | INFO | Epoch 15 train batch 302/450: 4832/7200 mean loss: 0.0013975725742056966 score: 1.0
2021-08-08 05:16:46,273 | train | INFO | Epoch 15 train batch 303/450: 4848/7200 mean loss: 0.0014555722009390593 score: 1.0
2021-08-08 05:16:47,084 | train | INFO | Epoch 15 train batch 304/450: 4864/7200 mean loss: 0.00137747370172292 score: 1.0
2021-08-08 05:16:47,945 | train | INFO | Epoch 15 train batch 305/450: 4880/7200 mean loss: 0.001400914741680026 score: 1.0
2021-08-08 05:16:48,772 | train | INFO | Epoch 15 train batch 306/450: 4896/7200 mean loss: 0.0013688731705769897 score: 1.0
2021-08-08 05:16:49,589 | train | INFO | Epoch 15 train batch 307/450: 4912/7200 mean loss: 0.001566897495649755 score: 1.0
2021-08-08 05:16:50,371 | train | INFO | Epoch 15 train batch 308/450: 4928/7200 mean loss: 0.0014569052727892995 score: 0.9963235294117647
2021-08-08 05:16:51,160 | train | INFO | Epoch 15 train batch 309/450: 4944/7200 mean loss: 0.0016002320917323232 score: 1.0
2021-08-08 05:16:51,977 | train | INFO | Epoch 15 train batch 310/450: 4960/7200 mean loss: 0.001421950408257544 score: 1.0
2021-08-08 05:16:52,771 | train | INFO | Epoch 15 train batch 311/450: 4976/7200 mean loss: 0.0013876527082175016 score: 0.9889705882352942
2021-08-08 05:16:53,554 | train | INFO | Epoch 15 train batch 312/450: 4992/7200 mean loss: 0.0014334904262796044 score: 1.0
2021-08-08 05:16:54,321 | train | INFO | Epoch 15 train batch 313/450: 5008/7200 mean loss: 0.0014523864956572652 score: 1.0
2021-08-08 05:16:55,196 | train | INFO | Epoch 15 train batch 314/450: 5024/7200 mean loss: 0.0014321382623165846 score: 1.0
2021-08-08 05:16:55,981 | train | INFO | Epoch 15 train batch 315/450: 5040/7200 mean loss: 0.0014694285346195102 score: 1.0
2021-08-08 05:16:56,794 | train | INFO | Epoch 15 train batch 316/450: 5056/7200 mean loss: 0.0013119367649778724 score: 0.9774509803921569
2021-08-08 05:16:57,573 | train | INFO | Epoch 15 train batch 317/450: 5072/7200 mean loss: 0.0014340683119371533 score: 1.0
2021-08-08 05:16:58,349 | train | INFO | Epoch 15 train batch 318/450: 5088/7200 mean loss: 0.0014446136774495244 score: 1.0
2021-08-08 05:16:59,155 | train | INFO | Epoch 15 train batch 319/450: 5104/7200 mean loss: 0.0016273502260446548 score: 1.0
2021-08-08 05:16:59,935 | train | INFO | Epoch 15 train batch 320/450: 5120/7200 mean loss: 0.001429512514732778 score: 1.0
2021-08-08 05:17:00,723 | train | INFO | Epoch 15 train batch 321/450: 5136/7200 mean loss: 0.001578961848281324 score: 1.0
2021-08-08 05:17:01,580 | train | INFO | Epoch 15 train batch 322/450: 5152/7200 mean loss: 0.0015918175922706723 score: 0.9772058823529413
2021-08-08 05:17:02,356 | train | INFO | Epoch 15 train batch 323/450: 5168/7200 mean loss: 0.0017764584627002478 score: 0.9698529411764706
2021-08-08 05:17:03,144 | train | INFO | Epoch 15 train batch 324/450: 5184/7200 mean loss: 0.0011756710009649396 score: 1.0
2021-08-08 05:17:03,917 | train | INFO | Epoch 15 train batch 325/450: 5200/7200 mean loss: 0.0013591463211923838 score: 1.0
2021-08-08 05:17:04,699 | train | INFO | Epoch 15 train batch 326/450: 5216/7200 mean loss: 0.0014112101634964347 score: 1.0
2021-08-08 05:17:05,497 | train | INFO | Epoch 15 train batch 327/450: 5232/7200 mean loss: 0.0011077303206548095 score: 1.0
2021-08-08 05:17:06,328 | train | INFO | Epoch 15 train batch 328/450: 5248/7200 mean loss: 0.001319470233283937 score: 1.0
2021-08-08 05:17:07,134 | train | INFO | Epoch 15 train batch 329/450: 5264/7200 mean loss: 0.0012213815934956074 score: 0.9963235294117647
2021-08-08 05:17:07,929 | train | INFO | Epoch 15 train batch 330/450: 5280/7200 mean loss: 0.0014668520307168365 score: 0.9963235294117647
2021-08-08 05:17:08,706 | train | INFO | Epoch 15 train batch 331/450: 5296/7200 mean loss: 0.0012252104934304953 score: 1.0
2021-08-08 05:17:09,512 | train | INFO | Epoch 15 train batch 332/450: 5312/7200 mean loss: 0.001440826221369207 score: 0.9887254901960785
2021-08-08 05:17:10,286 | train | INFO | Epoch 15 train batch 333/450: 5328/7200 mean loss: 0.0012909475481137633 score: 1.0
2021-08-08 05:17:11,057 | train | INFO | Epoch 15 train batch 334/450: 5344/7200 mean loss: 0.0012966726208105683 score: 1.0
2021-08-08 05:17:11,832 | train | INFO | Epoch 15 train batch 335/450: 5360/7200 mean loss: 0.0015169298276305199 score: 1.0
2021-08-08 05:17:12,603 | train | INFO | Epoch 15 train batch 336/450: 5376/7200 mean loss: 0.0014825371326878667 score: 1.0
2021-08-08 05:17:13,378 | train | INFO | Epoch 15 train batch 337/450: 5392/7200 mean loss: 0.001445835456252098 score: 0.996078431372549
2021-08-08 05:17:14,158 | train | INFO | Epoch 15 train batch 338/450: 5408/7200 mean loss: 0.0016194956842809916 score: 1.0
2021-08-08 05:17:14,965 | train | INFO | Epoch 15 train batch 339/450: 5424/7200 mean loss: 0.001339253387413919 score: 1.0
2021-08-08 05:17:15,752 | train | INFO | Epoch 15 train batch 340/450: 5440/7200 mean loss: 0.0012657521292567253 score: 1.0
2021-08-08 05:17:16,587 | train | INFO | Epoch 15 train batch 341/450: 5456/7200 mean loss: 0.0013233626959845424 score: 1.0
2021-08-08 05:17:17,394 | train | INFO | Epoch 15 train batch 342/450: 5472/7200 mean loss: 0.0014920037938281894 score: 1.0
2021-08-08 05:17:18,225 | train | INFO | Epoch 15 train batch 343/450: 5488/7200 mean loss: 0.0014840359799563885 score: 1.0
2021-08-08 05:17:19,020 | train | INFO | Epoch 15 train batch 344/450: 5504/7200 mean loss: 0.0014536407543346286 score: 1.0
2021-08-08 05:17:19,810 | train | INFO | Epoch 15 train batch 345/450: 5520/7200 mean loss: 0.0016827076906338334 score: 0.9700980392156863
2021-08-08 05:17:20,586 | train | INFO | Epoch 15 train batch 346/450: 5536/7200 mean loss: 0.0017394282622262836 score: 1.0
2021-08-08 05:17:21,397 | train | INFO | Epoch 15 train batch 347/450: 5552/7200 mean loss: 0.0014502223348245025 score: 0.9887254901960785
2021-08-08 05:17:22,198 | train | INFO | Epoch 15 train batch 348/450: 5568/7200 mean loss: 0.0013200020184740424 score: 0.9926470588235294
2021-08-08 05:17:22,979 | train | INFO | Epoch 15 train batch 349/450: 5584/7200 mean loss: 0.0014494966017082334 score: 1.0
2021-08-08 05:17:23,785 | train | INFO | Epoch 15 train batch 350/450: 5600/7200 mean loss: 0.0014297766610980034 score: 1.0
2021-08-08 05:17:24,578 | train | INFO | Epoch 15 train batch 351/450: 5616/7200 mean loss: 0.0016259591793641448 score: 1.0
2021-08-08 05:17:25,358 | train | INFO | Epoch 15 train batch 352/450: 5632/7200 mean loss: 0.0015860999701544642 score: 1.0
2021-08-08 05:17:26,132 | train | INFO | Epoch 15 train batch 353/450: 5648/7200 mean loss: 0.001400342327542603 score: 1.0
2021-08-08 05:17:26,952 | train | INFO | Epoch 15 train batch 354/450: 5664/7200 mean loss: 0.0012923069298267365 score: 1.0
2021-08-08 05:17:27,728 | train | INFO | Epoch 15 train batch 355/450: 5680/7200 mean loss: 0.0013598480727523565 score: 1.0
2021-08-08 05:17:28,518 | train | INFO | Epoch 15 train batch 356/450: 5696/7200 mean loss: 0.0015156229492276907 score: 1.0
2021-08-08 05:17:29,344 | train | INFO | Epoch 15 train batch 357/450: 5712/7200 mean loss: 0.0013897124445065856 score: 0.9850490196078432
2021-08-08 05:17:30,148 | train | INFO | Epoch 15 train batch 358/450: 5728/7200 mean loss: 0.0012269545113667846 score: 0.9847689075630252
2021-08-08 05:17:30,921 | train | INFO | Epoch 15 train batch 359/450: 5744/7200 mean loss: 0.0012681374792009592 score: 1.0
2021-08-08 05:17:31,706 | train | INFO | Epoch 15 train batch 360/450: 5760/7200 mean loss: 0.0014899398665875196 score: 1.0
2021-08-08 05:17:32,479 | train | INFO | Epoch 15 train batch 361/450: 5776/7200 mean loss: 0.0013483355287462473 score: 1.0
2021-08-08 05:17:33,274 | train | INFO | Epoch 15 train batch 362/450: 5792/7200 mean loss: 0.0015396997332572937 score: 1.0
2021-08-08 05:17:34,044 | train | INFO | Epoch 15 train batch 363/450: 5808/7200 mean loss: 0.0013520553475245833 score: 1.0
2021-08-08 05:17:34,840 | train | INFO | Epoch 15 train batch 364/450: 5824/7200 mean loss: 0.0014006057754158974 score: 1.0
2021-08-08 05:17:35,621 | train | INFO | Epoch 15 train batch 365/450: 5840/7200 mean loss: 0.001606882899068296 score: 1.0
2021-08-08 05:17:36,414 | train | INFO | Epoch 15 train batch 366/450: 5856/7200 mean loss: 0.0014634166145697236 score: 1.0
2021-08-08 05:17:37,231 | train | INFO | Epoch 15 train batch 367/450: 5872/7200 mean loss: 0.0013545053079724312 score: 0.6752450980392157
2021-08-08 05:17:38,031 | train | INFO | Epoch 15 train batch 368/450: 5888/7200 mean loss: 0.0015662552323192358 score: 1.0
2021-08-08 05:17:38,868 | train | INFO | Epoch 15 train batch 369/450: 5904/7200 mean loss: 0.0014099185355007648 score: 1.0
2021-08-08 05:17:39,684 | train | INFO | Epoch 15 train batch 370/450: 5920/7200 mean loss: 0.0015291549498215318 score: 1.0
2021-08-08 05:17:40,477 | train | INFO | Epoch 15 train batch 371/450: 5936/7200 mean loss: 0.001418165978975594 score: 1.0
2021-08-08 05:17:41,248 | train | INFO | Epoch 15 train batch 372/450: 5952/7200 mean loss: 0.0012078823056071997 score: 1.0
2021-08-08 05:17:42,021 | train | INFO | Epoch 15 train batch 373/450: 5968/7200 mean loss: 0.0014858671929687262 score: 0.9884803921568628
2021-08-08 05:17:42,838 | train | INFO | Epoch 15 train batch 374/450: 5984/7200 mean loss: 0.0013844618806615472 score: 1.0
2021-08-08 05:17:43,633 | train | INFO | Epoch 15 train batch 375/450: 6000/7200 mean loss: 0.0013910367852076888 score: 1.0
2021-08-08 05:17:44,500 | train | INFO | Epoch 15 train batch 376/450: 6016/7200 mean loss: 0.0012394448276609182 score: 0.9963235294117647
2021-08-08 05:17:45,320 | train | INFO | Epoch 15 train batch 377/450: 6032/7200 mean loss: 0.001316106878221035 score: 1.0
2021-08-08 05:17:46,141 | train | INFO | Epoch 15 train batch 378/450: 6048/7200 mean loss: 0.0012600162299349904 score: 0.9850490196078432
2021-08-08 05:17:47,001 | train | INFO | Epoch 15 train batch 379/450: 6064/7200 mean loss: 0.0014167451299726963 score: 1.0
2021-08-08 05:17:47,832 | train | INFO | Epoch 15 train batch 380/450: 6080/7200 mean loss: 0.0014584623277187347 score: 1.0
2021-08-08 05:17:48,604 | train | INFO | Epoch 15 train batch 381/450: 6096/7200 mean loss: 0.0013937110779806972 score: 1.0
2021-08-08 05:17:49,392 | train | INFO | Epoch 15 train batch 382/450: 6112/7200 mean loss: 0.0013711757492274046 score: 1.0
2021-08-08 05:17:50,187 | train | INFO | Epoch 15 train batch 383/450: 6128/7200 mean loss: 0.0016447880771011114 score: 1.0
2021-08-08 05:17:51,002 | train | INFO | Epoch 15 train batch 384/450: 6144/7200 mean loss: 0.001670671976171434 score: 1.0
2021-08-08 05:17:51,778 | train | INFO | Epoch 15 train batch 385/450: 6160/7200 mean loss: 0.0014592553488910198 score: 1.0
2021-08-08 05:17:52,555 | train | INFO | Epoch 15 train batch 386/450: 6176/7200 mean loss: 0.0016595018096268177 score: 1.0
2021-08-08 05:17:53,423 | train | INFO | Epoch 15 train batch 387/450: 6192/7200 mean loss: 0.0013794464757665992 score: 1.0
2021-08-08 05:17:54,231 | train | INFO | Epoch 15 train batch 388/450: 6208/7200 mean loss: 0.0015751005848869681 score: 1.0
2021-08-08 05:17:55,016 | train | INFO | Epoch 15 train batch 389/450: 6224/7200 mean loss: 0.0015328375156968832 score: 1.0
2021-08-08 05:17:55,813 | train | INFO | Epoch 15 train batch 390/450: 6240/7200 mean loss: 0.001292482134886086 score: 1.0
2021-08-08 05:17:56,590 | train | INFO | Epoch 15 train batch 391/450: 6256/7200 mean loss: 0.0012071981327608228 score: 0.8022247360482655
2021-08-08 05:17:57,407 | train | INFO | Epoch 15 train batch 392/450: 6272/7200 mean loss: 0.0013079594355076551 score: 1.0
2021-08-08 05:17:58,233 | train | INFO | Epoch 15 train batch 393/450: 6288/7200 mean loss: 0.0014570393832400441 score: 1.0
2021-08-08 05:17:59,019 | train | INFO | Epoch 15 train batch 394/450: 6304/7200 mean loss: 0.0013308408670127392 score: 1.0
2021-08-08 05:17:59,841 | train | INFO | Epoch 15 train batch 395/450: 6320/7200 mean loss: 0.0013196113286539912 score: 0.9963235294117647
2021-08-08 05:18:00,624 | train | INFO | Epoch 15 train batch 396/450: 6336/7200 mean loss: 0.0014081076951697469 score: 1.0
2021-08-08 05:18:01,484 | train | INFO | Epoch 15 train batch 397/450: 6352/7200 mean loss: 0.0014818586641922593 score: 1.0
2021-08-08 05:18:02,278 | train | INFO | Epoch 15 train batch 398/450: 6368/7200 mean loss: 0.00160555902402848 score: 0.9963235294117647
2021-08-08 05:18:03,067 | train | INFO | Epoch 15 train batch 399/450: 6384/7200 mean loss: 0.0013179165543988347 score: 1.0
2021-08-08 05:18:03,885 | train | INFO | Epoch 15 train batch 400/450: 6400/7200 mean loss: 0.001480962848290801 score: 1.0
2021-08-08 05:18:04,674 | train | INFO | Epoch 15 train batch 401/450: 6416/7200 mean loss: 0.001545832841657102 score: 1.0
2021-08-08 05:18:05,456 | train | INFO | Epoch 15 train batch 402/450: 6432/7200 mean loss: 0.0014325820375233889 score: 1.0
2021-08-08 05:18:06,241 | train | INFO | Epoch 15 train batch 403/450: 6448/7200 mean loss: 0.0015171972336247563 score: 0.9963235294117647
2021-08-08 05:18:07,022 | train | INFO | Epoch 15 train batch 404/450: 6464/7200 mean loss: 0.0012778291711583734 score: 0.9850490196078432
2021-08-08 05:18:07,831 | train | INFO | Epoch 15 train batch 405/450: 6480/7200 mean loss: 0.0011404270771890879 score: 1.0
2021-08-08 05:18:08,670 | train | INFO | Epoch 15 train batch 406/450: 6496/7200 mean loss: 0.0014378039631992579 score: 1.0
2021-08-08 05:18:09,478 | train | INFO | Epoch 15 train batch 407/450: 6512/7200 mean loss: 0.001363422954455018 score: 1.0
2021-08-08 05:18:10,280 | train | INFO | Epoch 15 train batch 408/450: 6528/7200 mean loss: 0.0016427310183644295 score: 1.0
2021-08-08 05:18:11,081 | train | INFO | Epoch 15 train batch 409/450: 6544/7200 mean loss: 0.0012375375954434276 score: 0.9852941176470589
2021-08-08 05:18:11,882 | train | INFO | Epoch 15 train batch 410/450: 6560/7200 mean loss: 0.0013538900529965758 score: 1.0
2021-08-08 05:18:12,688 | train | INFO | Epoch 15 train batch 411/450: 6576/7200 mean loss: 0.0013468796387314796 score: 1.0
2021-08-08 05:18:13,469 | train | INFO | Epoch 15 train batch 412/450: 6592/7200 mean loss: 0.001180299324914813 score: 0.995798319327731
2021-08-08 05:18:14,268 | train | INFO | Epoch 15 train batch 413/450: 6608/7200 mean loss: 0.0012234816094860435 score: 1.0
2021-08-08 05:18:15,043 | train | INFO | Epoch 15 train batch 414/450: 6624/7200 mean loss: 0.0014090304030105472 score: 1.0
2021-08-08 05:18:15,819 | train | INFO | Epoch 15 train batch 415/450: 6640/7200 mean loss: 0.0013894130242988467 score: 1.0
2021-08-08 05:18:16,636 | train | INFO | Epoch 15 train batch 416/450: 6656/7200 mean loss: 0.0014778950717300177 score: 1.0
2021-08-08 05:18:17,446 | train | INFO | Epoch 15 train batch 417/450: 6672/7200 mean loss: 0.001527153654024005 score: 1.0
2021-08-08 05:18:18,227 | train | INFO | Epoch 15 train batch 418/450: 6688/7200 mean loss: 0.0012246676487848163 score: 1.0
2021-08-08 05:18:19,035 | train | INFO | Epoch 15 train batch 419/450: 6704/7200 mean loss: 0.0014609239296987653 score: 1.0
2021-08-08 05:18:19,827 | train | INFO | Epoch 15 train batch 420/450: 6720/7200 mean loss: 0.001359610236249864 score: 0.9926470588235294
2021-08-08 05:18:20,597 | train | INFO | Epoch 15 train batch 421/450: 6736/7200 mean loss: 0.0013700943673029542 score: 0.9926470588235294
2021-08-08 05:18:21,375 | train | INFO | Epoch 15 train batch 422/450: 6752/7200 mean loss: 0.0013965334510430694 score: 0.9889705882352942
2021-08-08 05:18:22,171 | train | INFO | Epoch 15 train batch 423/450: 6768/7200 mean loss: 0.0014574344968423247 score: 1.0
2021-08-08 05:18:22,949 | train | INFO | Epoch 15 train batch 424/450: 6784/7200 mean loss: 0.0012842650758102536 score: 1.0
2021-08-08 05:18:23,769 | train | INFO | Epoch 15 train batch 425/450: 6800/7200 mean loss: 0.0014562740689143538 score: 1.0
2021-08-08 05:18:24,553 | train | INFO | Epoch 15 train batch 426/450: 6816/7200 mean loss: 0.001517213648185134 score: 0.9887254901960785
2021-08-08 05:18:25,354 | train | INFO | Epoch 15 train batch 427/450: 6832/7200 mean loss: 0.00140653015114367 score: 1.0
2021-08-08 05:18:26,181 | train | INFO | Epoch 15 train batch 428/450: 6848/7200 mean loss: 0.0014494109200313687 score: 0.9889705882352942
2021-08-08 05:18:26,957 | train | INFO | Epoch 15 train batch 429/450: 6864/7200 mean loss: 0.0015552217373624444 score: 1.0
2021-08-08 05:18:27,755 | train | INFO | Epoch 15 train batch 430/450: 6880/7200 mean loss: 0.0015464226016774774 score: 1.0
2021-08-08 05:18:28,565 | train | INFO | Epoch 15 train batch 431/450: 6896/7200 mean loss: 0.0014654849655926228 score: 0.9887254901960785
2021-08-08 05:18:29,345 | train | INFO | Epoch 15 train batch 432/450: 6912/7200 mean loss: 0.0014637191779911518 score: 1.0
2021-08-08 05:18:30,161 | train | INFO | Epoch 15 train batch 433/450: 6928/7200 mean loss: 0.001499414094723761 score: 1.0
2021-08-08 05:18:30,934 | train | INFO | Epoch 15 train batch 434/450: 6944/7200 mean loss: 0.0013565955450758338 score: 1.0
2021-08-08 05:18:31,739 | train | INFO | Epoch 15 train batch 435/450: 6960/7200 mean loss: 0.0014564159791916609 score: 1.0
2021-08-08 05:18:32,561 | train | INFO | Epoch 15 train batch 436/450: 6976/7200 mean loss: 0.001383199472911656 score: 0.9811274509803922
2021-08-08 05:18:33,380 | train | INFO | Epoch 15 train batch 437/450: 6992/7200 mean loss: 0.001473027397878468 score: 0.996078431372549
2021-08-08 05:18:34,152 | train | INFO | Epoch 15 train batch 438/450: 7008/7200 mean loss: 0.0014132953947409987 score: 0.9963235294117647
2021-08-08 05:18:34,927 | train | INFO | Epoch 15 train batch 439/450: 7024/7200 mean loss: 0.0013338190037757158 score: 1.0
2021-08-08 05:18:35,708 | train | INFO | Epoch 15 train batch 440/450: 7040/7200 mean loss: 0.0013808516087010503 score: 1.0
2021-08-08 05:18:36,486 | train | INFO | Epoch 15 train batch 441/450: 7056/7200 mean loss: 0.0016993290046229959 score: 0.9884803921568628
2021-08-08 05:18:37,267 | train | INFO | Epoch 15 train batch 442/450: 7072/7200 mean loss: 0.0014968886971473694 score: 1.0
2021-08-08 05:18:38,044 | train | INFO | Epoch 15 train batch 443/450: 7088/7200 mean loss: 0.0015122807817533612 score: 1.0
2021-08-08 05:18:38,895 | train | INFO | Epoch 15 train batch 444/450: 7104/7200 mean loss: 0.0015760490205138922 score: 0.9963235294117647
2021-08-08 05:18:39,667 | train | INFO | Epoch 15 train batch 445/450: 7120/7200 mean loss: 0.0013658426469191909 score: 1.0
2021-08-08 05:18:40,444 | train | INFO | Epoch 15 train batch 446/450: 7136/7200 mean loss: 0.00136584194842726 score: 1.0
2021-08-08 05:18:41,264 | train | INFO | Epoch 15 train batch 447/450: 7152/7200 mean loss: 0.0013473860453814268 score: 1.0
2021-08-08 05:18:42,042 | train | INFO | Epoch 15 train batch 448/450: 7168/7200 mean loss: 0.0012785496655851603 score: 1.0
2021-08-08 05:18:42,826 | train | INFO | Epoch 15 train batch 449/450: 7184/7200 mean loss: 0.001440984196960926 score: 1.0
2021-08-08 05:18:42,985 | train | INFO | Epoch 15, Train, Mean loss: 0.022770517836842273, Score: 0.9950607567813451
2021-08-08 05:18:44,471 | train | INFO | Epoch 15 validation batch 0/113: 0/1800 mean loss: 0.0009747638250701129 score: 0.996078431372549
2021-08-08 05:18:44,764 | train | INFO | Epoch 15 validation batch 1/113: 16/1800 mean loss: 0.001043207012116909 score: 0.9963235294117647
2021-08-08 05:18:44,996 | train | INFO | Epoch 15 validation batch 2/113: 32/1800 mean loss: 0.0013169992016628385 score: 1.0
2021-08-08 05:18:45,238 | train | INFO | Epoch 15 validation batch 3/113: 48/1800 mean loss: 0.0011026350548490882 score: 1.0
2021-08-08 05:18:45,475 | train | INFO | Epoch 15 validation batch 4/113: 64/1800 mean loss: 0.0009824881562963128 score: 1.0
2021-08-08 05:18:45,729 | train | INFO | Epoch 15 validation batch 5/113: 80/1800 mean loss: 0.0009958753362298012 score: 1.0
2021-08-08 05:18:45,962 | train | INFO | Epoch 15 validation batch 6/113: 96/1800 mean loss: 0.0009310845052823424 score: 1.0
2021-08-08 05:18:46,231 | train | INFO | Epoch 15 validation batch 7/113: 112/1800 mean loss: 0.0010935832979157567 score: 1.0
2021-08-08 05:18:46,492 | train | INFO | Epoch 15 validation batch 8/113: 128/1800 mean loss: 0.0010389593662694097 score: 1.0
2021-08-08 05:18:46,725 | train | INFO | Epoch 15 validation batch 9/113: 144/1800 mean loss: 0.0010396548314020038 score: 1.0
2021-08-08 05:18:46,958 | train | INFO | Epoch 15 validation batch 10/113: 160/1800 mean loss: 0.0011125050950795412 score: 0.9852941176470589
2021-08-08 05:18:47,206 | train | INFO | Epoch 15 validation batch 11/113: 176/1800 mean loss: 0.0011190454242751002 score: 0.9963235294117647
2021-08-08 05:18:47,458 | train | INFO | Epoch 15 validation batch 12/113: 192/1800 mean loss: 0.0010350191732868552 score: 1.0
2021-08-08 05:18:47,696 | train | INFO | Epoch 15 validation batch 13/113: 208/1800 mean loss: 0.0009351820917800069 score: 1.0
2021-08-08 05:18:47,933 | train | INFO | Epoch 15 validation batch 14/113: 224/1800 mean loss: 0.0009097664151340723 score: 1.0
2021-08-08 05:18:48,185 | train | INFO | Epoch 15 validation batch 15/113: 240/1800 mean loss: 0.0010347674833610654 score: 1.0
2021-08-08 05:18:48,432 | train | INFO | Epoch 15 validation batch 16/113: 256/1800 mean loss: 0.0010084165260195732 score: 1.0
2021-08-08 05:18:48,722 | train | INFO | Epoch 15 validation batch 17/113: 272/1800 mean loss: 0.0011528573231771588 score: 1.0
2021-08-08 05:18:48,955 | train | INFO | Epoch 15 validation batch 18/113: 288/1800 mean loss: 0.0008256621076725423 score: 1.0
2021-08-08 05:18:49,186 | train | INFO | Epoch 15 validation batch 19/113: 304/1800 mean loss: 0.0010292456718161702 score: 1.0
2021-08-08 05:18:49,418 | train | INFO | Epoch 15 validation batch 20/113: 320/1800 mean loss: 0.0011205000337213278 score: 0.9926470588235294
2021-08-08 05:18:49,650 | train | INFO | Epoch 15 validation batch 21/113: 336/1800 mean loss: 0.0009976673172786832 score: 1.0
2021-08-08 05:18:49,881 | train | INFO | Epoch 15 validation batch 22/113: 352/1800 mean loss: 0.0009905567858368158 score: 1.0
2021-08-08 05:18:50,131 | train | INFO | Epoch 15 validation batch 23/113: 368/1800 mean loss: 0.0009555498836562037 score: 1.0
2021-08-08 05:18:50,365 | train | INFO | Epoch 15 validation batch 24/113: 384/1800 mean loss: 0.0010153157636523247 score: 1.0
2021-08-08 05:18:50,597 | train | INFO | Epoch 15 validation batch 25/113: 400/1800 mean loss: 0.001100942026823759 score: 1.0
2021-08-08 05:18:50,828 | train | INFO | Epoch 15 validation batch 26/113: 416/1800 mean loss: 0.0008417746867053211 score: 1.0
2021-08-08 05:18:51,060 | train | INFO | Epoch 15 validation batch 27/113: 432/1800 mean loss: 0.0010995955672115088 score: 1.0
2021-08-08 05:18:51,291 | train | INFO | Epoch 15 validation batch 28/113: 448/1800 mean loss: 0.0010088684502989054 score: 1.0
2021-08-08 05:18:51,523 | train | INFO | Epoch 15 validation batch 29/113: 464/1800 mean loss: 0.0010218319948762655 score: 1.0
2021-08-08 05:18:51,756 | train | INFO | Epoch 15 validation batch 30/113: 480/1800 mean loss: 0.0010263180593028665 score: 1.0
2021-08-08 05:18:51,987 | train | INFO | Epoch 15 validation batch 31/113: 496/1800 mean loss: 0.0009996653534471989 score: 1.0
2021-08-08 05:18:52,218 | train | INFO | Epoch 15 validation batch 32/113: 512/1800 mean loss: 0.0010447027161717415 score: 1.0
2021-08-08 05:18:52,449 | train | INFO | Epoch 15 validation batch 33/113: 528/1800 mean loss: 0.0008756800089031458 score: 1.0
2021-08-08 05:18:52,681 | train | INFO | Epoch 15 validation batch 34/113: 544/1800 mean loss: 0.0007704027811996639 score: 1.0
2021-08-08 05:18:52,913 | train | INFO | Epoch 15 validation batch 35/113: 560/1800 mean loss: 0.0012188592227175832 score: 1.0
2021-08-08 05:18:53,148 | train | INFO | Epoch 15 validation batch 36/113: 576/1800 mean loss: 0.0011254975106567144 score: 0.9406862745098039
2021-08-08 05:18:53,380 | train | INFO | Epoch 15 validation batch 37/113: 592/1800 mean loss: 0.0008233765256591141 score: 1.0
2021-08-08 05:18:53,611 | train | INFO | Epoch 15 validation batch 38/113: 608/1800 mean loss: 0.0010458630276843905 score: 1.0
2021-08-08 05:18:53,841 | train | INFO | Epoch 15 validation batch 39/113: 624/1800 mean loss: 0.000990086467936635 score: 1.0
2021-08-08 05:18:54,074 | train | INFO | Epoch 15 validation batch 40/113: 640/1800 mean loss: 0.0010181081015616655 score: 1.0
2021-08-08 05:18:54,306 | train | INFO | Epoch 15 validation batch 41/113: 656/1800 mean loss: 0.000951104739215225 score: 1.0
2021-08-08 05:18:54,537 | train | INFO | Epoch 15 validation batch 42/113: 672/1800 mean loss: 0.000962308025918901 score: 0.9963235294117647
2021-08-08 05:18:54,768 | train | INFO | Epoch 15 validation batch 43/113: 688/1800 mean loss: 0.0009711423190310597 score: 1.0
2021-08-08 05:18:55,000 | train | INFO | Epoch 15 validation batch 44/113: 704/1800 mean loss: 0.0012302370741963387 score: 0.9742647058823529
2021-08-08 05:18:55,234 | train | INFO | Epoch 15 validation batch 45/113: 720/1800 mean loss: 0.001068081590346992 score: 1.0
2021-08-08 05:18:55,465 | train | INFO | Epoch 15 validation batch 46/113: 736/1800 mean loss: 0.0010119011858478189 score: 0.9926470588235294
2021-08-08 05:18:55,705 | train | INFO | Epoch 15 validation batch 47/113: 752/1800 mean loss: 0.0009514499688521028 score: 1.0
2021-08-08 05:18:55,937 | train | INFO | Epoch 15 validation batch 48/113: 768/1800 mean loss: 0.0009545473731122911 score: 1.0
2021-08-08 05:18:56,168 | train | INFO | Epoch 15 validation batch 49/113: 784/1800 mean loss: 0.0010361301247030497 score: 1.0
2021-08-08 05:18:56,399 | train | INFO | Epoch 15 validation batch 50/113: 800/1800 mean loss: 0.0009002741426229477 score: 1.0
2021-08-08 05:18:56,632 | train | INFO | Epoch 15 validation batch 51/113: 816/1800 mean loss: 0.001088205841369927 score: 0.9852941176470589
2021-08-08 05:18:56,864 | train | INFO | Epoch 15 validation batch 52/113: 832/1800 mean loss: 0.0009881258010864258 score: 1.0
2021-08-08 05:18:57,096 | train | INFO | Epoch 15 validation batch 53/113: 848/1800 mean loss: 0.0009326415602117777 score: 1.0
2021-08-08 05:18:57,336 | train | INFO | Epoch 15 validation batch 54/113: 864/1800 mean loss: 0.0009670439758338034 score: 1.0
2021-08-08 05:18:57,587 | train | INFO | Epoch 15 validation batch 55/113: 880/1800 mean loss: 0.0010629930766299367 score: 1.0
2021-08-08 05:18:57,818 | train | INFO | Epoch 15 validation batch 56/113: 896/1800 mean loss: 0.001049531507305801 score: 1.0
2021-08-08 05:18:58,051 | train | INFO | Epoch 15 validation batch 57/113: 912/1800 mean loss: 0.0010627759620547295 score: 1.0
2021-08-08 05:18:58,285 | train | INFO | Epoch 15 validation batch 58/113: 928/1800 mean loss: 0.001081965514458716 score: 0.9852941176470589
2021-08-08 05:18:58,518 | train | INFO | Epoch 15 validation batch 59/113: 944/1800 mean loss: 0.0009723177645355463 score: 1.0
2021-08-08 05:18:58,757 | train | INFO | Epoch 15 validation batch 60/113: 960/1800 mean loss: 0.0008448129519820213 score: 1.0
2021-08-08 05:18:58,990 | train | INFO | Epoch 15 validation batch 61/113: 976/1800 mean loss: 0.0009159676847048104 score: 1.0
2021-08-08 05:18:59,222 | train | INFO | Epoch 15 validation batch 62/113: 992/1800 mean loss: 0.0009761594119481742 score: 1.0
2021-08-08 05:18:59,453 | train | INFO | Epoch 15 validation batch 63/113: 1008/1800 mean loss: 0.0009338423842564225 score: 1.0
2021-08-08 05:18:59,686 | train | INFO | Epoch 15 validation batch 64/113: 1024/1800 mean loss: 0.0009729606099426746 score: 1.0
2021-08-08 05:18:59,919 | train | INFO | Epoch 15 validation batch 65/113: 1040/1800 mean loss: 0.0010897258762270212 score: 1.0
2021-08-08 05:19:00,155 | train | INFO | Epoch 15 validation batch 66/113: 1056/1800 mean loss: 0.001039450871758163 score: 1.0
2021-08-08 05:19:00,387 | train | INFO | Epoch 15 validation batch 67/113: 1072/1800 mean loss: 0.0011435672640800476 score: 1.0
2021-08-08 05:19:00,620 | train | INFO | Epoch 15 validation batch 68/113: 1088/1800 mean loss: 0.000867289665620774 score: 1.0
2021-08-08 05:19:00,853 | train | INFO | Epoch 15 validation batch 69/113: 1104/1800 mean loss: 0.0009457318810746074 score: 1.0
2021-08-08 05:19:01,087 | train | INFO | Epoch 15 validation batch 70/113: 1120/1800 mean loss: 0.001187436981126666 score: 0.9963235294117647
2021-08-08 05:19:01,316 | train | INFO | Epoch 15 validation batch 71/113: 1136/1800 mean loss: 0.0009267639252357185 score: 1.0
2021-08-08 05:19:01,548 | train | INFO | Epoch 15 validation batch 72/113: 1152/1800 mean loss: 0.0009541800827719271 score: 1.0
2021-08-08 05:19:01,779 | train | INFO | Epoch 15 validation batch 73/113: 1168/1800 mean loss: 0.001199679565615952 score: 1.0
2021-08-08 05:19:02,011 | train | INFO | Epoch 15 validation batch 74/113: 1184/1800 mean loss: 0.0011022521648555994 score: 1.0
2021-08-08 05:19:02,244 | train | INFO | Epoch 15 validation batch 75/113: 1200/1800 mean loss: 0.0009474242688156664 score: 1.0
2021-08-08 05:19:02,474 | train | INFO | Epoch 15 validation batch 76/113: 1216/1800 mean loss: 0.0008699646568857133 score: 1.0
2021-08-08 05:19:02,762 | train | INFO | Epoch 15 validation batch 77/113: 1232/1800 mean loss: 0.0008297621970996261 score: 1.0
2021-08-08 05:19:03,021 | train | INFO | Epoch 15 validation batch 78/113: 1248/1800 mean loss: 0.0009539519669488072 score: 0.9852941176470589
2021-08-08 05:19:03,252 | train | INFO | Epoch 15 validation batch 79/113: 1264/1800 mean loss: 0.0011477480875328183 score: 0.9921568627450981
2021-08-08 05:19:03,524 | train | INFO | Epoch 15 validation batch 80/113: 1280/1800 mean loss: 0.0011781930224969983 score: 1.0
2021-08-08 05:19:03,781 | train | INFO | Epoch 15 validation batch 81/113: 1296/1800 mean loss: 0.0009963198099285364 score: 1.0
2021-08-08 05:19:04,015 | train | INFO | Epoch 15 validation batch 82/113: 1312/1800 mean loss: 0.0010253983782604337 score: 1.0
2021-08-08 05:19:04,265 | train | INFO | Epoch 15 validation batch 83/113: 1328/1800 mean loss: 0.0011756321182474494 score: 1.0
2021-08-08 05:19:04,525 | train | INFO | Epoch 15 validation batch 84/113: 1344/1800 mean loss: 0.0011441317619755864 score: 0.9889705882352942
2021-08-08 05:19:04,761 | train | INFO | Epoch 15 validation batch 85/113: 1360/1800 mean loss: 0.0010317383566871285 score: 1.0
2021-08-08 05:19:04,996 | train | INFO | Epoch 15 validation batch 86/113: 1376/1800 mean loss: 0.0012744744308292866 score: 1.0
2021-08-08 05:19:05,250 | train | INFO | Epoch 15 validation batch 87/113: 1392/1800 mean loss: 0.0011811020085588098 score: 1.0
2021-08-08 05:19:05,504 | train | INFO | Epoch 15 validation batch 88/113: 1408/1800 mean loss: 0.0009954035049304366 score: 1.0
2021-08-08 05:19:05,762 | train | INFO | Epoch 15 validation batch 89/113: 1424/1800 mean loss: 0.0008566387114115059 score: 1.0
2021-08-08 05:19:06,031 | train | INFO | Epoch 15 validation batch 90/113: 1440/1800 mean loss: 0.0009489990770816803 score: 1.0
2021-08-08 05:19:06,273 | train | INFO | Epoch 15 validation batch 91/113: 1456/1800 mean loss: 0.00131713948212564 score: 1.0
2021-08-08 05:19:06,533 | train | INFO | Epoch 15 validation batch 92/113: 1472/1800 mean loss: 0.000955372815951705 score: 1.0
2021-08-08 05:19:06,791 | train | INFO | Epoch 15 validation batch 93/113: 1488/1800 mean loss: 0.0010319271823391318 score: 1.0
2021-08-08 05:19:07,033 | train | INFO | Epoch 15 validation batch 94/113: 1504/1800 mean loss: 0.0010159224038943648 score: 1.0
2021-08-08 05:19:07,294 | train | INFO | Epoch 15 validation batch 95/113: 1520/1800 mean loss: 0.0010693797376006842 score: 1.0
2021-08-08 05:19:07,554 | train | INFO | Epoch 15 validation batch 96/113: 1536/1800 mean loss: 0.0011560849379748106 score: 1.0
2021-08-08 05:19:07,788 | train | INFO | Epoch 15 validation batch 97/113: 1552/1800 mean loss: 0.0010574468178674579 score: 1.0
2021-08-08 05:19:08,031 | train | INFO | Epoch 15 validation batch 98/113: 1568/1800 mean loss: 0.0009863824816420674 score: 1.0
2021-08-08 05:19:08,288 | train | INFO | Epoch 15 validation batch 99/113: 1584/1800 mean loss: 0.0009853583760559559 score: 1.0
2021-08-08 05:19:08,519 | train | INFO | Epoch 15 validation batch 100/113: 1600/1800 mean loss: 0.001167752780020237 score: 1.0
2021-08-08 05:19:08,750 | train | INFO | Epoch 15 validation batch 101/113: 1616/1800 mean loss: 0.0009809366893023252 score: 1.0
2021-08-08 05:19:08,981 | train | INFO | Epoch 15 validation batch 102/113: 1632/1800 mean loss: 0.0009135663276538253 score: 1.0
2021-08-08 05:19:09,211 | train | INFO | Epoch 15 validation batch 103/113: 1648/1800 mean loss: 0.00096144835697487 score: 1.0
2021-08-08 05:19:09,443 | train | INFO | Epoch 15 validation batch 104/113: 1664/1800 mean loss: 0.0011116561945527792 score: 1.0
2021-08-08 05:19:09,674 | train | INFO | Epoch 15 validation batch 105/113: 1680/1800 mean loss: 0.001038535381667316 score: 1.0
2021-08-08 05:19:09,907 | train | INFO | Epoch 15 validation batch 106/113: 1696/1800 mean loss: 0.0010542570380493999 score: 1.0
2021-08-08 05:19:10,139 | train | INFO | Epoch 15 validation batch 107/113: 1712/1800 mean loss: 0.0012870352948084474 score: 1.0
2021-08-08 05:19:10,372 | train | INFO | Epoch 15 validation batch 108/113: 1728/1800 mean loss: 0.0012581057380884886 score: 1.0
2021-08-08 05:19:10,604 | train | INFO | Epoch 15 validation batch 109/113: 1744/1800 mean loss: 0.00113943952601403 score: 1.0
2021-08-08 05:19:10,837 | train | INFO | Epoch 15 validation batch 110/113: 1760/1800 mean loss: 0.0009228375856764615 score: 1.0
2021-08-08 05:19:11,069 | train | INFO | Epoch 15 validation batch 111/113: 1776/1800 mean loss: 0.0009637607727199793 score: 1.0
2021-08-08 05:19:11,235 | train | INFO | Epoch 15 validation batch 112/113: 1792/1800 mean loss: 0.0009321820107288659 score: 1.0
2021-08-08 05:19:11,401 | train | INFO | Epoch 15, Validation, Mean loss: 0.016421789641335473, Score: 0.9982647926427207
2021-08-08 05:19:11,402 | train | INFO | Write row 15
2021-08-08 05:19:13,295 | train | INFO | Epoch 16 train batch 0/450: 0/7200 mean loss: 0.0010970591101795435 score: 1.0
2021-08-08 05:19:14,102 | train | INFO | Epoch 16 train batch 1/450: 16/7200 mean loss: 0.0013204769929870963 score: 0.9805672268907564
2021-08-08 05:19:14,891 | train | INFO | Epoch 16 train batch 2/450: 32/7200 mean loss: 0.0012335098581388593 score: 1.0
2021-08-08 05:19:15,684 | train | INFO | Epoch 16 train batch 3/450: 48/7200 mean loss: 0.0012706731213256717 score: 1.0
2021-08-08 05:19:16,466 | train | INFO | Epoch 16 train batch 4/450: 64/7200 mean loss: 0.0010227725142613053 score: 0.996078431372549
2021-08-08 05:19:17,250 | train | INFO | Epoch 16 train batch 5/450: 80/7200 mean loss: 0.0011577496770769358 score: 1.0
2021-08-08 05:19:18,070 | train | INFO | Epoch 16 train batch 6/450: 96/7200 mean loss: 0.0015536797000095248 score: 1.0
2021-08-08 05:19:18,877 | train | INFO | Epoch 16 train batch 7/450: 112/7200 mean loss: 0.0015255656326189637 score: 0.9831932773109244
2021-08-08 05:19:19,679 | train | INFO | Epoch 16 train batch 8/450: 128/7200 mean loss: 0.0016212371410802007 score: 0.9917986425339367
2021-08-08 05:19:20,452 | train | INFO | Epoch 16 train batch 9/450: 144/7200 mean loss: 0.0015653949230909348 score: 0.9889705882352942
2021-08-08 05:19:21,262 | train | INFO | Epoch 16 train batch 10/450: 160/7200 mean loss: 0.0013931023422628641 score: 1.0
2021-08-08 05:19:22,083 | train | INFO | Epoch 16 train batch 11/450: 176/7200 mean loss: 0.0012663722736760974 score: 1.0
2021-08-08 05:19:22,868 | train | INFO | Epoch 16 train batch 12/450: 192/7200 mean loss: 0.001444176770746708 score: 0.9926470588235294
2021-08-08 05:19:23,644 | train | INFO | Epoch 16 train batch 13/450: 208/7200 mean loss: 0.001486539258621633 score: 1.0
2021-08-08 05:19:24,474 | train | INFO | Epoch 16 train batch 14/450: 224/7200 mean loss: 0.0015539543237537146 score: 1.0
2021-08-08 05:19:25,244 | train | INFO | Epoch 16 train batch 15/450: 240/7200 mean loss: 0.0015239479253068566 score: 1.0
2021-08-08 05:19:26,018 | train | INFO | Epoch 16 train batch 16/450: 256/7200 mean loss: 0.0015484507894143462 score: 1.0
2021-08-08 05:19:26,806 | train | INFO | Epoch 16 train batch 17/450: 272/7200 mean loss: 0.0015091850655153394 score: 0.9887254901960785
2021-08-08 05:19:27,599 | train | INFO | Epoch 16 train batch 18/450: 288/7200 mean loss: 0.0016076854662969708 score: 1.0
2021-08-08 05:19:28,432 | train | INFO | Epoch 16 train batch 19/450: 304/7200 mean loss: 0.0014500864781439304 score: 1.0
2021-08-08 05:19:29,220 | train | INFO | Epoch 16 train batch 20/450: 320/7200 mean loss: 0.001484121661633253 score: 1.0
2021-08-08 05:19:29,998 | train | INFO | Epoch 16 train batch 21/450: 336/7200 mean loss: 0.0015994417481124401 score: 1.0
2021-08-08 05:19:30,779 | train | INFO | Epoch 16 train batch 22/450: 352/7200 mean loss: 0.0016522618243470788 score: 1.0
2021-08-08 05:19:31,566 | train | INFO | Epoch 16 train batch 23/450: 368/7200 mean loss: 0.001403297996148467 score: 0.9926470588235294
2021-08-08 05:19:32,345 | train | INFO | Epoch 16 train batch 24/450: 384/7200 mean loss: 0.0011717850575223565 score: 1.0
2021-08-08 05:19:33,156 | train | INFO | Epoch 16 train batch 25/450: 400/7200 mean loss: 0.0015524668851867318 score: 1.0
2021-08-08 05:19:33,946 | train | INFO | Epoch 16 train batch 26/450: 416/7200 mean loss: 0.0015166281955316663 score: 0.9884453781512604
2021-08-08 05:19:34,760 | train | INFO | Epoch 16 train batch 27/450: 432/7200 mean loss: 0.0015088864602148533 score: 0.9852941176470589
2021-08-08 05:19:35,576 | train | INFO | Epoch 16 train batch 28/450: 448/7200 mean loss: 0.001602887292392552 score: 1.0
2021-08-08 05:19:36,357 | train | INFO | Epoch 16 train batch 29/450: 464/7200 mean loss: 0.0013046588283032179 score: 1.0
2021-08-08 05:19:37,186 | train | INFO | Epoch 16 train batch 30/450: 480/7200 mean loss: 0.0016478885663673282 score: 1.0
2021-08-08 05:19:37,971 | train | INFO | Epoch 16 train batch 31/450: 496/7200 mean loss: 0.0015635504387319088 score: 1.0
2021-08-08 05:19:38,740 | train | INFO | Epoch 16 train batch 32/450: 512/7200 mean loss: 0.0013596704229712486 score: 0.9921568627450981
2021-08-08 05:19:39,568 | train | INFO | Epoch 16 train batch 33/450: 528/7200 mean loss: 0.0014095871010795236 score: 1.0
2021-08-08 05:19:40,348 | train | INFO | Epoch 16 train batch 34/450: 544/7200 mean loss: 0.0014872793108224869 score: 1.0
2021-08-08 05:19:41,124 | train | INFO | Epoch 16 train batch 35/450: 560/7200 mean loss: 0.0014096592785790563 score: 1.0
2021-08-08 05:19:41,938 | train | INFO | Epoch 16 train batch 36/450: 576/7200 mean loss: 0.0013595109339803457 score: 1.0
2021-08-08 05:19:42,728 | train | INFO | Epoch 16 train batch 37/450: 592/7200 mean loss: 0.0012800217373296618 score: 1.0
2021-08-08 05:19:43,540 | train | INFO | Epoch 16 train batch 38/450: 608/7200 mean loss: 0.0013284416636452079 score: 1.0
2021-08-08 05:19:44,317 | train | INFO | Epoch 16 train batch 39/450: 624/7200 mean loss: 0.001339460490271449 score: 1.0
2021-08-08 05:19:45,115 | train | INFO | Epoch 16 train batch 40/450: 640/7200 mean loss: 0.0014355398016050458 score: 0.9963235294117647
2021-08-08 05:19:45,936 | train | INFO | Epoch 16 train batch 41/450: 656/7200 mean loss: 0.0016024339711293578 score: 0.996078431372549
2021-08-08 05:19:46,810 | train | INFO | Epoch 16 train batch 42/450: 672/7200 mean loss: 0.0013626688160002232 score: 1.0
2021-08-08 05:19:47,617 | train | INFO | Epoch 16 train batch 43/450: 688/7200 mean loss: 0.0012574396096169949 score: 1.0
2021-08-08 05:19:48,414 | train | INFO | Epoch 16 train batch 44/450: 704/7200 mean loss: 0.0013387661892920732 score: 0.9889705882352942
2021-08-08 05:19:49,203 | train | INFO | Epoch 16 train batch 45/450: 720/7200 mean loss: 0.0014431721065193415 score: 1.0
2021-08-08 05:19:49,989 | train | INFO | Epoch 16 train batch 46/450: 736/7200 mean loss: 0.0011857067001983523 score: 1.0
2021-08-08 05:19:50,812 | train | INFO | Epoch 16 train batch 47/450: 752/7200 mean loss: 0.0014752927236258984 score: 0.995798319327731
2021-08-08 05:19:51,617 | train | INFO | Epoch 16 train batch 48/450: 768/7200 mean loss: 0.0013265176676213741 score: 1.0
2021-08-08 05:19:52,387 | train | INFO | Epoch 16 train batch 49/450: 784/7200 mean loss: 0.0013092949520796537 score: 1.0
2021-08-08 05:19:53,163 | train | INFO | Epoch 16 train batch 50/450: 800/7200 mean loss: 0.0014095274964347482 score: 0.9522058823529411
2021-08-08 05:19:53,938 | train | INFO | Epoch 16 train batch 51/450: 816/7200 mean loss: 0.0013340458972379565 score: 1.0
2021-08-08 05:19:54,721 | train | INFO | Epoch 16 train batch 52/450: 832/7200 mean loss: 0.001403345842845738 score: 1.0
2021-08-08 05:19:55,526 | train | INFO | Epoch 16 train batch 53/450: 848/7200 mean loss: 0.0011443743715062737 score: 1.0
2021-08-08 05:19:56,333 | train | INFO | Epoch 16 train batch 54/450: 864/7200 mean loss: 0.0014835820766165853 score: 1.0
2021-08-08 05:19:57,103 | train | INFO | Epoch 16 train batch 55/450: 880/7200 mean loss: 0.0015496539417654276 score: 0.9926470588235294
2021-08-08 05:19:57,917 | train | INFO | Epoch 16 train batch 56/450: 896/7200 mean loss: 0.0012814487563446164 score: 1.0
2021-08-08 05:19:58,691 | train | INFO | Epoch 16 train batch 57/450: 912/7200 mean loss: 0.0011142141884192824 score: 0.996078431372549
2021-08-08 05:19:59,473 | train | INFO | Epoch 16 train batch 58/450: 928/7200 mean loss: 0.0013295101234689355 score: 1.0
2021-08-08 05:20:00,281 | train | INFO | Epoch 16 train batch 59/450: 944/7200 mean loss: 0.0010318856220692396 score: 1.0
2021-08-08 05:20:01,102 | train | INFO | Epoch 16 train batch 60/450: 960/7200 mean loss: 0.0014002966927364469 score: 1.0
2021-08-08 05:20:01,986 | train | INFO | Epoch 16 train batch 61/450: 976/7200 mean loss: 0.0017274387646466494 score: 1.0
2021-08-08 05:20:02,810 | train | INFO | Epoch 16 train batch 62/450: 992/7200 mean loss: 0.0014369423734024167 score: 0.9963235294117647
2021-08-08 05:20:03,631 | train | INFO | Epoch 16 train batch 63/450: 1008/7200 mean loss: 0.0014719326281920075 score: 1.0
2021-08-08 05:20:04,486 | train | INFO | Epoch 16 train batch 64/450: 1024/7200 mean loss: 0.0017069245222955942 score: 1.0
2021-08-08 05:20:05,324 | train | INFO | Epoch 16 train batch 65/450: 1040/7200 mean loss: 0.0014994880184531212 score: 1.0
2021-08-08 05:20:06,202 | train | INFO | Epoch 16 train batch 66/450: 1056/7200 mean loss: 0.0011947646271437407 score: 1.0
2021-08-08 05:20:07,036 | train | INFO | Epoch 16 train batch 67/450: 1072/7200 mean loss: 0.0012972882250323892 score: 1.0
2021-08-08 05:20:07,853 | train | INFO | Epoch 16 train batch 68/450: 1088/7200 mean loss: 0.001460515079088509 score: 1.0
2021-08-08 05:20:08,668 | train | INFO | Epoch 16 train batch 69/450: 1104/7200 mean loss: 0.0012894581304863095 score: 1.0
2021-08-08 05:20:09,439 | train | INFO | Epoch 16 train batch 70/450: 1120/7200 mean loss: 0.001300400821492076 score: 1.0
2021-08-08 05:20:10,256 | train | INFO | Epoch 16 train batch 71/450: 1136/7200 mean loss: 0.0011880499077960849 score: 1.0
2021-08-08 05:20:11,060 | train | INFO | Epoch 16 train batch 72/450: 1152/7200 mean loss: 0.0014025978744029999 score: 1.0
2021-08-08 05:20:11,843 | train | INFO | Epoch 16 train batch 73/450: 1168/7200 mean loss: 0.0013106090482324362 score: 1.0
2021-08-08 05:20:12,660 | train | INFO | Epoch 16 train batch 74/450: 1184/7200 mean loss: 0.0012095089768990874 score: 0.883578431372549
2021-08-08 05:20:13,442 | train | INFO | Epoch 16 train batch 75/450: 1200/7200 mean loss: 0.0010952624725177884 score: 0.9409313725490196
2021-08-08 05:20:14,229 | train | INFO | Epoch 16 train batch 76/450: 1216/7200 mean loss: 0.0014997803373262286 score: 1.0
2021-08-08 05:20:15,040 | train | INFO | Epoch 16 train batch 77/450: 1232/7200 mean loss: 0.0013700291747227311 score: 1.0
2021-08-08 05:20:15,836 | train | INFO | Epoch 16 train batch 78/450: 1248/7200 mean loss: 0.001503072096966207 score: 1.0
2021-08-08 05:20:16,651 | train | INFO | Epoch 16 train batch 79/450: 1264/7200 mean loss: 0.0013781198067590594 score: 1.0
2021-08-08 05:20:17,427 | train | INFO | Epoch 16 train batch 80/450: 1280/7200 mean loss: 0.0015534646809101105 score: 1.0
2021-08-08 05:20:18,248 | train | INFO | Epoch 16 train batch 81/450: 1296/7200 mean loss: 0.0013234359212219715 score: 1.0
2021-08-08 05:20:19,070 | train | INFO | Epoch 16 train batch 82/450: 1312/7200 mean loss: 0.0012315178755670786 score: 0.9924019607843138
2021-08-08 05:20:19,873 | train | INFO | Epoch 16 train batch 83/450: 1328/7200 mean loss: 0.001289921347051859 score: 1.0
2021-08-08 05:20:20,686 | train | INFO | Epoch 16 train batch 84/450: 1344/7200 mean loss: 0.0012971720425412059 score: 0.996078431372549
2021-08-08 05:20:21,473 | train | INFO | Epoch 16 train batch 85/450: 1360/7200 mean loss: 0.0013154881307855248 score: 1.0
2021-08-08 05:20:22,279 | train | INFO | Epoch 16 train batch 86/450: 1376/7200 mean loss: 0.0014960374683141708 score: 1.0
2021-08-08 05:20:23,102 | train | INFO | Epoch 16 train batch 87/450: 1392/7200 mean loss: 0.0011379775824025273 score: 1.0
2021-08-08 05:20:23,874 | train | INFO | Epoch 16 train batch 88/450: 1408/7200 mean loss: 0.0011089690960943699 score: 1.0
2021-08-08 05:20:24,652 | train | INFO | Epoch 16 train batch 89/450: 1424/7200 mean loss: 0.0014502886915579438 score: 0.9963235294117647
2021-08-08 05:20:25,463 | train | INFO | Epoch 16 train batch 90/450: 1440/7200 mean loss: 0.001528021995909512 score: 1.0
2021-08-08 05:20:26,289 | train | INFO | Epoch 16 train batch 91/450: 1456/7200 mean loss: 0.0012870749924331903 score: 1.0
2021-08-08 05:20:27,067 | train | INFO | Epoch 16 train batch 92/450: 1472/7200 mean loss: 0.001409874646924436 score: 1.0
2021-08-08 05:20:27,834 | train | INFO | Epoch 16 train batch 93/450: 1488/7200 mean loss: 0.001451563322916627 score: 1.0
2021-08-08 05:20:28,621 | train | INFO | Epoch 16 train batch 94/450: 1504/7200 mean loss: 0.0016791914822533727 score: 0.8487745098039216
2021-08-08 05:20:29,433 | train | INFO | Epoch 16 train batch 95/450: 1520/7200 mean loss: 0.0015063221799209714 score: 0.9963235294117647
2021-08-08 05:20:30,201 | train | INFO | Epoch 16 train batch 96/450: 1536/7200 mean loss: 0.0015531398821622133 score: 1.0
2021-08-08 05:20:31,001 | train | INFO | Epoch 16 train batch 97/450: 1552/7200 mean loss: 0.001374299405142665 score: 0.9915966386554622
2021-08-08 05:20:31,812 | train | INFO | Epoch 16 train batch 98/450: 1568/7200 mean loss: 0.0015682035591453314 score: 1.0
2021-08-08 05:20:32,589 | train | INFO | Epoch 16 train batch 99/450: 1584/7200 mean loss: 0.0014629594516009092 score: 1.0
2021-08-08 05:20:33,421 | train | INFO | Epoch 16 train batch 100/450: 1600/7200 mean loss: 0.0013999849325045943 score: 1.0
2021-08-08 05:20:34,236 | train | INFO | Epoch 16 train batch 101/450: 1616/7200 mean loss: 0.0014167517656460404 score: 1.0
2021-08-08 05:20:35,053 | train | INFO | Epoch 16 train batch 102/450: 1632/7200 mean loss: 0.001258141710422933 score: 0.9921568627450981
2021-08-08 05:20:35,859 | train | INFO | Epoch 16 train batch 103/450: 1648/7200 mean loss: 0.0012945083435624838 score: 1.0
2021-08-08 05:20:36,672 | train | INFO | Epoch 16 train batch 104/450: 1664/7200 mean loss: 0.0012971030082553625 score: 1.0
2021-08-08 05:20:37,451 | train | INFO | Epoch 16 train batch 105/450: 1680/7200 mean loss: 0.001333431457169354 score: 0.9963235294117647
2021-08-08 05:20:38,265 | train | INFO | Epoch 16 train batch 106/450: 1696/7200 mean loss: 0.001269324216991663 score: 0.9963235294117647
2021-08-08 05:20:39,059 | train | INFO | Epoch 16 train batch 107/450: 1712/7200 mean loss: 0.0014197509735822678 score: 1.0
2021-08-08 05:20:39,850 | train | INFO | Epoch 16 train batch 108/450: 1728/7200 mean loss: 0.0015769832534715533 score: 0.9963235294117647
2021-08-08 05:20:40,623 | train | INFO | Epoch 16 train batch 109/450: 1744/7200 mean loss: 0.001467704656533897 score: 0.9926470588235294
2021-08-08 05:20:41,530 | train | INFO | Epoch 16 train batch 110/450: 1760/7200 mean loss: 0.001516167540103197 score: 1.0
2021-08-08 05:20:42,335 | train | INFO | Epoch 16 train batch 111/450: 1776/7200 mean loss: 0.0017504404531791806 score: 1.0
2021-08-08 05:20:43,113 | train | INFO | Epoch 16 train batch 112/450: 1792/7200 mean loss: 0.0014898821245878935 score: 1.0
2021-08-08 05:20:44,019 | train | INFO | Epoch 16 train batch 113/450: 1808/7200 mean loss: 0.0018378776730969548 score: 0.9963235294117647
2021-08-08 05:20:44,830 | train | INFO | Epoch 16 train batch 114/450: 1824/7200 mean loss: 0.0012672959128394723 score: 1.0
2021-08-08 05:20:45,634 | train | INFO | Epoch 16 train batch 115/450: 1840/7200 mean loss: 0.001324075972661376 score: 0.995798319327731
2021-08-08 05:20:46,441 | train | INFO | Epoch 16 train batch 116/450: 1856/7200 mean loss: 0.0012737178476527333 score: 1.0
2021-08-08 05:20:47,249 | train | INFO | Epoch 16 train batch 117/450: 1872/7200 mean loss: 0.0014547969913110137 score: 1.0
2021-08-08 05:20:48,079 | train | INFO | Epoch 16 train batch 118/450: 1888/7200 mean loss: 0.0012721718521788716 score: 0.9963235294117647
2021-08-08 05:20:48,859 | train | INFO | Epoch 16 train batch 119/450: 1904/7200 mean loss: 0.001336506800726056 score: 1.0
2021-08-08 05:20:49,667 | train | INFO | Epoch 16 train batch 120/450: 1920/7200 mean loss: 0.0015066713094711304 score: 1.0
2021-08-08 05:20:50,469 | train | INFO | Epoch 16 train batch 121/450: 1936/7200 mean loss: 0.0014099637046456337 score: 1.0
2021-08-08 05:20:51,376 | train | INFO | Epoch 16 train batch 122/450: 1952/7200 mean loss: 0.0013717833207920194 score: 1.0
2021-08-08 05:20:52,191 | train | INFO | Epoch 16 train batch 123/450: 1968/7200 mean loss: 0.0014908475568518043 score: 0.9816176470588235
2021-08-08 05:20:52,999 | train | INFO | Epoch 16 train batch 124/450: 1984/7200 mean loss: 0.0014278594171628356 score: 0.996078431372549
2021-08-08 05:20:53,803 | train | INFO | Epoch 16 train batch 125/450: 2000/7200 mean loss: 0.0015478080604225397 score: 1.0
2021-08-08 05:20:54,582 | train | INFO | Epoch 16 train batch 126/450: 2016/7200 mean loss: 0.0012271455489099026 score: 1.0
2021-08-08 05:20:55,353 | train | INFO | Epoch 16 train batch 127/450: 2032/7200 mean loss: 0.0012661345535889268 score: 1.0
2021-08-08 05:20:56,164 | train | INFO | Epoch 16 train batch 128/450: 2048/7200 mean loss: 0.0011050088796764612 score: 1.0
2021-08-08 05:20:56,992 | train | INFO | Epoch 16 train batch 129/450: 2064/7200 mean loss: 0.0012806468876078725 score: 1.0
2021-08-08 05:20:57,797 | train | INFO | Epoch 16 train batch 130/450: 2080/7200 mean loss: 0.0016400880413129926 score: 1.0
2021-08-08 05:20:58,607 | train | INFO | Epoch 16 train batch 131/450: 2096/7200 mean loss: 0.0015946393832564354 score: 0.9737394957983192
2021-08-08 05:20:59,416 | train | INFO | Epoch 16 train batch 132/450: 2112/7200 mean loss: 0.0012195676099509 score: 1.0
2021-08-08 05:21:00,226 | train | INFO | Epoch 16 train batch 133/450: 2128/7200 mean loss: 0.0014578643022105098 score: 1.0
2021-08-08 05:21:01,017 | train | INFO | Epoch 16 train batch 134/450: 2144/7200 mean loss: 0.0014245000202208757 score: 0.7681372549019608
2021-08-08 05:21:01,816 | train | INFO | Epoch 16 train batch 135/450: 2160/7200 mean loss: 0.0014004644472151995 score: 1.0
2021-08-08 05:21:02,601 | train | INFO | Epoch 16 train batch 136/450: 2176/7200 mean loss: 0.0013321706792339683 score: 1.0
2021-08-08 05:21:03,414 | train | INFO | Epoch 16 train batch 137/450: 2192/7200 mean loss: 0.0013408564263954759 score: 1.0
2021-08-08 05:21:04,218 | train | INFO | Epoch 16 train batch 138/450: 2208/7200 mean loss: 0.001371509744785726 score: 1.0
2021-08-08 05:21:05,025 | train | INFO | Epoch 16 train batch 139/450: 2224/7200 mean loss: 0.0013568325666710734 score: 1.0
2021-08-08 05:21:05,851 | train | INFO | Epoch 16 train batch 140/450: 2240/7200 mean loss: 0.001313313259743154 score: 1.0
2021-08-08 05:21:06,640 | train | INFO | Epoch 16 train batch 141/450: 2256/7200 mean loss: 0.0011680484749376774 score: 1.0
2021-08-08 05:21:07,430 | train | INFO | Epoch 16 train batch 142/450: 2272/7200 mean loss: 0.0014395290054380894 score: 1.0
2021-08-08 05:21:08,247 | train | INFO | Epoch 16 train batch 143/450: 2288/7200 mean loss: 0.0012386926682665944 score: 1.0
2021-08-08 05:21:09,047 | train | INFO | Epoch 16 train batch 144/450: 2304/7200 mean loss: 0.0011606724001467228 score: 1.0
2021-08-08 05:21:09,856 | train | INFO | Epoch 16 train batch 145/450: 2320/7200 mean loss: 0.0015057408018037677 score: 0.9921568627450981
2021-08-08 05:21:10,683 | train | INFO | Epoch 16 train batch 146/450: 2336/7200 mean loss: 0.0015629755798727274 score: 1.0
2021-08-08 05:21:11,507 | train | INFO | Epoch 16 train batch 147/450: 2352/7200 mean loss: 0.0015049104113131762 score: 1.0
2021-08-08 05:21:12,282 | train | INFO | Epoch 16 train batch 148/450: 2368/7200 mean loss: 0.0013168348232284188 score: 0.9963235294117647
2021-08-08 05:21:13,089 | train | INFO | Epoch 16 train batch 149/450: 2384/7200 mean loss: 0.0014574138913303614 score: 1.0
2021-08-08 05:21:13,903 | train | INFO | Epoch 16 train batch 150/450: 2400/7200 mean loss: 0.0013708167243748903 score: 0.996078431372549
2021-08-08 05:21:14,682 | train | INFO | Epoch 16 train batch 151/450: 2416/7200 mean loss: 0.001460147905163467 score: 1.0
2021-08-08 05:21:15,480 | train | INFO | Epoch 16 train batch 152/450: 2432/7200 mean loss: 0.0015847476897761226 score: 0.9926470588235294
2021-08-08 05:21:16,289 | train | INFO | Epoch 16 train batch 153/450: 2448/7200 mean loss: 0.0013214133214205503 score: 1.0
2021-08-08 05:21:17,097 | train | INFO | Epoch 16 train batch 154/450: 2464/7200 mean loss: 0.001426705508492887 score: 1.0
2021-08-08 05:21:17,897 | train | INFO | Epoch 16 train batch 155/450: 2480/7200 mean loss: 0.0014882079558447003 score: 1.0
2021-08-08 05:21:18,714 | train | INFO | Epoch 16 train batch 156/450: 2496/7200 mean loss: 0.0014863397227600217 score: 1.0
2021-08-08 05:21:19,531 | train | INFO | Epoch 16 train batch 157/450: 2512/7200 mean loss: 0.0014430657029151917 score: 1.0
2021-08-08 05:21:20,326 | train | INFO | Epoch 16 train batch 158/450: 2528/7200 mean loss: 0.0013693177606910467 score: 0.9963235294117647
2021-08-08 05:21:21,140 | train | INFO | Epoch 16 train batch 159/450: 2544/7200 mean loss: 0.0014014808693900704 score: 1.0
2021-08-08 05:21:21,925 | train | INFO | Epoch 16 train batch 160/450: 2560/7200 mean loss: 0.0013895725132897496 score: 1.0
2021-08-08 05:21:22,723 | train | INFO | Epoch 16 train batch 161/450: 2576/7200 mean loss: 0.0015573567943647504 score: 1.0
2021-08-08 05:21:23,497 | train | INFO | Epoch 16 train batch 162/450: 2592/7200 mean loss: 0.0014443612890318036 score: 1.0
2021-08-08 05:21:24,274 | train | INFO | Epoch 16 train batch 163/450: 2608/7200 mean loss: 0.0015493861865252256 score: 1.0
2021-08-08 05:21:25,098 | train | INFO | Epoch 16 train batch 164/450: 2624/7200 mean loss: 0.0015087330248206854 score: 1.0
2021-08-08 05:21:25,983 | train | INFO | Epoch 16 train batch 165/450: 2640/7200 mean loss: 0.001603839104063809 score: 1.0
2021-08-08 05:21:26,778 | train | INFO | Epoch 16 train batch 166/450: 2656/7200 mean loss: 0.001608898863196373 score: 1.0
2021-08-08 05:21:27,602 | train | INFO | Epoch 16 train batch 167/450: 2672/7200 mean loss: 0.0013524701353162527 score: 0.9963235294117647
2021-08-08 05:21:28,425 | train | INFO | Epoch 16 train batch 168/450: 2688/7200 mean loss: 0.0014626611955463886 score: 1.0
2021-08-08 05:21:29,214 | train | INFO | Epoch 16 train batch 169/450: 2704/7200 mean loss: 0.0011821890948340297 score: 1.0
2021-08-08 05:21:29,988 | train | INFO | Epoch 16 train batch 170/450: 2720/7200 mean loss: 0.001029365579597652 score: 1.0
2021-08-08 05:21:30,759 | train | INFO | Epoch 16 train batch 171/450: 2736/7200 mean loss: 0.0014271266991272569 score: 0.9629901960784314
2021-08-08 05:21:31,539 | train | INFO | Epoch 16 train batch 172/450: 2752/7200 mean loss: 0.0014250585809350014 score: 1.0
2021-08-08 05:21:32,319 | train | INFO | Epoch 16 train batch 173/450: 2768/7200 mean loss: 0.0014540791744366288 score: 0.9889705882352942
2021-08-08 05:21:33,126 | train | INFO | Epoch 16 train batch 174/450: 2784/7200 mean loss: 0.0013879138277843595 score: 1.0
2021-08-08 05:21:33,944 | train | INFO | Epoch 16 train batch 175/450: 2800/7200 mean loss: 0.0013413710985332727 score: 1.0
2021-08-08 05:21:34,748 | train | INFO | Epoch 16 train batch 176/450: 2816/7200 mean loss: 0.0013368147192522883 score: 1.0
2021-08-08 05:21:35,533 | train | INFO | Epoch 16 train batch 177/450: 2832/7200 mean loss: 0.0013744488824158907 score: 1.0
2021-08-08 05:21:36,306 | train | INFO | Epoch 16 train batch 178/450: 2848/7200 mean loss: 0.001736216014251113 score: 0.9625
2021-08-08 05:21:37,120 | train | INFO | Epoch 16 train batch 179/450: 2864/7200 mean loss: 0.0013323480961844325 score: 1.0
2021-08-08 05:21:37,923 | train | INFO | Epoch 16 train batch 180/450: 2880/7200 mean loss: 0.0014069576282054186 score: 1.0
2021-08-08 05:21:38,709 | train | INFO | Epoch 16 train batch 181/450: 2896/7200 mean loss: 0.0012806759914383292 score: 1.0
2021-08-08 05:21:39,485 | train | INFO | Epoch 16 train batch 182/450: 2912/7200 mean loss: 0.0015833904035389423 score: 1.0
2021-08-08 05:21:40,282 | train | INFO | Epoch 16 train batch 183/450: 2928/7200 mean loss: 0.001426303293555975 score: 1.0
2021-08-08 05:21:41,084 | train | INFO | Epoch 16 train batch 184/450: 2944/7200 mean loss: 0.0012922778259962797 score: 0.9963235294117647
2021-08-08 05:21:41,897 | train | INFO | Epoch 16 train batch 185/450: 2960/7200 mean loss: 0.001475007738918066 score: 1.0
2021-08-08 05:21:42,705 | train | INFO | Epoch 16 train batch 186/450: 2976/7200 mean loss: 0.001346884062513709 score: 1.0
2021-08-08 05:21:43,505 | train | INFO | Epoch 16 train batch 187/450: 2992/7200 mean loss: 0.001462434185668826 score: 1.0
2021-08-08 05:21:44,280 | train | INFO | Epoch 16 train batch 188/450: 3008/7200 mean loss: 0.0013433517888188362 score: 1.0
2021-08-08 05:21:45,077 | train | INFO | Epoch 16 train batch 189/450: 3024/7200 mean loss: 0.0014081798726692796 score: 1.0
2021-08-08 05:21:45,891 | train | INFO | Epoch 16 train batch 190/450: 3040/7200 mean loss: 0.0016382700996473432 score: 1.0
2021-08-08 05:21:46,669 | train | INFO | Epoch 16 train batch 191/450: 3056/7200 mean loss: 0.0012729440350085497 score: 1.0
2021-08-08 05:21:47,476 | train | INFO | Epoch 16 train batch 192/450: 3072/7200 mean loss: 0.0013346689520403743 score: 1.0
2021-08-08 05:21:48,274 | train | INFO | Epoch 16 train batch 193/450: 3088/7200 mean loss: 0.0012510231463238597 score: 1.0
2021-08-08 05:21:49,062 | train | INFO | Epoch 16 train batch 194/450: 3104/7200 mean loss: 0.001341849914751947 score: 1.0
2021-08-08 05:21:49,993 | train | INFO | Epoch 16 train batch 195/450: 3120/7200 mean loss: 0.0010740231955423951 score: 1.0
2021-08-08 05:21:50,785 | train | INFO | Epoch 16 train batch 196/450: 3136/7200 mean loss: 0.0012134101707488298 score: 0.9926470588235294
2021-08-08 05:21:51,576 | train | INFO | Epoch 16 train batch 197/450: 3152/7200 mean loss: 0.0013368211220949888 score: 1.0
2021-08-08 05:21:52,383 | train | INFO | Epoch 16 train batch 198/450: 3168/7200 mean loss: 0.0015748218866065145 score: 1.0
2021-08-08 05:21:53,162 | train | INFO | Epoch 16 train batch 199/450: 3184/7200 mean loss: 0.0015985978534445167 score: 1.0
2021-08-08 05:21:53,980 | train | INFO | Epoch 16 train batch 200/450: 3200/7200 mean loss: 0.0014725059736520052 score: 1.0
2021-08-08 05:21:54,775 | train | INFO | Epoch 16 train batch 201/450: 3216/7200 mean loss: 0.0015113380504772067 score: 1.0
2021-08-08 05:21:55,540 | train | INFO | Epoch 16 train batch 202/450: 3232/7200 mean loss: 0.001313527813181281 score: 1.0
2021-08-08 05:21:56,352 | train | INFO | Epoch 16 train batch 203/450: 3248/7200 mean loss: 0.0011848629219457507 score: 0.9705882352941176
2021-08-08 05:21:57,148 | train | INFO | Epoch 16 train batch 204/450: 3264/7200 mean loss: 0.0014386369148269296 score: 0.9963235294117647
2021-08-08 05:21:57,922 | train | INFO | Epoch 16 train batch 205/450: 3280/7200 mean loss: 0.0013497081818059087 score: 1.0
2021-08-08 05:21:58,707 | train | INFO | Epoch 16 train batch 206/450: 3296/7200 mean loss: 0.0014835946494713426 score: 0.9963235294117647
2021-08-08 05:21:59,484 | train | INFO | Epoch 16 train batch 207/450: 3312/7200 mean loss: 0.0013708298793062568 score: 1.0
2021-08-08 05:22:00,259 | train | INFO | Epoch 16 train batch 208/450: 3328/7200 mean loss: 0.0013944880338385701 score: 0.9963235294117647
2021-08-08 05:22:01,054 | train | INFO | Epoch 16 train batch 209/450: 3344/7200 mean loss: 0.0014619134599342942 score: 1.0
2021-08-08 05:22:01,864 | train | INFO | Epoch 16 train batch 210/450: 3360/7200 mean loss: 0.0014548740582540631 score: 1.0
2021-08-08 05:22:02,644 | train | INFO | Epoch 16 train batch 211/450: 3376/7200 mean loss: 0.0015821264823898673 score: 0.9926470588235294
2021-08-08 05:22:03,448 | train | INFO | Epoch 16 train batch 212/450: 3392/7200 mean loss: 0.0014192044036462903 score: 1.0
2021-08-08 05:22:04,359 | train | INFO | Epoch 16 train batch 213/450: 3408/7200 mean loss: 0.001430680276826024 score: 1.0
2021-08-08 05:22:05,185 | train | INFO | Epoch 16 train batch 214/450: 3424/7200 mean loss: 0.001338641857728362 score: 1.0
2021-08-08 05:22:05,983 | train | INFO | Epoch 16 train batch 215/450: 3440/7200 mean loss: 0.00177460175473243 score: 1.0
2021-08-08 05:22:06,802 | train | INFO | Epoch 16 train batch 216/450: 3456/7200 mean loss: 0.0016072611324489117 score: 1.0
2021-08-08 05:22:07,621 | train | INFO | Epoch 16 train batch 217/450: 3472/7200 mean loss: 0.0014128832845017314 score: 1.0
2021-08-08 05:22:08,445 | train | INFO | Epoch 16 train batch 218/450: 3488/7200 mean loss: 0.0016474853036925197 score: 1.0
2021-08-08 05:22:09,219 | train | INFO | Epoch 16 train batch 219/450: 3504/7200 mean loss: 0.0015905771870166063 score: 0.9852941176470589
2021-08-08 05:22:09,996 | train | INFO | Epoch 16 train batch 220/450: 3520/7200 mean loss: 0.0015564076602458954 score: 0.996078431372549
2021-08-08 05:22:10,800 | train | INFO | Epoch 16 train batch 221/450: 3536/7200 mean loss: 0.0015964130870997906 score: 0.996078431372549
2021-08-08 05:22:11,631 | train | INFO | Epoch 16 train batch 222/450: 3552/7200 mean loss: 0.0012547378428280354 score: 0.9963235294117647
2021-08-08 05:22:12,438 | train | INFO | Epoch 16 train batch 223/450: 3568/7200 mean loss: 0.0015043735038489103 score: 1.0
2021-08-08 05:22:13,242 | train | INFO | Epoch 16 train batch 224/450: 3584/7200 mean loss: 0.001556801493279636 score: 0.9102941176470588
2021-08-08 05:22:14,022 | train | INFO | Epoch 16 train batch 225/450: 3600/7200 mean loss: 0.0015082703903317451 score: 1.0
2021-08-08 05:22:14,792 | train | INFO | Epoch 16 train batch 226/450: 3616/7200 mean loss: 0.0014049295568838716 score: 1.0
2021-08-08 05:22:15,567 | train | INFO | Epoch 16 train batch 227/450: 3632/7200 mean loss: 0.0014796993928030133 score: 1.0
2021-08-08 05:22:16,390 | train | INFO | Epoch 16 train batch 228/450: 3648/7200 mean loss: 0.0012667240807786584 score: 1.0
2021-08-08 05:22:17,198 | train | INFO | Epoch 16 train batch 229/450: 3664/7200 mean loss: 0.001255985233001411 score: 1.0
2021-08-08 05:22:18,000 | train | INFO | Epoch 16 train batch 230/450: 3680/7200 mean loss: 0.001406181021593511 score: 1.0
2021-08-08 05:22:18,781 | train | INFO | Epoch 16 train batch 231/450: 3696/7200 mean loss: 0.0012946027563884854 score: 0.9848039215686275
2021-08-08 05:22:19,610 | train | INFO | Epoch 16 train batch 232/450: 3712/7200 mean loss: 0.0014260446187108755 score: 0.9963235294117647
2021-08-08 05:22:20,395 | train | INFO | Epoch 16 train batch 233/450: 3728/7200 mean loss: 0.0014263377524912357 score: 1.0
2021-08-08 05:22:21,202 | train | INFO | Epoch 16 train batch 234/450: 3744/7200 mean loss: 0.001101813861168921 score: 1.0
2021-08-08 05:22:22,043 | train | INFO | Epoch 16 train batch 235/450: 3760/7200 mean loss: 0.0013035734882578254 score: 0.9889705882352942
2021-08-08 05:22:22,829 | train | INFO | Epoch 16 train batch 236/450: 3776/7200 mean loss: 0.0010189871536567807 score: 1.0
2021-08-08 05:22:23,620 | train | INFO | Epoch 16 train batch 237/450: 3792/7200 mean loss: 0.0012696123449131846 score: 0.9963235294117647
2021-08-08 05:22:24,400 | train | INFO | Epoch 16 train batch 238/450: 3808/7200 mean loss: 0.0011303683277219534 score: 1.0
2021-08-08 05:22:25,218 | train | INFO | Epoch 16 train batch 239/450: 3824/7200 mean loss: 0.0013440183829516172 score: 1.0
2021-08-08 05:22:26,040 | train | INFO | Epoch 16 train batch 240/450: 3840/7200 mean loss: 0.0012679594801738858 score: 0.9811274509803922
2021-08-08 05:22:26,808 | train | INFO | Epoch 16 train batch 241/450: 3856/7200 mean loss: 0.0013650492765009403 score: 1.0
2021-08-08 05:22:27,614 | train | INFO | Epoch 16 train batch 242/450: 3872/7200 mean loss: 0.001344553311355412 score: 1.0
2021-08-08 05:22:28,457 | train | INFO | Epoch 16 train batch 243/450: 3888/7200 mean loss: 0.0013378154253587127 score: 1.0
2021-08-08 05:22:29,242 | train | INFO | Epoch 16 train batch 244/450: 3904/7200 mean loss: 0.001520965131931007 score: 1.0
2021-08-08 05:22:30,036 | train | INFO | Epoch 16 train batch 245/450: 3920/7200 mean loss: 0.0014105685986578465 score: 1.0
2021-08-08 05:22:30,835 | train | INFO | Epoch 16 train batch 246/450: 3936/7200 mean loss: 0.0013229430187493563 score: 0.9924019607843138
2021-08-08 05:22:31,645 | train | INFO | Epoch 16 train batch 247/450: 3952/7200 mean loss: 0.0014105174923315644 score: 1.0
2021-08-08 05:22:32,443 | train | INFO | Epoch 16 train batch 248/450: 3968/7200 mean loss: 0.001357300323434174 score: 1.0
2021-08-08 05:22:33,290 | train | INFO | Epoch 16 train batch 249/450: 3984/7200 mean loss: 0.001407694653607905 score: 0.996078431372549
2021-08-08 05:22:34,080 | train | INFO | Epoch 16 train batch 250/450: 4000/7200 mean loss: 0.0012729025911539793 score: 1.0
2021-08-08 05:22:34,852 | train | INFO | Epoch 16 train batch 251/450: 4016/7200 mean loss: 0.001240957877598703 score: 1.0
2021-08-08 05:22:35,650 | train | INFO | Epoch 16 train batch 252/450: 4032/7200 mean loss: 0.0015249266289174557 score: 1.0
2021-08-08 05:22:36,437 | train | INFO | Epoch 16 train batch 253/450: 4048/7200 mean loss: 0.001454719458706677 score: 0.9887254901960785
2021-08-08 05:22:37,219 | train | INFO | Epoch 16 train batch 254/450: 4064/7200 mean loss: 0.0013079553609713912 score: 0.9852941176470589
2021-08-08 05:22:38,015 | train | INFO | Epoch 16 train batch 255/450: 4080/7200 mean loss: 0.0014097951352596283 score: 0.9963235294117647
2021-08-08 05:22:38,788 | train | INFO | Epoch 16 train batch 256/450: 4096/7200 mean loss: 0.001430399832315743 score: 1.0
2021-08-08 05:22:39,578 | train | INFO | Epoch 16 train batch 257/450: 4112/7200 mean loss: 0.0012837486574426293 score: 1.0
2021-08-08 05:22:40,364 | train | INFO | Epoch 16 train batch 258/450: 4128/7200 mean loss: 0.001323617878369987 score: 0.9926470588235294
2021-08-08 05:22:41,151 | train | INFO | Epoch 16 train batch 259/450: 4144/7200 mean loss: 0.0016099013155326247 score: 1.0
2021-08-08 05:22:41,934 | train | INFO | Epoch 16 train batch 260/450: 4160/7200 mean loss: 0.001480976934544742 score: 1.0
2021-08-08 05:22:42,737 | train | INFO | Epoch 16 train batch 261/450: 4176/7200 mean loss: 0.0013264577137306333 score: 1.0
2021-08-08 05:22:43,564 | train | INFO | Epoch 16 train batch 262/450: 4192/7200 mean loss: 0.0013955412432551384 score: 1.0
2021-08-08 05:22:44,348 | train | INFO | Epoch 16 train batch 263/450: 4208/7200 mean loss: 0.0012310867896303535 score: 1.0
2021-08-08 05:22:45,132 | train | INFO | Epoch 16 train batch 264/450: 4224/7200 mean loss: 0.0016010423423722386 score: 1.0
2021-08-08 05:22:45,911 | train | INFO | Epoch 16 train batch 265/450: 4240/7200 mean loss: 0.001390716410242021 score: 1.0
2021-08-08 05:22:46,687 | train | INFO | Epoch 16 train batch 266/450: 4256/7200 mean loss: 0.0013875478180125356 score: 1.0
2021-08-08 05:22:47,473 | train | INFO | Epoch 16 train batch 267/450: 4272/7200 mean loss: 0.0013652138877660036 score: 0.9963235294117647
2021-08-08 05:22:48,247 | train | INFO | Epoch 16 train batch 268/450: 4288/7200 mean loss: 0.0012777420924976468 score: 1.0
2021-08-08 05:22:49,055 | train | INFO | Epoch 16 train batch 269/450: 4304/7200 mean loss: 0.0013655126094818115 score: 1.0
2021-08-08 05:22:49,876 | train | INFO | Epoch 16 train batch 270/450: 4320/7200 mean loss: 0.001532599562779069 score: 1.0
2021-08-08 05:22:50,753 | train | INFO | Epoch 16 train batch 271/450: 4336/7200 mean loss: 0.001511401031166315 score: 1.0
2021-08-08 05:22:51,574 | train | INFO | Epoch 16 train batch 272/450: 4352/7200 mean loss: 0.0015341986436396837 score: 1.0
2021-08-08 05:22:52,383 | train | INFO | Epoch 16 train batch 273/450: 4368/7200 mean loss: 0.001451803371310234 score: 1.0
2021-08-08 05:22:53,271 | train | INFO | Epoch 16 train batch 274/450: 4384/7200 mean loss: 0.0015647297259420156 score: 1.0
2021-08-08 05:22:54,076 | train | INFO | Epoch 16 train batch 275/450: 4400/7200 mean loss: 0.0016753622330725193 score: 1.0
2021-08-08 05:22:54,858 | train | INFO | Epoch 16 train batch 276/450: 4416/7200 mean loss: 0.001430992502719164 score: 0.9669117647058824
2021-08-08 05:22:55,672 | train | INFO | Epoch 16 train batch 277/450: 4432/7200 mean loss: 0.0013107025297358632 score: 1.0
2021-08-08 05:22:56,462 | train | INFO | Epoch 16 train batch 278/450: 4448/7200 mean loss: 0.0012893382227048278 score: 1.0
2021-08-08 05:22:57,275 | train | INFO | Epoch 16 train batch 279/450: 4464/7200 mean loss: 0.0012809467734768987 score: 1.0
2021-08-08 05:22:58,069 | train | INFO | Epoch 16 train batch 280/450: 4480/7200 mean loss: 0.0015138342278078198 score: 0.9779411764705882
2021-08-08 05:22:58,887 | train | INFO | Epoch 16 train batch 281/450: 4496/7200 mean loss: 0.0014186088228598237 score: 1.0
2021-08-08 05:22:59,697 | train | INFO | Epoch 16 train batch 282/450: 4512/7200 mean loss: 0.001365377800539136 score: 1.0
2021-08-08 05:23:00,483 | train | INFO | Epoch 16 train batch 283/450: 4528/7200 mean loss: 0.0013275215169414878 score: 1.0
2021-08-08 05:23:01,258 | train | INFO | Epoch 16 train batch 284/450: 4544/7200 mean loss: 0.0013985191471874714 score: 1.0
2021-08-08 05:23:02,067 | train | INFO | Epoch 16 train batch 285/450: 4560/7200 mean loss: 0.001439375220797956 score: 1.0
2021-08-08 05:23:02,848 | train | INFO | Epoch 16 train batch 286/450: 4576/7200 mean loss: 0.0014045170973986387 score: 0.996078431372549
2021-08-08 05:23:03,638 | train | INFO | Epoch 16 train batch 287/450: 4592/7200 mean loss: 0.0015599459875375032 score: 0.8911764705882353
2021-08-08 05:23:04,421 | train | INFO | Epoch 16 train batch 288/450: 4608/7200 mean loss: 0.0015799361281096935 score: 1.0
2021-08-08 05:23:05,198 | train | INFO | Epoch 16 train batch 289/450: 4624/7200 mean loss: 0.0014505281578749418 score: 1.0
2021-08-08 05:23:05,969 | train | INFO | Epoch 16 train batch 290/450: 4640/7200 mean loss: 0.0013982716482132673 score: 1.0
2021-08-08 05:23:06,768 | train | INFO | Epoch 16 train batch 291/450: 4656/7200 mean loss: 0.0015331911854445934 score: 1.0
2021-08-08 05:23:07,543 | train | INFO | Epoch 16 train batch 292/450: 4672/7200 mean loss: 0.0017193697858601809 score: 0.9887254901960785
2021-08-08 05:23:08,327 | train | INFO | Epoch 16 train batch 293/450: 4688/7200 mean loss: 0.0012822793796658516 score: 1.0
2021-08-08 05:23:09,124 | train | INFO | Epoch 16 train batch 294/450: 4704/7200 mean loss: 0.0014060318935662508 score: 1.0
2021-08-08 05:23:09,899 | train | INFO | Epoch 16 train batch 295/450: 4720/7200 mean loss: 0.0013997957576066256 score: 1.0
2021-08-08 05:23:10,715 | train | INFO | Epoch 16 train batch 296/450: 4736/7200 mean loss: 0.0013830394018441439 score: 0.9889705882352942
2021-08-08 05:23:11,512 | train | INFO | Epoch 16 train batch 297/450: 4752/7200 mean loss: 0.0014434076147153974 score: 1.0
2021-08-08 05:23:12,290 | train | INFO | Epoch 16 train batch 298/450: 4768/7200 mean loss: 0.0012431497452780604 score: 1.0
2021-08-08 05:23:13,093 | train | INFO | Epoch 16 train batch 299/450: 4784/7200 mean loss: 0.0012689903378486633 score: 0.9963235294117647
2021-08-08 05:23:13,918 | train | INFO | Epoch 16 train batch 300/450: 4800/7200 mean loss: 0.0016048334073275328 score: 1.0
2021-08-08 05:23:14,706 | train | INFO | Epoch 16 train batch 301/450: 4816/7200 mean loss: 0.0014986585592851043 score: 1.0
2021-08-08 05:23:15,478 | train | INFO | Epoch 16 train batch 302/450: 4832/7200 mean loss: 0.0014833341119810939 score: 0.9763655462184874
2021-08-08 05:23:16,275 | train | INFO | Epoch 16 train batch 303/450: 4848/7200 mean loss: 0.001576663227751851 score: 1.0
2021-08-08 05:23:17,099 | train | INFO | Epoch 16 train batch 304/450: 4864/7200 mean loss: 0.0013935117749497294 score: 1.0
2021-08-08 05:23:17,913 | train | INFO | Epoch 16 train batch 305/450: 4880/7200 mean loss: 0.0014037651708349586 score: 1.0
2021-08-08 05:23:18,692 | train | INFO | Epoch 16 train batch 306/450: 4896/7200 mean loss: 0.0017222192836925387 score: 0.9881221719457014
2021-08-08 05:23:19,496 | train | INFO | Epoch 16 train batch 307/450: 4912/7200 mean loss: 0.001553984940983355 score: 0.996078431372549
2021-08-08 05:23:20,283 | train | INFO | Epoch 16 train batch 308/450: 4928/7200 mean loss: 0.0016120123909786344 score: 1.0
2021-08-08 05:23:21,109 | train | INFO | Epoch 16 train batch 309/450: 4944/7200 mean loss: 0.0015213231090456247 score: 1.0
2021-08-08 05:23:21,899 | train | INFO | Epoch 16 train batch 310/450: 4960/7200 mean loss: 0.0016921054339036345 score: 1.0
2021-08-08 05:23:22,693 | train | INFO | Epoch 16 train batch 311/450: 4976/7200 mean loss: 0.0012547645019367337 score: 1.0
2021-08-08 05:23:23,521 | train | INFO | Epoch 16 train batch 312/450: 4992/7200 mean loss: 0.001269331551156938 score: 0.995798319327731
2021-08-08 05:23:24,303 | train | INFO | Epoch 16 train batch 313/450: 5008/7200 mean loss: 0.0012600874761119485 score: 1.0
2021-08-08 05:23:25,082 | train | INFO | Epoch 16 train batch 314/450: 5024/7200 mean loss: 0.0015454795211553574 score: 0.9921568627450981
2021-08-08 05:23:25,907 | train | INFO | Epoch 16 train batch 315/450: 5040/7200 mean loss: 0.0013587352586910129 score: 0.9732843137254903
2021-08-08 05:23:26,681 | train | INFO | Epoch 16 train batch 316/450: 5056/7200 mean loss: 0.0013169900048524141 score: 1.0
2021-08-08 05:23:27,460 | train | INFO | Epoch 16 train batch 317/450: 5072/7200 mean loss: 0.0013958560302853584 score: 1.0
2021-08-08 05:23:28,282 | train | INFO | Epoch 16 train batch 318/450: 5088/7200 mean loss: 0.001529425149783492 score: 1.0
2021-08-08 05:23:29,088 | train | INFO | Epoch 16 train batch 319/450: 5104/7200 mean loss: 0.0016283796867355704 score: 0.9963235294117647
2021-08-08 05:23:29,867 | train | INFO | Epoch 16 train batch 320/450: 5120/7200 mean loss: 0.0017172859515994787 score: 1.0
2021-08-08 05:23:30,669 | train | INFO | Epoch 16 train batch 321/450: 5136/7200 mean loss: 0.0015226569958031178 score: 1.0
2021-08-08 05:23:31,444 | train | INFO | Epoch 16 train batch 322/450: 5152/7200 mean loss: 0.001791229355148971 score: 0.9264705882352942
2021-08-08 05:23:32,221 | train | INFO | Epoch 16 train batch 323/450: 5168/7200 mean loss: 0.001569674233905971 score: 1.0
2021-08-08 05:23:33,014 | train | INFO | Epoch 16 train batch 324/450: 5184/7200 mean loss: 0.0013423645868897438 score: 1.0
2021-08-08 05:23:33,820 | train | INFO | Epoch 16 train batch 325/450: 5200/7200 mean loss: 0.0013271438656374812 score: 0.9884803921568628
2021-08-08 05:23:34,639 | train | INFO | Epoch 16 train batch 326/450: 5216/7200 mean loss: 0.0010729744099080563 score: 1.0
2021-08-08 05:23:35,410 | train | INFO | Epoch 16 train batch 327/450: 5232/7200 mean loss: 0.0012669474817812443 score: 1.0
2021-08-08 05:23:36,177 | train | INFO | Epoch 16 train batch 328/450: 5248/7200 mean loss: 0.0012946753995493054 score: 1.0
2021-08-08 05:23:36,939 | train | INFO | Epoch 16 train batch 329/450: 5264/7200 mean loss: 0.0012968257069587708 score: 0.9963235294117647
2021-08-08 05:23:37,730 | train | INFO | Epoch 16 train batch 330/450: 5280/7200 mean loss: 0.0012531612301245332 score: 1.0
2021-08-08 05:23:38,515 | train | INFO | Epoch 16 train batch 331/450: 5296/7200 mean loss: 0.0014127197209745646 score: 1.0
2021-08-08 05:23:39,340 | train | INFO | Epoch 16 train batch 332/450: 5312/7200 mean loss: 0.0016025754157453775 score: 0.9921568627450981
2021-08-08 05:23:40,138 | train | INFO | Epoch 16 train batch 333/450: 5328/7200 mean loss: 0.0014070098986849189 score: 1.0
2021-08-08 05:23:40,935 | train | INFO | Epoch 16 train batch 334/450: 5344/7200 mean loss: 0.0013550337171182036 score: 1.0
2021-08-08 05:23:41,761 | train | INFO | Epoch 16 train batch 335/450: 5360/7200 mean loss: 0.0013563852990046144 score: 0.8110294117647059
2021-08-08 05:23:42,558 | train | INFO | Epoch 16 train batch 336/450: 5376/7200 mean loss: 0.001388136763125658 score: 1.0
2021-08-08 05:23:43,349 | train | INFO | Epoch 16 train batch 337/450: 5392/7200 mean loss: 0.0014837586786597967 score: 0.9742647058823529
2021-08-08 05:23:44,241 | train | INFO | Epoch 16 train batch 338/450: 5408/7200 mean loss: 0.0014288100646808743 score: 1.0
2021-08-08 05:23:45,035 | train | INFO | Epoch 16 train batch 339/450: 5424/7200 mean loss: 0.0013700247509405017 score: 0.9779411764705882
2021-08-08 05:23:45,835 | train | INFO | Epoch 16 train batch 340/450: 5440/7200 mean loss: 0.0014558157417923212 score: 0.996078431372549
2021-08-08 05:23:46,682 | train | INFO | Epoch 16 train batch 341/450: 5456/7200 mean loss: 0.0015186889795586467 score: 1.0
2021-08-08 05:23:47,507 | train | INFO | Epoch 16 train batch 342/450: 5472/7200 mean loss: 0.0015477001434192061 score: 1.0
2021-08-08 05:23:48,284 | train | INFO | Epoch 16 train batch 343/450: 5488/7200 mean loss: 0.0017440790543332696 score: 0.8080882352941177
2021-08-08 05:23:49,072 | train | INFO | Epoch 16 train batch 344/450: 5504/7200 mean loss: 0.0015779495006427169 score: 0.9963235294117647
2021-08-08 05:23:49,899 | train | INFO | Epoch 16 train batch 345/450: 5520/7200 mean loss: 0.001683882437646389 score: 1.0
2021-08-08 05:23:50,678 | train | INFO | Epoch 16 train batch 346/450: 5536/7200 mean loss: 0.001655461615882814 score: 1.0
2021-08-08 05:23:51,463 | train | INFO | Epoch 16 train batch 347/450: 5552/7200 mean loss: 0.001465409528464079 score: 1.0
2021-08-08 05:23:52,294 | train | INFO | Epoch 16 train batch 348/450: 5568/7200 mean loss: 0.0014648876385763288 score: 1.0
2021-08-08 05:23:53,112 | train | INFO | Epoch 16 train batch 349/450: 5584/7200 mean loss: 0.0012931646779179573 score: 0.995798319327731
2021-08-08 05:23:53,916 | train | INFO | Epoch 16 train batch 350/450: 5600/7200 mean loss: 0.0015983752673491836 score: 1.0
2021-08-08 05:23:54,727 | train | INFO | Epoch 16 train batch 351/450: 5616/7200 mean loss: 0.0014612101949751377 score: 1.0
2021-08-08 05:23:55,523 | train | INFO | Epoch 16 train batch 352/450: 5632/7200 mean loss: 0.0015905656618997455 score: 1.0
2021-08-08 05:23:56,412 | train | INFO | Epoch 16 train batch 353/450: 5648/7200 mean loss: 0.0014254928100854158 score: 0.9963235294117647
2021-08-08 05:23:57,238 | train | INFO | Epoch 16 train batch 354/450: 5664/7200 mean loss: 0.0013505161041393876 score: 1.0
2021-08-08 05:23:58,072 | train | INFO | Epoch 16 train batch 355/450: 5680/7200 mean loss: 0.0015113736735656857 score: 0.9963235294117647
2021-08-08 05:23:58,856 | train | INFO | Epoch 16 train batch 356/450: 5696/7200 mean loss: 0.0011997352121397853 score: 1.0
2021-08-08 05:23:59,683 | train | INFO | Epoch 16 train batch 357/450: 5712/7200 mean loss: 0.0011037759250029922 score: 1.0
2021-08-08 05:24:00,465 | train | INFO | Epoch 16 train batch 358/450: 5728/7200 mean loss: 0.0015265054535120726 score: 1.0
2021-08-08 05:24:01,299 | train | INFO | Epoch 16 train batch 359/450: 5744/7200 mean loss: 0.0010575546184554696 score: 1.0
2021-08-08 05:24:02,068 | train | INFO | Epoch 16 train batch 360/450: 5760/7200 mean loss: 0.0014576627872884274 score: 0.9080882352941176
2021-08-08 05:24:02,897 | train | INFO | Epoch 16 train batch 361/450: 5776/7200 mean loss: 0.0012647140538319945 score: 0.9852941176470589
2021-08-08 05:24:03,701 | train | INFO | Epoch 16 train batch 362/450: 5792/7200 mean loss: 0.0014086372684687376 score: 1.0
2021-08-08 05:24:04,496 | train | INFO | Epoch 16 train batch 363/450: 5808/7200 mean loss: 0.0014385086251422763 score: 0.9669117647058824
2021-08-08 05:24:05,327 | train | INFO | Epoch 16 train batch 364/450: 5824/7200 mean loss: 0.0015792070189490914 score: 1.0
2021-08-08 05:24:06,115 | train | INFO | Epoch 16 train batch 365/450: 5840/7200 mean loss: 0.0014413128374144435 score: 1.0
2021-08-08 05:24:06,901 | train | INFO | Epoch 16 train batch 366/450: 5856/7200 mean loss: 0.0013613714836537838 score: 1.0
2021-08-08 05:24:07,712 | train | INFO | Epoch 16 train batch 367/450: 5872/7200 mean loss: 0.0014226480852812529 score: 1.0
2021-08-08 05:24:08,501 | train | INFO | Epoch 16 train batch 368/450: 5888/7200 mean loss: 0.0016216497169807553 score: 1.0
2021-08-08 05:24:09,276 | train | INFO | Epoch 16 train batch 369/450: 5904/7200 mean loss: 0.0012868765043094754 score: 1.0
2021-08-08 05:24:10,050 | train | INFO | Epoch 16 train batch 370/450: 5920/7200 mean loss: 0.0013563595712184906 score: 1.0
2021-08-08 05:24:10,827 | train | INFO | Epoch 16 train batch 371/450: 5936/7200 mean loss: 0.0013264525914564729 score: 0.996078431372549
2021-08-08 05:24:11,654 | train | INFO | Epoch 16 train batch 372/450: 5952/7200 mean loss: 0.0013407680671662092 score: 0.9963235294117647
2021-08-08 05:24:12,439 | train | INFO | Epoch 16 train batch 373/450: 5968/7200 mean loss: 0.0014142084401100874 score: 1.0
2021-08-08 05:24:13,256 | train | INFO | Epoch 16 train batch 374/450: 5984/7200 mean loss: 0.0014600185677409172 score: 1.0
2021-08-08 05:24:14,038 | train | INFO | Epoch 16 train batch 375/450: 6000/7200 mean loss: 0.0013365503400564194 score: 0.9963235294117647
2021-08-08 05:24:14,856 | train | INFO | Epoch 16 train batch 376/450: 6016/7200 mean loss: 0.0013933462323620915 score: 1.0
2021-08-08 05:24:15,640 | train | INFO | Epoch 16 train batch 377/450: 6032/7200 mean loss: 0.0012406958267092705 score: 0.9963235294117647
2021-08-08 05:24:16,441 | train | INFO | Epoch 16 train batch 378/450: 6048/7200 mean loss: 0.0012432136572897434 score: 1.0
2021-08-08 05:24:17,208 | train | INFO | Epoch 16 train batch 379/450: 6064/7200 mean loss: 0.0014794589951634407 score: 1.0
2021-08-08 05:24:17,999 | train | INFO | Epoch 16 train batch 380/450: 6080/7200 mean loss: 0.0014541271375492215 score: 1.0
2021-08-08 05:24:18,785 | train | INFO | Epoch 16 train batch 381/450: 6096/7200 mean loss: 0.001515321433544159 score: 1.0
2021-08-08 05:24:19,570 | train | INFO | Epoch 16 train batch 382/450: 6112/7200 mean loss: 0.0015670792199671268 score: 1.0
2021-08-08 05:24:20,363 | train | INFO | Epoch 16 train batch 383/450: 6128/7200 mean loss: 0.0013151789316907525 score: 1.0
2021-08-08 05:24:21,138 | train | INFO | Epoch 16 train batch 384/450: 6144/7200 mean loss: 0.001770245609804988 score: 1.0
2021-08-08 05:24:21,930 | train | INFO | Epoch 16 train batch 385/450: 6160/7200 mean loss: 0.0018730448791757226 score: 0.9522058823529411
2021-08-08 05:24:22,762 | train | INFO | Epoch 16 train batch 386/450: 6176/7200 mean loss: 0.0016955226892605424 score: 1.0
2021-08-08 05:24:23,580 | train | INFO | Epoch 16 train batch 387/450: 6192/7200 mean loss: 0.001649291254580021 score: 1.0
2021-08-08 05:24:24,402 | train | INFO | Epoch 16 train batch 388/450: 6208/7200 mean loss: 0.001625373144634068 score: 1.0
2021-08-08 05:24:25,209 | train | INFO | Epoch 16 train batch 389/450: 6224/7200 mean loss: 0.0017305940855294466 score: 0.9963235294117647
2021-08-08 05:24:26,028 | train | INFO | Epoch 16 train batch 390/450: 6240/7200 mean loss: 0.0013110890286043286 score: 1.0
2021-08-08 05:24:26,838 | train | INFO | Epoch 16 train batch 391/450: 6256/7200 mean loss: 0.0013915288727730513 score: 1.0
2021-08-08 05:24:27,623 | train | INFO | Epoch 16 train batch 392/450: 6272/7200 mean loss: 0.0013378638541325927 score: 0.9178921568627451
2021-08-08 05:24:28,402 | train | INFO | Epoch 16 train batch 393/450: 6288/7200 mean loss: 0.0011660270392894745 score: 1.0
2021-08-08 05:24:29,175 | train | INFO | Epoch 16 train batch 394/450: 6304/7200 mean loss: 0.0011935100192204118 score: 1.0
2021-08-08 05:24:29,956 | train | INFO | Epoch 16 train batch 395/450: 6320/7200 mean loss: 0.0010729655623435974 score: 1.0
2021-08-08 05:24:30,771 | train | INFO | Epoch 16 train batch 396/450: 6336/7200 mean loss: 0.0015845608431845903 score: 1.0
2021-08-08 05:24:31,543 | train | INFO | Epoch 16 train batch 397/450: 6352/7200 mean loss: 0.0015276136109605432 score: 1.0
2021-08-08 05:24:32,451 | train | INFO | Epoch 16 train batch 398/450: 6368/7200 mean loss: 0.0014625780750066042 score: 1.0
2021-08-08 05:24:33,357 | train | INFO | Epoch 16 train batch 399/450: 6384/7200 mean loss: 0.0015356861986219883 score: 1.0
2021-08-08 05:24:34,150 | train | INFO | Epoch 16 train batch 400/450: 6400/7200 mean loss: 0.0013755870750173926 score: 1.0
2021-08-08 05:24:34,959 | train | INFO | Epoch 16 train batch 401/450: 6416/7200 mean loss: 0.0014649374643340707 score: 1.0
2021-08-08 05:24:35,759 | train | INFO | Epoch 16 train batch 402/450: 6432/7200 mean loss: 0.001245231949724257 score: 1.0
2021-08-08 05:24:36,571 | train | INFO | Epoch 16 train batch 403/450: 6448/7200 mean loss: 0.0011945307487621903 score: 1.0
2021-08-08 05:24:37,346 | train | INFO | Epoch 16 train batch 404/450: 6464/7200 mean loss: 0.0016513190930709243 score: 1.0
2021-08-08 05:24:38,135 | train | INFO | Epoch 16 train batch 405/450: 6480/7200 mean loss: 0.0012436134275048971 score: 1.0
2021-08-08 05:24:38,953 | train | INFO | Epoch 16 train batch 406/450: 6496/7200 mean loss: 0.001420670305378735 score: 0.996078431372549
2021-08-08 05:24:39,747 | train | INFO | Epoch 16 train batch 407/450: 6512/7200 mean loss: 0.0015110505046322942 score: 0.996078431372549
2021-08-08 05:24:40,529 | train | INFO | Epoch 16 train batch 408/450: 6528/7200 mean loss: 0.001188219990581274 score: 1.0
2021-08-08 05:24:41,365 | train | INFO | Epoch 16 train batch 409/450: 6544/7200 mean loss: 0.0012791104381904006 score: 1.0
2021-08-08 05:24:42,141 | train | INFO | Epoch 16 train batch 410/450: 6560/7200 mean loss: 0.0015151321422308683 score: 1.0
2021-08-08 05:24:42,920 | train | INFO | Epoch 16 train batch 411/450: 6576/7200 mean loss: 0.0015447087353095412 score: 0.9963235294117647
2021-08-08 05:24:43,716 | train | INFO | Epoch 16 train batch 412/450: 6592/7200 mean loss: 0.0012362550478428602 score: 1.0
2021-08-08 05:24:44,534 | train | INFO | Epoch 16 train batch 413/450: 6608/7200 mean loss: 0.00112731393892318 score: 1.0
2021-08-08 05:24:45,310 | train | INFO | Epoch 16 train batch 414/450: 6624/7200 mean loss: 0.001285404316149652 score: 0.9629901960784314
2021-08-08 05:24:46,097 | train | INFO | Epoch 16 train batch 415/450: 6640/7200 mean loss: 0.0016553686000406742 score: 1.0
2021-08-08 05:24:46,901 | train | INFO | Epoch 16 train batch 416/450: 6656/7200 mean loss: 0.0014295532600954175 score: 1.0
2021-08-08 05:24:47,700 | train | INFO | Epoch 16 train batch 417/450: 6672/7200 mean loss: 0.0014303559437394142 score: 1.0
2021-08-08 05:24:48,481 | train | INFO | Epoch 16 train batch 418/450: 6688/7200 mean loss: 0.001319470931775868 score: 0.8811274509803921
2021-08-08 05:24:49,247 | train | INFO | Epoch 16 train batch 419/450: 6704/7200 mean loss: 0.001402300433255732 score: 1.0
2021-08-08 05:24:50,066 | train | INFO | Epoch 16 train batch 420/450: 6720/7200 mean loss: 0.0014688026858493686 score: 1.0
2021-08-08 05:24:50,869 | train | INFO | Epoch 16 train batch 421/450: 6736/7200 mean loss: 0.0015717314090579748 score: 1.0
2021-08-08 05:24:51,719 | train | INFO | Epoch 16 train batch 422/450: 6752/7200 mean loss: 0.001511693000793457 score: 1.0
2021-08-08 05:24:52,615 | train | INFO | Epoch 16 train batch 423/450: 6768/7200 mean loss: 0.001292085973545909 score: 1.0
2021-08-08 05:24:53,429 | train | INFO | Epoch 16 train batch 424/450: 6784/7200 mean loss: 0.0016827763756737113 score: 0.9963235294117647
2021-08-08 05:24:54,216 | train | INFO | Epoch 16 train batch 425/450: 6800/7200 mean loss: 0.001550688175484538 score: 1.0
2021-08-08 05:24:55,013 | train | INFO | Epoch 16 train batch 426/450: 6816/7200 mean loss: 0.0015218867920339108 score: 0.9963235294117647
2021-08-08 05:24:55,848 | train | INFO | Epoch 16 train batch 427/450: 6832/7200 mean loss: 0.0014616388361901045 score: 0.9926470588235294
2021-08-08 05:24:56,648 | train | INFO | Epoch 16 train batch 428/450: 6848/7200 mean loss: 0.0015357299707829952 score: 0.9301470588235294
2021-08-08 05:24:57,434 | train | INFO | Epoch 16 train batch 429/450: 6864/7200 mean loss: 0.0014490907778963447 score: 1.0
2021-08-08 05:24:58,217 | train | INFO | Epoch 16 train batch 430/450: 6880/7200 mean loss: 0.0014487303560599685 score: 1.0
2021-08-08 05:24:59,027 | train | INFO | Epoch 16 train batch 431/450: 6896/7200 mean loss: 0.0014022658579051495 score: 1.0
2021-08-08 05:24:59,833 | train | INFO | Epoch 16 train batch 432/450: 6912/7200 mean loss: 0.0013550264993682504 score: 1.0
2021-08-08 05:25:00,622 | train | INFO | Epoch 16 train batch 433/450: 6928/7200 mean loss: 0.001382810645736754 score: 1.0
2021-08-08 05:25:01,420 | train | INFO | Epoch 16 train batch 434/450: 6944/7200 mean loss: 0.0013206127332523465 score: 1.0
2021-08-08 05:25:02,219 | train | INFO | Epoch 16 train batch 435/450: 6960/7200 mean loss: 0.0013592225732281804 score: 1.0
2021-08-08 05:25:03,030 | train | INFO | Epoch 16 train batch 436/450: 6976/7200 mean loss: 0.001556878094561398 score: 0.9963235294117647
2021-08-08 05:25:03,811 | train | INFO | Epoch 16 train batch 437/450: 6992/7200 mean loss: 0.0016348755452781916 score: 0.9811274509803922
2021-08-08 05:25:04,590 | train | INFO | Epoch 16 train batch 438/450: 7008/7200 mean loss: 0.001432705787010491 score: 1.0
2021-08-08 05:25:05,361 | train | INFO | Epoch 16 train batch 439/450: 7024/7200 mean loss: 0.0014980867272242904 score: 0.9247737556561086
2021-08-08 05:25:06,131 | train | INFO | Epoch 16 train batch 440/450: 7040/7200 mean loss: 0.0015898847486823797 score: 0.996078431372549
2021-08-08 05:25:06,901 | train | INFO | Epoch 16 train batch 441/450: 7056/7200 mean loss: 0.001542832818813622 score: 1.0
2021-08-08 05:25:07,672 | train | INFO | Epoch 16 train batch 442/450: 7072/7200 mean loss: 0.0015005129389464855 score: 1.0
2021-08-08 05:25:08,448 | train | INFO | Epoch 16 train batch 443/450: 7088/7200 mean loss: 0.0014693925622850657 score: 1.0
2021-08-08 05:25:09,219 | train | INFO | Epoch 16 train batch 444/450: 7104/7200 mean loss: 0.0013650307664647698 score: 0.9926470588235294
2021-08-08 05:25:09,994 | train | INFO | Epoch 16 train batch 445/450: 7120/7200 mean loss: 0.0011226824717596173 score: 1.0
2021-08-08 05:25:10,775 | train | INFO | Epoch 16 train batch 446/450: 7136/7200 mean loss: 0.0012621590867638588 score: 1.0
2021-08-08 05:25:11,550 | train | INFO | Epoch 16 train batch 447/450: 7152/7200 mean loss: 0.0013505980605259538 score: 1.0
2021-08-08 05:25:12,323 | train | INFO | Epoch 16 train batch 448/450: 7168/7200 mean loss: 0.0011965928133577108 score: 1.0
2021-08-08 05:25:13,100 | train | INFO | Epoch 16 train batch 449/450: 7184/7200 mean loss: 0.0015121330507099628 score: 1.0
2021-08-08 05:25:13,250 | train | INFO | Epoch 16, Train, Mean loss: 0.02262965615010924, Score: 0.9939072577749047
2021-08-08 05:25:14,693 | train | INFO | Epoch 16 validation batch 0/113: 0/1800 mean loss: 0.0009862564038485289 score: 1.0
2021-08-08 05:25:14,928 | train | INFO | Epoch 16 validation batch 1/113: 16/1800 mean loss: 0.001041509909555316 score: 0.9963235294117647
2021-08-08 05:25:15,159 | train | INFO | Epoch 16 validation batch 2/113: 32/1800 mean loss: 0.0013247798196971416 score: 1.0
2021-08-08 05:25:15,405 | train | INFO | Epoch 16 validation batch 3/113: 48/1800 mean loss: 0.0011127926409244537 score: 1.0
2021-08-08 05:25:15,671 | train | INFO | Epoch 16 validation batch 4/113: 64/1800 mean loss: 0.0009564484353177249 score: 1.0
2021-08-08 05:25:15,905 | train | INFO | Epoch 16 validation batch 5/113: 80/1800 mean loss: 0.0009732776670716703 score: 1.0
2021-08-08 05:25:16,142 | train | INFO | Epoch 16 validation batch 6/113: 96/1800 mean loss: 0.0009326772415079176 score: 1.0
2021-08-08 05:25:16,401 | train | INFO | Epoch 16 validation batch 7/113: 112/1800 mean loss: 0.0010819642338901758 score: 1.0
2021-08-08 05:25:16,660 | train | INFO | Epoch 16 validation batch 8/113: 128/1800 mean loss: 0.0010458120377734303 score: 1.0
2021-08-08 05:25:16,901 | train | INFO | Epoch 16 validation batch 9/113: 144/1800 mean loss: 0.0010391895193606615 score: 1.0
2021-08-08 05:25:17,133 | train | INFO | Epoch 16 validation batch 10/113: 160/1800 mean loss: 0.0010849563404917717 score: 0.9779411764705882
2021-08-08 05:25:17,391 | train | INFO | Epoch 16 validation batch 11/113: 176/1800 mean loss: 0.0010984163964167237 score: 0.9963235294117647
2021-08-08 05:25:17,629 | train | INFO | Epoch 16 validation batch 12/113: 192/1800 mean loss: 0.0010704485466703773 score: 1.0
2021-08-08 05:25:17,887 | train | INFO | Epoch 16 validation batch 13/113: 208/1800 mean loss: 0.0009374477085657418 score: 1.0
2021-08-08 05:25:18,119 | train | INFO | Epoch 16 validation batch 14/113: 224/1800 mean loss: 0.0008750736596994102 score: 1.0
2021-08-08 05:25:18,352 | train | INFO | Epoch 16 validation batch 15/113: 240/1800 mean loss: 0.0010694655356928706 score: 1.0
2021-08-08 05:25:18,605 | train | INFO | Epoch 16 validation batch 16/113: 256/1800 mean loss: 0.0010155964409932494 score: 1.0
2021-08-08 05:25:18,853 | train | INFO | Epoch 16 validation batch 17/113: 272/1800 mean loss: 0.0011239456944167614 score: 1.0
2021-08-08 05:25:19,086 | train | INFO | Epoch 16 validation batch 18/113: 288/1800 mean loss: 0.0008244596538133919 score: 1.0
2021-08-08 05:25:19,327 | train | INFO | Epoch 16 validation batch 19/113: 304/1800 mean loss: 0.0010551094310358167 score: 1.0
2021-08-08 05:25:19,587 | train | INFO | Epoch 16 validation batch 20/113: 320/1800 mean loss: 0.0011160779977217317 score: 0.9887254901960785
2021-08-08 05:25:19,849 | train | INFO | Epoch 16 validation batch 21/113: 336/1800 mean loss: 0.0009843361331149936 score: 1.0
2021-08-08 05:25:20,113 | train | INFO | Epoch 16 validation batch 22/113: 352/1800 mean loss: 0.0009906438644975424 score: 1.0
2021-08-08 05:25:20,345 | train | INFO | Epoch 16 validation batch 23/113: 368/1800 mean loss: 0.0009568805689923465 score: 1.0
2021-08-08 05:25:20,610 | train | INFO | Epoch 16 validation batch 24/113: 384/1800 mean loss: 0.001043848693370819 score: 1.0
2021-08-08 05:25:20,870 | train | INFO | Epoch 16 validation batch 25/113: 400/1800 mean loss: 0.0011126120807603002 score: 1.0
2021-08-08 05:25:21,164 | train | INFO | Epoch 16 validation batch 26/113: 416/1800 mean loss: 0.0008558448753319681 score: 1.0
2021-08-08 05:25:21,403 | train | INFO | Epoch 16 validation batch 27/113: 432/1800 mean loss: 0.0010988585418090224 score: 1.0
2021-08-08 05:25:21,646 | train | INFO | Epoch 16 validation batch 28/113: 448/1800 mean loss: 0.001009801053442061 score: 1.0
2021-08-08 05:25:21,876 | train | INFO | Epoch 16 validation batch 29/113: 464/1800 mean loss: 0.0010305409086868167 score: 1.0
2021-08-08 05:25:22,111 | train | INFO | Epoch 16 validation batch 30/113: 480/1800 mean loss: 0.0010157127398997545 score: 1.0
2021-08-08 05:25:22,350 | train | INFO | Epoch 16 validation batch 31/113: 496/1800 mean loss: 0.0009982261108234525 score: 1.0
2021-08-08 05:25:22,603 | train | INFO | Epoch 16 validation batch 32/113: 512/1800 mean loss: 0.0010618565138429403 score: 1.0
2021-08-08 05:25:22,842 | train | INFO | Epoch 16 validation batch 33/113: 528/1800 mean loss: 0.00088822579709813 score: 1.0
2021-08-08 05:25:23,095 | train | INFO | Epoch 16 validation batch 34/113: 544/1800 mean loss: 0.0007533670286647975 score: 1.0
2021-08-08 05:25:23,351 | train | INFO | Epoch 16 validation batch 35/113: 560/1800 mean loss: 0.0012237385381013155 score: 1.0
2021-08-08 05:25:23,607 | train | INFO | Epoch 16 validation batch 36/113: 576/1800 mean loss: 0.0011241910979151726 score: 0.9333333333333333
2021-08-08 05:25:23,838 | train | INFO | Epoch 16 validation batch 37/113: 592/1800 mean loss: 0.0008370833238586783 score: 1.0
2021-08-08 05:25:24,070 | train | INFO | Epoch 16 validation batch 38/113: 608/1800 mean loss: 0.0010401002364233136 score: 1.0
2021-08-08 05:25:24,315 | train | INFO | Epoch 16 validation batch 39/113: 624/1800 mean loss: 0.0009640236385166645 score: 1.0
2021-08-08 05:25:24,569 | train | INFO | Epoch 16 validation batch 40/113: 640/1800 mean loss: 0.0010139101650565863 score: 1.0
2021-08-08 05:25:24,798 | train | INFO | Epoch 16 validation batch 41/113: 656/1800 mean loss: 0.0009490126394666731 score: 1.0
2021-08-08 05:25:25,030 | train | INFO | Epoch 16 validation batch 42/113: 672/1800 mean loss: 0.00097361218649894 score: 0.9963235294117647
2021-08-08 05:25:25,265 | train | INFO | Epoch 16 validation batch 43/113: 688/1800 mean loss: 0.0009643646772019565 score: 1.0
2021-08-08 05:25:25,518 | train | INFO | Epoch 16 validation batch 44/113: 704/1800 mean loss: 0.0012258801143616438 score: 0.9742647058823529
2021-08-08 05:25:25,757 | train | INFO | Epoch 16 validation batch 45/113: 720/1800 mean loss: 0.0010705561144277453 score: 1.0
2021-08-08 05:25:26,016 | train | INFO | Epoch 16 validation batch 46/113: 736/1800 mean loss: 0.001004127087071538 score: 0.9926470588235294
2021-08-08 05:25:26,247 | train | INFO | Epoch 16 validation batch 47/113: 752/1800 mean loss: 0.0009526251233182847 score: 1.0
2021-08-08 05:25:26,480 | train | INFO | Epoch 16 validation batch 48/113: 768/1800 mean loss: 0.0009410937782377005 score: 1.0
2021-08-08 05:25:26,722 | train | INFO | Epoch 16 validation batch 49/113: 784/1800 mean loss: 0.0010288312332704663 score: 1.0
2021-08-08 05:25:26,955 | train | INFO | Epoch 16 validation batch 50/113: 800/1800 mean loss: 0.0009129339014180005 score: 1.0
2021-08-08 05:25:27,218 | train | INFO | Epoch 16 validation batch 51/113: 816/1800 mean loss: 0.001070815254934132 score: 0.9852941176470589
2021-08-08 05:25:27,463 | train | INFO | Epoch 16 validation batch 52/113: 832/1800 mean loss: 0.0009858004050329328 score: 1.0
2021-08-08 05:25:27,714 | train | INFO | Epoch 16 validation batch 53/113: 848/1800 mean loss: 0.0009483324829488993 score: 1.0
2021-08-08 05:25:27,949 | train | INFO | Epoch 16 validation batch 54/113: 864/1800 mean loss: 0.0009940664749592543 score: 1.0
2021-08-08 05:25:28,198 | train | INFO | Epoch 16 validation batch 55/113: 880/1800 mean loss: 0.0010708206100389361 score: 1.0
2021-08-08 05:25:28,435 | train | INFO | Epoch 16 validation batch 56/113: 896/1800 mean loss: 0.0010270315688103437 score: 1.0
2021-08-08 05:25:28,676 | train | INFO | Epoch 16 validation batch 57/113: 912/1800 mean loss: 0.0010657826205715537 score: 1.0
2021-08-08 05:25:28,907 | train | INFO | Epoch 16 validation batch 58/113: 928/1800 mean loss: 0.0010829910170286894 score: 0.9779411764705882
2021-08-08 05:25:29,141 | train | INFO | Epoch 16 validation batch 59/113: 944/1800 mean loss: 0.0009639609488658607 score: 1.0
2021-08-08 05:25:29,399 | train | INFO | Epoch 16 validation batch 60/113: 960/1800 mean loss: 0.0008672612602822483 score: 1.0
2021-08-08 05:25:29,629 | train | INFO | Epoch 16 validation batch 61/113: 976/1800 mean loss: 0.0009129050886258483 score: 1.0
2021-08-08 05:25:29,859 | train | INFO | Epoch 16 validation batch 62/113: 992/1800 mean loss: 0.0009757373481988907 score: 1.0
2021-08-08 05:25:30,117 | train | INFO | Epoch 16 validation batch 63/113: 1008/1800 mean loss: 0.0009488732903264463 score: 1.0
2021-08-08 05:25:30,370 | train | INFO | Epoch 16 validation batch 64/113: 1024/1800 mean loss: 0.0009600237244740129 score: 1.0
2021-08-08 05:25:30,626 | train | INFO | Epoch 16 validation batch 65/113: 1040/1800 mean loss: 0.0010854604188352823 score: 1.0
2021-08-08 05:25:30,859 | train | INFO | Epoch 16 validation batch 66/113: 1056/1800 mean loss: 0.0010335370898246765 score: 1.0
2021-08-08 05:25:31,109 | train | INFO | Epoch 16 validation batch 67/113: 1072/1800 mean loss: 0.0011128532933071256 score: 1.0
2021-08-08 05:25:31,375 | train | INFO | Epoch 16 validation batch 68/113: 1088/1800 mean loss: 0.0008687862427905202 score: 1.0
2021-08-08 05:25:31,608 | train | INFO | Epoch 16 validation batch 69/113: 1104/1800 mean loss: 0.0009440286667086184 score: 1.0
2021-08-08 05:25:31,841 | train | INFO | Epoch 16 validation batch 70/113: 1120/1800 mean loss: 0.0011931824265047908 score: 0.9963235294117647
2021-08-08 05:25:32,073 | train | INFO | Epoch 16 validation batch 71/113: 1136/1800 mean loss: 0.0009251403389498591 score: 1.0
2021-08-08 05:25:32,337 | train | INFO | Epoch 16 validation batch 72/113: 1152/1800 mean loss: 0.0009564667707309127 score: 1.0
2021-08-08 05:25:32,578 | train | INFO | Epoch 16 validation batch 73/113: 1168/1800 mean loss: 0.0011827938724309206 score: 1.0
2021-08-08 05:25:32,853 | train | INFO | Epoch 16 validation batch 74/113: 1184/1800 mean loss: 0.0010985982371494174 score: 1.0
2021-08-08 05:25:33,090 | train | INFO | Epoch 16 validation batch 75/113: 1200/1800 mean loss: 0.0009625067468732595 score: 1.0
2021-08-08 05:25:33,322 | train | INFO | Epoch 16 validation batch 76/113: 1216/1800 mean loss: 0.000866171030793339 score: 1.0
2021-08-08 05:25:33,575 | train | INFO | Epoch 16 validation batch 77/113: 1232/1800 mean loss: 0.0008302641799673438 score: 1.0
2021-08-08 05:25:33,822 | train | INFO | Epoch 16 validation batch 78/113: 1248/1800 mean loss: 0.0009645603713579476 score: 0.9889705882352942
2021-08-08 05:25:34,058 | train | INFO | Epoch 16 validation batch 79/113: 1264/1800 mean loss: 0.001160004292614758 score: 0.9884803921568628
2021-08-08 05:25:34,309 | train | INFO | Epoch 16 validation batch 80/113: 1280/1800 mean loss: 0.0011774172307923436 score: 1.0
2021-08-08 05:25:34,561 | train | INFO | Epoch 16 validation batch 81/113: 1296/1800 mean loss: 0.0010072644799947739 score: 1.0
2021-08-08 05:25:34,794 | train | INFO | Epoch 16 validation batch 82/113: 1312/1800 mean loss: 0.001033428474329412 score: 1.0
2021-08-08 05:25:35,028 | train | INFO | Epoch 16 validation batch 83/113: 1328/1800 mean loss: 0.0011654153931885958 score: 1.0
2021-08-08 05:25:35,264 | train | INFO | Epoch 16 validation batch 84/113: 1344/1800 mean loss: 0.0011395150795578957 score: 0.9889705882352942
2021-08-08 05:25:35,514 | train | INFO | Epoch 16 validation batch 85/113: 1360/1800 mean loss: 0.0010328816715627909 score: 1.0
2021-08-08 05:25:35,748 | train | INFO | Epoch 16 validation batch 86/113: 1376/1800 mean loss: 0.001274865004234016 score: 1.0
2021-08-08 05:25:35,986 | train | INFO | Epoch 16 validation batch 87/113: 1392/1800 mean loss: 0.0011781357461586595 score: 1.0
2021-08-08 05:25:36,234 | train | INFO | Epoch 16 validation batch 88/113: 1408/1800 mean loss: 0.0009903059108182788 score: 1.0
2021-08-08 05:25:36,465 | train | INFO | Epoch 16 validation batch 89/113: 1424/1800 mean loss: 0.0008584954193793237 score: 1.0
2021-08-08 05:25:36,700 | train | INFO | Epoch 16 validation batch 90/113: 1440/1800 mean loss: 0.000937152246478945 score: 1.0
2021-08-08 05:25:36,931 | train | INFO | Epoch 16 validation batch 91/113: 1456/1800 mean loss: 0.0012992434203624725 score: 1.0
2021-08-08 05:25:37,164 | train | INFO | Epoch 16 validation batch 92/113: 1472/1800 mean loss: 0.0009649283019825816 score: 1.0
2021-08-08 05:25:37,405 | train | INFO | Epoch 16 validation batch 93/113: 1488/1800 mean loss: 0.0010238938266411424 score: 1.0
2021-08-08 05:25:37,656 | train | INFO | Epoch 16 validation batch 94/113: 1504/1800 mean loss: 0.001009038183838129 score: 1.0
2021-08-08 05:25:37,890 | train | INFO | Epoch 16 validation batch 95/113: 1520/1800 mean loss: 0.001057724584825337 score: 1.0
2021-08-08 05:25:38,123 | train | INFO | Epoch 16 validation batch 96/113: 1536/1800 mean loss: 0.0011597118573263288 score: 1.0
2021-08-08 05:25:38,356 | train | INFO | Epoch 16 validation batch 97/113: 1552/1800 mean loss: 0.0010598334483802319 score: 1.0
2021-08-08 05:25:38,608 | train | INFO | Epoch 16 validation batch 98/113: 1568/1800 mean loss: 0.0009787301532924175 score: 1.0
2021-08-08 05:25:38,841 | train | INFO | Epoch 16 validation batch 99/113: 1584/1800 mean loss: 0.0010115051409229636 score: 1.0
2021-08-08 05:25:39,074 | train | INFO | Epoch 16 validation batch 100/113: 1600/1800 mean loss: 0.0011666060891002417 score: 1.0
2021-08-08 05:25:39,305 | train | INFO | Epoch 16 validation batch 101/113: 1616/1800 mean loss: 0.0009834037628024817 score: 1.0
2021-08-08 05:25:39,536 | train | INFO | Epoch 16 validation batch 102/113: 1632/1800 mean loss: 0.0009229789138771594 score: 1.0
2021-08-08 05:25:39,767 | train | INFO | Epoch 16 validation batch 103/113: 1648/1800 mean loss: 0.0009862176375463605 score: 1.0
2021-08-08 05:25:39,997 | train | INFO | Epoch 16 validation batch 104/113: 1664/1800 mean loss: 0.001117110252380371 score: 1.0
2021-08-08 05:25:40,231 | train | INFO | Epoch 16 validation batch 105/113: 1680/1800 mean loss: 0.0010244132718071342 score: 1.0
2021-08-08 05:25:40,463 | train | INFO | Epoch 16 validation batch 106/113: 1696/1800 mean loss: 0.0010599904926493764 score: 1.0
2021-08-08 05:25:40,696 | train | INFO | Epoch 16 validation batch 107/113: 1712/1800 mean loss: 0.0012974785640835762 score: 1.0
2021-08-08 05:25:40,928 | train | INFO | Epoch 16 validation batch 108/113: 1728/1800 mean loss: 0.0011958250543102622 score: 1.0
2021-08-08 05:25:41,160 | train | INFO | Epoch 16 validation batch 109/113: 1744/1800 mean loss: 0.001143737230449915 score: 1.0
2021-08-08 05:25:41,395 | train | INFO | Epoch 16 validation batch 110/113: 1760/1800 mean loss: 0.0009326240397058427 score: 1.0
2021-08-08 05:25:41,625 | train | INFO | Epoch 16 validation batch 111/113: 1776/1800 mean loss: 0.0009520571329630911 score: 1.0
2021-08-08 05:25:41,793 | train | INFO | Epoch 16 validation batch 112/113: 1792/1800 mean loss: 0.0009366035228595138 score: 1.0
2021-08-08 05:25:41,977 | train | INFO | Epoch 16, Validation, Mean loss: 0.016414843425484358, Score: 0.9980695818150269
2021-08-08 05:25:41,977 | train | INFO | Write row 16
2021-08-08 05:25:44,035 | train | INFO | Epoch 17 train batch 0/450: 0/7200 mean loss: 0.0011882685357704759 score: 1.0
2021-08-08 05:25:44,816 | train | INFO | Epoch 17 train batch 1/450: 16/7200 mean loss: 0.0013594547053799033 score: 1.0
2021-08-08 05:25:45,640 | train | INFO | Epoch 17 train batch 2/450: 32/7200 mean loss: 0.0014295622240751982 score: 0.9963235294117647
2021-08-08 05:25:46,439 | train | INFO | Epoch 17 train batch 3/450: 48/7200 mean loss: 0.0012841306161135435 score: 0.9813725490196079
2021-08-08 05:25:47,284 | train | INFO | Epoch 17 train batch 4/450: 64/7200 mean loss: 0.0013726275647059083 score: 1.0
2021-08-08 05:25:48,087 | train | INFO | Epoch 17 train batch 5/450: 80/7200 mean loss: 0.000991867040283978 score: 1.0
2021-08-08 05:25:48,863 | train | INFO | Epoch 17 train batch 6/450: 96/7200 mean loss: 0.0015576425939798355 score: 0.9887254901960785
2021-08-08 05:25:49,741 | train | INFO | Epoch 17 train batch 7/450: 112/7200 mean loss: 0.0016449346439912915 score: 1.0
2021-08-08 05:25:50,630 | train | INFO | Epoch 17 train batch 8/450: 128/7200 mean loss: 0.0014654049882665277 score: 1.0
2021-08-08 05:25:51,526 | train | INFO | Epoch 17 train batch 9/450: 144/7200 mean loss: 0.001615769462659955 score: 1.0
2021-08-08 05:25:52,301 | train | INFO | Epoch 17 train batch 10/450: 160/7200 mean loss: 0.0013877960154786706 score: 1.0
2021-08-08 05:25:53,099 | train | INFO | Epoch 17 train batch 11/450: 176/7200 mean loss: 0.001344543881714344 score: 0.9879201680672269
2021-08-08 05:25:53,911 | train | INFO | Epoch 17 train batch 12/450: 192/7200 mean loss: 0.001421372639015317 score: 1.0
2021-08-08 05:25:54,722 | train | INFO | Epoch 17 train batch 13/450: 208/7200 mean loss: 0.0015161618357524276 score: 1.0
2021-08-08 05:25:55,546 | train | INFO | Epoch 17 train batch 14/450: 224/7200 mean loss: 0.001368384575471282 score: 1.0
2021-08-08 05:25:56,362 | train | INFO | Epoch 17 train batch 15/450: 240/7200 mean loss: 0.00143249926622957 score: 0.913935574229692
2021-08-08 05:25:57,129 | train | INFO | Epoch 17 train batch 16/450: 256/7200 mean loss: 0.0013643174897879362 score: 1.0
2021-08-08 05:25:57,901 | train | INFO | Epoch 17 train batch 17/450: 272/7200 mean loss: 0.0013618175871670246 score: 1.0
2021-08-08 05:25:58,679 | train | INFO | Epoch 17 train batch 18/450: 288/7200 mean loss: 0.0017060802783817053 score: 1.0
2021-08-08 05:25:59,500 | train | INFO | Epoch 17 train batch 19/450: 304/7200 mean loss: 0.0015485933981835842 score: 0.9963235294117647
2021-08-08 05:26:00,299 | train | INFO | Epoch 17 train batch 20/450: 320/7200 mean loss: 0.0016744921449571848 score: 0.996078431372549
2021-08-08 05:26:01,112 | train | INFO | Epoch 17 train batch 21/450: 336/7200 mean loss: 0.0013046329841017723 score: 1.0
2021-08-08 05:26:02,017 | train | INFO | Epoch 17 train batch 22/450: 352/7200 mean loss: 0.0015069767832756042 score: 1.0
2021-08-08 05:26:02,829 | train | INFO | Epoch 17 train batch 23/450: 368/7200 mean loss: 0.0013383086770772934 score: 0.996078431372549
2021-08-08 05:26:03,608 | train | INFO | Epoch 17 train batch 24/450: 384/7200 mean loss: 0.001321180840022862 score: 1.0
2021-08-08 05:26:04,416 | train | INFO | Epoch 17 train batch 25/450: 400/7200 mean loss: 0.001420167158357799 score: 1.0
2021-08-08 05:26:05,223 | train | INFO | Epoch 17 train batch 26/450: 416/7200 mean loss: 0.001426054979674518 score: 1.0
2021-08-08 05:26:06,008 | train | INFO | Epoch 17 train batch 27/450: 432/7200 mean loss: 0.0014947185991331935 score: 1.0
2021-08-08 05:26:06,815 | train | INFO | Epoch 17 train batch 28/450: 448/7200 mean loss: 0.001361366594210267 score: 1.0
2021-08-08 05:26:07,618 | train | INFO | Epoch 17 train batch 29/450: 464/7200 mean loss: 0.0014263975899666548 score: 0.996078431372549
2021-08-08 05:26:08,411 | train | INFO | Epoch 17 train batch 30/450: 480/7200 mean loss: 0.0014262881595641375 score: 1.0
2021-08-08 05:26:09,188 | train | INFO | Epoch 17 train batch 31/450: 496/7200 mean loss: 0.0014456770149990916 score: 1.0
2021-08-08 05:26:09,995 | train | INFO | Epoch 17 train batch 32/450: 512/7200 mean loss: 0.0016068076947703958 score: 1.0
2021-08-08 05:26:10,773 | train | INFO | Epoch 17 train batch 33/450: 528/7200 mean loss: 0.0014813716989010572 score: 1.0
2021-08-08 05:26:11,592 | train | INFO | Epoch 17 train batch 34/450: 544/7200 mean loss: 0.0013670853804796934 score: 0.996078431372549
2021-08-08 05:26:12,369 | train | INFO | Epoch 17 train batch 35/450: 560/7200 mean loss: 0.0016753923846408725 score: 0.9963235294117647
2021-08-08 05:26:13,191 | train | INFO | Epoch 17 train batch 36/450: 576/7200 mean loss: 0.0013573324540629983 score: 1.0
2021-08-08 05:26:13,997 | train | INFO | Epoch 17 train batch 37/450: 592/7200 mean loss: 0.0013308021007105708 score: 1.0
2021-08-08 05:26:14,768 | train | INFO | Epoch 17 train batch 38/450: 608/7200 mean loss: 0.0014880517264828086 score: 1.0
2021-08-08 05:26:15,593 | train | INFO | Epoch 17 train batch 39/450: 624/7200 mean loss: 0.0014707513619214296 score: 1.0
2021-08-08 05:26:16,375 | train | INFO | Epoch 17 train batch 40/450: 640/7200 mean loss: 0.0015655002789571881 score: 1.0
2021-08-08 05:26:17,174 | train | INFO | Epoch 17 train batch 41/450: 656/7200 mean loss: 0.001158938161097467 score: 1.0
2021-08-08 05:26:17,958 | train | INFO | Epoch 17 train batch 42/450: 672/7200 mean loss: 0.00147331936750561 score: 1.0
2021-08-08 05:26:18,781 | train | INFO | Epoch 17 train batch 43/450: 688/7200 mean loss: 0.0015241047367453575 score: 1.0
2021-08-08 05:26:19,577 | train | INFO | Epoch 17 train batch 44/450: 704/7200 mean loss: 0.0013448774116113782 score: 1.0
2021-08-08 05:26:20,353 | train | INFO | Epoch 17 train batch 45/450: 720/7200 mean loss: 0.0013179737143218517 score: 1.0
2021-08-08 05:26:21,127 | train | INFO | Epoch 17 train batch 46/450: 736/7200 mean loss: 0.001467641443014145 score: 1.0
2021-08-08 05:26:21,937 | train | INFO | Epoch 17 train batch 47/450: 752/7200 mean loss: 0.001231592264957726 score: 1.0
2021-08-08 05:26:22,721 | train | INFO | Epoch 17 train batch 48/450: 768/7200 mean loss: 0.0013754318933933973 score: 1.0
2021-08-08 05:26:23,521 | train | INFO | Epoch 17 train batch 49/450: 784/7200 mean loss: 0.0012141027254983783 score: 1.0
2021-08-08 05:26:24,326 | train | INFO | Epoch 17 train batch 50/450: 800/7200 mean loss: 0.0012596120359376073 score: 1.0
2021-08-08 05:26:25,127 | train | INFO | Epoch 17 train batch 51/450: 816/7200 mean loss: 0.001115325721912086 score: 1.0
2021-08-08 05:26:25,915 | train | INFO | Epoch 17 train batch 52/450: 832/7200 mean loss: 0.00131163967307657 score: 1.0
2021-08-08 05:26:26,787 | train | INFO | Epoch 17 train batch 53/450: 848/7200 mean loss: 0.0011952273780480027 score: 0.9924019607843138
2021-08-08 05:26:27,612 | train | INFO | Epoch 17 train batch 54/450: 864/7200 mean loss: 0.0012014388339594007 score: 1.0
2021-08-08 05:26:28,401 | train | INFO | Epoch 17 train batch 55/450: 880/7200 mean loss: 0.001148306648246944 score: 0.9963235294117647
2021-08-08 05:26:29,214 | train | INFO | Epoch 17 train batch 56/450: 896/7200 mean loss: 0.001467183348722756 score: 1.0
2021-08-08 05:26:30,011 | train | INFO | Epoch 17 train batch 57/450: 912/7200 mean loss: 0.0012260294752195477 score: 1.0
2021-08-08 05:26:30,819 | train | INFO | Epoch 17 train batch 58/450: 928/7200 mean loss: 0.0015658414922654629 score: 1.0
2021-08-08 05:26:31,597 | train | INFO | Epoch 17 train batch 59/450: 944/7200 mean loss: 0.0013091739965602756 score: 1.0
2021-08-08 05:26:32,398 | train | INFO | Epoch 17 train batch 60/450: 960/7200 mean loss: 0.00168245704844594 score: 0.9963235294117647
2021-08-08 05:26:33,186 | train | INFO | Epoch 17 train batch 61/450: 976/7200 mean loss: 0.001603212091140449 score: 1.0
2021-08-08 05:26:33,985 | train | INFO | Epoch 17 train batch 62/450: 992/7200 mean loss: 0.0014654453843832016 score: 0.9926470588235294
2021-08-08 05:26:34,795 | train | INFO | Epoch 17 train batch 63/450: 1008/7200 mean loss: 0.0014537308597937226 score: 1.0
2021-08-08 05:26:35,611 | train | INFO | Epoch 17 train batch 64/450: 1024/7200 mean loss: 0.0015088097425177693 score: 1.0
2021-08-08 05:26:36,411 | train | INFO | Epoch 17 train batch 65/450: 1040/7200 mean loss: 0.0015546230133622885 score: 1.0
2021-08-08 05:26:37,198 | train | INFO | Epoch 17 train batch 66/450: 1056/7200 mean loss: 0.0011352482251822948 score: 1.0
2021-08-08 05:26:37,996 | train | INFO | Epoch 17 train batch 67/450: 1072/7200 mean loss: 0.001410850090906024 score: 0.9622549019607843
2021-08-08 05:26:38,777 | train | INFO | Epoch 17 train batch 68/450: 1088/7200 mean loss: 0.0013250684132799506 score: 1.0
2021-08-08 05:26:39,569 | train | INFO | Epoch 17 train batch 69/450: 1104/7200 mean loss: 0.0014198219869285822 score: 1.0
2021-08-08 05:26:40,382 | train | INFO | Epoch 17 train batch 70/450: 1120/7200 mean loss: 0.001311226631514728 score: 1.0
2021-08-08 05:26:41,168 | train | INFO | Epoch 17 train batch 71/450: 1136/7200 mean loss: 0.0013242181157693267 score: 0.9963235294117647
2021-08-08 05:26:41,952 | train | INFO | Epoch 17 train batch 72/450: 1152/7200 mean loss: 0.0012348918244242668 score: 1.0
2021-08-08 05:26:42,762 | train | INFO | Epoch 17 train batch 73/450: 1168/7200 mean loss: 0.001093460014089942 score: 1.0
2021-08-08 05:26:43,529 | train | INFO | Epoch 17 train batch 74/450: 1184/7200 mean loss: 0.001381774083711207 score: 0.8786764705882353
2021-08-08 05:26:44,336 | train | INFO | Epoch 17 train batch 75/450: 1200/7200 mean loss: 0.0013237320818006992 score: 0.9963235294117647
2021-08-08 05:26:45,141 | train | INFO | Epoch 17 train batch 76/450: 1216/7200 mean loss: 0.0014072502963244915 score: 0.9963235294117647
2021-08-08 05:26:45,945 | train | INFO | Epoch 17 train batch 77/450: 1232/7200 mean loss: 0.0013167117722332478 score: 1.0
2021-08-08 05:26:46,762 | train | INFO | Epoch 17 train batch 78/450: 1248/7200 mean loss: 0.0015471617225557566 score: 1.0
2021-08-08 05:26:47,540 | train | INFO | Epoch 17 train batch 79/450: 1264/7200 mean loss: 0.0013611692702397704 score: 0.9850490196078432
2021-08-08 05:26:48,320 | train | INFO | Epoch 17 train batch 80/450: 1280/7200 mean loss: 0.0013456953456625342 score: 1.0
2021-08-08 05:26:49,126 | train | INFO | Epoch 17 train batch 81/450: 1296/7200 mean loss: 0.0013899027835577726 score: 1.0
2021-08-08 05:26:49,950 | train | INFO | Epoch 17 train batch 82/450: 1312/7200 mean loss: 0.0013019891921430826 score: 0.9921568627450981
2021-08-08 05:26:50,768 | train | INFO | Epoch 17 train batch 83/450: 1328/7200 mean loss: 0.0016536032781004906 score: 0.9963235294117647
2021-08-08 05:26:51,578 | train | INFO | Epoch 17 train batch 84/450: 1344/7200 mean loss: 0.001273039379157126 score: 1.0
2021-08-08 05:26:52,404 | train | INFO | Epoch 17 train batch 85/450: 1360/7200 mean loss: 0.0011991321807727218 score: 0.996078431372549
2021-08-08 05:26:53,182 | train | INFO | Epoch 17 train batch 86/450: 1376/7200 mean loss: 0.001332675339654088 score: 1.0
2021-08-08 05:26:53,962 | train | INFO | Epoch 17 train batch 87/450: 1392/7200 mean loss: 0.0014260105090215802 score: 1.0
2021-08-08 05:26:54,783 | train | INFO | Epoch 17 train batch 88/450: 1408/7200 mean loss: 0.0012151214759796858 score: 1.0
2021-08-08 05:26:55,569 | train | INFO | Epoch 17 train batch 89/450: 1424/7200 mean loss: 0.0010180814424529672 score: 1.0
2021-08-08 05:26:56,342 | train | INFO | Epoch 17 train batch 90/450: 1440/7200 mean loss: 0.0013185787247493863 score: 1.0
2021-08-08 05:26:57,122 | train | INFO | Epoch 17 train batch 91/450: 1456/7200 mean loss: 0.0016312535153701901 score: 0.8183823529411764
2021-08-08 05:26:57,911 | train | INFO | Epoch 17 train batch 92/450: 1472/7200 mean loss: 0.0015329673187807202 score: 0.9963235294117647
2021-08-08 05:26:58,702 | train | INFO | Epoch 17 train batch 93/450: 1488/7200 mean loss: 0.0012890396174043417 score: 1.0
2021-08-08 05:26:59,510 | train | INFO | Epoch 17 train batch 94/450: 1504/7200 mean loss: 0.001332905376330018 score: 1.0
2021-08-08 05:27:00,302 | train | INFO | Epoch 17 train batch 95/450: 1520/7200 mean loss: 0.0014250949025154114 score: 1.0
2021-08-08 05:27:01,104 | train | INFO | Epoch 17 train batch 96/450: 1536/7200 mean loss: 0.0013250695774331689 score: 0.9926470588235294
2021-08-08 05:27:01,903 | train | INFO | Epoch 17 train batch 97/450: 1552/7200 mean loss: 0.001271213754080236 score: 1.0
2021-08-08 05:27:02,692 | train | INFO | Epoch 17 train batch 98/450: 1568/7200 mean loss: 0.0013077212497591972 score: 0.9808823529411765
2021-08-08 05:27:03,508 | train | INFO | Epoch 17 train batch 99/450: 1584/7200 mean loss: 0.0014978050021454692 score: 1.0
2021-08-08 05:27:04,298 | train | INFO | Epoch 17 train batch 100/450: 1600/7200 mean loss: 0.0015620350604876876 score: 1.0
2021-08-08 05:27:05,112 | train | INFO | Epoch 17 train batch 101/450: 1616/7200 mean loss: 0.0013763069873675704 score: 1.0
2021-08-08 05:27:05,898 | train | INFO | Epoch 17 train batch 102/450: 1632/7200 mean loss: 0.0014478773809969425 score: 1.0
2021-08-08 05:27:06,713 | train | INFO | Epoch 17 train batch 103/450: 1648/7200 mean loss: 0.0012756383512169123 score: 1.0
2021-08-08 05:27:07,488 | train | INFO | Epoch 17 train batch 104/450: 1664/7200 mean loss: 0.0012998927850276232 score: 1.0
2021-08-08 05:27:08,333 | train | INFO | Epoch 17 train batch 105/450: 1680/7200 mean loss: 0.0010860785841941833 score: 1.0
2021-08-08 05:27:09,139 | train | INFO | Epoch 17 train batch 106/450: 1696/7200 mean loss: 0.001323164557106793 score: 1.0
2021-08-08 05:27:09,975 | train | INFO | Epoch 17 train batch 107/450: 1712/7200 mean loss: 0.001610631006769836 score: 1.0
2021-08-08 05:27:10,752 | train | INFO | Epoch 17 train batch 108/450: 1728/7200 mean loss: 0.001531259506009519 score: 1.0
2021-08-08 05:27:11,524 | train | INFO | Epoch 17 train batch 109/450: 1744/7200 mean loss: 0.0015750691527500749 score: 0.9240196078431373
2021-08-08 05:27:12,330 | train | INFO | Epoch 17 train batch 110/450: 1760/7200 mean loss: 0.0016357593704015017 score: 1.0
2021-08-08 05:27:13,105 | train | INFO | Epoch 17 train batch 111/450: 1776/7200 mean loss: 0.0015214727027341723 score: 1.0
2021-08-08 05:27:13,912 | train | INFO | Epoch 17 train batch 112/450: 1792/7200 mean loss: 0.001390449469909072 score: 1.0
2021-08-08 05:27:14,710 | train | INFO | Epoch 17 train batch 113/450: 1808/7200 mean loss: 0.0015930079389363527 score: 1.0
2021-08-08 05:27:15,610 | train | INFO | Epoch 17 train batch 114/450: 1824/7200 mean loss: 0.0012042188318446279 score: 1.0
2021-08-08 05:27:16,412 | train | INFO | Epoch 17 train batch 115/450: 1840/7200 mean loss: 0.001197243225760758 score: 1.0
2021-08-08 05:27:17,250 | train | INFO | Epoch 17 train batch 116/450: 1856/7200 mean loss: 0.0013164954725652933 score: 1.0
2021-08-08 05:27:18,091 | train | INFO | Epoch 17 train batch 117/450: 1872/7200 mean loss: 0.0015540474560111761 score: 1.0
2021-08-08 05:27:18,909 | train | INFO | Epoch 17 train batch 118/450: 1888/7200 mean loss: 0.0013540842337533832 score: 0.9779411764705882
2021-08-08 05:27:19,693 | train | INFO | Epoch 17 train batch 119/450: 1904/7200 mean loss: 0.0010893195867538452 score: 1.0
2021-08-08 05:27:20,584 | train | INFO | Epoch 17 train batch 120/450: 1920/7200 mean loss: 0.0013656718656420708 score: 0.9852941176470589
2021-08-08 05:27:21,491 | train | INFO | Epoch 17 train batch 121/450: 1936/7200 mean loss: 0.001466757501475513 score: 1.0
2021-08-08 05:27:22,267 | train | INFO | Epoch 17 train batch 122/450: 1952/7200 mean loss: 0.0012856349349021912 score: 0.9963235294117647
2021-08-08 05:27:23,058 | train | INFO | Epoch 17 train batch 123/450: 1968/7200 mean loss: 0.0014564644079655409 score: 0.996078431372549
2021-08-08 05:27:23,836 | train | INFO | Epoch 17 train batch 124/450: 1984/7200 mean loss: 0.0013128452701494098 score: 0.9963235294117647
2021-08-08 05:27:24,745 | train | INFO | Epoch 17 train batch 125/450: 2000/7200 mean loss: 0.001373344217427075 score: 1.0
2021-08-08 05:27:25,547 | train | INFO | Epoch 17 train batch 126/450: 2016/7200 mean loss: 0.0012768723536282778 score: 0.9889705882352942
2021-08-08 05:27:26,336 | train | INFO | Epoch 17 train batch 127/450: 2032/7200 mean loss: 0.001243688864633441 score: 0.9963235294117647
2021-08-08 05:27:27,145 | train | INFO | Epoch 17 train batch 128/450: 2048/7200 mean loss: 0.001257945317775011 score: 1.0
2021-08-08 05:27:27,929 | train | INFO | Epoch 17 train batch 129/450: 2064/7200 mean loss: 0.0013858183519914746 score: 1.0
2021-08-08 05:27:28,707 | train | INFO | Epoch 17 train batch 130/450: 2080/7200 mean loss: 0.0014363510999828577 score: 1.0
2021-08-08 05:27:29,512 | train | INFO | Epoch 17 train batch 131/450: 2096/7200 mean loss: 0.0013214044738560915 score: 0.9889705882352942
2021-08-08 05:27:30,285 | train | INFO | Epoch 17 train batch 132/450: 2112/7200 mean loss: 0.0013073786394670606 score: 1.0
2021-08-08 05:27:31,074 | train | INFO | Epoch 17 train batch 133/450: 2128/7200 mean loss: 0.0011954375077039003 score: 0.987028657616893
2021-08-08 05:27:31,900 | train | INFO | Epoch 17 train batch 134/450: 2144/7200 mean loss: 0.001335426582954824 score: 1.0
2021-08-08 05:27:32,682 | train | INFO | Epoch 17 train batch 135/450: 2160/7200 mean loss: 0.001182530540972948 score: 1.0
2021-08-08 05:27:33,458 | train | INFO | Epoch 17 train batch 136/450: 2176/7200 mean loss: 0.001208373112604022 score: 1.0
2021-08-08 05:27:34,275 | train | INFO | Epoch 17 train batch 137/450: 2192/7200 mean loss: 0.001352157793007791 score: 1.0
2021-08-08 05:27:35,077 | train | INFO | Epoch 17 train batch 138/450: 2208/7200 mean loss: 0.0012384915025904775 score: 1.0
2021-08-08 05:27:35,888 | train | INFO | Epoch 17 train batch 139/450: 2224/7200 mean loss: 0.0010887942044064403 score: 1.0
2021-08-08 05:27:36,700 | train | INFO | Epoch 17 train batch 140/450: 2240/7200 mean loss: 0.001421246211975813 score: 0.9700630252100839
2021-08-08 05:27:37,485 | train | INFO | Epoch 17 train batch 141/450: 2256/7200 mean loss: 0.0012259648647159338 score: 1.0
2021-08-08 05:27:38,290 | train | INFO | Epoch 17 train batch 142/450: 2272/7200 mean loss: 0.0014840115327388048 score: 1.0
2021-08-08 05:27:39,093 | train | INFO | Epoch 17 train batch 143/450: 2288/7200 mean loss: 0.0013257325626909733 score: 1.0
2021-08-08 05:27:39,974 | train | INFO | Epoch 17 train batch 144/450: 2304/7200 mean loss: 0.001469917711801827 score: 1.0
2021-08-08 05:27:40,793 | train | INFO | Epoch 17 train batch 145/450: 2320/7200 mean loss: 0.001491985865868628 score: 1.0
2021-08-08 05:27:41,564 | train | INFO | Epoch 17 train batch 146/450: 2336/7200 mean loss: 0.0012642010115087032 score: 1.0
2021-08-08 05:27:42,369 | train | INFO | Epoch 17 train batch 147/450: 2352/7200 mean loss: 0.0012517942814156413 score: 1.0
2021-08-08 05:27:43,157 | train | INFO | Epoch 17 train batch 148/450: 2368/7200 mean loss: 0.001524279941804707 score: 1.0
2021-08-08 05:27:43,963 | train | INFO | Epoch 17 train batch 149/450: 2384/7200 mean loss: 0.001443646615371108 score: 0.9887254901960785
2021-08-08 05:27:44,741 | train | INFO | Epoch 17 train batch 150/450: 2400/7200 mean loss: 0.0016609536251053214 score: 1.0
2021-08-08 05:27:45,520 | train | INFO | Epoch 17 train batch 151/450: 2416/7200 mean loss: 0.0014577015535905957 score: 0.996078431372549
2021-08-08 05:27:46,330 | train | INFO | Epoch 17 train batch 152/450: 2432/7200 mean loss: 0.0012827332830056548 score: 1.0
2021-08-08 05:27:47,154 | train | INFO | Epoch 17 train batch 153/450: 2448/7200 mean loss: 0.001641355687752366 score: 1.0
2021-08-08 05:27:47,992 | train | INFO | Epoch 17 train batch 154/450: 2464/7200 mean loss: 0.0013863940257579088 score: 1.0
2021-08-08 05:27:48,823 | train | INFO | Epoch 17 train batch 155/450: 2480/7200 mean loss: 0.001397435669787228 score: 1.0
2021-08-08 05:27:49,602 | train | INFO | Epoch 17 train batch 156/450: 2496/7200 mean loss: 0.0014439895749092102 score: 1.0
2021-08-08 05:27:50,409 | train | INFO | Epoch 17 train batch 157/450: 2512/7200 mean loss: 0.0012694423785433173 score: 1.0
2021-08-08 05:27:51,246 | train | INFO | Epoch 17 train batch 158/450: 2528/7200 mean loss: 0.0015347856096923351 score: 0.9705882352941176
2021-08-08 05:27:52,052 | train | INFO | Epoch 17 train batch 159/450: 2544/7200 mean loss: 0.0014257939765229821 score: 1.0
2021-08-08 05:27:52,876 | train | INFO | Epoch 17 train batch 160/450: 2560/7200 mean loss: 0.0014707517111673951 score: 1.0
2021-08-08 05:27:53,684 | train | INFO | Epoch 17 train batch 161/450: 2576/7200 mean loss: 0.0016681966371834278 score: 1.0
2021-08-08 05:27:54,502 | train | INFO | Epoch 17 train batch 162/450: 2592/7200 mean loss: 0.001407938078045845 score: 1.0
2021-08-08 05:27:55,301 | train | INFO | Epoch 17 train batch 163/450: 2608/7200 mean loss: 0.0016001439653337002 score: 1.0
2021-08-08 05:27:56,129 | train | INFO | Epoch 17 train batch 164/450: 2624/7200 mean loss: 0.0014819472562521696 score: 1.0
2021-08-08 05:27:56,936 | train | INFO | Epoch 17 train batch 165/450: 2640/7200 mean loss: 0.0012743968982249498 score: 1.0
2021-08-08 05:27:57,817 | train | INFO | Epoch 17 train batch 166/450: 2656/7200 mean loss: 0.0015404527075588703 score: 1.0
2021-08-08 05:27:58,637 | train | INFO | Epoch 17 train batch 167/450: 2672/7200 mean loss: 0.0015987210208550096 score: 1.0
2021-08-08 05:27:59,415 | train | INFO | Epoch 17 train batch 168/450: 2688/7200 mean loss: 0.0015338468365371227 score: 1.0
2021-08-08 05:28:00,229 | train | INFO | Epoch 17 train batch 169/450: 2704/7200 mean loss: 0.001390813966281712 score: 0.9921568627450981
2021-08-08 05:28:00,997 | train | INFO | Epoch 17 train batch 170/450: 2720/7200 mean loss: 0.0011807483388110995 score: 1.0
2021-08-08 05:28:01,830 | train | INFO | Epoch 17 train batch 171/450: 2736/7200 mean loss: 0.0012864135205745697 score: 1.0
2021-08-08 05:28:02,621 | train | INFO | Epoch 17 train batch 172/450: 2752/7200 mean loss: 0.0014129811897873878 score: 0.996078431372549
2021-08-08 05:28:03,409 | train | INFO | Epoch 17 train batch 173/450: 2768/7200 mean loss: 0.001237024087458849 score: 1.0
2021-08-08 05:28:04,232 | train | INFO | Epoch 17 train batch 174/450: 2784/7200 mean loss: 0.0014156142715364695 score: 1.0
2021-08-08 05:28:05,005 | train | INFO | Epoch 17 train batch 175/450: 2800/7200 mean loss: 0.0014056265354156494 score: 1.0
2021-08-08 05:28:05,785 | train | INFO | Epoch 17 train batch 176/450: 2816/7200 mean loss: 0.0015021424042060971 score: 0.9926470588235294
2021-08-08 05:28:06,582 | train | INFO | Epoch 17 train batch 177/450: 2832/7200 mean loss: 0.0014110520714893937 score: 1.0
2021-08-08 05:28:07,391 | train | INFO | Epoch 17 train batch 178/450: 2848/7200 mean loss: 0.0013727742480114102 score: 0.9811274509803922
2021-08-08 05:28:08,183 | train | INFO | Epoch 17 train batch 179/450: 2864/7200 mean loss: 0.0013404313940554857 score: 0.996078431372549
2021-08-08 05:28:08,986 | train | INFO | Epoch 17 train batch 180/450: 2880/7200 mean loss: 0.0014356770552694798 score: 1.0
2021-08-08 05:28:09,779 | train | INFO | Epoch 17 train batch 181/450: 2896/7200 mean loss: 0.0013497205218300223 score: 1.0
2021-08-08 05:28:10,588 | train | INFO | Epoch 17 train batch 182/450: 2912/7200 mean loss: 0.0015191886341199279 score: 1.0
2021-08-08 05:28:11,403 | train | INFO | Epoch 17 train batch 183/450: 2928/7200 mean loss: 0.0014748246176168323 score: 1.0
2021-08-08 05:28:12,202 | train | INFO | Epoch 17 train batch 184/450: 2944/7200 mean loss: 0.001414747559465468 score: 0.996078431372549
2021-08-08 05:28:13,006 | train | INFO | Epoch 17 train batch 185/450: 2960/7200 mean loss: 0.001284235273487866 score: 0.9758403361344539
2021-08-08 05:28:13,816 | train | INFO | Epoch 17 train batch 186/450: 2976/7200 mean loss: 0.0014223726466298103 score: 0.9737745098039216
2021-08-08 05:28:14,650 | train | INFO | Epoch 17 train batch 187/450: 2992/7200 mean loss: 0.001347799552604556 score: 1.0
2021-08-08 05:28:15,473 | train | INFO | Epoch 17 train batch 188/450: 3008/7200 mean loss: 0.001463727094233036 score: 0.9852941176470589
2021-08-08 05:28:16,253 | train | INFO | Epoch 17 train batch 189/450: 3024/7200 mean loss: 0.0017783184302970767 score: 1.0
2021-08-08 05:28:17,037 | train | INFO | Epoch 17 train batch 190/450: 3040/7200 mean loss: 0.0014251322718337178 score: 1.0
2021-08-08 05:28:17,840 | train | INFO | Epoch 17 train batch 191/450: 3056/7200 mean loss: 0.0014979781117290258 score: 1.0
2021-08-08 05:28:18,654 | train | INFO | Epoch 17 train batch 192/450: 3072/7200 mean loss: 0.0014266399666666985 score: 1.0
2021-08-08 05:28:19,426 | train | INFO | Epoch 17 train batch 193/450: 3088/7200 mean loss: 0.0015746798599138856 score: 1.0
2021-08-08 05:28:20,272 | train | INFO | Epoch 17 train batch 194/450: 3104/7200 mean loss: 0.001437716418877244 score: 1.0
2021-08-08 05:28:21,073 | train | INFO | Epoch 17 train batch 195/450: 3120/7200 mean loss: 0.0012421021237969398 score: 1.0
2021-08-08 05:28:21,870 | train | INFO | Epoch 17 train batch 196/450: 3136/7200 mean loss: 0.0013607667060568929 score: 0.9963235294117647
2021-08-08 05:28:22,743 | train | INFO | Epoch 17 train batch 197/450: 3152/7200 mean loss: 0.0014312213752418756 score: 1.0
2021-08-08 05:28:23,533 | train | INFO | Epoch 17 train batch 198/450: 3168/7200 mean loss: 0.0013403799384832382 score: 0.9847689075630254
2021-08-08 05:28:24,313 | train | INFO | Epoch 17 train batch 199/450: 3184/7200 mean loss: 0.0014301615301519632 score: 1.0
2021-08-08 05:28:25,110 | train | INFO | Epoch 17 train batch 200/450: 3200/7200 mean loss: 0.0013260047417134047 score: 1.0
2021-08-08 05:28:25,876 | train | INFO | Epoch 17 train batch 201/450: 3216/7200 mean loss: 0.0014852865133434534 score: 1.0
2021-08-08 05:28:26,675 | train | INFO | Epoch 17 train batch 202/450: 3232/7200 mean loss: 0.0012813369976356626 score: 1.0
2021-08-08 05:28:27,478 | train | INFO | Epoch 17 train batch 203/450: 3248/7200 mean loss: 0.0015873349038884044 score: 1.0
2021-08-08 05:28:28,252 | train | INFO | Epoch 17 train batch 204/450: 3264/7200 mean loss: 0.001229642191901803 score: 0.9963235294117647
2021-08-08 05:28:29,061 | train | INFO | Epoch 17 train batch 205/450: 3280/7200 mean loss: 0.001362640643492341 score: 0.996078431372549
2021-08-08 05:28:29,859 | train | INFO | Epoch 17 train batch 206/450: 3296/7200 mean loss: 0.0013878830941393971 score: 1.0
2021-08-08 05:28:30,638 | train | INFO | Epoch 17 train batch 207/450: 3312/7200 mean loss: 0.0013562473468482494 score: 1.0
2021-08-08 05:28:31,442 | train | INFO | Epoch 17 train batch 208/450: 3328/7200 mean loss: 0.001484924228861928 score: 1.0
2021-08-08 05:28:32,229 | train | INFO | Epoch 17 train batch 209/450: 3344/7200 mean loss: 0.0014276313595473766 score: 1.0
2021-08-08 05:28:33,008 | train | INFO | Epoch 17 train batch 210/450: 3360/7200 mean loss: 0.0014725485816597939 score: 0.9779411764705882
2021-08-08 05:28:33,784 | train | INFO | Epoch 17 train batch 211/450: 3376/7200 mean loss: 0.001490331836976111 score: 1.0
2021-08-08 05:28:34,594 | train | INFO | Epoch 17 train batch 212/450: 3392/7200 mean loss: 0.0016290707280859351 score: 0.9705882352941176
2021-08-08 05:28:35,387 | train | INFO | Epoch 17 train batch 213/450: 3408/7200 mean loss: 0.0013945366954430938 score: 1.0
2021-08-08 05:28:36,212 | train | INFO | Epoch 17 train batch 214/450: 3424/7200 mean loss: 0.0016069053672254086 score: 1.0
2021-08-08 05:28:37,027 | train | INFO | Epoch 17 train batch 215/450: 3440/7200 mean loss: 0.0015741161769255996 score: 1.0
2021-08-08 05:28:37,799 | train | INFO | Epoch 17 train batch 216/450: 3456/7200 mean loss: 0.0015908594941720366 score: 1.0
2021-08-08 05:28:38,614 | train | INFO | Epoch 17 train batch 217/450: 3472/7200 mean loss: 0.0015807704767212272 score: 1.0
2021-08-08 05:28:39,430 | train | INFO | Epoch 17 train batch 218/450: 3488/7200 mean loss: 0.0015093015972524881 score: 0.9811274509803922
2021-08-08 05:28:40,242 | train | INFO | Epoch 17 train batch 219/450: 3504/7200 mean loss: 0.001571431290358305 score: 1.0
2021-08-08 05:28:41,019 | train | INFO | Epoch 17 train batch 220/450: 3520/7200 mean loss: 0.0015726510901004076 score: 1.0
2021-08-08 05:28:41,820 | train | INFO | Epoch 17 train batch 221/450: 3536/7200 mean loss: 0.001502720289863646 score: 1.0
2021-08-08 05:28:42,594 | train | INFO | Epoch 17 train batch 222/450: 3552/7200 mean loss: 0.001412008423358202 score: 1.0
2021-08-08 05:28:43,415 | train | INFO | Epoch 17 train batch 223/450: 3568/7200 mean loss: 0.001157845021225512 score: 1.0
2021-08-08 05:28:44,237 | train | INFO | Epoch 17 train batch 224/450: 3584/7200 mean loss: 0.001297428971156478 score: 1.0
2021-08-08 05:28:45,051 | train | INFO | Epoch 17 train batch 225/450: 3600/7200 mean loss: 0.0014777188189327717 score: 1.0
2021-08-08 05:28:45,866 | train | INFO | Epoch 17 train batch 226/450: 3616/7200 mean loss: 0.0014140598941594362 score: 1.0
2021-08-08 05:28:46,678 | train | INFO | Epoch 17 train batch 227/450: 3632/7200 mean loss: 0.0012624806258827448 score: 0.9848039215686275
2021-08-08 05:28:47,475 | train | INFO | Epoch 17 train batch 228/450: 3648/7200 mean loss: 0.0013729834463447332 score: 0.9889705882352942
2021-08-08 05:28:48,296 | train | INFO | Epoch 17 train batch 229/450: 3664/7200 mean loss: 0.0012694238685071468 score: 0.9529411764705882
2021-08-08 05:28:49,070 | train | INFO | Epoch 17 train batch 230/450: 3680/7200 mean loss: 0.0013273387448862195 score: 0.9487583494936436
2021-08-08 05:28:49,891 | train | INFO | Epoch 17 train batch 231/450: 3696/7200 mean loss: 0.0013108173152431846 score: 1.0
2021-08-08 05:28:50,709 | train | INFO | Epoch 17 train batch 232/450: 3712/7200 mean loss: 0.0011704390635713935 score: 1.0
2021-08-08 05:28:51,484 | train | INFO | Epoch 17 train batch 233/450: 3728/7200 mean loss: 0.001332937623374164 score: 1.0
2021-08-08 05:28:52,330 | train | INFO | Epoch 17 train batch 234/450: 3744/7200 mean loss: 0.0011729745892807841 score: 1.0
2021-08-08 05:28:53,133 | train | INFO | Epoch 17 train batch 235/450: 3760/7200 mean loss: 0.0014071145560592413 score: 1.0
2021-08-08 05:28:53,909 | train | INFO | Epoch 17 train batch 236/450: 3776/7200 mean loss: 0.0013047803658992052 score: 0.996078431372549
2021-08-08 05:28:54,682 | train | INFO | Epoch 17 train batch 237/450: 3792/7200 mean loss: 0.0010385747300460935 score: 1.0
2021-08-08 05:28:55,448 | train | INFO | Epoch 17 train batch 238/450: 3808/7200 mean loss: 0.001119653694331646 score: 1.0
2021-08-08 05:28:56,258 | train | INFO | Epoch 17 train batch 239/450: 3824/7200 mean loss: 0.0010808733059093356 score: 1.0
2021-08-08 05:28:57,073 | train | INFO | Epoch 17 train batch 240/450: 3840/7200 mean loss: 0.0017039955127984285 score: 1.0
2021-08-08 05:28:57,858 | train | INFO | Epoch 17 train batch 241/450: 3856/7200 mean loss: 0.0014806668041273952 score: 1.0
2021-08-08 05:28:58,669 | train | INFO | Epoch 17 train batch 242/450: 3872/7200 mean loss: 0.0012622660724446177 score: 0.9852941176470589
2021-08-08 05:28:59,489 | train | INFO | Epoch 17 train batch 243/450: 3888/7200 mean loss: 0.001538277487270534 score: 0.996078431372549
2021-08-08 05:29:00,274 | train | INFO | Epoch 17 train batch 244/450: 3904/7200 mean loss: 0.001434073317795992 score: 1.0
2021-08-08 05:29:01,055 | train | INFO | Epoch 17 train batch 245/450: 3920/7200 mean loss: 0.001271268236450851 score: 1.0
2021-08-08 05:29:01,855 | train | INFO | Epoch 17 train batch 246/450: 3936/7200 mean loss: 0.001580326701514423 score: 0.9705882352941176
2021-08-08 05:29:02,663 | train | INFO | Epoch 17 train batch 247/450: 3952/7200 mean loss: 0.0012020822614431381 score: 1.0
2021-08-08 05:29:03,505 | train | INFO | Epoch 17 train batch 248/450: 3968/7200 mean loss: 0.001359034446068108 score: 0.9963235294117647
2021-08-08 05:29:04,314 | train | INFO | Epoch 17 train batch 249/450: 3984/7200 mean loss: 0.0013846945948898792 score: 0.9887254901960785
2021-08-08 05:29:05,092 | train | INFO | Epoch 17 train batch 250/450: 4000/7200 mean loss: 0.0014426272828131914 score: 1.0
2021-08-08 05:29:05,878 | train | INFO | Epoch 17 train batch 251/450: 4016/7200 mean loss: 0.0014332914724946022 score: 1.0
2021-08-08 05:29:06,653 | train | INFO | Epoch 17 train batch 252/450: 4032/7200 mean loss: 0.0012277965433895588 score: 1.0
2021-08-08 05:29:07,480 | train | INFO | Epoch 17 train batch 253/450: 4048/7200 mean loss: 0.0012494225520640612 score: 1.0
2021-08-08 05:29:08,300 | train | INFO | Epoch 17 train batch 254/450: 4064/7200 mean loss: 0.0013117709895595908 score: 1.0
2021-08-08 05:29:09,076 | train | INFO | Epoch 17 train batch 255/450: 4080/7200 mean loss: 0.001443793997168541 score: 1.0
2021-08-08 05:29:09,856 | train | INFO | Epoch 17 train batch 256/450: 4096/7200 mean loss: 0.0015584053471684456 score: 1.0
2021-08-08 05:29:10,659 | train | INFO | Epoch 17 train batch 257/450: 4112/7200 mean loss: 0.0013977678027004004 score: 1.0
2021-08-08 05:29:11,504 | train | INFO | Epoch 17 train batch 258/450: 4128/7200 mean loss: 0.0015333343762904406 score: 1.0
2021-08-08 05:29:12,281 | train | INFO | Epoch 17 train batch 259/450: 4144/7200 mean loss: 0.0013653646456077695 score: 1.0
2021-08-08 05:29:13,113 | train | INFO | Epoch 17 train batch 260/450: 4160/7200 mean loss: 0.0012661280343309045 score: 1.0
2021-08-08 05:29:13,912 | train | INFO | Epoch 17 train batch 261/450: 4176/7200 mean loss: 0.001438357518054545 score: 0.9963235294117647
2021-08-08 05:29:14,726 | train | INFO | Epoch 17 train batch 262/450: 4192/7200 mean loss: 0.0013225612929090858 score: 1.0
2021-08-08 05:29:15,572 | train | INFO | Epoch 17 train batch 263/450: 4208/7200 mean loss: 0.0013079149648547173 score: 1.0
2021-08-08 05:29:16,402 | train | INFO | Epoch 17 train batch 264/450: 4224/7200 mean loss: 0.0012041504960507154 score: 0.9963235294117647
2021-08-08 05:29:17,184 | train | INFO | Epoch 17 train batch 265/450: 4240/7200 mean loss: 0.0012922665337100625 score: 1.0
2021-08-08 05:29:18,038 | train | INFO | Epoch 17 train batch 266/450: 4256/7200 mean loss: 0.0013520732754841447 score: 1.0
2021-08-08 05:29:18,860 | train | INFO | Epoch 17 train batch 267/450: 4272/7200 mean loss: 0.0014372910372912884 score: 0.995798319327731
2021-08-08 05:29:19,634 | train | INFO | Epoch 17 train batch 268/450: 4288/7200 mean loss: 0.001373136998154223 score: 0.9963235294117647
2021-08-08 05:29:20,429 | train | INFO | Epoch 17 train batch 269/450: 4304/7200 mean loss: 0.0013606258435174823 score: 1.0
2021-08-08 05:29:21,208 | train | INFO | Epoch 17 train batch 270/450: 4320/7200 mean loss: 0.0017962405690923333 score: 1.0
2021-08-08 05:29:21,996 | train | INFO | Epoch 17 train batch 271/450: 4336/7200 mean loss: 0.0015545436181128025 score: 1.0
2021-08-08 05:29:22,793 | train | INFO | Epoch 17 train batch 272/450: 4352/7200 mean loss: 0.001331106759607792 score: 1.0
2021-08-08 05:29:23,568 | train | INFO | Epoch 17 train batch 273/450: 4368/7200 mean loss: 0.001467404537834227 score: 1.0
2021-08-08 05:29:24,345 | train | INFO | Epoch 17 train batch 274/450: 4384/7200 mean loss: 0.0015787346055731177 score: 1.0
2021-08-08 05:29:25,122 | train | INFO | Epoch 17 train batch 275/450: 4400/7200 mean loss: 0.0014216676354408264 score: 0.9963235294117647
2021-08-08 05:29:25,898 | train | INFO | Epoch 17 train batch 276/450: 4416/7200 mean loss: 0.0012945934431627393 score: 0.9926470588235294
2021-08-08 05:29:26,684 | train | INFO | Epoch 17 train batch 277/450: 4432/7200 mean loss: 0.0016034479485824704 score: 1.0
2021-08-08 05:29:27,467 | train | INFO | Epoch 17 train batch 278/450: 4448/7200 mean loss: 0.0014339901972562075 score: 0.9742647058823529
2021-08-08 05:29:28,247 | train | INFO | Epoch 17 train batch 279/450: 4464/7200 mean loss: 0.0012838093098253012 score: 1.0
2021-08-08 05:29:29,068 | train | INFO | Epoch 17 train batch 280/450: 4480/7200 mean loss: 0.001414588070474565 score: 1.0
2021-08-08 05:29:29,954 | train | INFO | Epoch 17 train batch 281/450: 4496/7200 mean loss: 0.0014747078530490398 score: 1.0
2021-08-08 05:29:30,860 | train | INFO | Epoch 17 train batch 282/450: 4512/7200 mean loss: 0.001506974920630455 score: 0.9774509803921569
2021-08-08 05:29:31,632 | train | INFO | Epoch 17 train batch 283/450: 4528/7200 mean loss: 0.001596652320586145 score: 1.0
2021-08-08 05:29:32,403 | train | INFO | Epoch 17 train batch 284/450: 4544/7200 mean loss: 0.0014762998325750232 score: 1.0
2021-08-08 05:29:33,184 | train | INFO | Epoch 17 train batch 285/450: 4560/7200 mean loss: 0.0014099706895649433 score: 0.966421568627451
2021-08-08 05:29:33,962 | train | INFO | Epoch 17 train batch 286/450: 4576/7200 mean loss: 0.0014020863454788923 score: 1.0
2021-08-08 05:29:34,826 | train | INFO | Epoch 17 train batch 287/450: 4592/7200 mean loss: 0.001451426767744124 score: 1.0
2021-08-08 05:29:35,639 | train | INFO | Epoch 17 train batch 288/450: 4608/7200 mean loss: 0.0016979327192530036 score: 1.0
2021-08-08 05:29:36,421 | train | INFO | Epoch 17 train batch 289/450: 4624/7200 mean loss: 0.0013348308857530355 score: 0.995798319327731
2021-08-08 05:29:37,196 | train | INFO | Epoch 17 train batch 290/450: 4640/7200 mean loss: 0.0014533576322719455 score: 1.0
2021-08-08 05:29:37,969 | train | INFO | Epoch 17 train batch 291/450: 4656/7200 mean loss: 0.0016344006871804595 score: 0.9963235294117647
2021-08-08 05:29:38,744 | train | INFO | Epoch 17 train batch 292/450: 4672/7200 mean loss: 0.0015682632802054286 score: 0.9963235294117647
2021-08-08 05:29:39,515 | train | INFO | Epoch 17 train batch 293/450: 4688/7200 mean loss: 0.0014486212749034166 score: 1.0
2021-08-08 05:29:40,341 | train | INFO | Epoch 17 train batch 294/450: 4704/7200 mean loss: 0.001622948213480413 score: 0.9852941176470589
2021-08-08 05:29:41,123 | train | INFO | Epoch 17 train batch 295/450: 4720/7200 mean loss: 0.0014221204910427332 score: 1.0
2021-08-08 05:29:42,022 | train | INFO | Epoch 17 train batch 296/450: 4736/7200 mean loss: 0.0012832622742280364 score: 0.9963235294117647
2021-08-08 05:29:42,800 | train | INFO | Epoch 17 train batch 297/450: 4752/7200 mean loss: 0.0015861840220168233 score: 1.0
2021-08-08 05:29:43,592 | train | INFO | Epoch 17 train batch 298/450: 4768/7200 mean loss: 0.0013922146754339337 score: 1.0
2021-08-08 05:29:44,406 | train | INFO | Epoch 17 train batch 299/450: 4784/7200 mean loss: 0.0015041560400277376 score: 1.0
2021-08-08 05:29:45,207 | train | INFO | Epoch 17 train batch 300/450: 4800/7200 mean loss: 0.0014374557649716735 score: 1.0
2021-08-08 05:29:45,985 | train | INFO | Epoch 17 train batch 301/450: 4816/7200 mean loss: 0.0014733863063156605 score: 1.0
2021-08-08 05:29:46,803 | train | INFO | Epoch 17 train batch 302/450: 4832/7200 mean loss: 0.0014488419983536005 score: 1.0
2021-08-08 05:29:47,575 | train | INFO | Epoch 17 train batch 303/450: 4848/7200 mean loss: 0.0013864277862012386 score: 1.0
2021-08-08 05:29:48,357 | train | INFO | Epoch 17 train batch 304/450: 4864/7200 mean loss: 0.0015240975189954042 score: 1.0
2021-08-08 05:29:49,217 | train | INFO | Epoch 17 train batch 305/450: 4880/7200 mean loss: 0.0014923140406608582 score: 1.0
2021-08-08 05:29:50,002 | train | INFO | Epoch 17 train batch 306/450: 4896/7200 mean loss: 0.001365272211842239 score: 1.0
2021-08-08 05:29:50,825 | train | INFO | Epoch 17 train batch 307/450: 4912/7200 mean loss: 0.0013464310904964805 score: 1.0
2021-08-08 05:29:51,603 | train | INFO | Epoch 17 train batch 308/450: 4928/7200 mean loss: 0.0017158789560198784 score: 1.0
2021-08-08 05:29:52,383 | train | INFO | Epoch 17 train batch 309/450: 4944/7200 mean loss: 0.0013612799812108278 score: 1.0
2021-08-08 05:29:53,211 | train | INFO | Epoch 17 train batch 310/450: 4960/7200 mean loss: 0.0016641075490042567 score: 0.9806372549019609
2021-08-08 05:29:53,986 | train | INFO | Epoch 17 train batch 311/450: 4976/7200 mean loss: 0.0014288036618381739 score: 1.0
2021-08-08 05:29:54,757 | train | INFO | Epoch 17 train batch 312/450: 4992/7200 mean loss: 0.0013894131407141685 score: 1.0
2021-08-08 05:29:55,525 | train | INFO | Epoch 17 train batch 313/450: 5008/7200 mean loss: 0.0013110339641571045 score: 1.0
2021-08-08 05:29:56,298 | train | INFO | Epoch 17 train batch 314/450: 5024/7200 mean loss: 0.0014265085337683558 score: 0.996078431372549
2021-08-08 05:29:57,070 | train | INFO | Epoch 17 train batch 315/450: 5040/7200 mean loss: 0.0013087098486721516 score: 1.0
2021-08-08 05:29:57,845 | train | INFO | Epoch 17 train batch 316/450: 5056/7200 mean loss: 0.0013112854212522507 score: 0.996078431372549
2021-08-08 05:29:58,618 | train | INFO | Epoch 17 train batch 317/450: 5072/7200 mean loss: 0.00127824314404279 score: 1.0
2021-08-08 05:29:59,387 | train | INFO | Epoch 17 train batch 318/450: 5088/7200 mean loss: 0.00159196846652776 score: 0.9887254901960785
2021-08-08 05:30:00,163 | train | INFO | Epoch 17 train batch 319/450: 5104/7200 mean loss: 0.0015625797677785158 score: 0.9963235294117647
2021-08-08 05:30:00,942 | train | INFO | Epoch 17 train batch 320/450: 5120/7200 mean loss: 0.001706557348370552 score: 1.0
2021-08-08 05:30:01,723 | train | INFO | Epoch 17 train batch 321/450: 5136/7200 mean loss: 0.0018038301495835185 score: 0.995798319327731
2021-08-08 05:30:02,506 | train | INFO | Epoch 17 train batch 322/450: 5152/7200 mean loss: 0.0016457414021715522 score: 1.0
